{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# (강의) IMDB 자료 살펴보기, 지도학습의 개념\n",
        "\n",
        "신록예찬  \n",
        "2024-08-28\n",
        "\n",
        "# 1. 상상 혹은 경험\n",
        "\n",
        "`-` 데이터 분석을 하고 싶음.\n",
        "\n",
        "-   할줄아는것이 별로 없음.\n",
        "-   이론적으로 처음부터 익히기엔 각이 안나옴. (엄두가 나지 않는다.)\n",
        "-   블로그등을 보면서 데이터 분석하는 코드를 독학하기로함.\n",
        "-   전략: (1) 블로그의 코드를 돌려본다. (2) 블로그의 코드를 이해한다.\n",
        "    (이론을 이해하는게 아님. 코드를 이해하는 것임) (3) 블로그의 코드에서\n",
        "    데이터 부분만 내가 사용할 데이터로 바꿔친다. (4) 돌려서 결과를\n",
        "    제출한다.\n",
        "\n",
        "`-` 어려울 것이라 예상하는 점\n",
        "\n",
        "-   1.  안돌아갈걸?\n",
        "-   1.  이해가 안될걸?\n",
        "-   1.  이게 진짜 어려움..\n",
        "-   1.  돌아는 가는데 결과가 안좋을거에요.\n",
        "\n",
        "`-` 소망:\n",
        "\n",
        "-   (1)-(4) 의 과정이 매끄럽게 되었으면..\n",
        "-   이 과정이 빠르게 반복해서 여러코드를 최대한 빨리 정리할 수 있으면..\n",
        "-   그래서 비슷한 분석을 할때 참고할 거리가 많았으면..\n",
        "-   나중에는 원리를 알아 코드를 많이 참고하지 않고도 내가 어느정도\n",
        "    분석할 수 있으면..\n",
        "\n",
        "`-` 마음가짐: 컨셉을 잘 잡아야함.\n",
        "\n",
        "-   나는 어떠한 코드도 짤 수 있는 사람이다. X\n",
        "-   나는 어떠한 코드도 이해할 수 있는 사람이다. X\n",
        "-   나는 어떠한 코드도 베낄 수 있는 (활용할 수 있는) 사람이다. O\n",
        "\n",
        "> 느리지만 정확하게 해결하는것은 옳지 않음. 모든 분석은 시간싸움임.\n",
        "> 느려지는 순간 이미 뒤쳐진다. (마라톤 하는게 아님. 100m달리기임.)\n",
        "\n",
        "`-` 전 컴공과 교수가 아니에요. (그럴만한 실력도 없어요) 그냥 먹고살기\n",
        "위해서 눈치껏 코딩할 뿐입니다.\n",
        "\n",
        "-   그래서 강의노트도 무식하게 만들예정..\n",
        "-   이전에는 예쁘게 만든 편임.. (빅데이터혁신공유대학 프로그램..\n",
        "    서해안권 어쩌고..)\n",
        "\n",
        "# 2. 감성분석 공부재료\n",
        "\n",
        "`-` 좋은 공부재료(데이터+분석방법)를 선정하는 것도 사실 어려워요.\n",
        "\n",
        "-   수업시간에 하는 것은 다 좋은 예제에요. 고르고 고른 자료이며\n",
        "    분석방법도 중요한 것들이에요 (성능이 좋거나, 최신 유행이거나,\n",
        "    고전적이라서 상식 같은 알고리즘)\n",
        "-   그 외에는 몇개의 사이트를 파놓고 공부하는게 좋아요.\n",
        "-   우선 추천하는 사이트는\n",
        "    <https://huggingface.co/docs/transformers/index> 입니당.\n",
        "\n",
        "`-` ref:\n",
        "<https://huggingface.co/docs/transformers/tasks/sequence_classification>\n",
        "\n",
        "-   ref는 reference의 약자.\n",
        "-   해당 사이트를 참고하였다는 의미.\n",
        "-   원 작가에 대한 예의 + 나중에 공부할때도 좋음. 숙제할때도 참고하세요.\n",
        "-   없어보이는 행동이 아님. 더 빛나게 만들어줌.\n",
        "\n",
        "`-` 허깅페이스\n",
        "\n",
        "-   대부분의 경진대회 분석은 (1) Tabular 를 분석하는 경우 (2) Tabular\n",
        "    데이터가 아닌 자료를 분석하는 경우 로 나눌 수 있음.\n",
        "-   Tabular 데이터를 분석하는 여러가지 전통적인 방법이 있으나 우승하려면\n",
        "    거의 무조건 Xgboost, LightGBM, Catboost 중 하나를 써야함.\n",
        "    의사결정기반의 모형을 사용해야함. (의사결정나무가 거의 크랙임\n",
        "    회귀분석, 로지스틱, SVM 등등 다 필요없음)\n",
        "-   Tabular 데이터가 아닌 자료를 분석할시에는 여러가지 방법이 있지만\n",
        "    최근에는 transformer 기반의 모형이 크랙임.\n",
        "-   허깅페이스는 transformer 기반의 다양한 모델을 다운로드 하고 사용하기\n",
        "    용이하게 도와주는 hub 임.\n",
        "\n",
        "# 3. Install\n",
        "\n",
        "`-` Before you begin, make sure you have all the necessary libraries\n",
        "installed:\n",
        "\n",
        "-   아래가 깔려있는지 확인하라는 의미\n",
        "\n",
        "pip install transformers datasets evaluate accelerate\n",
        "\n",
        "`-` 저게 뭐하는 코드냐?\n",
        "\n",
        "-   GPT에게 물어보세요 (분이 풀릴때까지)\n",
        "\n",
        "> 질문: `pip install transformers datasets evaluate accelerate` 는\n",
        "> 뭐하는 코드야?\n",
        "\n",
        "> 질문: 코랩에서 저 명령어를 실행하면 어디에 설치되는거야? 내 윈도우\n",
        "> 컴퓨터에 설치되는거야?\n",
        "\n",
        "> 질문: 그럼 코랩을 끄면 다시 설치해야해?\n",
        "\n",
        "# 4. Imports"
      ],
      "id": "db55d2f9-2460-42fa-8f13-450e503aae0c"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset"
      ],
      "id": "cell-18"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   `from datasets import load_dataset` 의 의미를 모른다면 GPT에게\n",
        "    물어보세요. (`from datasets import load_dataset`의 의미는 뭐지??\n",
        "    나는 \\`import numpy\\`\\` 이런식으로만 써봤는데??)\n",
        "-   `import dataset` 하면 안되나??\n",
        "\n",
        "# 5. `load_dataset` 함수의 사용\n",
        "\n",
        "`-` `load_dataset` 이 뭐지??"
      ],
      "id": "2262f56e-146a-487b-8ade-80c0a7db3117"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "function"
            ]
          }
        }
      ],
      "source": [
        "type(load_dataset) # 함수"
      ],
      "id": "cell-22"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "{'__call__'}"
            ]
          }
        }
      ],
      "source": [
        "set(dir(load_dataset)) & {'__call__'}"
      ],
      "id": "cell-23"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   대충 `load_dataset(??)`와 같은 방식으로 쓰면 되겠군\n",
        "\n",
        "`-` `load_dataset` 는 어떻게 쓰지?\n",
        "\n",
        "``` python\n",
        "load_dataset(\n",
        "    path: str,\n",
        "    name: Optional[str] = None,\n",
        "    data_dir: Optional[str] = None,\n",
        "    data_files: Union[str, Sequence[str], Mapping[str, Union[str, Sequence[str]]], NoneType] = None,\n",
        "    split: Union[str, datasets.splits.Split, NoneType] = None,\n",
        "    cache_dir: Optional[str] = None,\n",
        "    features: Optional[datasets.features.features.Features] = None,\n",
        "    download_config: Optional[datasets.download.download_config.DownloadConfig] = None,\n",
        "    download_mode: Union[datasets.download.download_manager.DownloadMode, str, NoneType] = None,\n",
        "    verification_mode: Union[datasets.utils.info_utils.VerificationMode, str, NoneType] = None,\n",
        "    ignore_verifications='deprecated',\n",
        "    keep_in_memory: Optional[bool] = None,\n",
        "    save_infos: bool = False,\n",
        "    revision: Union[str, datasets.utils.version.Version, NoneType] = None,\n",
        "    token: Union[bool, str, NoneType] = None,\n",
        "    use_auth_token='deprecated',\n",
        "    task='deprecated',\n",
        "    streaming: bool = False,\n",
        "    num_proc: Optional[int] = None,\n",
        "    storage_options: Optional[Dict] = None,\n",
        "    trust_remote_code: bool = None,\n",
        "    **config_kwargs,\n",
        ") -> Union[datasets.dataset_dict.DatasetDict, datasets.arrow_dataset.Dataset, datasets.dataset_dict.IterableDatasetDict, datasets.iterable_dataset.IterableDataset]\n",
        "```\n",
        "\n",
        "-   하나의 위치인자를 가지고있음. 따라서 `load_dataset()` 와 같은\n",
        "    형식으로 쓸수는 없겠어. –\\> 확인\n",
        "-   타입힌트를 보니 `load_dataset(\"asdf\")`에는 와 같이 반드시 하나의\n",
        "    위치인자를 문자열로 전달해야겠어. (나머지는 알아서 디폴트값으로\n",
        "    되겠지)\n",
        "-   전달된 문자열은 함수내의 `path`라는 변수에 저장되겠지?\n",
        "-   난 `path`에 뭘 써야하지? –\\> 생각1: `load_dataset`은 아마 데이터를\n",
        "    불러오는 함수일텐데, 이 데이터가 저장되는 path인가? // 생각2: 아니면\n",
        "    불러올 데이터가 저장된 `path`인가? –\\> 도움말 참고 or GPT\n",
        "\n",
        "> 질문: load_dataset을 사용하는 방법은?? path의 의미?"
      ],
      "id": "185453cd-ca26-48e2-b002-0df8a1f69eb6"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "imdb = load_dataset(\"imdb\")"
      ],
      "id": "cell-29"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. `imdb` 탐색\n",
        "\n",
        "## A. `imdb`\n",
        "\n",
        "`-` 그럼 이제 `imdb` 는 뭐지??\n",
        "\n",
        "-   아마 데이터가 있겠죠?\n",
        "-   그런데 그걸 어떻게 보죠??\n",
        "-   되게 궁금한데 이거 홈페이지에도 데이터 살펴보는 방법 없어요\n",
        "\n",
        "`-` 뜯어보자.."
      ],
      "id": "f763531f-8afe-471f-9597-d007a5f391a6"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    unsupervised: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 50000\n",
              "    })\n",
              "})"
            ]
          }
        }
      ],
      "source": [
        "imdb"
      ],
      "id": "cell-34"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   딕셔너리 아니야?\n",
        "\n",
        "`-` 딕셔너리는 아님"
      ],
      "id": "d1cb1e88-ee05-4946-9b2f-01b8c831512e"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "datasets.dataset_dict.DatasetDict"
            ]
          }
        }
      ],
      "source": [
        "type(imdb)"
      ],
      "id": "cell-37"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 그런데 거의 딕셔너리처럼 쓰라는거 같음"
      ],
      "id": "66f746b0-b555-4187-8b1f-6a4c692dc961"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "dict_keys(['train', 'test', 'unsupervised'])"
            ]
          }
        }
      ],
      "source": [
        "imdb.keys()"
      ],
      "id": "cell-39"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 25000\n",
              "})"
            ]
          }
        }
      ],
      "source": [
        "imdb['train']"
      ],
      "id": "cell-40"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 25000\n",
              "})"
            ]
          }
        }
      ],
      "source": [
        "imdb['test']"
      ],
      "id": "cell-41"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 50000\n",
              "})"
            ]
          }
        }
      ],
      "source": [
        "imdb['unsupervised']"
      ],
      "id": "cell-42"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` `imdb`는 딕셔너리 같은것이고 `imdb['train']` 와 같은 명령어로\n",
        "세부항목에 접근가능함. 즉 아래의 구조임.\n",
        "\n",
        "-   `imdb['train']` $\\subset$ `imdb`\n",
        "-   `imdb['test']` $\\subset$ `imdb`\n",
        "-   `imdb['unsupervised']` $\\subset$ `imdb`\n",
        "\n",
        "## B. `imdb['train']`\n",
        "\n",
        "`-` 그럼 이제 `imdb['train']` 가 뭔지 볼까?"
      ],
      "id": "22af87df-57a1-436d-9bef-8360b0d1b9e6"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 25000\n",
              "})"
            ]
          }
        }
      ],
      "source": [
        "imdb['train']"
      ],
      "id": "cell-46"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   이것도 혹시 딕셔너리 비슷한것??"
      ],
      "id": "87d53d2c-d7f6-4af0-b9af-299713d1c44d"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "imdb['train'].keys()"
      ],
      "id": "cell-48"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "imdb['train']['features']"
      ],
      "id": "cell-49"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   딕셔너리 처럼 잘 안되네..\n",
        "\n",
        "`-` 쓸만한게 있을까? `__getitem__` 이 있음.. –\\> 이런거 리스트에도\n",
        "있었는데"
      ],
      "id": "2cfe1818-2fcd-47c6-aff4-5238ada5c293"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "{'_TF_DATASET_REFS',\n",
              " '__class__',\n",
              " '__del__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__enter__',\n",
              " '__eq__',\n",
              " '__exit__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__getitems__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_build_local_temp_path',\n",
              " '_check_index_is_initialized',\n",
              " '_data',\n",
              " '_estimate_nbytes',\n",
              " '_fingerprint',\n",
              " '_format_columns',\n",
              " '_format_kwargs',\n",
              " '_format_type',\n",
              " '_generate_tables_from_cache_file',\n",
              " '_generate_tables_from_shards',\n",
              " '_get_cache_file_path',\n",
              " '_get_output_signature',\n",
              " '_getitem',\n",
              " '_indexes',\n",
              " '_indices',\n",
              " '_info',\n",
              " '_map_single',\n",
              " '_new_dataset_with_indices',\n",
              " '_output_all_columns',\n",
              " '_push_parquet_shards_to_hub',\n",
              " '_save_to_disk_single',\n",
              " '_select_contiguous',\n",
              " '_select_with_indices_mapping',\n",
              " '_split',\n",
              " 'add_column',\n",
              " 'add_elasticsearch_index',\n",
              " 'add_faiss_index',\n",
              " 'add_faiss_index_from_external_arrays',\n",
              " 'add_item',\n",
              " 'align_labels_with_mapping',\n",
              " 'builder_name',\n",
              " 'cache_files',\n",
              " 'cast',\n",
              " 'cast_column',\n",
              " 'citation',\n",
              " 'class_encode_column',\n",
              " 'cleanup_cache_files',\n",
              " 'column_names',\n",
              " 'config_name',\n",
              " 'data',\n",
              " 'dataset_size',\n",
              " 'description',\n",
              " 'download_checksums',\n",
              " 'download_size',\n",
              " 'drop_index',\n",
              " 'export',\n",
              " 'features',\n",
              " 'filter',\n",
              " 'flatten',\n",
              " 'flatten_indices',\n",
              " 'format',\n",
              " 'formatted_as',\n",
              " 'from_buffer',\n",
              " 'from_csv',\n",
              " 'from_dict',\n",
              " 'from_file',\n",
              " 'from_generator',\n",
              " 'from_json',\n",
              " 'from_list',\n",
              " 'from_pandas',\n",
              " 'from_parquet',\n",
              " 'from_polars',\n",
              " 'from_spark',\n",
              " 'from_sql',\n",
              " 'from_text',\n",
              " 'get_index',\n",
              " 'get_nearest_examples',\n",
              " 'get_nearest_examples_batch',\n",
              " 'homepage',\n",
              " 'info',\n",
              " 'is_index_initialized',\n",
              " 'iter',\n",
              " 'license',\n",
              " 'list_indexes',\n",
              " 'load_elasticsearch_index',\n",
              " 'load_faiss_index',\n",
              " 'load_from_disk',\n",
              " 'map',\n",
              " 'num_columns',\n",
              " 'num_rows',\n",
              " 'prepare_for_task',\n",
              " 'push_to_hub',\n",
              " 'remove_columns',\n",
              " 'rename_column',\n",
              " 'rename_columns',\n",
              " 'reset_format',\n",
              " 'save_faiss_index',\n",
              " 'save_to_disk',\n",
              " 'search',\n",
              " 'search_batch',\n",
              " 'select',\n",
              " 'select_columns',\n",
              " 'set_format',\n",
              " 'set_transform',\n",
              " 'shape',\n",
              " 'shard',\n",
              " 'shuffle',\n",
              " 'size_in_bytes',\n",
              " 'skip',\n",
              " 'sort',\n",
              " 'split',\n",
              " 'supervised_keys',\n",
              " 'take',\n",
              " 'task_templates',\n",
              " 'to_csv',\n",
              " 'to_dict',\n",
              " 'to_iterable_dataset',\n",
              " 'to_json',\n",
              " 'to_list',\n",
              " 'to_pandas',\n",
              " 'to_parquet',\n",
              " 'to_polars',\n",
              " 'to_sql',\n",
              " 'to_tf_dataset',\n",
              " 'train_test_split',\n",
              " 'unique',\n",
              " 'version',\n",
              " 'with_format',\n",
              " 'with_transform'}"
            ]
          }
        }
      ],
      "source": [
        "set(dir(imdb['train'])) # get_item 가지고 있넹.. "
      ],
      "id": "cell-52"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 리스트처럼 써볼까?"
      ],
      "id": "37af6fab-f740-4239-a67c-8907cdad323c"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "{'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n",
              " 'label': 0}"
            ]
          }
        }
      ],
      "source": [
        "imdb['train'][0]"
      ],
      "id": "cell-54"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "{'text': '\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn\\'t matter what one\\'s political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn\\'t true. I\\'ve seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don\\'t exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we\\'re treated to the site of Vincent Gallo\\'s throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won\\'t see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women\\'s bodies.',\n",
              " 'label': 0}"
            ]
          }
        }
      ],
      "source": [
        "imdb['train'][1]"
      ],
      "id": "cell-55"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "{'text': ['I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n",
              "  '\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn\\'t matter what one\\'s political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn\\'t true. I\\'ve seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don\\'t exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we\\'re treated to the site of Vincent Gallo\\'s throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won\\'t see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women\\'s bodies.'],\n",
              " 'label': [0, 0]}"
            ]
          }
        }
      ],
      "source": [
        "imdb['train'][:2]"
      ],
      "id": "cell-56"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "{'text': 'The story centers around Barry McKenzie who must go to England if he wishes to claim his inheritance. Being about the grossest Aussie shearer ever to set foot outside this great Nation of ours there is something of a culture clash and much fun and games ensue. The songs of Barry McKenzie(Barry Crocker) are highlights.',\n",
              " 'label': 1}"
            ]
          }
        }
      ],
      "source": [
        "imdb['train'][-1]"
      ],
      "id": "cell-57"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` text와 label의 의미는 뭐지??"
      ],
      "id": "e3e9d68e-91bd-4101-bcfe-79bd35d966f3"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "dict"
            ]
          }
        }
      ],
      "source": [
        "type(imdb['train'][1])"
      ],
      "id": "cell-59"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn't matter what one's political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn't true. I've seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don't exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we're treated to the site of Vincent Gallo's throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won't see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women's bodies."
          ]
        }
      ],
      "source": [
        "print(imdb['train'][1]['text'])"
      ],
      "id": "cell-60"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> 영어: “I Am Curious: Yellow” is a risible and pretentious steaming\n",
        "> pile. It doesn’t matter what one’s political views are because this\n",
        "> film can hardly be taken seriously on any level. As for the claim that\n",
        "> frontal male nudity is an automatic NC-17, that isn’t true. I’ve seen\n",
        "> R-rated films with male nudity. Granted, they only offer some fleeting\n",
        "> views, but where are the R-rated films with gaping vulvas and flapping\n",
        "> labia? Nowhere, because they don’t exist. The same goes for those\n",
        "> crappy cable shows: schlongs swinging in the breeze but not a clitoris\n",
        "> in sight. And those pretentious indie movies like The Brown Bunny, in\n",
        "> which we’re treated to the site of Vincent Gallo’s throbbing johnson,\n",
        "> but not a trace of pink visible on Chloe Sevigny. Before crying (or\n",
        "> implying) “double-standard” in matters of nudity, the mentally obtuse\n",
        "> should take into account one unavoidably obvious anatomical difference\n",
        "> between men and women: there are no genitals on display when actresses\n",
        "> appears nude, and the same cannot be said for a man. In fact, you\n",
        "> generally won’t see female genitals in an American film in anything\n",
        "> short of porn or explicit erotica. This alleged double-standard is\n",
        "> less a double standard than an admittedly depressing ability to come\n",
        "> to terms culturally with the insides of women’s bodies.\n",
        "\n",
        "> 한글: 영화 I Am Curious: Yellow는 우스꽝스럽고 허세 가득한 쓰레기일\n",
        "> 뿐입니다. 정치적 견해가 무엇이든 상관없이, 이 영화는 어떤 수준에서도\n",
        "> 진지하게 받아들일 수 없습니다. 남성의 전면 누드가 자동으로 NC-17\n",
        "> 등급을 받는다는 주장에 대해서는, 그것은 사실이 아닙니다. 저는 남성\n",
        "> 누드가 나오는 R등급 영화들을 본 적이 있습니다. 물론, 잠깐 등장하는\n",
        "> 장면일 뿐이었지만, 그럼 여성의 외음부가 드러나는 R등급 영화는 어디\n",
        "> 있나요? 그런 영화는 존재하지 않습니다. 같은 논리가 케이블 TV 쇼에도\n",
        "> 적용됩니다. 남성의 성기가 흔들리는 장면은 나오지만, 클리토리스는\n",
        "> 보이지 않습니다. 그리고 The Brown Bunny 같은 허세 가득한 독립\n",
        "> 영화에서도, 빈센트 갈로의 성기가 등장하는 반면, 클로이 세비니의 여성\n",
        "> 성기는 보이지 않습니다. 누드에 있어서 ’이중잣대’라고 우는 사람들은,\n",
        "> 남성과 여성 간의 불가피한 해부학적 차이를 고려해야 합니다. 여배우가\n",
        "> 누드로 등장할 때는 성기가 드러나지 않지만, 남성의 경우 그렇지 않다는\n",
        "> 점입니다. 사실, 여성의 성기가 나오는 미국 영화는 포르노나 노골적인\n",
        "> 에로 영화를 제외하면 거의 없습니다. 이 이중잣대는 문화적으로 여성의\n",
        "> 신체 내부를 다루는 방식에 대한 문제일 뿐, 진정한 이중잣대라고 할 수는\n",
        "> 없습니다.\n",
        "\n",
        "-   영화평인듯..\n",
        "-   겁나 뭐라함\n",
        "\n",
        "`-` 이 텍스트에 대한 라벨은 0"
      ],
      "id": "afd9edcc-45cb-4b3f-98f9-88a6423d9f0d"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "0"
            ]
          }
        }
      ],
      "source": [
        "imdb['train'][1]['label']"
      ],
      "id": "cell-64"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` `imdb['train'][2]` 도 살펴보자. $\\to$ 부정적으로 평가하고 라벨이 0"
      ],
      "id": "8bd312d5-7da2-4391-ae18-49c8d667eead"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "{'text': \"If only to avoid making this type of film in the future. This film is interesting as an experiment but tells no cogent story.<br /><br />One might feel virtuous for sitting thru it because it touches on so many IMPORTANT issues but it does so without any discernable motive. The viewer comes away with no new perspectives (unless one comes up with one while one's mind wanders, as it will invariably do during this pointless film).<br /><br />One might better spend one's time staring out a window at a tree growing.<br /><br />\",\n",
              " 'label': 0}"
            ]
          }
        }
      ],
      "source": [
        "imdb['train'][2]"
      ],
      "id": "cell-66"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` `imdb['train'][-2]` 도 살펴보자. $\\to$ 긍정적으로 평가하고 라벨이 1"
      ],
      "id": "aa9c346b-cb06-4824-aec2-d0a1267bfb94"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "{'text': '\\'The Adventures Of Barry McKenzie\\' started life as a satirical comic strip in \\'Private Eye\\', written by Barry Humphries and based on an idea by Peter Cook. McKenzie ( \\'Bazza\\' to his friends ) is a lanky, loud, hat-wearing Australian whose two main interests in life are sex ( despite never having had any ) and Fosters lager. In 1972, he found his way to the big screen for the first of two outings. It must have been tempting for Humphries to cast himself as \\'Bazza\\', but he wisely left the job to Barry Crocker ( later to sing the theme to the television soap opera \\'Neighbours\\'! ). Humphries instead played multiple roles in true Peter Sellers fashion, most notably Bazza\\'s overbearing Aunt \\'Edna Everage\\' ( this was before she became a Dame ).<br /><br />You know this is not going to be \\'The Importance Of Being Ernest\\' when its censorship classification N.P.A. stands for \\'No Poofters Allowed\\'. Pom-hating Bazza is told by a Sydney solicitor that in order to inherit a share in his father\\'s will he must go to England to absorb British culture. With Aunt Edna in tow, he catches a Quantas flight to Hong Kong, and then on to London. An over-efficient customs officer makes Bazza pay import duties on everything he bought over there, including a suitcase full of \\'tubes of Fosters lager\\'. As he puts it: \"when it comes to fleecing you, the Poms have got the edge on the gyppos!\". A crafty taxi driver ( Bernard Spear ) maximises the fare by taking Bazza and Edna first to Stonehenge, then Scotland. The streets of London are filthy, and their hotel is a hovel run by a seedy landlord ( Spike Milligan ) who makes Bazza put pound notes in the electricity meter every twenty minutes. There is some good news for our hero though; he meets up with other Aussies in Earls Court, and Fosters is on sale in British pubs.<br /><br />What happens next is a series of comical escapades that take Bazza from starring in his own cigarette commercial, putting curry down his pants in the belief it is some form of aphrodisiac, a bizarre encounter with Dennis Price as an upper-class pervert who loves being spanked while wearing a schoolboy\\'s uniform, a Young Conservative dance in Rickmansworth to a charity rock concert where his song about \\'chundering\\' ( vomiting ) almost makes him an international star, and finally to the B.B.C. T.V. Centre where he pulls his pants down on a live talk-show hosted by the thinking man\\'s crumpet herself, Joan Bakewell. A fire breaks out, and Bazza\\'s friends come to the rescue - downing cans of Fosters, they urinate on the flames en masse.<br /><br />This is a far cry from Bruce Beresford\\'s later works - \\'Breaker Morant\\' and \\'Driving Miss Daisy\\'. On release, it was savaged by critics for being too \\'vulgar\\'. Well, yes, it is, but it is also great non-P.C. fun. \\'Bazza\\' is a disgusting creation, but his zest for life is unmistakable, you cannot help but like the guy. His various euphemisms for urinating ( \\'point Percy at the porcelain\\' ) and vomiting ( \\'the Technicolour yawn\\' ) have passed into the English language without a lot of people knowing where they came from. Other guest stars include Dick Bentley ( as a detective who chases Bazza everywhere ), Peter Cook, Julie Covington ( later to star in \\'Rock Follies\\' ), and even future arts presenter Russell Davies.<br /><br />A sequel - the wonderfully-named \\'Barry McKenzie Holds His Own - came out two years later. At its premiere, Humphries took the opportunity to blast the critics who had savaged the first film. Good for him.<br /><br />What must have been of greater concern to him, though, was the release of \\'Crocodile Dundee\\' in 1985. It also featured a lanky, hat-wearing Aussie struggling to come to terms with a foreign culture. And made tonnes more money.<br /><br />The song on the end credits ( performed by Snacka Fitzgibbon ) is magnificent. You have a love a lyric that includes the line: \"If you want to send your sister in a frenzy, introduce her to Barry McKenzie!\". Time to end this review. I have to go the dunny to shake hands with the unemployed...',\n",
              " 'label': 1}"
            ]
          }
        }
      ],
      "source": [
        "imdb['train'][-2]"
      ],
      "id": "cell-68"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 요약: `imdb['train']` 에는 여러개의 영화평이 있고, 각각 긍정평가와\n",
        "부정평가를 담고 있다.\n",
        "\n",
        "-   몇개의 영화평??"
      ],
      "id": "2bdc5dd7-3b32-4cd6-baef-29171c15a2de"
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "25000"
            ]
          }
        }
      ],
      "source": [
        "len(imdb['train']) # 어케 len을 쓸 생각을 했어?? 어지간하면 리스트 비슷한건 len이 있더라고요.."
      ],
      "id": "cell-71"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "{'text': 'The story centers around Barry McKenzie who must go to England if he wishes to claim his inheritance. Being about the grossest Aussie shearer ever to set foot outside this great Nation of ours there is something of a culture clash and much fun and games ensue. The songs of Barry McKenzie(Barry Crocker) are highlights.',\n",
              " 'label': 1}"
            ]
          }
        }
      ],
      "source": [
        "imdb['train'][-1]"
      ],
      "id": "cell-72"
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "{'text': 'The story centers around Barry McKenzie who must go to England if he wishes to claim his inheritance. Being about the grossest Aussie shearer ever to set foot outside this great Nation of ours there is something of a culture clash and much fun and games ensue. The songs of Barry McKenzie(Barry Crocker) are highlights.',\n",
              " 'label': 1}"
            ]
          }
        }
      ],
      "source": [
        "imdb['train'][24999]"
      ],
      "id": "cell-73"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## C. `imdb['test']`\n",
        "\n",
        "`-` `imdb[\"train\"]` 과 비슷함"
      ],
      "id": "ce1b5205-abe8-497c-a18a-4a05d4809a79"
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "{'text': 'I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I really did, but it is to good TV sci-fi as Babylon 5 is to Star Trek (the original). Silly prosthetics, cheap cardboard sets, stilted dialogues, CG that doesn\\'t match the background, and painfully one-dimensional characters cannot be overcome with a \\'sci-fi\\' setting. (I\\'m sure there are those of you out there who think Babylon 5 is good sci-fi TV. It\\'s not. It\\'s clichéd and uninspiring.) While US viewers might like emotion and character development, sci-fi is a genre that does not take itself seriously (cf. Star Trek). It may treat important issues, yet not as a serious philosophy. It\\'s really difficult to care about the characters here as they are not simply foolish, just missing a spark of life. Their actions and reactions are wooden and predictable, often painful to watch. The makers of Earth KNOW it\\'s rubbish as they have to always say \"Gene Roddenberry\\'s Earth...\" otherwise people would not continue watching. Roddenberry\\'s ashes must be turning in their orbit as this dull, cheap, poorly edited (watching it without advert breaks really brings this home) trudging Trabant of a show lumbers into space. Spoiler. So, kill off a main character. And then bring him back as another actor. Jeeez! Dallas all over again.',\n",
              " 'label': 0}"
            ]
          }
        }
      ],
      "source": [
        "imdb[\"test\"][0]"
      ],
      "id": "cell-76"
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "25000"
            ]
          }
        }
      ],
      "source": [
        "len(imdb[\"test\"])"
      ],
      "id": "cell-77"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## D. `imdb['unsupervised']`\n",
        "\n",
        "`-` 대충 이러한 구조임"
      ],
      "id": "1d4248c2-f4f4-46e6-85ac-baba79c660c9"
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    unsupervised: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 50000\n",
              "    })\n",
              "})"
            ]
          }
        }
      ],
      "source": [
        "imdb"
      ],
      "id": "cell-80"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 느낌적으로 `imdb['unsupervised']` 는.. 두개의 합집합이 아닐까?\n",
        "(아니야..)"
      ],
      "id": "87c9a728-6442-4f11-828a-8ab2dd9b70da"
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "{'text': 'This is just a precious little diamond. The play, the script are excellent. I cant compare this movie with anything else, maybe except the movie \"Leon\" wonderfully played by Jean Reno and Natalie Portman. But... What can I say about this one? This is the best movie Anne Parillaud has ever played in (See please \"Frankie Starlight\", she\\'s speaking English there) to see what I mean. The story of young punk girl Nikita, taken into the depraved world of the secret government forces has been exceptionally over used by Americans. Never mind the \"Point of no return\" and especially the \"La femme Nikita\" TV series. They cannot compare the original believe me! Trash these videos. Buy this one, do not rent it, BUY it. BTW beware of the subtitles of the LA company which \"translate\" the US release. What a disgrace! If you cant understand French, get a dubbed version. But you\\'ll regret later :)',\n",
              " 'label': -1}"
            ]
          }
        }
      ],
      "source": [
        "imdb['unsupervised'][0]"
      ],
      "id": "cell-82"
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "{-1}"
            ]
          }
        }
      ],
      "source": [
        "set([l['label'] for l in imdb['unsupervised']])"
      ],
      "id": "cell-83"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   일단 라벨은 -1 밖에 없넹.."
      ],
      "id": "c5fa4d08-4897-422f-bf11-e2692ebc154e"
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "{'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n",
              " 'label': 0}"
            ]
          }
        }
      ],
      "source": [
        "imdb['train'][0]"
      ],
      "id": "cell-85"
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "text0 = imdb['unsupervised'][0]['text']"
      ],
      "id": "cell-86"
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "0"
            ]
          }
        }
      ],
      "source": [
        "sum([text0 in l['text'] for l in imdb['train']])"
      ],
      "id": "cell-87"
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "0"
            ]
          }
        }
      ],
      "source": [
        "sum([text0 in l['text'] for l in imdb['test']])"
      ],
      "id": "cell-88"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## F. 정리\n",
        "\n",
        "`-` 요약:\n",
        "\n",
        "-   `imdb`는 각각 `imdb['train']`, `imdb['test']`,\n",
        "    `imdb['unsupervised']` 로 나누어져 있다.\n",
        "-   `imdb['train']`, `imdb['test']` 에는 각각 (text,label) 과 같은\n",
        "    형식의 정보가 있다. 여기에서 label은 0 혹은 1의 값을 가지는데 0은\n",
        "    부정, 1은 긍정을 나타낸다.\n",
        "-   `imdb['unsupervised']` 에도 각각 (text,label) 과 같은 형식의 정보가\n",
        "    있으나, 여기에서 label은 -1의 값만 있다. 이는 긍정 혹은 부정도\n",
        "    의미하지 않는듯 하다. 따라서 이것은 사실상 `imdb['unsupervised']`\n",
        "    에는 text 정보만 있고 그 text가 긍정평가인지 부정평가인지는 분류가\n",
        "    되어있지 않은 상태라고 볼 수 있다.\n",
        "\n",
        "`-` 외우세요: “train”, “test”, “unsupervised” 란 단어는 중요한 단어니까\n",
        "외우세여\n",
        "\n",
        "# 7. 지도학습 흐름\n",
        "\n",
        "## A. 기계학습/딥러닝의 과업\n",
        "\n",
        "`-` 왜 이렇게 데이터가 나누어져 있나?\n",
        "\n",
        "-   개념: 머신러닝에는 지도학습과 비지도학습이 있음.\n",
        "-   데이터 세트에서 `imdb['train']`, `imdb['test']` 은 지도학습 모델을\n",
        "    배우기 위한 예제데이터이고, `imdb['unsupervised']`는 비지도학습을\n",
        "    모델을 배우기 위한 예제데이터임.\n",
        "-   아무튼 지금 이 수업에서는 지도학습을 설명할 것이고 따라서\n",
        "    `imdb['train']`, `imdb['test']` 만 쓰겠음\n",
        "\n",
        "## B. 지도학습의 목표\n",
        "\n",
        "`-` 지도학습이란? (이 예제 한정해서 설명)\n",
        "\n",
        "-   자료가 “(텍스트,라벨)” 의 형태로 정리되어 있을 때, “텍스트”를\n",
        "    입력으로 주면 “라벨”을 출력해주는 함수 `f`를 찾는 일\n",
        "-   코드로 예를들어 설명하면 적당히 `f`이라는 이름의 함수가 존재하여\n",
        "    아래와 같은 동작이 가능해야함.\n",
        "\n",
        "``` python\n",
        "f(\"영화가 너무 재미없어요.\")\n",
        "> \"부정평가입니다\"\n",
        "\n",
        "f(\"영화 괜찮은데요??\")\n",
        "> \"긍정평가입니다\"\n",
        "\n",
        "f(\"배우들 연기 진짜 잘함. 영상미도 있음. 그런데 스토리가 망했네.\")\n",
        "> \"부정평가입니다\"\n",
        "```\n",
        "\n",
        "`-` 이러한 함수 `f` 을 우리가 잘 정의한다면 좋겠음. (가능한가?)\n",
        "\n",
        "`-` 대충 아래의 과정을 거친다고 생각하면 편리함\n",
        "\n",
        "> 정보(숫자,텍스트,이미지,…) $\\to$ 숫자 $\\to$ 계산 $\\to$ 계산된숫자\n",
        "> $\\to$ 정보\n",
        "\n",
        "`-` 예를들면 아래와 같은 방식이 가능"
      ],
      "id": "a01d687e-845e-42df-855e-461e6b6cae52"
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "긍정단어 = {'좋아', '재미있었음', '잘생김', '예뻐', '연기훌륭함'}\n",
        "부정단어 = {'지루해', '재미없었음', '비추천'}"
      ],
      "id": "cell-100"
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [],
      "source": [
        "text0 = '남주가 너무 잘생김 여주도 예뻐 영화가 중간에 조금 지루해 그래도 아무튼 재미있었음'"
      ],
      "id": "cell-101"
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "0.75"
            ]
          }
        }
      ],
      "source": [
        "긍정단어수 = sum([l in 긍정단어 for l in text0.split(' ')]) \n",
        "부정단어수 = sum([l in 부정단어 for l in text0.split(' ')]) \n",
        "긍정단어수/(긍정단어수+부정단어수) "
      ],
      "id": "cell-102"
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [],
      "source": [
        "def f(text):\n",
        "    긍정단어수 = sum([l in 긍정단어 for l in text.split(' ')]) \n",
        "    부정단어수 = sum([l in 부정단어 for l in text.split(' ')]) \n",
        "    결과 = 긍정단어수/(긍정단어수+부정단어수) \n",
        "    if 결과>0.5: \n",
        "        return 결과, \"긍정평가\"\n",
        "    else:\n",
        "        return 결과, \"부정평가\"\n"
      ],
      "id": "cell-103"
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "(0.75, '긍정평가')"
            ]
          }
        }
      ],
      "source": [
        "f('남주가 너무 잘생김 여주도 예뻐 영화가 중간에 조금 지루해 그래도 아무튼 재미있었음')"
      ],
      "id": "cell-104"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 그렇지만 당연히 위의 모델은 약점이 많음."
      ],
      "id": "f6ab70c7-ef75-4f0b-bc3f-91f80229ecbf"
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "(0.0, '부정평가')"
            ]
          }
        }
      ],
      "source": [
        "f('남주가 너무 잘생겼어 여주도 예쁨 영화가 중간에 조금 지루해 그래도 아무튼 괜찮았음')"
      ],
      "id": "cell-106"
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "(0.6666666666666666, '긍정평가')"
            ]
          }
        }
      ],
      "source": [
        "f('캐스팅 좋아 여주인공이 특히 예쁨 배우들 연기훌륭함 그렇지만 스토리때문에 나는 개인적으로 비추천')"
      ],
      "id": "cell-107"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 다행인점: 좋은 `f`를 만들기 위해서 고민할 필요 없음. (똑똑한사람들이\n",
        "다 만들어 놓음)\n",
        "\n",
        "-   옜날방식: `f`를 한땀한땀 설계. 초고수가 밤새 코딩해서 진짜 잘 맞추는\n",
        "    `f`를 한번에 제시.\n",
        "-   최근방식: `f`를 대충 설계. 거의 멍청이 `f`임. 그런데 데이터를 줄수록\n",
        "    `f`가 점점 똑똑해짐. 나중에는 다 맞춤. $\\to$ 인공지능?????\n",
        "\n",
        "## C. train/test 자료의 의미\n",
        "\n",
        "`-` 초고수가 `f`를 직접 설계하는 경우와는 다르게 컴퓨터가 데이터를 보고\n",
        "`f`를 알아서 수정할 경우 이상한 방식으로 수정할 수가 있음.\n",
        "\n",
        "-   어떻게 이런일이 가능할까?\n",
        "\n",
        "`-` 최규빈 교수의 착각\n",
        "\n",
        "-   상상: 나는 학생들에게 파이썬프로그래밍을 잘 강의하고 싶었다. 나는\n",
        "    학생들에게 다양한 문제를 풀어줬으며, 문제를 풀면서 학생들이 스스로\n",
        "    개념을 깨우치길 원했다. 나는 다양한 예시를 통하여 이해하는 것이\n",
        "    좋다고 생각했기 때문이다. 예시는 많을수록 좋다고 생각해서 한\n",
        "    학기동안 총 1000개의 문제를 풀어줬다. 기말고사는 풀어준 문제중에서\n",
        "    약 20문항을 샘플링하여 출제했다. 놀랍게도 학생들이 모두 만점을\n",
        "    받았으며 나는 아주 만족스러웠다. 한 학기 동안 고생한 보람이\n",
        "    있어보였다. 눈물이 흘렀다.\n",
        "-   질문: 저는 잘 평가한 걸까요? 학생들은 진짜 파이썬프로그래밍을 잘\n",
        "    이해했을까요? (학과 교수님들께 자랑해도 될까요??)\n",
        "-   이렇게 하고 싶지 않나요?: 1000개의 문제에서 샘플링하여 100% 출제하지\n",
        "    않고, 새로운 문항을 개발하여 학생들에게 준다면??\n",
        "-   요령있는 교수라면 이렇게 할거에요: 50000개의 문제세트가 있다고 가정.\n",
        "    수업시간에는 학생들에게 예시로 25000개정도의 문항만 풀이하며 설명.\n",
        "    기말고사에는 수업시간에 풀이하지 않은 25000의 문항을 출제함.\n",
        "-   만약에 학생들이 수업시간에 풀어준 25000개의 문제를 올바르게\n",
        "    이해했다면, 수업시간에 풀이하지 않은 문항 25000개 역시 잘 풀었을\n",
        "    것임.\n",
        "\n",
        "`-` 이 상황을 살짝 바꿔볼게요.\n",
        "\n",
        "-   상상: 나는 인공지능에게 “영화평가 텍스트를 주면 그것이 긍정평가인지\n",
        "    부정평가인지 판단하는 능력”을 잘 학습시키고 싶었다. 나는\n",
        "    인공지능에게 다양한 데이터를 제공했으며, 데이터를 보고 인공지능이\n",
        "    스스로 원리를 깨우치길 원했다. 데이터는 많을수록 좋다고 생각해서 약\n",
        "    50000개의 “(텍스트,라벨)” 쌍을 제공했다. 그리고 50000개의\n",
        "    “(텍스트,라벨)” 쌍에서 약 20문항을 샘플링하여 테스트했다. 놀랍게도\n",
        "    인공지능은 20문항을 모두 맞추었다. 나는 아주 만족스러웠다.\n",
        "-   질문: 저는 인공지능을 잘 학습시켰을까요?\n",
        "-   이렇게 하고 싶지 않나요?: 50000개의 데이터중, 25000개의\n",
        "    “(텍스트,라벨)”만 인공지능에게 제공하여 학습시킴. 그리고 나머지\n",
        "    25000개는 평가용으로 테스트해봄.\n",
        "-   만약에 인공지능이 진짜 영화평가 텍스트를 바탕으로 그것이\n",
        "    긍정평가인지 부정평가인지 판단하는 능력을 길렀다면? 내가 인공지능에\n",
        "    제공하지 않은 25000에 대하여서도 함수 `f`가 올바르게 동작해야함!\n",
        "\n",
        "`-` train data / test data\n",
        "\n",
        "-   train data 는 인공지능에게 학습용으로 미리 제공하는 데이터\n",
        "-   test data 는 인공지능이 진짜 잘 학습했는지 평가하기 위해 학습시\n",
        "    제공하지 않는 자료\n",
        "\n",
        "## D. train/val/test 자료의 의미\n",
        "\n",
        "`-` 학생입장에서 생각해본다면?\n",
        "\n",
        "-   소망: 내가 외우려고 한게 아니고 하도 공부하다보니까 문제가 외워졌음.\n",
        "    나도 그러기 싫음. 나도 내가 올바르게 공부했는지 체크하고 싶어.\n",
        "-   아이디어: 교수님이 풀어준 25000개중에서 15000개정도만 내가 풀이를\n",
        "    보면서 공부하고 나머지 10000개는 나 스스로 올바르게 공부했는지\n",
        "    체크하는 용도로 삼자.\n",
        "-   진행사항:\n",
        "    -   1일차: 15000: 50점, 10000: 30점\n",
        "    -   2일차: 15000: 90점, 10000: 85점\n",
        "    -   3일차: 15000: 100점, 10000: 80점 \\<– 이런 경험 없어요??\n",
        "-   판단: 이게 한 3일차 공부하다보니까 문제를 내가 너무 외운것같네?\n",
        "    오히려 2일차때의 느낌이 더 좋음. 그냥 2일차의 느낌으로 시험보러\n",
        "    가자.\n",
        "\n",
        "`-` 이럴경우 아래와 같이 상황이 정리된다.\n",
        "\n",
        "-   원래: 교수가 수업시간에 풀어준 25000문제 = 학생이 공부할 25000문제 =\n",
        "    train // 교수가 기말시험으로 제출한 25000문제 = test\n",
        "-   바뀐상황: 학생공부할 15000문제 = train / 학생자체test 10000문제 =\n",
        "    test // 교수가 기말시험으로 제출한 25000문제 = 찐 test\n",
        "\n",
        "`-` 이때 학생자체적으로 빼둔 test set을 validation set이라고 부른다\n",
        "따라서 아래와 같이 정리가능하다.\n",
        "\n",
        "-   train = 15000문제 = 학생이 스스로 공부\n",
        "-   validation = 10000문제 = 학생이 공부할때 사용하지 않음. 자가진단용.\n",
        "-   test = 25000문제 = 교수가 출제하는 시험\n",
        "\n",
        "`-` train/validation/test에 대한 용어는 엄밀하지 않게 사용되는 경우가\n",
        "많아 그때그때 상황에 따라 맞게 알아서 해석해야 한다.\n",
        "\n",
        "-   억지상황1: 교수가 시험보지 않음. 그런데 내가 스스로 공부하면서\n",
        "    체크하고 싶어서 1000개의 문제를 구하고 매일 800개를 학습하고 200개를\n",
        "    이용하여 검증함. 이 경우는 200개의 문항을 validation이라고 부르기도\n",
        "    하고 test라고 부르기도함. (엄밀하게는 validation이 맞지만,\n",
        "    외부데이터가 없으므로 val/test의 경계가 흐릿해지는 상황)\n",
        "-   억지상황2: 나혼자 1000개의 문항을 800/200으로 나누어 매일 공부하고\n",
        "    있었음. 이때 나는 200개의 문항을 test라고 부르기도 하고\n",
        "    validation이라고 부르기도함. 그런데 교수가 보고 갑자기 나보고 외부\n",
        "    코딩대회에 나가라고 했음. 이 경우 200개의 문항은 validation이 되고\n",
        "    외부코딩대회에서 출제된 문항이 test가 되는 것임.\n",
        "\n",
        "`-` 느낌: 아래의 느낌을 기억하는게 중요함.\n",
        "\n",
        "-   train: 학습에 사용하는 자료.\n",
        "-   validation: 학습에 사용하지 않는 자료. 왜 안써? 더 좋은 훈련을 위한\n",
        "    목적.\n",
        "-   test: 학습에 사용하지 않는 자료. 왜 안써? 올바르게 학습됨을 평가하기\n",
        "    위한 목적.\n",
        "\n",
        "> 헷갈리는 이유는 더 좋은 훈련을 위한 목적과 올바르게 학습됨을 폄가하기\n",
        "> 위한 목적이 무 자르듯이 구분되지 않기 때문\n",
        "\n",
        "`-` 이상한 분류법\n",
        "\n",
        "-   데이터를 보통2개로 나누면 train/test 로 3개로 나누면 train/val/test\n",
        "    라고 표현한다고 생각하면 편리함.\n",
        "-   딱 맞는 정의는 아님. 의미상 구분해야함.\n",
        "\n",
        "## E. 코딩 패턴\n",
        "\n",
        "`-` 학습을 위한 패턴1\n",
        "\n",
        "``` python\n",
        "## Step1: 데이터 정리 \n",
        "데이터 = 데이터읽기(???)\n",
        "train_data, test_data = 데이터분리함수(데이터)\n",
        "\n",
        "## Step2: 인공지능 생성\n",
        "인공지능 = 인공지능생성기()\n",
        "\n",
        "## Step3: 인공지능 학습 \n",
        "인공지능.학습(train_data)\n",
        "\n",
        "## Step4: 예측\n",
        "인공지능.예측(train_data) # train_data 풀기 \n",
        "인공지능.예측(val_data) # val_data 풀기 \n",
        "인공지능.예측(test_data) # test_data 풀기 \n",
        "인공지능.예측(기습질문) # 기습질문 풀기 \n",
        "```\n",
        "\n",
        "`-` 학습을 위한 패턴1\n",
        "\n",
        "`-` 전형적인 디자인 패턴"
      ],
      "id": "4c39bd99-ee78-43eb-a693-55a6d6312641"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "```Python\n",
        "데이터 = 데이터읽기()\n",
        "...\n",
        "정리된데이터 = ...\n",
        "\n",
        "인공지능 = 인공지능생성기(정리된데이터)\n",
        "\n",
        "인공지능.학습()\n",
        "인공지능.예측(새로운데이터)"
      ],
      "id": "cell-131"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 8. 토큰화\n",
        "\n",
        "`-`"
      ],
      "id": "6ae3a118-bd8d-4c05-8c30-b9413c443e2d"
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 토큰화할 문장\n",
        "text = \"Hugging Face is creating a tool that democratizes AI.\"\n",
        "\n",
        "# 텍스트를 토큰으로 변환\n",
        "tokens = tokenizer.tokenize(text)\n",
        "print(tokens)\n"
      ],
      "id": "cell-134"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 텍스트를 인풋 형태로 변환한 후, 인덱스 추출\n",
        "text = \"Hugging Face is creating a tool that democratizes AI.\"\n",
        "inputs = tokenizer(text,truncation=True)\n",
        "inputs"
      ],
      "id": "cell-135"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 텍스트를 인풋 형태로 변환한 후, 인덱스 추출\n",
        "text = \"Hugging Hugging Hugging\"\n",
        "inputs = tokenizer(text,truncation=True)\n",
        "inputs"
      ],
      "id": "cell-136"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 텍스트를 인풋 형태로 변환한 후, 인덱스 추출\n",
        "text = \"Face Face Face face face face\"\n",
        "inputs = tokenizer(text,truncation=True)\n",
        "inputs"
      ],
      "id": "cell-137"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 텍스트를 인풋 형태로 변환한 후, 인덱스 추출\n",
        "text = \"is is is\"\n",
        "inputs = tokenizer(text,truncation=True)\n",
        "inputs"
      ],
      "id": "cell-138"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "set(dir(tokenizer)) & {'__call__'}"
      ],
      "id": "cell-139"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)"
      ],
      "id": "cell-140"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenized_imdb = imdb.map(preprocess_function, batched=True)"
      ],
      "id": "cell-141"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "id": "cell-142"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_collator"
      ],
      "id": "cell-143"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")"
      ],
      "id": "cell-144"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ],
      "id": "cell-145"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
      ],
      "id": "cell-146"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert/distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
        ")"
      ],
      "id": "cell-147"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"my_awesome_model\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_imdb[\"train\"],\n",
        "    eval_dataset=tokenized_imdb[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "id": "cell-148"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = \"This was a masterpiece. Not completely faithful to the books, but enthralling from beginning to end. Might be my favorite of the three.\""
      ],
      "id": "cell-149"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\", model=\"stevhliu/my_awesome_model\")\n",
        "classifier(text)"
      ],
      "id": "cell-150"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"stevhliu/my_awesome_model\")\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")"
      ],
      "id": "cell-151"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "import torch\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"stevhliu/my_awesome_model\")\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits"
      ],
      "id": "cell-152"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predicted_class_id = logits.argmax().item()\n",
        "model.config.iㅌd2label[predicted_class_id]"
      ],
      "id": "cell-153"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "hf",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  }
}