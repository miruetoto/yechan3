{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# (Ïó∞Íµ¨&Ïû¨Ïù∏) MBTI ‚Äì Í∞êÏÑ±Î∂ÑÏÑù\n",
        "\n",
        "Ïã†Î°ùÏòàÏ∞¨  \n",
        "2023-10-11"
      ],
      "id": "e20c7d90-161f-4751-ae93-aa045d0e778c"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "from autogluon.core.utils.loaders import load_pd\n",
        "train_data = load_pd.load('https://autogluon-text.s3-accelerate.amazonaws.com/glue/sst/train.parquet')\n",
        "test_data = load_pd.load('https://autogluon-text.s3-accelerate.amazonaws.com/glue/sst/dev.parquet')\n",
        "subsample_size = 1000  # subsample data for faster demo, try setting this to larger values\n",
        "train_data = train_data.sample(n=subsample_size, random_state=0)\n",
        "train_data.head(10)"
      ],
      "id": "cell-1"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libc10_cuda.so: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n",
            "/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
            "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "    2 unique label values:  [0, 1]\n",
            "    If 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Global seed set to 0\n",
            "AutoMM starts to create your model. ‚ú®\n",
            "\n",
            "- AutoGluon version is 0.8.2.\n",
            "\n",
            "- Pytorch version is 2.0.0.post2.\n",
            "\n",
            "- Model will be saved to \"/home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst\".\n",
            "\n",
            "- Validation metric is \"acc\".\n",
            "\n",
            "- To track the learning progress, you can open a terminal and launch Tensorboard:\n",
            "    ```shell\n",
            "    # Assume you have installed tensorboard\n",
            "    tensorboard --logdir /home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst\n",
            "    ```\n",
            "\n",
            "Enjoy your coffee, and let AutoMM do the job ‚òï‚òï‚òï Learn more at https://auto.gluon.ai\n",
            "\n",
            "Downloading (‚Ä¶)lve/main/config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 666/666 [00:00<00:00, 1.35MB/s]\n",
            "Downloading pytorch_model.bin: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 440M/440M [00:21<00:00, 20.0MB/s] \n",
            "Downloading (‚Ä¶)okenizer_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27.0/27.0 [00:00<00:00, 59.8kB/s]\n",
            "Downloading (‚Ä¶)solve/main/vocab.txt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 232k/232k [00:00<00:00, 1.16MB/s]\n",
            "Downloading (‚Ä¶)/main/tokenizer.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 466k/466k [00:00<00:00, 58.6MB/s]\n",
            "0 GPUs are detected, and 0 GPUs will be used.\n",
            "\n",
            "/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/autogluon/multimodal/utils/environment.py:91: UserWarning: Only CPU is detected in the instance. This may result in slow speed for MultiModalPredictor. Consider using an instance with GPU support.\n",
            "  warnings.warn(\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name              | Type                         | Params\n",
            "-------------------------------------------------------------------\n",
            "0 | model             | HFAutoModelForTextPrediction | 108 M \n",
            "1 | validation_metric | MulticlassAccuracy           | 0     \n",
            "2 | loss_func         | CrossEntropyLoss             | 0     \n",
            "-------------------------------------------------------------------\n",
            "108 M     Trainable params\n",
            "0         Non-trainable params\n",
            "108 M     Total params\n",
            "435.573   Total estimated model params size (MB)\n",
            "Epoch 0, global step 3: 'val_acc' reached 0.46500 (best 0.46500), saving model to '/home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst/epoch=0-step=3.ckpt' as top 3\n",
            "Epoch 0, global step 7: 'val_acc' reached 0.57000 (best 0.57000), saving model to '/home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst/epoch=0-step=7.ckpt' as top 3\n",
            "Epoch 1, global step 10: 'val_acc' reached 0.77500 (best 0.77500), saving model to '/home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst/epoch=1-step=10.ckpt' as top 3\n",
            "Epoch 1, global step 14: 'val_acc' reached 0.79500 (best 0.79500), saving model to '/home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst/epoch=1-step=14.ckpt' as top 3\n",
            "Time limit reached. Elapsed time is 0:03:01. Signaling Trainer to stop.\n",
            "Start to fuse 3 checkpoints via the greedy soup algorithm.\n",
            "AutoMM has created your model üéâüéâüéâ\n",
            "\n",
            "- To load the model, use the code below:\n",
            "    ```python\n",
            "    from autogluon.multimodal import MultiModalPredictor\n",
            "    predictor = MultiModalPredictor.load(\"/home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst\")\n",
            "    ```\n",
            "\n",
            "- You can open a terminal and launch Tensorboard to visualize the training log:\n",
            "    ```shell\n",
            "    # Assume you have installed tensorboard\n",
            "    tensorboard --logdir /home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst\n",
            "    ```\n",
            "\n",
            "- If you are not satisfied with the model, try to increase the training time, \n",
            "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
            "or post issues on GitHub: https://github.com/autogluon/autogluon\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 50/100 [00:38<00:38,  1.29it/s]                  Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [01:25<00:00,  1.18it/s]Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 50/100 [00:43<00:43,  1.14it/s] Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [01:30<00:00,  1.10it/s]Epoch 2:   0%|          | 0/100 [00:00<?, ?it/s]          Epoch 2:   1%|          | 1/100 [00:06<10:45,  6.52s/it]\n",
            "Predicting DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:05<00:00,  1.25it/s]\n",
            "Predicting DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:05<00:00,  1.29it/s]\n",
            "Predicting DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:05<00:00,  1.25it/s]"
          ]
        },
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "<autogluon.multimodal.predictor.MultiModalPredictor at 0x7f8acd4349a0>"
            ]
          }
        }
      ],
      "source": [
        "from autogluon.multimodal import MultiModalPredictor\n",
        "import uuid\n",
        "model_path = f\"./tmp/{uuid.uuid4().hex}-automm_sst\"\n",
        "predictor = MultiModalPredictor(label='label', eval_metric='acc', path=model_path)\n",
        "predictor.fit(train_data, time_limit=180)"
      ],
      "id": "cell-2"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Sentence\": it's a charming and often affecting journey. \"Predicted Sentiment\": 1\n",
            "\"Sentence\": It's slow, very, very, very slow. \"Predicted Sentiment\": 0"
          ]
        }
      ],
      "source": [
        "sentence1 = \"it's a charming and often affecting journey.\"\n",
        "sentence2 = \"It's slow, very, very, very slow.\"\n",
        "predictions = predictor.predict({'sentence': [sentence1, sentence2]})\n",
        "print('\"Sentence\":', sentence1, '\"Predicted Sentiment\":', predictions[0])\n",
        "print('\"Sentence\":', sentence2, '\"Predicted Sentiment\":', predictions[1])"
      ],
      "id": "cell-3"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  }
}