<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.533">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="신록예찬">
<meta name="dcterms.date" content="2024-10-31">

<title>신록예찬’s Blog - (강의) 이미지캡셔닝2</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">신록예찬’s Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://guebin.github.io/DL2024/"> 
<span class="menu-text">DL2024</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://guebin.github.io/AP2023/"> 
<span class="menu-text">AP2023</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://guebin.github.io/PP2024/"> 
<span class="menu-text">PP2024</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://guebin.github.io/DV2023/"> 
<span class="menu-text">DV2023</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://guebin.github.io/MP2023/"> 
<span class="menu-text">MP2023</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://guebin.github.io/SC2024/"> 
<span class="menu-text">SC2024</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://guebin.github.io/DS2022/"> 
<span class="menu-text">DS2022</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://guebin.github.io/SP2023/"> 
<span class="menu-text">SP2023</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://guebin.github.io/IR2021/"> 
<span class="menu-text">IR2021</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://miruetoto.github.io/yechan/"> 
<span class="menu-text">yechan</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://miruetoto.github.io/yechan2/"> 
<span class="menu-text">yechan2</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/miruetoto/yechan3"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">(강의) 이미지캡셔닝2</li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../메모.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">메모</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../공부.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">공부</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../연구.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">연구</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../자료.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">자료</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#imports" id="toc-imports" class="nav-link active" data-scroll-target="#imports">1. Imports</a></li>
  <li><a href="#datasets" id="toc-datasets" class="nav-link" data-scroll-target="#datasets">2. Datasets</a>
  <ul class="collapse">
  <li><a href="#preprocess-the-dataset" id="toc-preprocess-the-dataset" class="nav-link" data-scroll-target="#preprocess-the-dataset">Preprocess the dataset</a></li>
  <li><a href="#load-a-base-model" id="toc-load-a-base-model" class="nav-link" data-scroll-target="#load-a-base-model">Load a base model</a></li>
  <li><a href="#evaluate" id="toc-evaluate" class="nav-link" data-scroll-target="#evaluate">Evaluate</a></li>
  <li><a href="#train" id="toc-train" class="nav-link" data-scroll-target="#train">Train!</a></li>
  <li><a href="#inference" id="toc-inference" class="nav-link" data-scroll-target="#inference">Inference</a></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="2024-10-31-(강의) 이미지캡셔닝2.out.ipynb" download="2024-10-31-(강의) 이미지캡셔닝2.out.ipynb"><i class="bi bi-journal-code"></i>Jupyter</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">(강의) 이미지캡셔닝2</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>신록예찬 </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 31, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<div id="cell-1" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="co"># Transformers installation</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="co"># ! pip install transformers datasets</span></span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="co"># To install from source instead of the last release, comment the command above and uncomment the following one.</span></span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="co"># ! pip install git+https://github.com/huggingface/transformers.git</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1"></a><span class="ex">pip</span> install transformers datasets evaluate <span class="at">-q</span></span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="ex">pip</span> install jiwer <span class="at">-q</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="imports" class="level1">
<h1>1. Imports</h1>
<div id="cell-4" class="cell" data-execution_count="209">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="im">import</span> PIL.Image</span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="im">import</span> torchvision</span>
<span id="cb3-3"><a href="#cb3-3"></a><span class="im">import</span> io</span>
<span id="cb3-4"><a href="#cb3-4"></a><span class="im">import</span> requests</span>
<span id="cb3-5"><a href="#cb3-5"></a><span class="im">import</span> datasets</span>
<span id="cb3-6"><a href="#cb3-6"></a><span class="im">import</span> transformers</span>
<span id="cb3-7"><a href="#cb3-7"></a><span class="im">from</span> transformers <span class="im">import</span> TrainingArguments, Trainer</span>
<span id="cb3-8"><a href="#cb3-8"></a><span class="im">import</span> torch</span>
<span id="cb3-9"><a href="#cb3-9"></a><span class="im">from</span> transformers <span class="im">import</span> AutoProcessor</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="datasets" class="level1">
<h1>2. Datasets</h1>
<div id="cell-6" class="cell" data-execution_count="231">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a><span class="co"># Conceptual Captions 데이터셋 불러오기</span></span>
<span id="cb4-2"><a href="#cb4-2"></a>ds <span class="op">=</span> datasets.load_dataset(<span class="st">"conceptual_captions"</span>, split<span class="op">=</span><span class="st">"train"</span>)</span>
<span id="cb4-3"><a href="#cb4-3"></a>ds <span class="op">=</span> ds.train_test_split(test_size<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb4-4"><a href="#cb4-4"></a>train_ds <span class="op">=</span> ds[<span class="st">"train"</span>]</span>
<span id="cb4-5"><a href="#cb4-5"></a>test_ds <span class="op">=</span> ds[<span class="st">"test"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-7" class="cell" data-execution_count="232">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a>train_ds[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="232">
<pre><code>{'image_url': 'https://i2.wp.com/englishcountrycooking.co.uk/wp-content/uploads/2016/01/DSC2042-2016January01-TomatoSoup-13.jpg',
 'caption': 'some key ingredients to a good tomato soup .'}</code></pre>
</div>
</div>
<div id="cell-8" class="cell" data-execution_count="233">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a>examples_dct <span class="op">=</span> train_ds[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-9" class="cell" data-execution_count="234">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a>examples_dct[<span class="st">'image_url'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="234">
<pre><code>['https://i2.wp.com/englishcountrycooking.co.uk/wp-content/uploads/2016/01/DSC2042-2016January01-TomatoSoup-13.jpg',
 'http://www.qualitygateco.com/wp-content/uploads/2017/03/Automatic-Gate-624x416.jpg',
 'http://l7.alamy.com/zooms/83fec0f314504bf28f0e14d1febafc45/composition-with-books-on-the-table-ctwpjt.jpg',
 'https://media.istockphoto.com/photos/man-making-a-decision-with-scale-above-head-and-people-on-a-balance-picture-id688771506?k=6&amp;m=688771506&amp;s=612x612&amp;w=0&amp;h=gUiT7kfGWYAma9zb37mmFP9OMQmLl702aWvjaIDB0eI=',
 'https://media.gettyimages.com/photos/chrissie-hynde-of-the-pretenders-performs-live-on-stage-at-o2-apollo-picture-id861039628?s=612x612']</code></pre>
</div>
</div>
<section id="preprocess-the-dataset" class="level2">
<h2 class="anchored" data-anchor-id="preprocess-the-dataset">Preprocess the dataset</h2>
<p>Since the dataset has two modalities (image and text), the pre-processing pipeline will preprocess images and the captions.</p>
<p>To do so, load the processor class associated with the model you are about to fine-tune.</p>
<div id="cell-12" class="cell" data-execution_count="235">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a>모델이름 <span class="op">=</span> <span class="st">"microsoft/git-base"</span></span>
<span id="cb10-2"><a href="#cb10-2"></a>전처리하기<span class="dv">1</span> <span class="op">=</span> AutoProcessor.from_pretrained(모델이름)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><code>-</code> <code>전처리하기1</code> 사용방법</p>
<div id="cell-14" class="cell" data-execution_count="236">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1"></a><span class="co">#전처리하기1(images=[img,img])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><code>-</code> 전처리하기2</p>
<div id="cell-16" class="cell" data-execution_count="238">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a><span class="kw">def</span> URL을PIL이미지로변환하기(url):</span>
<span id="cb12-2"><a href="#cb12-2"></a>    img <span class="op">=</span> PIL.Image.<span class="bu">open</span>(io.BytesIO(requests.get(url).content))</span>
<span id="cb12-3"><a href="#cb12-3"></a>    <span class="cf">return</span> img</span>
<span id="cb12-4"><a href="#cb12-4"></a><span class="kw">def</span> 전처리하기<span class="dv">2</span>(examples_dct):</span>
<span id="cb12-5"><a href="#cb12-5"></a>    PIL이미지리스트 <span class="op">=</span> [URL을PIL이미지로변환하기(url) <span class="cf">for</span> url <span class="kw">in</span> examples_dct[<span class="st">'image_url'</span>]]</span>
<span id="cb12-6"><a href="#cb12-6"></a>    캡션리스트 <span class="op">=</span> [x <span class="cf">for</span> x <span class="kw">in</span> examples_dct[<span class="st">"caption"</span>]]</span>
<span id="cb12-7"><a href="#cb12-7"></a>    전처리된자료 <span class="op">=</span> 전처리하기<span class="dv">1</span>(images<span class="op">=</span>PIL이미지리스트, text<span class="op">=</span>캡션리스트, padding<span class="op">=</span><span class="st">"max_length"</span>)</span>
<span id="cb12-8"><a href="#cb12-8"></a>    <span class="cf">return</span> 전처리된자료</span>
<span id="cb12-9"><a href="#cb12-9"></a>train전처리된자료 <span class="op">=</span> train_ds.with_transform(전처리하기<span class="dv">2</span>)</span>
<span id="cb12-10"><a href="#cb12-10"></a>test전처리된자료 <span class="op">=</span> test_ds.with_transform(전처리하기<span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-17" class="cell" data-execution_count="250">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1"></a>train전처리된자료[<span class="dv">6</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="250">
<pre><code>{'input_ids': [101,
  2402,
  2450,
  3564,
  2006,
  1037,
  2380,
  6847,
  24588,
  1996,
  3193,
  102,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0],
 'attention_mask': [1,
  1,
  1,
  1,
  1,
  1,
  1,
  1,
  1,
  1,
  1,
  1,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0,
  0],
 'pixel_values': array([[[ 1.5653756,  1.5653756,  1.5945723, ...,  1.7697535,
           1.7697535,  1.7697535],
         [ 1.5945723,  1.5945723,  1.5945723, ...,  1.7551551,
           1.7551551,  1.7551551],
         [ 1.5945723,  1.5945723,  1.5945723, ...,  1.7405566,
           1.7405566,  1.7259582],
         ...,
         [-1.7922626, -1.7922626, -1.7922626, ..., -1.7922626,
          -1.7922626, -1.7922626],
         [-1.7922626, -1.7922626, -1.7922626, ..., -1.7922626,
          -1.7922626, -1.7922626],
         [-1.7922626, -1.7922626, -1.7922626, ..., -1.7922626,
          -1.7922626, -1.7922626]],
 
        [[ 1.7447128,  1.7447128,  1.7597206, ...,  1.924806 ,
           1.924806 ,  1.924806 ],
         [ 1.7447128,  1.7447128,  1.7447128, ...,  1.9097983,
           1.9097983,  1.9097983],
         [ 1.7447128,  1.7447128,  1.7447128, ...,  1.8947905,
           1.8947905,  1.8797828],
         ...,
         [-1.7520971, -1.7520971, -1.7520971, ..., -1.7520971,
          -1.7520971, -1.7520971],
         [-1.7520971, -1.7520971, -1.7520971, ..., -1.7520971,
          -1.7520971, -1.7520971],
         [-1.7520971, -1.7520971, -1.7520971, ..., -1.7520971,
          -1.7520971, -1.7520971]],
 
        [[ 1.9325962,  1.9325962,  1.9610363, ...,  2.074797 ,
           2.074797 ,  2.074797 ],
         [ 1.918376 ,  1.918376 ,  1.918376 , ...,  2.0605767,
           2.0605767,  2.0605767],
         [ 1.9041561,  1.9041561,  1.8899357, ...,  2.0463567,
           2.0463567,  2.0321364],
         ...,
         [-1.4802198, -1.4802198, -1.4802198, ..., -1.4802198,
          -1.4802198, -1.4802198],
         [-1.4802198, -1.4802198, -1.4802198, ..., -1.4802198,
          -1.4802198, -1.4802198],
         [-1.4802198, -1.4802198, -1.4802198, ..., -1.4802198,
          -1.4802198, -1.4802198]]], dtype=float32)}</code></pre>
</div>
</div>
<div id="cell-18" class="cell" data-execution_count="196">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1"></a>_데이터콜렉터입력샘플[:<span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>SyntaxError: invalid syntax. Perhaps you forgot a comma? (97606739.py, line 3)</code></pre>
</div>
</div>
<div id="cell-19" class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1"></a>model_input_sample <span class="op">=</span> <span class="bu">dict</span>(</span>
<span id="cb17-2"><a href="#cb17-2"></a>    input_ids <span class="op">=</span> torch.tensor(train_ds_transformed[:<span class="dv">2</span>][<span class="st">'input_ids'</span>]),</span>
<span id="cb17-3"><a href="#cb17-3"></a>    attention_mask <span class="op">=</span> torch.tensor(train_ds_transformed[:<span class="dv">2</span>][<span class="st">'attention_mask'</span>]),</span>
<span id="cb17-4"><a href="#cb17-4"></a>    pixel_values <span class="op">=</span> torch.tensor(train_ds_transformed[:<span class="dv">2</span>][<span class="st">'pixel_values'</span>])</span>
<span id="cb17-5"><a href="#cb17-5"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-20" class="cell" data-execution_count="141">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1"></a>trainer <span class="op">=</span> Trainer(</span>
<span id="cb18-2"><a href="#cb18-2"></a>    model<span class="op">=</span>model,</span>
<span id="cb18-3"><a href="#cb18-3"></a>    <span class="co">#args=training_args,</span></span>
<span id="cb18-4"><a href="#cb18-4"></a>    train_dataset<span class="op">=</span>train_ds,</span>
<span id="cb18-5"><a href="#cb18-5"></a>    <span class="co">#eval_dataset=test_ds,</span></span>
<span id="cb18-6"><a href="#cb18-6"></a>    <span class="co">#compute_metrics=compute_metrics,</span></span>
<span id="cb18-7"><a href="#cb18-7"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at /opt/conda/conda-bld/pytorch_1720538439675/work/c10/cuda/CUDAFunctions.cpp:108.)
  return torch._C._cuda_getDeviceCount() &gt; 0
/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")</code></pre>
</div>
</div>
<div id="cell-21" class="cell" data-execution_count="161">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1"></a>train_ds_transformed[:<span class="dv">2</span>].keys()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="161">
<pre><code>dict_keys(['input_ids', 'attention_mask', 'pixel_values'])</code></pre>
</div>
</div>
<div id="cell-22" class="cell" data-execution_count="171">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1"></a>model_input_sample <span class="op">=</span> <span class="bu">dict</span>(</span>
<span id="cb22-2"><a href="#cb22-2"></a>    input_ids <span class="op">=</span> torch.tensor(train_ds_transformed[:<span class="dv">2</span>][<span class="st">'input_ids'</span>]),</span>
<span id="cb22-3"><a href="#cb22-3"></a>    attention_mask <span class="op">=</span> torch.tensor(train_ds_transformed[:<span class="dv">2</span>][<span class="st">'attention_mask'</span>]),</span>
<span id="cb22-4"><a href="#cb22-4"></a>    pixel_values <span class="op">=</span> torch.tensor(train_ds_transformed[:<span class="dv">2</span>][<span class="st">'pixel_values'</span>])</span>
<span id="cb22-5"><a href="#cb22-5"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-23" class="cell" data-execution_count="172">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1"></a>model(<span class="op">**</span>model_input_sample)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="172">
<pre><code>CausalLMOutputWithPast(loss=None, logits=tensor([[[-0.8686, -0.8685, -0.8684,  ..., -0.8684, -0.8684, -0.8684],
         [-0.5816, -0.5817, -0.5818,  ..., -0.5815, -0.5818, -0.5812],
         [-0.7298, -0.7297, -0.7296,  ..., -0.7297, -0.7296, -0.7297],
         ...,
         [-2.0791, -2.0784, -2.0771,  ..., -2.0789, -2.0774, -2.0801],
         [-1.7354, -1.7346, -1.7330,  ..., -1.7352, -1.7332, -1.7364],
         [-2.1231, -2.1235, -2.1239,  ..., -2.1229, -2.1234, -2.1227]],

        [[-0.5791, -0.5787, -0.5777,  ..., -0.5791, -0.5781, -0.5796],
         [ 0.1308,  0.1317,  0.1333,  ...,  0.1309,  0.1326,  0.1299],
         [-1.4053, -1.4058, -1.4065,  ..., -1.4052, -1.4061, -1.4047],
         ...,
         [-1.6593, -1.6588, -1.6575,  ..., -1.6593, -1.6578, -1.6602],
         [-1.7329, -1.7321, -1.7304,  ..., -1.7328, -1.7308, -1.7340],
         [-1.8127, -1.8122, -1.8111,  ..., -1.8125, -1.8112, -1.8135]]],
       grad_fn=&lt;ViewBackward0&gt;), past_key_values=((tensor([[[[ 1.9375e-01,  3.1010e-01, -1.0511e+00,  ..., -1.3663e+00,
           -5.5004e-01, -1.3451e+00],
          [-1.8597e-01, -1.6028e-01,  5.9457e-04,  ..., -1.6100e+00,
           -6.4203e-01,  6.0570e-01],
          [ 3.1200e-01, -9.9397e-02, -1.0618e+00,  ...,  8.7237e-02,
           -3.7231e-01,  4.8643e-01],
          ...,
          [ 1.4355e-01, -3.2263e-01,  5.0533e-01,  ..., -1.9786e-01,
           -4.2618e-01, -5.9881e-01],
          [-2.7728e-01,  2.7516e-02,  1.4594e+00,  ...,  7.9899e-01,
           -1.1421e+00,  4.7761e-01],
          [-1.7415e+00,  4.2855e-01,  1.0616e+00,  ..., -2.7485e-01,
           -1.0219e+00,  1.7465e+00]],

         [[-2.9919e-01, -1.7201e+00,  1.7518e-01,  ..., -9.7178e-02,
           -4.8926e-02, -1.4152e+00],
          [-2.3960e-01,  1.6626e-01, -1.7535e+00,  ...,  4.6674e-01,
            1.2276e+00,  8.9152e-01],
          [ 6.6364e-01, -6.0340e-01, -8.3493e-01,  ...,  2.8431e-01,
            1.2189e+00,  8.8266e-01],
          ...,
          [ 5.3933e-01, -1.8208e-01, -3.7493e-01,  ...,  1.5417e-01,
            3.5528e-01, -9.5434e-02],
          [ 5.5640e-01, -1.1423e+00, -5.1604e-01,  ...,  7.2188e-01,
            1.1156e+00, -1.4921e-01],
          [-2.8036e-01, -4.3995e-01, -1.8103e+00,  ...,  5.9085e-02,
           -5.1629e-01,  3.5109e-01]],

         [[ 1.3482e+00, -1.1218e+00,  7.0254e-01,  ...,  1.6043e+00,
            5.7014e-01, -5.0520e-01],
          [-1.6461e+00,  4.2192e-01,  9.8516e-01,  ...,  8.1529e-01,
            1.5163e+00,  2.2049e+00],
          [ 2.0344e-02, -1.4759e+00,  9.4407e-02,  ..., -2.1322e-01,
            8.9514e-02, -1.0332e+00],
          ...,
          [-3.5737e-01,  1.3127e+00,  6.7603e-01,  ..., -7.7371e-01,
            3.8866e-01,  8.9492e-01],
          [ 5.3393e-01,  6.2738e-01,  1.1487e+00,  ...,  7.4362e-02,
           -8.5900e-01,  1.4815e-03],
          [ 4.2316e-01,  1.0821e+00, -3.7240e-01,  ..., -1.1375e+00,
           -1.6078e+00,  5.5229e-01]],

         ...,

         [[ 1.5312e-02,  4.4311e-01,  5.2784e-01,  ..., -1.9521e-01,
           -4.6427e-01,  2.4929e-01],
          [ 1.9631e-01,  7.7510e-01, -2.1099e-01,  ..., -3.2323e-01,
           -2.8644e-01, -1.2726e+00],
          [ 5.3894e-01,  8.9984e-01,  3.1434e-01,  ..., -8.9520e-01,
           -1.3979e+00, -5.9446e-02],
          ...,
          [-6.0119e-01,  9.3451e-02, -7.4138e-01,  ...,  2.2749e-02,
            4.6133e-01, -1.0050e+00],
          [-9.2757e-01,  7.2079e-01,  2.0370e-01,  ..., -6.3908e-01,
            8.1654e-01, -6.3096e-01],
          [-6.7301e-01, -8.8804e-01,  4.1811e-01,  ..., -1.2485e+00,
            1.0979e-01,  9.5769e-01]],

         [[-8.4666e-01,  1.4426e-01,  8.4658e-01,  ..., -1.2141e+00,
           -1.5110e-01,  6.4643e-01],
          [-1.4110e+00, -3.2311e-01,  6.4477e-01,  ...,  8.4139e-01,
           -4.9039e-01,  1.2668e+00],
          [ 4.8872e-01,  4.1300e-01, -6.2338e-01,  ..., -1.6185e-01,
           -5.4531e-02, -2.3765e-01],
          ...,
          [-1.1719e+00, -8.1337e-02, -2.3084e-02,  ..., -2.3793e-01,
            5.3974e-01, -1.2476e+00],
          [-1.2101e+00, -7.5789e-02,  1.0674e+00,  ...,  5.6805e-01,
           -9.3938e-01,  1.3090e+00],
          [ 8.4824e-01, -1.5573e+00, -4.7890e-01,  ...,  3.0592e-01,
           -2.2296e-01, -1.4555e-01]],

         [[ 8.6837e-01,  4.3609e-01, -4.1973e-03,  ...,  5.3829e-01,
           -1.9280e-01,  6.7194e-01],
          [ 1.5347e-01, -5.0688e-01,  1.3914e+00,  ..., -2.7652e-01,
           -3.4188e-02,  3.9072e-01],
          [ 6.4373e-02, -1.7093e-01,  5.5048e-01,  ...,  7.5335e-01,
            1.8037e-01, -1.5667e-01],
          ...,
          [-2.7674e-01, -2.7613e-01,  7.6596e-01,  ..., -5.2240e-02,
            3.8216e-01, -6.3454e-01],
          [-1.5042e+00, -2.9667e-01, -1.2710e+00,  ...,  1.0229e+00,
            1.4715e+00, -6.8493e-01],
          [-2.0173e-01,  6.3312e-02, -1.0395e+00,  ..., -2.2178e-01,
            1.2415e+00, -1.1142e+00]]],


        [[[ 1.9375e-01,  3.1010e-01, -1.0511e+00,  ..., -1.3663e+00,
           -5.5004e-01, -1.3451e+00],
          [ 3.3911e-02, -5.0327e-01, -6.2649e-01,  ..., -1.0354e+00,
           -5.0909e-01,  1.1714e+00],
          [ 3.3267e-01, -3.4700e-01,  1.0528e+00,  ..., -4.3279e-01,
           -9.3120e-01, -6.2877e-01],
          ...,
          [ 1.4355e-01, -3.2263e-01,  5.0533e-01,  ..., -1.9786e-01,
           -4.2618e-01, -5.9881e-01],
          [-2.7728e-01,  2.7516e-02,  1.4594e+00,  ...,  7.9899e-01,
           -1.1421e+00,  4.7761e-01],
          [-1.7415e+00,  4.2855e-01,  1.0616e+00,  ..., -2.7485e-01,
           -1.0219e+00,  1.7465e+00]],

         [[-2.9919e-01, -1.7201e+00,  1.7518e-01,  ..., -9.7178e-02,
           -4.8926e-02, -1.4152e+00],
          [ 5.1473e-01,  3.9121e-01,  8.1901e-01,  ...,  1.4315e-02,
            9.7076e-01,  2.8438e-02],
          [-1.2701e+00, -9.3325e-01,  1.0487e+00,  ...,  1.1926e+00,
           -1.8625e-01,  2.3429e+00],
          ...,
          [ 5.3933e-01, -1.8208e-01, -3.7493e-01,  ...,  1.5417e-01,
            3.5528e-01, -9.5434e-02],
          [ 5.5640e-01, -1.1423e+00, -5.1604e-01,  ...,  7.2188e-01,
            1.1156e+00, -1.4921e-01],
          [-2.8036e-01, -4.3995e-01, -1.8103e+00,  ...,  5.9085e-02,
           -5.1629e-01,  3.5109e-01]],

         [[ 1.3482e+00, -1.1218e+00,  7.0254e-01,  ...,  1.6043e+00,
            5.7014e-01, -5.0520e-01],
          [-1.0343e+00, -6.6107e-01,  4.6725e-01,  ...,  2.9628e-01,
           -6.1961e-01,  6.7905e-02],
          [ 1.8580e+00, -1.3868e-01,  1.9230e+00,  ...,  5.2860e-01,
            9.0522e-01, -3.1135e-01],
          ...,
          [-3.5737e-01,  1.3127e+00,  6.7603e-01,  ..., -7.7371e-01,
            3.8866e-01,  8.9492e-01],
          [ 5.3393e-01,  6.2738e-01,  1.1487e+00,  ...,  7.4362e-02,
           -8.5900e-01,  1.4815e-03],
          [ 4.2316e-01,  1.0821e+00, -3.7240e-01,  ..., -1.1375e+00,
           -1.6078e+00,  5.5229e-01]],

         ...,

         [[ 1.5312e-02,  4.4311e-01,  5.2784e-01,  ..., -1.9521e-01,
           -4.6427e-01,  2.4929e-01],
          [-4.5462e-01,  1.4643e-01, -9.0199e-01,  ..., -1.2708e+00,
           -2.4794e-01, -4.6308e-01],
          [-8.6780e-01, -1.2426e+00,  8.3803e-01,  ...,  4.5168e-02,
           -7.8951e-01, -6.3934e-01],
          ...,
          [-6.0119e-01,  9.3451e-02, -7.4138e-01,  ...,  2.2749e-02,
            4.6133e-01, -1.0050e+00],
          [-9.2757e-01,  7.2079e-01,  2.0370e-01,  ..., -6.3908e-01,
            8.1654e-01, -6.3096e-01],
          [-6.7301e-01, -8.8804e-01,  4.1811e-01,  ..., -1.2485e+00,
            1.0979e-01,  9.5769e-01]],

         [[-8.4666e-01,  1.4426e-01,  8.4658e-01,  ..., -1.2141e+00,
           -1.5110e-01,  6.4643e-01],
          [ 1.2243e+00, -6.9426e-01, -8.2443e-01,  ...,  3.1692e-01,
            2.0410e-01,  1.4449e-02],
          [-1.2411e+00, -3.2398e-01,  1.0108e-01,  ...,  1.1011e+00,
           -7.0270e-01,  7.1698e-01],
          ...,
          [-1.1719e+00, -8.1337e-02, -2.3084e-02,  ..., -2.3793e-01,
            5.3974e-01, -1.2476e+00],
          [-1.2101e+00, -7.5789e-02,  1.0674e+00,  ...,  5.6805e-01,
           -9.3938e-01,  1.3090e+00],
          [ 8.4824e-01, -1.5573e+00, -4.7890e-01,  ...,  3.0592e-01,
           -2.2296e-01, -1.4555e-01]],

         [[ 8.6837e-01,  4.3609e-01, -4.1973e-03,  ...,  5.3829e-01,
           -1.9280e-01,  6.7194e-01],
          [-9.2990e-01,  1.6191e+00,  3.1779e+00,  ...,  6.5596e-02,
           -1.1603e+00,  1.1722e+00],
          [ 5.0437e-01,  2.2104e-01,  1.4210e+00,  ...,  2.3792e-01,
           -2.5211e-01, -3.8230e-01],
          ...,
          [-2.7674e-01, -2.7613e-01,  7.6596e-01,  ..., -5.2240e-02,
            3.8216e-01, -6.3454e-01],
          [-1.5042e+00, -2.9667e-01, -1.2710e+00,  ...,  1.0229e+00,
            1.4715e+00, -6.8493e-01],
          [-2.0173e-01,  6.3312e-02, -1.0395e+00,  ..., -2.2178e-01,
            1.2415e+00, -1.1142e+00]]]], grad_fn=&lt;SliceBackward0&gt;), tensor([[[[ 0.3468,  0.2674,  0.6806,  ..., -0.5576, -0.8018, -0.3822],
          [ 0.2077, -0.8225, -1.0729,  ...,  0.0638,  0.1410, -0.4680],
          [ 0.2173, -0.1175, -0.6626,  ..., -0.1462,  0.1122,  0.3583],
          ...,
          [-0.9810,  0.3846,  0.7253,  ..., -0.0969, -0.5991,  0.3640],
          [ 0.9459, -0.0189, -0.4344,  ...,  0.1173,  0.1561, -0.0534],
          [-0.1970, -0.2514,  1.2863,  ..., -0.0547, -0.0291, -0.0071]],

         [[-0.3503,  0.6246,  0.7316,  ..., -0.1079, -1.7153,  0.4577],
          [-0.8190,  0.0365, -0.4120,  ..., -0.3128, -0.5801, -0.1420],
          [-0.3801,  0.9701, -1.3983,  ...,  0.8896,  0.1686, -1.3431],
          ...,
          [-0.6157,  0.6389, -0.7054,  ...,  0.7407,  0.7759, -0.9144],
          [-0.3179, -0.9158, -1.0796,  ..., -1.0638,  0.6043, -0.6307],
          [ 0.7405, -0.6475,  0.1572,  ...,  0.2414, -0.7104,  0.3518]],

         [[-0.8659,  2.6103, -0.7099,  ..., -1.0782, -0.1854,  2.5314],
          [ 0.5637,  0.4407, -0.2710,  ..., -0.5323,  1.1105, -0.5068],
          [-0.4363,  0.3672, -0.0196,  ...,  0.3123,  1.3554, -0.1860],
          ...,
          [ 0.1920, -0.4334,  0.4825,  ...,  0.7690,  0.3248, -0.6599],
          [-0.1454,  0.1027, -0.0070,  ...,  0.2673,  0.8113, -0.1014],
          [ 0.3117, -1.5749,  0.1301,  ...,  0.1748,  1.2687,  0.6563]],

         ...,

         [[-0.8885,  1.3934,  0.5002,  ...,  1.4465, -0.5924,  1.0802],
          [ 0.7191,  0.5163, -0.5691,  ..., -0.7198, -0.1255,  0.8071],
          [-0.5205, -0.2419, -0.2832,  ..., -0.1177,  0.4866, -0.1828],
          ...,
          [-0.3486,  0.1810, -0.1828,  ..., -0.5201, -0.2097,  0.3841],
          [-0.4151,  0.2877, -0.5131,  ..., -0.9315, -0.3443, -0.1587],
          [-0.2623,  0.7359, -0.0467,  ..., -0.5599,  0.5231,  0.0485]],

         [[-0.2632,  1.2923,  0.6667,  ...,  0.2128,  0.5910,  0.4571],
          [ 0.0989,  0.0049, -0.0143,  ...,  0.7489, -0.2894,  0.0558],
          [ 0.6856, -0.3523,  0.7475,  ...,  0.5963, -0.5182, -0.5011],
          ...,
          [ 0.3282,  0.9957,  0.0923,  ..., -0.5896, -0.2065, -0.9152],
          [ 0.1073,  0.5789, -0.5728,  ..., -0.0914,  0.3198,  0.0769],
          [ 0.5457,  0.9229,  0.9921,  ..., -0.0882,  0.0718, -0.3817]],

         [[-0.2082, -1.0482,  0.0552,  ...,  1.0777, -0.8423, -1.0574],
          [ 0.3106,  0.0383,  1.2930,  ..., -0.1327, -0.5853, -0.4445],
          [ 0.7011, -0.3638,  0.1634,  ..., -0.3616,  1.1077, -0.0182],
          ...,
          [ 0.4755, -0.2540,  1.0018,  ..., -0.4663,  0.1266,  0.5790],
          [ 1.2339, -0.5437,  0.0828,  ..., -0.3326, -0.1317,  0.5315],
          [ 0.1847, -0.6711,  0.4120,  ...,  0.2586, -0.3980,  1.0246]]],


        [[[ 0.3468,  0.2674,  0.6806,  ..., -0.5576, -0.8018, -0.3822],
          [-0.0300,  0.5748, -0.1682,  ...,  0.1349,  0.8576,  0.0094],
          [-0.2589, -1.3112,  0.7692,  ..., -1.3987, -0.9025,  0.3455],
          ...,
          [-0.9810,  0.3846,  0.7253,  ..., -0.0969, -0.5991,  0.3640],
          [ 0.9459, -0.0189, -0.4344,  ...,  0.1173,  0.1561, -0.0534],
          [-0.1970, -0.2514,  1.2863,  ..., -0.0547, -0.0291, -0.0071]],

         [[-0.3503,  0.6246,  0.7316,  ..., -0.1079, -1.7153,  0.4577],
          [ 0.4185,  0.3057, -0.8699,  ...,  0.4144,  0.0414,  0.0522],
          [-0.4177, -0.1054,  0.8339,  ..., -0.3635,  0.6346, -0.5092],
          ...,
          [-0.6157,  0.6389, -0.7054,  ...,  0.7407,  0.7759, -0.9144],
          [-0.3179, -0.9158, -1.0796,  ..., -1.0638,  0.6043, -0.6307],
          [ 0.7405, -0.6475,  0.1572,  ...,  0.2414, -0.7104,  0.3518]],

         [[-0.8659,  2.6103, -0.7099,  ..., -1.0782, -0.1854,  2.5314],
          [ 0.3189, -0.4587, -0.0224,  ..., -0.2007,  0.0769, -0.4861],
          [-0.3056,  1.3060, -0.9059,  ...,  0.0775, -0.8312,  1.1116],
          ...,
          [ 0.1920, -0.4334,  0.4825,  ...,  0.7690,  0.3248, -0.6599],
          [-0.1454,  0.1027, -0.0070,  ...,  0.2673,  0.8113, -0.1014],
          [ 0.3117, -1.5749,  0.1301,  ...,  0.1748,  1.2687,  0.6563]],

         ...,

         [[-0.8885,  1.3934,  0.5002,  ...,  1.4465, -0.5924,  1.0802],
          [-0.5062, -0.2358, -0.2454,  ...,  0.6201,  0.9616,  0.2096],
          [-0.3854,  0.4615,  0.0306,  ...,  0.3817, -0.9777, -0.5925],
          ...,
          [-0.3486,  0.1810, -0.1828,  ..., -0.5201, -0.2097,  0.3841],
          [-0.4151,  0.2877, -0.5131,  ..., -0.9315, -0.3443, -0.1587],
          [-0.2623,  0.7359, -0.0467,  ..., -0.5599,  0.5231,  0.0485]],

         [[-0.2632,  1.2923,  0.6667,  ...,  0.2128,  0.5910,  0.4571],
          [-0.3290, -0.5656,  0.5450,  ...,  0.5823, -0.4497, -0.3798],
          [-0.3001,  0.4131, -0.3063,  ...,  0.0719,  0.5099,  0.0973],
          ...,
          [ 0.3282,  0.9957,  0.0923,  ..., -0.5896, -0.2065, -0.9152],
          [ 0.1073,  0.5789, -0.5728,  ..., -0.0914,  0.3198,  0.0769],
          [ 0.5457,  0.9229,  0.9921,  ..., -0.0882,  0.0718, -0.3817]],

         [[-0.2082, -1.0482,  0.0552,  ...,  1.0777, -0.8423, -1.0574],
          [-0.5739, -0.8622,  0.0789,  ...,  0.3372, -0.0363, -0.6949],
          [-0.3875,  0.4595, -0.2355,  ...,  1.4219,  0.1769, -0.3665],
          ...,
          [ 0.4755, -0.2540,  1.0018,  ..., -0.4663,  0.1266,  0.5790],
          [ 1.2339, -0.5437,  0.0828,  ..., -0.3326, -0.1317,  0.5315],
          [ 0.1847, -0.6711,  0.4120,  ...,  0.2586, -0.3980,  1.0246]]]],
       grad_fn=&lt;SliceBackward0&gt;)), (tensor([[[[ 0.5534, -0.8357,  0.7879,  ..., -0.0222,  0.9217, -0.5340],
          [ 1.3659, -0.5448,  0.1845,  ...,  1.1096,  0.0117,  0.9818],
          [ 0.9702, -0.7956,  0.0639,  ...,  0.8099, -1.1350,  2.0403],
          ...,
          [-0.7355, -1.3218, -1.6085,  ...,  1.2973,  0.8775,  0.7778],
          [-0.8838,  0.4802,  0.0197,  ...,  1.7597,  1.4583, -0.3795],
          [ 1.8444, -0.0392, -0.3059,  ...,  1.5101,  0.1970,  0.5627]],

         [[ 0.3573,  3.4818,  0.0853,  ..., -1.3702, -0.2629, -0.4318],
          [ 0.3332, -0.7501, -0.9947,  ...,  0.6446, -2.1947, -0.0701],
          [-2.4164,  0.7011, -1.1549,  ...,  1.8299, -0.5424,  1.0608],
          ...,
          [-1.0868, -0.0080, -0.4305,  ...,  0.8031,  1.2539, -0.4807],
          [ 0.7300,  0.3649, -1.1807,  ..., -1.0574, -0.4600, -0.8927],
          [-0.0725,  0.4825,  0.0045,  ...,  1.2557, -0.1633, -1.0662]],

         [[ 1.0454, -0.1477, -0.2662,  ..., -0.9573,  0.4093,  0.4073],
          [-0.5993,  0.6362, -0.0533,  ..., -0.6155,  1.5610, -0.7037],
          [-0.2530,  0.1004, -0.5784,  ..., -0.2070,  0.5543,  0.6050],
          ...,
          [ 0.4310,  0.2454,  0.4755,  ...,  0.1365,  0.2796,  0.5320],
          [-0.3572,  0.6259,  0.4723,  ..., -0.7015, -1.0135, -1.6197],
          [ 0.0746,  0.2546, -0.7271,  ...,  0.7949,  0.0690, -0.5031]],

         ...,

         [[-0.2134,  0.3219, -0.2290,  ...,  0.3704, -0.8611,  0.5134],
          [-0.0129, -1.4428,  0.3949,  ...,  1.0703,  1.4115,  0.2696],
          [ 0.1947, -0.5021, -0.0187,  ...,  1.0275, -0.5410,  0.7203],
          ...,
          [ 0.4984,  0.7396,  0.5283,  ...,  0.8209, -1.0560, -1.0523],
          [-1.9095, -1.5646, -0.0334,  ...,  1.6209, -0.3021, -0.2627],
          [-1.0303,  0.2261, -1.3961,  ..., -0.1892,  0.3890,  1.0288]],

         [[-0.5576,  1.4741, -0.4816,  ...,  0.1964, -1.0650, -0.2139],
          [-1.1255,  1.0031, -0.4426,  ...,  0.4044, -0.7082,  0.9192],
          [ 0.2012,  1.1542, -0.2299,  ..., -0.9817,  0.4657,  0.1230],
          ...,
          [-0.6997, -0.2290,  1.4194,  ...,  0.3089, -1.0956,  0.8073],
          [ 1.6187,  0.2898,  0.5798,  ...,  1.2501, -0.2113, -0.1699],
          [-0.1230, -1.0911, -0.0498,  ...,  0.0102,  0.3921, -0.3597]],

         [[ 0.0268,  1.3958, -1.3271,  ...,  0.0505,  1.5174, -1.2919],
          [ 0.1891, -1.4693,  0.1993,  ...,  0.4755, -0.6136, -1.0357],
          [ 0.4710, -0.4399, -0.4236,  ...,  0.5906,  0.2195,  0.1701],
          ...,
          [ 1.1820, -0.4357, -0.6343,  ..., -0.7740,  0.8785,  0.0527],
          [ 0.8563, -0.5610, -0.0296,  ..., -0.7923,  0.4748,  0.3095],
          [ 1.4234,  0.9120,  0.1244,  ..., -0.3501,  0.8764, -1.1154]]],


        [[[ 0.6379, -0.8805,  0.6617,  ..., -0.1316,  0.9472, -0.5717],
          [ 0.4328, -0.8192,  0.6503,  ..., -0.6833,  0.0438, -0.9863],
          [-0.0170, -0.3205, -0.9738,  ...,  0.2552, -0.7156, -0.8261],
          ...,
          [-0.7116, -1.3896, -1.8042,  ...,  0.9930,  1.2796,  0.6496],
          [-0.9875,  0.1526, -0.1506,  ...,  1.5660,  2.0929, -0.3237],
          [ 1.8315, -0.0460, -0.5761,  ...,  1.1371,  0.7636,  0.5857]],

         [[ 0.3168,  3.2341,  0.2561,  ..., -1.3285, -0.1859, -0.0324],
          [-0.2012, -0.1555, -0.6908,  ...,  1.7488, -0.5844, -0.5642],
          [ 0.4719, -0.1689,  1.6601,  ..., -0.7192, -0.9241, -0.8503],
          ...,
          [-1.1082, -0.3803, -0.3349,  ...,  1.0040,  1.1407, -0.1651],
          [ 1.0145,  0.0459, -0.9317,  ..., -0.8331, -0.3758, -0.4682],
          [ 0.0972,  0.0277, -0.0839,  ...,  1.0936, -0.0585, -0.4520]],

         [[ 0.9914, -0.4290, -0.2831,  ..., -0.9294,  0.6701,  0.4708],
          [-0.7924,  0.7379, -1.0581,  ...,  0.6024,  0.6708, -0.3762],
          [ 1.0996,  0.6896, -1.7443,  ..., -0.8329, -0.5106,  1.1019],
          ...,
          [ 0.1848,  0.1705,  0.7456,  ...,  0.2837,  0.4293,  0.6462],
          [-0.3216,  0.4864,  0.4873,  ..., -0.6214, -0.6364, -1.5178],
          [-0.1732, -0.2241, -0.8322,  ...,  0.7763,  0.1972, -0.5512]],

         ...,

         [[-0.0160,  0.2199, -0.1483,  ...,  0.3089, -0.7334,  0.2621],
          [-1.2576, -1.7775,  0.2703,  ...,  0.7181,  1.7428,  0.9473],
          [ 1.0461,  0.7570,  0.1600,  ...,  1.8827, -0.0231, -0.0663],
          ...,
          [ 0.8052,  0.4821,  0.6699,  ...,  0.7183, -0.7759, -1.2795],
          [-1.1753, -1.8669, -0.1740,  ...,  1.3596, -0.0751, -0.6003],
          [-0.7750,  0.0371, -1.1603,  ..., -0.0544,  1.0625,  0.8130]],

         [[-0.2942,  1.3663, -0.5308,  ...,  0.3166, -1.0881, -0.1037],
          [-0.0501,  1.7272, -1.2322,  ..., -1.3306, -1.1577,  0.2673],
          [ 0.0458,  1.6365, -0.0450,  ...,  0.6063,  0.4532,  1.2021],
          ...,
          [-0.3453, -0.3671,  1.2270,  ...,  0.4807, -0.9373,  0.7865],
          [ 2.1246,  0.0806,  0.5049,  ...,  1.1633, -0.0390, -0.1218],
          [ 0.3081, -1.3099, -0.1424,  ...,  0.0588,  0.5833, -0.1600]],

         [[-0.1078,  1.2415, -1.5009,  ..., -0.1165,  1.1165, -0.9612],
          [-0.1925,  0.3675, -0.2939,  ...,  1.1929,  0.2002, -0.3039],
          [-3.0344, -0.4685, -1.8780,  ..., -0.6028, -1.7705,  0.2040],
          ...,
          [ 0.7563, -0.9669, -0.6811,  ..., -1.0653,  0.4371,  0.3627],
          [ 0.5623, -0.9506,  0.0386,  ..., -1.2202, -0.0503,  0.7195],
          [ 0.8104,  0.6454, -0.1913,  ..., -0.3312,  0.8819, -0.6611]]]],
       grad_fn=&lt;SliceBackward0&gt;), tensor([[[[-6.9225e-01, -8.6235e-02, -2.3913e-02,  ...,  5.2182e-04,
            5.0705e-01,  9.2492e-01],
          [-8.4690e-03,  4.2347e-01,  4.4488e-02,  ..., -4.5095e-01,
           -6.4461e-01, -7.1103e-01],
          [ 3.7747e-01,  7.6635e-01, -4.8942e-01,  ...,  5.2421e-01,
           -4.9000e-01, -4.9867e-01],
          ...,
          [-6.3098e-01,  7.0760e-01,  1.9912e-01,  ..., -7.4724e-01,
           -4.1749e-01, -3.9548e-01],
          [-3.8089e-01,  1.5793e-01, -6.5837e-01,  ..., -2.1369e-01,
            1.7289e-02, -3.7339e-01],
          [-5.4333e-01,  3.3943e-01,  9.2538e-02,  ..., -1.2650e+00,
           -7.8162e-01, -2.7854e-01]],

         [[ 5.3773e-01,  2.0051e+00, -7.0954e-01,  ...,  1.0975e-01,
            7.1277e-01, -2.7239e-01],
          [-2.3015e-01,  1.6978e+00, -2.5360e-01,  ..., -3.9514e-01,
           -6.3184e-01, -1.0565e+00],
          [-4.0506e-01,  1.2826e+00, -2.9747e-01,  ...,  2.1480e+00,
            1.2943e-01, -2.5388e-01],
          ...,
          [-4.7979e-01,  1.0622e-01,  3.2000e-01,  ..., -6.6349e-01,
            6.7513e-01, -2.2739e-01],
          [ 3.8541e-01,  7.1452e-02, -6.8774e-01,  ..., -2.7411e-01,
            2.9301e-01, -3.9220e-01],
          [ 7.0534e-01,  5.1736e-01,  5.2808e-01,  ..., -1.3071e-01,
            8.1681e-01, -6.2947e-01]],

         [[-7.4259e-01, -1.9179e-01,  1.7502e+00,  ..., -6.0174e-01,
           -1.0788e+00, -8.4622e-01],
          [-6.1800e-01, -5.5680e-01, -1.2147e+00,  ...,  3.3582e-01,
           -8.2232e-01, -7.7695e-01],
          [ 1.3566e+00, -3.0812e-01, -4.1635e-01,  ...,  4.5131e-01,
            3.3204e-01,  8.4732e-01],
          ...,
          [-4.6458e-02,  9.8802e-01, -3.1632e-01,  ...,  1.0501e+00,
            3.4802e-01,  3.1673e-01],
          [ 4.7566e-01,  2.1773e-01, -6.5473e-01,  ...,  1.4730e-01,
            4.4923e-01,  1.1547e+00],
          [ 5.8766e-01, -3.1546e-01, -7.3987e-01,  ..., -2.1619e-01,
            2.7958e-01, -2.8598e-01]],

         ...,

         [[-3.6590e-01, -5.8104e-01,  7.7066e-01,  ...,  1.0824e+00,
           -7.5492e-01,  6.7063e-01],
          [ 3.1652e-01, -1.1067e-01, -2.4726e-01,  ...,  4.6299e-01,
            2.4017e-01,  1.0152e+00],
          [ 5.6395e-01,  1.1262e+00, -1.1502e+00,  ...,  1.5479e-01,
            5.9694e-01,  4.1479e-01],
          ...,
          [-4.1987e-01,  3.8315e-01, -1.3260e-01,  ..., -2.3239e-01,
            7.7730e-01, -5.0806e-01],
          [ 3.7072e-01, -3.9401e-02, -6.7806e-01,  ...,  2.6252e-01,
           -4.4145e-01, -8.1970e-01],
          [ 7.5148e-01, -2.8865e-02,  8.4630e-01,  ...,  3.6651e-01,
            1.3361e+00,  7.3687e-02]],

         [[ 4.7251e-01, -2.3206e-01,  4.8661e-01,  ..., -3.2048e-01,
           -2.9479e-03, -2.3741e-02],
          [ 1.9412e-01, -6.0270e-01, -2.2148e-02,  ..., -1.2478e-01,
           -5.0117e-01,  1.6415e-01],
          [ 1.4046e+00,  9.9121e-01,  2.7049e-03,  ..., -5.1365e-01,
           -1.7728e-01, -1.2539e-02],
          ...,
          [ 8.3707e-01,  7.9321e-01,  7.1341e-01,  ...,  1.0438e+00,
            7.9632e-01,  1.3536e+00],
          [ 7.8148e-01,  2.9604e-01,  3.3040e-01,  ..., -1.0760e-02,
           -3.6140e-01,  3.1064e-01],
          [ 4.4380e-01, -5.2092e-01,  3.7860e-01,  ...,  1.1100e+00,
           -7.5269e-01,  1.2252e-01]],

         [[ 1.6595e-01, -4.0771e-01,  1.1672e+00,  ...,  1.7320e-01,
           -2.5459e-01,  1.4581e-03],
          [ 5.2432e-01, -8.9160e-01,  1.4135e+00,  ..., -2.6170e-01,
            4.9682e-01, -1.8483e-01],
          [-7.0582e-01, -1.2020e+00,  6.6214e-02,  ..., -2.8845e-02,
           -1.2198e+00,  1.8644e-02],
          ...,
          [-9.2727e-01, -1.5637e-01,  8.7742e-01,  ..., -1.1703e+00,
           -7.3776e-01, -2.3842e-01],
          [-9.1357e-01, -1.0052e+00,  8.6252e-01,  ..., -1.2670e+00,
            4.4366e-02,  4.2487e-01],
          [-4.2936e-01, -9.3063e-01, -9.4334e-01,  ...,  9.8191e-02,
           -7.9160e-01, -8.9561e-01]]],


        [[[-6.0926e-01, -8.5310e-02,  1.4170e-01,  ..., -5.8299e-02,
            4.7512e-01,  9.7824e-01],
          [ 6.8439e-01,  1.9721e+00,  5.8705e-02,  ..., -1.0058e+00,
           -2.3058e-01, -1.8415e-02],
          [ 2.6710e-02, -5.6930e-01, -8.1226e-01,  ..., -8.6100e-01,
           -1.6417e+00,  1.5819e-01],
          ...,
          [-5.8813e-01,  7.2461e-01,  2.5640e-01,  ..., -1.1997e+00,
           -6.8491e-02, -4.6638e-01],
          [-4.6675e-01,  2.7148e-01, -6.6760e-01,  ..., -9.4335e-01,
            2.7454e-01, -2.2747e-01],
          [-6.7553e-01,  2.2508e-01,  1.1598e-01,  ..., -1.5957e+00,
           -6.8385e-01,  3.1628e-01]],

         [[ 6.3609e-01,  1.7976e+00, -6.5647e-01,  ...,  1.6832e-01,
            6.5235e-01, -1.4552e-01],
          [ 1.3234e+00, -4.4416e-02, -1.5120e+00,  ..., -2.9694e-01,
            8.1444e-01, -5.7584e-01],
          [ 4.0710e-01, -4.2378e-01, -3.1498e-01,  ..., -5.7164e-01,
            1.1047e-01, -2.6977e-01],
          ...,
          [-3.2633e-01, -1.5999e-01,  2.2909e-01,  ..., -7.4235e-01,
            5.7336e-01, -5.0077e-02],
          [ 5.0301e-01, -7.2368e-02, -5.7428e-01,  ..., -2.9604e-01,
            1.7114e-01, -2.0033e-01],
          [ 4.9031e-01,  2.7366e-01,  4.5276e-01,  ..., -1.2460e-01,
            8.1672e-01, -4.5791e-01]],

         [[-8.7512e-01, -1.5698e-01,  1.5723e+00,  ..., -2.6226e-01,
           -1.2539e+00, -8.2637e-01],
          [-6.2396e-02,  8.1165e-04, -1.3149e+00,  ..., -1.4601e-01,
            2.5212e-01,  5.6438e-01],
          [-7.1969e-02, -3.8267e-01, -1.5393e-01,  ...,  3.8794e-01,
           -1.4968e+00,  8.1935e-01],
          ...,
          [-1.3910e-02,  8.8566e-01, -5.8290e-01,  ...,  1.0643e+00,
            1.5518e-01,  2.5683e-01],
          [ 5.5292e-01, -2.4295e-01, -8.7927e-01,  ...,  2.2663e-01,
            2.2373e-01,  8.5859e-01],
          [ 5.0789e-01, -1.5001e-01, -1.1945e+00,  ..., -3.5646e-01,
           -3.1595e-03, -2.5819e-01]],

         ...,

         [[-6.4195e-01, -6.0932e-01,  7.8163e-01,  ...,  9.3841e-01,
           -9.4299e-01,  6.8104e-01],
          [ 2.1809e-01, -1.1816e+00, -9.5257e-01,  ..., -6.6933e-01,
            2.5985e-01, -4.9981e-01],
          [ 1.9683e-01,  7.2836e-01,  1.0264e+00,  ...,  1.9796e-01,
            4.3719e-01,  1.0973e-01],
          ...,
          [-7.7588e-01,  4.1506e-01, -2.8213e-01,  ..., -3.3525e-01,
            7.2113e-01, -6.5667e-01],
          [-2.4192e-01,  7.4519e-02, -7.4324e-01,  ..., -5.3820e-02,
           -5.3854e-01, -1.0669e+00],
          [ 2.6136e-01, -2.3797e-01,  8.6567e-01,  ..., -2.0922e-01,
            1.1730e+00, -2.2677e-01]],

         [[ 5.0538e-01, -7.4580e-02,  3.5768e-01,  ..., -2.4668e-01,
            6.8291e-02,  3.2235e-02],
          [ 1.8845e+00,  9.6184e-02, -1.0366e+00,  ..., -1.3208e+00,
           -1.2928e-02, -3.7994e-01],
          [ 5.6555e-01, -2.4078e-01, -1.3606e+00,  ...,  5.0007e-01,
            3.7760e-01, -1.3164e-01],
          ...,
          [ 7.0990e-01,  9.7860e-01,  6.2473e-01,  ...,  1.0878e+00,
            9.4817e-01,  1.3491e+00],
          [ 5.7738e-01,  6.5318e-01,  3.0427e-01,  ...,  1.3473e-01,
           -2.7588e-01,  6.2779e-01],
          [ 2.9322e-01, -3.6585e-01,  3.3321e-02,  ...,  1.2524e+00,
           -5.6200e-01,  3.9036e-01]],

         [[ 2.6401e-01, -3.1395e-01,  1.0736e+00,  ...,  2.2768e-01,
            5.9676e-02,  2.2289e-01],
          [ 4.4163e-01, -1.8440e-01,  4.3930e-01,  ..., -9.4821e-03,
            3.6147e-01, -1.0078e-01],
          [-1.4339e+00,  8.7045e-01, -1.8376e+00,  ...,  1.5617e+00,
            1.1465e+00,  1.6417e+00],
          ...,
          [-7.4799e-01,  7.0783e-02,  6.4389e-01,  ..., -1.2426e+00,
           -4.3454e-01,  9.6295e-03],
          [-7.7604e-01, -4.9898e-01,  4.8467e-01,  ..., -1.5874e+00,
            3.1084e-01,  5.6817e-01],
          [-1.7205e-01, -6.5901e-01, -1.2613e+00,  ..., -1.2266e-01,
           -3.2442e-01, -3.3595e-01]]]], grad_fn=&lt;SliceBackward0&gt;)), (tensor([[[[-1.4973e+00, -8.7146e-01, -2.6898e-01,  ..., -2.4897e+00,
            1.0216e+00, -1.4551e+00],
          [ 3.6423e-01,  1.1707e-01, -4.4604e-01,  ..., -7.7163e-01,
            2.5017e-01, -7.1768e-01],
          [ 2.7988e-02, -2.1133e+00, -1.3752e+00,  ...,  6.3329e-01,
            7.8978e-01, -2.6303e-01],
          ...,
          [ 5.0446e-01, -3.5854e-01,  1.3936e+00,  ...,  1.0084e-01,
           -2.9858e-01, -1.9458e+00],
          [ 7.1531e-01, -2.3246e-01, -3.1745e-02,  ...,  1.4221e+00,
           -9.5029e-01, -2.1072e+00],
          [ 4.9262e-01, -5.0428e-01,  1.3199e+00,  ...,  4.1377e-01,
            2.4554e-01, -5.6439e-01]],

         [[-3.3909e-01, -5.6326e-01, -2.3403e+00,  ..., -2.4875e-01,
           -6.5334e-01, -3.1420e-01],
          [ 7.4163e-02, -9.1746e-03, -7.7562e-01,  ..., -7.0166e-01,
            5.3035e-01,  2.7478e-01],
          [-9.4843e-01, -3.2074e-01, -3.8344e-01,  ..., -1.8069e-01,
           -3.4004e-01, -9.5452e-01],
          ...,
          [-1.0088e-01, -1.2577e+00, -1.5104e+00,  ...,  6.4446e-01,
           -4.1333e-02,  4.3739e-01],
          [-4.9704e-01,  4.9621e-01, -6.8449e-01,  ..., -3.4015e-03,
           -5.9145e-01,  7.8801e-01],
          [-8.7685e-01,  1.0099e+00, -2.5964e+00,  ..., -7.7252e-01,
            1.1479e+00,  1.1210e+00]],

         [[-1.5959e+00, -2.2106e+00,  1.0977e+00,  ..., -3.2455e-01,
           -1.4359e+00, -1.8357e+00],
          [-4.2242e-01,  8.2513e-01, -2.8049e-01,  ..., -8.1915e-01,
            5.5756e-01, -3.5696e-01],
          [ 4.8411e-01,  1.4982e-01,  7.5672e-01,  ..., -7.8707e-01,
           -2.5858e-01, -5.5284e-01],
          ...,
          [-1.5358e+00,  2.1188e-02,  1.8763e-01,  ..., -1.8286e+00,
            2.3373e+00,  5.8714e-01],
          [ 1.1488e-01, -4.0251e-01, -5.2378e-01,  ..., -5.1286e-01,
            1.9467e+00,  6.9344e-01],
          [ 1.1755e+00,  7.2210e-01, -1.4174e-01,  ..., -2.9972e-01,
            5.2154e-01, -6.3261e-01]],

         ...,

         [[-7.5437e-01, -1.3050e+00, -1.6307e-03,  ...,  6.5825e-01,
           -5.0687e-01,  5.6577e-02],
          [ 1.5644e+00, -1.7565e-01, -4.2230e-01,  ..., -9.2223e-02,
            2.9411e-01,  1.2862e+00],
          [ 4.7953e-01, -5.0074e-01, -1.1877e+00,  ...,  1.3467e+00,
           -9.2814e-01,  2.2748e+00],
          ...,
          [-8.0856e-02,  7.1892e-01, -1.9801e-01,  ..., -7.4237e-01,
            1.3421e-01,  3.4210e-01],
          [ 1.0369e+00,  1.8743e-04, -5.8461e-01,  ..., -3.9104e-01,
           -3.0065e-03,  8.7694e-01],
          [ 1.6049e+00,  9.0428e-01, -6.6358e-01,  ...,  7.9605e-01,
           -4.7573e-01,  2.7893e-01]],

         [[ 1.1432e+00,  7.7556e-01,  2.5738e-01,  ...,  1.0440e+00,
           -1.5902e+00, -6.7507e-02],
          [-2.5039e+00, -5.7925e-02,  1.7820e+00,  ...,  2.2491e+00,
           -5.0803e-01, -2.9204e-01],
          [-2.1951e-01,  1.4579e+00,  7.5645e-01,  ..., -2.3297e-02,
           -5.4205e-01,  1.0605e+00],
          ...,
          [-1.3829e-01,  9.6010e-01,  3.5389e-01,  ...,  6.1646e-01,
            3.0209e-01,  8.1465e-02],
          [-7.0815e-01,  7.7632e-01, -2.7195e-01,  ...,  9.0400e-01,
            4.1261e-01,  1.5276e+00],
          [-5.2681e-01, -2.5049e-01, -2.0841e-01,  ...,  1.1109e-01,
            5.2670e-01,  5.7710e-01]],

         [[ 1.6438e-01, -1.5029e+00,  6.2255e-01,  ...,  1.7893e-01,
            1.7594e+00, -3.0212e-01],
          [-6.2753e-01, -6.2021e-01,  3.6557e-01,  ...,  2.6977e+00,
            2.0869e-01, -2.1255e-02],
          [ 2.7752e-02, -2.1946e-01, -1.4753e+00,  ...,  1.0724e+00,
           -3.5050e-01,  7.7257e-01],
          ...,
          [ 1.9565e-01,  8.8208e-01,  1.5430e+00,  ...,  1.6399e+00,
            3.2760e-01, -2.2080e+00],
          [ 1.0194e-01,  1.3865e+00,  5.9588e-01,  ...,  7.1330e-01,
           -9.1427e-02,  1.0087e+00],
          [ 9.7428e-01,  6.7196e-01,  8.2634e-01,  ...,  1.4944e+00,
            1.4642e-02,  9.7790e-02]]],


        [[[-1.2421e+00, -9.3849e-01,  2.9043e-01,  ..., -2.7293e+00,
            1.2467e+00, -1.3095e+00],
          [-2.1822e-01, -1.2437e+00,  3.1833e-01,  ...,  9.0346e-02,
            2.7635e-01, -9.4781e-01],
          [ 4.7329e-01, -1.6631e+00, -2.2561e-02,  ..., -1.0695e+00,
            1.0774e+00, -1.3035e+00],
          ...,
          [ 1.3765e-01, -4.5961e-01,  1.7399e+00,  ...,  2.8554e-01,
           -1.8405e-01, -2.0122e+00],
          [ 8.3286e-01, -3.6188e-01,  4.1980e-01,  ...,  1.2572e+00,
           -1.0249e+00, -1.9559e+00],
          [ 9.6271e-01, -7.7418e-02,  1.7593e+00,  ...,  6.0480e-01,
            1.9209e-01, -2.7059e-01]],

         [[-4.1102e-01, -2.3191e-01, -2.0051e+00,  ..., -6.2406e-01,
           -1.9433e-01, -4.4396e-01],
          [ 1.3476e-01, -8.1467e-01, -2.8825e-01,  ..., -7.9886e-01,
           -7.2412e-01, -8.1461e-02],
          [-2.1274e+00, -9.8275e-01, -7.0232e-02,  ...,  6.7782e-01,
           -9.5052e-01, -1.2465e+00],
          ...,
          [-8.4990e-01, -1.1587e+00, -1.3050e+00,  ...,  7.6410e-01,
            2.3342e-01,  1.8360e-01],
          [-4.8102e-01,  9.2336e-01, -3.7911e-01,  ...,  1.4763e-01,
           -5.6558e-01,  3.4280e-01],
          [-5.4606e-01,  8.0720e-01, -2.1749e+00,  ..., -1.5117e-01,
            9.0764e-01,  5.8874e-01]],

         [[-1.5456e+00, -2.2755e+00,  6.9664e-01,  ..., -4.5026e-01,
           -1.4554e+00, -1.2307e+00],
          [ 2.0691e+00,  2.2132e+00, -1.0307e+00,  ...,  1.2446e-02,
            2.5627e+00,  5.0446e-01],
          [-2.6739e-01, -9.5957e-01,  2.3743e+00,  ..., -2.8300e+00,
           -5.9305e-02, -8.4889e-01],
          ...,
          [-1.4543e+00, -4.3024e-01,  5.2102e-01,  ..., -2.4267e+00,
            2.0887e+00,  4.9834e-01],
          [-1.1585e-01, -1.2186e+00,  1.5300e-01,  ..., -9.8184e-01,
            1.5473e+00,  6.8710e-01],
          [ 1.3745e+00,  5.5926e-01, -3.0946e-01,  ..., -4.9713e-01,
            1.2485e-01, -3.3547e-01]],

         ...,

         [[-8.4436e-01, -1.7565e+00, -1.8964e-01,  ...,  5.4165e-01,
           -9.4231e-02, -1.2528e-01],
          [-1.4373e-01, -1.7489e+00, -1.4445e+00,  ..., -2.8645e-01,
            3.0451e-02,  9.1370e-01],
          [-9.3749e-01, -3.0216e-01,  2.5991e-01,  ..., -1.4051e+00,
           -6.6138e-01,  1.5291e+00],
          ...,
          [-2.5835e-01,  1.0030e+00, -6.9844e-01,  ..., -7.7500e-01,
            6.6706e-01,  6.8073e-01],
          [ 2.7284e-01,  5.2542e-01, -7.9255e-01,  ..., -2.7631e-01,
            8.2238e-01,  8.6949e-01],
          [ 1.3971e+00,  1.0991e+00, -1.0577e+00,  ...,  8.5873e-01,
            1.5739e-01,  9.7901e-01]],

         [[ 1.0417e+00,  5.7617e-01, -2.6387e-01,  ...,  1.0984e+00,
           -2.1561e+00, -1.7069e-01],
          [ 2.6936e-01, -3.0826e-01,  8.5458e-01,  ...,  1.8561e+00,
            4.7692e-01, -8.0228e-01],
          [ 3.7703e-02,  8.1668e-01, -1.4547e+00,  ...,  1.3535e+00,
           -4.1001e-01,  6.8687e-02],
          ...,
          [-3.3887e-01,  6.7123e-01, -4.7569e-04,  ...,  2.1964e-01,
           -1.1869e-01,  6.0006e-01],
          [-8.6949e-01,  7.1597e-01, -9.7713e-01,  ...,  2.1736e-01,
           -3.4020e-01,  1.5980e+00],
          [-1.0407e+00, -5.1045e-01, -2.9114e-01,  ..., -1.8082e-01,
           -3.4004e-02,  5.6772e-01]],

         [[ 1.6219e-02, -1.2539e+00,  2.8142e-01,  ...,  2.0996e-01,
            1.7298e+00, -3.1795e-01],
          [ 1.1527e+00, -7.7719e-03, -1.2197e+00,  ..., -2.4761e-01,
            1.1038e-01, -6.8184e-01],
          [-4.5157e-01, -1.3857e+00,  1.1488e+00,  ...,  1.2731e+00,
            4.6336e-01, -4.7560e-01],
          ...,
          [ 3.6374e-01,  5.7689e-01,  1.5040e+00,  ...,  1.8712e+00,
            2.1075e-01, -1.7562e+00],
          [ 2.5781e-01,  1.2828e+00,  1.0572e+00,  ...,  9.4024e-01,
            4.1424e-01,  1.0013e+00],
          [ 5.6027e-01,  9.3355e-02,  5.0406e-01,  ...,  1.6577e+00,
            3.9181e-01,  4.0939e-02]]]], grad_fn=&lt;SliceBackward0&gt;), tensor([[[[ 1.5202e-01,  4.9815e-01, -1.0323e-01,  ..., -4.5924e-01,
           -5.7551e-01,  2.8249e-01],
          [ 4.9065e-01, -5.4043e-01, -7.6391e-01,  ...,  4.2971e-01,
           -8.5069e-01, -6.0732e-01],
          [-5.6013e-01,  3.9550e-01,  3.8520e-01,  ..., -9.0020e-01,
            3.9479e-01, -6.4134e-01],
          ...,
          [ 4.4851e-01,  5.6500e-01,  9.2207e-01,  ...,  8.8227e-01,
           -5.4115e-01, -6.2747e-01],
          [ 9.5350e-01, -9.4110e-01,  1.3734e+00,  ...,  7.1261e-01,
           -2.6114e-01, -4.5924e-01],
          [-1.5957e-03,  2.2667e-01, -8.4375e-01,  ...,  7.3414e-01,
           -6.7901e-02,  3.4550e-01]],

         [[-1.5476e-01, -1.3419e+00,  4.0170e-02,  ..., -2.0279e-01,
            2.3105e-01,  3.5525e-01],
          [-1.1263e-01, -1.1670e+00,  2.7564e-01,  ...,  7.8952e-01,
           -1.9808e-01, -8.6554e-01],
          [ 7.8433e-01, -1.4938e+00,  3.0061e-02,  ..., -4.0351e-01,
            1.9862e+00, -6.6651e-03],
          ...,
          [ 4.3409e-01, -1.3359e-01, -5.2352e-01,  ..., -1.0661e-01,
           -1.5665e-01, -6.2805e-01],
          [ 4.6332e-01, -1.0520e+00,  8.9743e-01,  ...,  5.5685e-03,
           -1.0599e+00,  3.4884e-02],
          [-5.6180e-03, -9.7093e-01,  5.9384e-02,  ...,  1.9605e-01,
            5.3872e-01,  9.6990e-01]],

         [[-6.0428e-01,  3.6242e-01,  6.0000e-01,  ...,  3.7929e-01,
            1.0534e+00,  6.0432e-01],
          [-5.2510e-01, -2.7924e-01, -4.1220e-01,  ...,  9.7930e-01,
           -1.6717e-01,  3.2723e-01],
          [-1.6752e+00, -1.6439e+00,  7.0241e-01,  ..., -6.7908e-01,
            4.2389e-01, -9.3648e-01],
          ...,
          [-3.3425e-01,  1.1878e-02,  7.0465e-01,  ...,  1.3187e-01,
           -3.0125e-01,  7.1115e-01],
          [ 4.5991e-01,  3.4907e-01,  6.6549e-02,  ...,  1.5457e+00,
           -2.5028e-01,  1.0241e-01],
          [ 6.5587e-01,  1.2889e-01,  7.2727e-02,  ...,  3.5015e-01,
           -1.3377e+00,  1.6162e-01]],

         ...,

         [[ 1.1356e+00, -1.9776e-01, -4.5054e-01,  ...,  2.7543e-01,
           -5.6334e-01, -1.1075e-01],
          [ 4.8669e-01, -7.3847e-01, -1.0116e+00,  ..., -3.1529e-01,
            3.0410e-01, -7.7571e-01],
          [ 1.4547e+00,  3.2651e-01, -7.5107e-01,  ...,  6.1786e-01,
            2.3149e-01,  2.0983e-01],
          ...,
          [ 9.8245e-01, -5.1509e-01, -1.2704e+00,  ..., -2.3438e+00,
            5.8232e-01,  2.9785e-01],
          [-3.5211e-01, -7.8160e-01, -1.3272e+00,  ..., -2.5487e-01,
            2.5711e-01, -4.8990e-01],
          [ 4.6216e-02,  7.2090e-01,  2.5475e-01,  ..., -1.5012e+00,
            3.9393e-01,  3.5587e-01]],

         [[-1.0408e+00, -8.7434e-01, -9.7044e-02,  ..., -7.8571e-01,
            2.9134e-01,  4.6353e-01],
          [-7.5741e-01, -4.7679e-01,  4.7995e-01,  ...,  1.0632e-01,
            2.2990e-01, -4.7195e-01],
          [-5.6367e-01,  3.7807e-01,  1.0053e+00,  ...,  1.5842e-01,
            9.7692e-02, -5.6090e-01],
          ...,
          [-8.0197e-01,  7.1200e-01, -6.2207e-01,  ...,  1.0414e-01,
            9.0345e-01,  3.6316e-01],
          [-6.7115e-01, -1.0832e+00,  4.1571e-01,  ...,  6.6142e-01,
            7.1565e-01,  1.5585e-01],
          [-7.2494e-01, -8.4598e-01,  3.8811e-01,  ...,  1.5846e-01,
            1.2773e+00, -7.9991e-01]],

         [[ 1.5220e-01, -2.8540e-01, -6.5491e-01,  ...,  6.9340e-01,
           -1.6653e-01, -2.2305e-01],
          [-8.1314e-01,  1.3755e+00,  1.8618e-02,  ...,  8.1482e-01,
            1.0765e+00,  6.0754e-01],
          [-1.4685e-01, -1.4005e+00,  8.8600e-01,  ..., -3.8173e-01,
            7.6143e-01,  2.1547e-01],
          ...,
          [ 9.9684e-01, -1.9042e-01,  6.9671e-01,  ..., -1.6164e-01,
            3.0401e-01,  1.1303e-01],
          [-4.0903e-01,  1.0075e-01,  4.7314e-01,  ..., -9.7912e-01,
            7.1196e-01,  4.6767e-01],
          [-1.3934e-01, -7.8715e-01, -5.4595e-01,  ..., -4.0936e-01,
            9.3347e-01,  1.1935e-01]]],


        [[[ 1.2117e-01,  7.5605e-01, -1.4175e-01,  ..., -4.2038e-01,
           -4.5723e-01,  5.2235e-01],
          [ 2.2427e+00,  7.9111e-01, -5.1527e-01,  ...,  1.3351e+00,
            2.0398e-01,  1.2193e+00],
          [-8.4189e-01,  7.1537e-01,  8.7461e-02,  ..., -8.0387e-01,
           -5.1773e-01, -1.0383e+00],
          ...,
          [ 1.3063e-02,  7.8948e-01,  9.2315e-01,  ...,  9.9531e-01,
           -7.4365e-01, -6.5788e-01],
          [ 4.5846e-01, -1.0823e+00,  2.0247e+00,  ...,  9.6114e-01,
           -9.0116e-02, -8.3256e-01],
          [-4.5643e-01,  9.9904e-01, -6.4704e-01,  ...,  6.0634e-01,
            8.6339e-02,  1.4280e-01]],

         [[-4.6502e-01, -1.1485e+00,  1.6679e-01,  ..., -5.3292e-02,
            1.7444e-01,  1.1508e-01],
          [ 4.1204e-01, -2.3472e+00,  1.2940e+00,  ..., -6.9818e-01,
            9.2824e-01, -8.9583e-01],
          [ 2.0952e-01, -1.1784e+00, -8.9157e-01,  ...,  2.0133e+00,
           -5.4938e-01, -2.6806e+00],
          ...,
          [ 5.1220e-01,  2.5948e-02, -2.2050e-01,  ...,  6.4226e-01,
           -1.9029e-01, -4.3868e-01],
          [ 2.3906e-01, -5.7505e-01,  9.9071e-01,  ...,  1.8572e-01,
           -1.5155e+00,  6.2679e-01],
          [ 8.0763e-02, -1.2720e+00,  5.0906e-01,  ...,  2.7580e-01,
            6.0078e-01,  1.0945e+00]],

         [[-3.6014e-01,  3.2527e-01,  3.8899e-01,  ...,  6.0025e-01,
            9.3316e-01, -7.7299e-02],
          [-2.5762e-01,  2.2067e-01, -9.4541e-01,  ..., -6.4035e-02,
           -9.0892e-01,  1.1157e+00],
          [ 5.2695e-01, -4.9842e-01,  1.0638e-01,  ..., -1.4627e-01,
            6.0169e-01, -2.1153e+00],
          ...,
          [-3.3778e-01,  2.9289e-01,  1.1749e+00,  ...,  1.8556e-01,
           -5.3838e-01,  6.6205e-01],
          [ 6.6937e-01,  7.7618e-01,  5.8851e-01,  ...,  1.8163e+00,
           -2.1148e-01, -2.5378e-01],
          [ 7.3907e-01,  2.7423e-02, -1.2438e-03,  ...,  6.5292e-01,
           -8.1415e-01, -4.1154e-01]],

         ...,

         [[ 1.1307e+00, -1.4537e-01, -5.2899e-01,  ...,  5.3038e-01,
           -1.1272e+00,  1.7626e-01],
          [ 1.3349e+00,  3.3739e-01,  9.2019e-01,  ..., -3.9250e-01,
            9.1435e-01,  1.1049e+00],
          [-1.8037e-01,  6.8808e-01, -1.2309e+00,  ...,  1.5958e+00,
           -7.7217e-01, -8.3669e-01],
          ...,
          [ 9.9639e-01, -5.3479e-01, -1.3343e+00,  ..., -1.6949e+00,
            3.6586e-01,  7.3246e-01],
          [-4.8805e-01, -9.6775e-01, -1.2164e+00,  ...,  1.0214e-01,
            2.9856e-01, -3.7874e-01],
          [ 2.8865e-01,  5.0572e-01,  5.2405e-01,  ..., -1.2645e+00,
            2.8438e-01,  3.6254e-01]],

         [[-6.1373e-01, -5.4370e-01, -5.7429e-01,  ..., -1.1152e+00,
           -3.8261e-02,  6.0385e-01],
          [ 1.2796e+00, -3.5175e-01,  1.4035e+00,  ...,  9.5949e-01,
            3.0124e-01, -7.6347e-01],
          [-4.3177e-01, -1.4824e-02, -1.5778e+00,  ..., -8.0742e-01,
            1.1896e+00,  1.4095e+00],
          ...,
          [-4.3904e-01,  6.1028e-01, -5.8194e-01,  ..., -2.3729e-01,
            4.2622e-01,  3.3864e-01],
          [-5.5094e-01, -1.2237e+00, -3.4662e-01,  ...,  3.5473e-01,
            5.6396e-01,  5.8785e-01],
          [-3.5808e-01, -8.3340e-01,  2.2828e-01,  ..., -3.2475e-01,
            7.5720e-01, -6.5483e-01]],

         [[-2.1950e-02, -5.1649e-01, -7.4524e-01,  ...,  9.4568e-01,
           -6.1469e-01, -4.1687e-01],
          [ 2.0348e-01,  7.2043e-01,  1.5306e-01,  ...,  2.8219e-01,
           -2.6684e-01, -9.1239e-01],
          [-1.6175e+00,  9.9794e-01, -3.3424e-01,  ..., -6.9282e-01,
           -8.6941e-01,  6.8771e-01],
          ...,
          [ 7.1653e-01,  1.1695e-01,  2.0990e-01,  ..., -1.6689e-01,
            3.3925e-01,  9.5178e-02],
          [-1.9238e-01,  6.7889e-02, -1.6031e-01,  ..., -9.8805e-01,
            6.6318e-01,  3.0045e-01],
          [-4.9893e-03, -1.9014e-01, -5.0441e-01,  ..., -3.1127e-01,
            1.0714e+00,  8.8301e-02]]]], grad_fn=&lt;SliceBackward0&gt;)), (tensor([[[[ 1.4861e+00,  3.3256e-01, -2.7052e+00,  ..., -5.5524e-01,
           -9.7125e-01, -1.3294e+00],
          [ 1.4432e+00,  8.3162e-01,  8.6520e-02,  ...,  3.1300e-01,
           -5.1590e-02,  1.3802e+00],
          [-3.9119e-01, -4.0472e-01,  7.1470e-01,  ..., -2.4295e-01,
            1.3039e+00, -1.1781e+00],
          ...,
          [ 6.8984e-01,  4.2478e-01,  1.2346e+00,  ...,  1.3184e-01,
            1.7878e+00,  1.5570e+00],
          [-1.6566e+00,  7.7455e-01,  1.8017e+00,  ..., -3.7989e-01,
            7.0449e-01,  1.9470e+00],
          [-1.5604e+00,  7.3988e-01,  9.4228e-01,  ..., -2.5508e-01,
            7.6339e-01,  9.3639e-01]],

         [[-1.2221e+00, -2.1794e+00,  7.2703e-01,  ...,  2.0538e+00,
           -1.2340e-01, -4.5001e-01],
          [-1.2932e+00, -4.4022e-01,  1.0763e+00,  ...,  1.1312e+00,
           -8.9997e-01,  3.1236e-02],
          [ 2.9022e-01, -2.3099e-01,  1.0936e+00,  ...,  6.5938e-01,
           -5.3988e-02, -6.3385e-01],
          ...,
          [ 1.2403e+00, -1.3548e+00,  8.1075e-02,  ...,  7.9200e-01,
           -7.4513e-01, -2.7460e-01],
          [ 1.2597e+00,  6.7813e-01, -7.5163e-01,  ..., -5.8502e-01,
           -1.5006e+00, -9.5387e-01],
          [ 1.7521e+00,  3.2469e-01,  1.7494e-02,  ..., -2.8540e-01,
           -2.4851e+00,  1.0296e+00]],

         [[ 4.5641e-01, -6.4466e-01,  5.2711e-01,  ..., -7.5219e-01,
           -2.6667e-01,  8.1356e-01],
          [-1.5578e-01, -3.8969e-01,  8.5773e-01,  ..., -8.5508e-01,
           -3.7471e-01, -5.8667e-01],
          [-1.0365e+00, -4.7672e-01,  4.7233e-01,  ..., -5.0378e-01,
           -3.0829e-01, -7.8448e-01],
          ...,
          [ 1.1067e+00, -9.0934e-02, -5.5070e-01,  ...,  2.2157e-01,
           -7.8159e-01,  7.0813e-01],
          [ 4.4252e-01, -2.7429e-01, -3.2612e-01,  ..., -5.6911e-02,
            3.3634e-01,  1.2480e+00],
          [-4.5798e-01, -2.6820e-01, -2.1740e-01,  ...,  3.7155e-01,
            5.4576e-01,  1.0016e+00]],

         ...,

         [[-1.2319e+00,  6.6492e-02,  1.6103e+00,  ...,  5.6447e-01,
            6.4761e-01, -5.3909e-02],
          [-4.4159e-01, -6.4843e-01,  4.1525e-02,  ...,  1.1187e+00,
            4.6718e-01,  9.6802e-01],
          [-4.0628e-01, -8.8379e-01, -5.8083e-02,  ...,  1.0941e+00,
            7.1802e-01,  9.6804e-01],
          ...,
          [ 1.3833e+00,  1.6021e+00,  7.6785e-01,  ...,  1.1107e+00,
            1.3164e+00,  7.7894e-01],
          [-5.5047e-02,  1.3129e+00,  2.9747e-01,  ...,  7.1375e-01,
            1.5552e+00,  3.7900e-01],
          [ 2.9887e-01,  5.2319e-01,  4.2036e-01,  ...,  1.5002e+00,
            7.2983e-01,  1.2236e+00]],

         [[-2.4051e+00, -6.2924e-01, -1.4077e+00,  ..., -1.0604e+00,
           -9.7096e-01,  4.3184e-01],
          [-1.4653e+00,  7.3813e-01, -2.4309e-01,  ...,  3.9321e-02,
           -1.0932e+00,  2.3068e+00],
          [-3.5448e+00, -1.7462e+00, -6.3666e-01,  ..., -2.0922e+00,
           -4.3501e-01, -3.6017e-02],
          ...,
          [ 7.3145e-01,  7.1348e-02,  5.9704e-01,  ...,  1.1878e+00,
           -9.5462e-02,  3.1659e-01],
          [ 6.0584e-01,  8.2117e-01,  3.5355e-01,  ..., -5.2773e-01,
           -1.6430e-01,  7.1911e-02],
          [-3.5545e-01,  9.0207e-01,  1.0904e+00,  ..., -7.7911e-01,
           -7.9976e-01, -8.4075e-01]],

         [[ 2.5390e+00,  2.4562e+00, -1.3933e+00,  ...,  2.0166e+00,
            1.1412e+00, -8.9200e-01],
          [ 2.1798e+00,  2.3158e+00, -2.1654e-01,  ...,  3.3783e+00,
           -5.3904e-01, -1.7433e-02],
          [ 1.3071e+00,  1.7488e-01, -8.7454e-01,  ...,  1.9319e+00,
           -1.7238e-01,  2.1395e+00],
          ...,
          [-5.7034e-01,  1.1057e+00,  2.4102e+00,  ...,  6.7794e-01,
           -1.7558e+00, -1.6150e-01],
          [-7.3815e-01, -1.3881e+00,  1.5598e+00,  ...,  1.3276e+00,
           -1.7900e+00,  6.1818e-01],
          [ 2.2991e-01, -2.5661e-01,  9.2056e-01,  ...,  3.8975e-01,
           -1.5442e+00, -4.9355e-01]]],


        [[[ 1.1515e+00, -1.7538e-01, -2.4685e+00,  ..., -6.3485e-01,
           -7.5513e-01, -1.9360e+00],
          [ 4.9321e-01,  3.4447e-01,  1.1832e-01,  ..., -6.1602e-01,
           -1.1835e+00, -1.3683e+00],
          [ 2.2399e+00,  7.8808e-01, -3.2128e-01,  ..., -8.9989e-01,
            4.2516e-01, -2.2196e+00],
          ...,
          [ 8.7337e-01, -2.2185e-01,  1.2653e+00,  ...,  7.1710e-01,
            1.7619e+00,  1.6203e+00],
          [-1.6929e+00,  6.5405e-01,  1.6983e+00,  ...,  8.3369e-02,
            4.6945e-01,  1.9084e+00],
          [-1.4491e+00,  3.2236e-01,  1.0166e+00,  ..., -1.8934e-01,
            7.6747e-01,  1.1422e+00]],

         [[-9.3005e-01, -2.5324e+00,  4.5441e-01,  ...,  1.3516e+00,
           -4.8225e-01, -3.8534e-01],
          [-5.9443e-02, -4.3253e-01, -5.5058e-01,  ...,  9.5287e-04,
           -1.8508e+00,  6.8159e-01],
          [ 8.8596e-01, -1.4570e+00,  5.3859e-01,  ...,  6.9005e-01,
           -8.4139e-01, -1.8245e+00],
          ...,
          [ 1.3265e+00, -1.0653e+00,  4.4358e-01,  ...,  8.7770e-01,
           -1.2419e+00, -6.2553e-01],
          [ 1.6095e+00,  2.9309e-01, -9.5475e-01,  ..., -8.4135e-01,
           -1.0459e+00, -1.1314e+00],
          [ 1.9767e+00,  7.6274e-01,  7.3833e-02,  ..., -4.3069e-01,
           -2.4486e+00,  8.4888e-01]],

         [[-2.9434e-01, -6.6325e-01,  1.1603e-01,  ..., -1.8546e-01,
           -4.5107e-01,  1.2411e+00],
          [ 4.6783e-02, -3.6099e-01, -6.2855e-01,  ..., -5.8712e-01,
           -1.3070e+00, -1.3789e-01],
          [-6.1932e-01,  1.1830e+00, -7.4503e-01,  ...,  9.1004e-01,
           -5.0870e-01, -6.3397e-02],
          ...,
          [ 1.1957e+00,  7.4289e-01, -3.3704e-02,  ...,  1.5462e-01,
           -1.0593e+00,  2.7873e-01],
          [ 5.0215e-01,  6.1077e-01, -1.2426e-01,  ...,  3.3990e-01,
            1.3882e-01,  1.2457e+00],
          [ 3.1555e-01,  6.7053e-01,  2.4521e-01,  ...,  1.7062e-01,
            5.8918e-01,  1.5763e+00]],

         ...,

         [[-1.1956e+00,  4.4359e-01,  1.5400e+00,  ...,  4.8795e-01,
            2.0788e-01,  5.7635e-02],
          [-1.5194e+00,  6.4507e-02, -1.8943e+00,  ...,  2.5408e+00,
            6.0521e-01,  5.2461e-01],
          [-1.4906e+00,  1.1620e+00, -1.0736e-01,  ...,  2.1893e+00,
           -4.7339e-01, -8.1836e-01],
          ...,
          [ 1.0254e+00,  8.2149e-01,  6.5381e-01,  ...,  1.0329e+00,
            1.5683e+00,  4.0970e-01],
          [-9.0313e-01,  1.1203e+00,  6.3111e-01,  ..., -1.2326e-01,
            1.2146e+00,  4.6537e-01],
          [-7.9224e-01,  6.8719e-01,  7.8754e-01,  ...,  1.6889e+00,
            1.1129e+00,  1.5146e+00]],

         [[-2.9517e+00, -8.5877e-01, -2.1857e+00,  ..., -1.5192e+00,
           -5.2459e-01,  1.3955e+00],
          [-2.8341e+00, -4.3968e-01, -8.5138e-01,  ..., -1.3334e+00,
           -1.2233e+00,  1.0084e+00],
          [-2.8942e+00, -1.9447e+00,  6.5674e-01,  ...,  7.0297e-01,
           -4.3100e-01,  1.6189e+00],
          ...,
          [ 2.8196e-02, -3.4330e-01,  2.4235e-01,  ...,  6.0912e-01,
            5.5999e-01,  4.8215e-01],
          [-3.1619e-01,  4.5550e-01,  8.5081e-02,  ..., -8.8915e-04,
            7.8680e-02,  2.3746e-01],
          [-6.0640e-01,  6.6355e-01,  6.0701e-01,  ..., -1.1138e+00,
           -1.3675e-01, -1.0490e+00]],

         [[ 3.1484e+00,  2.7411e+00, -1.6943e+00,  ...,  1.2743e+00,
            1.6933e+00, -1.2173e+00],
          [ 1.2249e+00,  1.5645e+00, -1.6819e+00,  ...,  9.5197e-01,
           -6.2620e-01,  8.7086e-01],
          [ 1.0041e+00,  3.0991e+00,  1.0703e+00,  ...,  1.7807e+00,
            3.0226e-01,  5.0259e-01],
          ...,
          [-4.5720e-01,  8.8306e-01,  1.9394e+00,  ...,  8.3644e-01,
           -1.3762e+00, -2.1242e-01],
          [-3.8886e-01, -1.5806e+00,  1.4321e+00,  ...,  1.3013e+00,
           -1.8314e+00,  6.3128e-01],
          [ 2.6165e-01, -9.2249e-01,  8.6146e-01,  ...,  4.5546e-01,
           -1.3717e+00, -3.9328e-02]]]], grad_fn=&lt;SliceBackward0&gt;), tensor([[[[-0.0280,  0.5879, -1.0148,  ..., -0.4084,  0.0098, -0.8906],
          [-0.9094,  1.0972,  0.6939,  ...,  0.5400,  0.4051,  0.1658],
          [-0.7279,  0.0123,  0.8590,  ...,  1.2926,  1.3681, -0.4779],
          ...,
          [-0.0270,  0.5832,  0.5161,  ..., -0.5907,  1.4780, -0.2920],
          [ 0.7290, -0.4587, -0.3466,  ...,  0.3848,  0.5888, -1.1412],
          [ 1.9044, -0.8934,  0.5703,  ..., -0.2452,  0.2441,  0.0159]],

         [[-0.4061,  0.1614, -0.2600,  ..., -0.1561, -0.0680,  0.6267],
          [-0.2732, -0.3262,  0.4460,  ..., -0.1148, -0.1297, -0.3474],
          [ 0.1137,  0.3977, -1.2040,  ..., -0.7727, -0.8333,  0.5672],
          ...,
          [-1.0291, -1.4539,  0.9286,  ...,  0.5921,  0.5964,  0.8151],
          [-0.9556, -0.5950,  0.6233,  ...,  0.8203,  1.5952, -0.4464],
          [-0.4989, -0.5701,  1.0755,  ..., -0.0834,  0.3257, -0.4846]],

         [[-0.5093,  0.6593,  1.2823,  ...,  0.3461, -0.5171,  0.3766],
          [-0.7996,  0.8184,  0.2581,  ..., -0.2177,  1.1026,  1.1717],
          [ 0.3521, -0.4509,  0.4881,  ...,  1.3422, -0.8343,  0.8271],
          ...,
          [-0.2624, -0.0311, -0.9995,  ...,  0.1647, -1.0796,  0.2805],
          [ 0.2780, -0.1857, -0.3353,  ..., -1.1080,  0.6886,  0.9687],
          [ 0.5271,  0.7354,  0.6245,  ...,  0.0988, -0.6618,  0.9661]],

         ...,

         [[ 0.1578, -0.1565, -0.7897,  ...,  0.1922,  0.2998, -0.4872],
          [-0.0661,  1.6370,  1.2897,  ...,  0.0458, -0.6296,  0.8467],
          [ 0.1028, -1.1194, -0.1003,  ..., -0.2813, -0.1776, -1.7658],
          ...,
          [ 0.3235,  1.0519,  0.7029,  ...,  0.2338,  0.2317, -0.4713],
          [-0.8115, -1.0458,  0.7536,  ...,  0.8732,  0.6539, -0.1575],
          [ 0.9089,  0.0409,  0.3054,  ...,  1.2995,  0.6927, -0.1508]],

         [[ 0.0855,  0.2263,  0.6205,  ..., -0.5828,  0.5376, -1.4511],
          [ 1.0133, -0.0498, -0.0237,  ...,  0.0767,  0.5579, -0.6016],
          [ 0.2026, -0.1862, -0.2570,  ..., -0.5589,  1.1690, -0.3479],
          ...,
          [ 0.6356,  0.8384, -0.3621,  ...,  1.3971,  1.4526,  0.5614],
          [ 0.9101, -0.2331, -1.2467,  ..., -0.2094,  1.0146,  0.2540],
          [ 1.5391, -0.9966,  0.6144,  ..., -0.0984,  1.3801, -0.9474]],

         [[-0.0450,  0.1167,  1.0272,  ...,  0.7206,  0.3369,  0.3064],
          [-0.2025,  1.6125, -0.6354,  ...,  0.2168,  0.6425, -0.1049],
          [ 0.1452, -2.1385,  1.2220,  ...,  0.2463,  1.4379,  0.3001],
          ...,
          [-1.3593, -0.7200, -0.7409,  ..., -0.6883, -0.4905,  0.4153],
          [-0.6351, -0.2555, -0.9554,  ..., -1.2080, -0.3239, -0.0395],
          [-0.0201,  0.4419, -1.5873,  ...,  0.1243,  0.3588,  1.1767]]],


        [[[ 0.1502,  0.1652, -0.6371,  ..., -0.1175,  0.2219, -0.3463],
          [-0.3343,  0.4163,  0.6774,  ...,  0.5609,  1.0828,  0.7432],
          [-1.3221,  1.9855, -0.5557,  ...,  0.3955,  0.5702,  0.0466],
          ...,
          [-1.1212,  0.6199,  0.9831,  ..., -0.6258,  1.5989, -0.4805],
          [ 0.3995, -0.0133, -0.8705,  ...,  0.0768,  0.7491, -1.6619],
          [ 1.4017, -1.0356,  0.2460,  ..., -0.6628,  0.0594,  0.2511]],

         [[-1.1014, -0.2468, -1.0223,  ...,  0.2221,  0.2812,  0.9189],
          [-2.0180,  0.8960, -2.0236,  ..., -0.1697, -0.2165,  0.1760],
          [-2.0800, -0.7763, -1.3734,  ..., -0.4931, -0.5595,  0.9252],
          ...,
          [-0.8373, -1.1056,  0.4421,  ...,  0.3361,  0.3262,  0.6378],
          [-0.7383, -0.5370,  0.0647,  ...,  0.5760,  1.7355, -0.2361],
          [-0.7545,  0.1964,  0.8956,  ..., -0.3292,  1.0578, -0.4592]],

         [[-0.2029,  0.3342,  0.5847,  ...,  0.4000, -0.2279,  0.4460],
          [-0.1387, -0.1449,  0.4782,  ..., -0.1168, -0.4185,  0.4375],
          [ 0.1885,  0.0186,  0.2806,  ...,  0.4424, -0.6211,  0.4311],
          ...,
          [ 0.1874, -0.3049, -1.4758,  ...,  0.2901, -1.0351,  0.1325],
          [ 0.4879, -0.9416, -0.8232,  ..., -1.0540,  0.4281,  0.4757],
          [ 0.5145,  0.2341,  0.0260,  ...,  0.3873, -0.7066,  1.0173]],

         ...,

         [[-0.4128,  0.1032, -0.6936,  ...,  0.0690, -0.2059, -0.7142],
          [ 0.5809, -0.5405, -0.5140,  ..., -0.3672, -1.2001,  0.0942],
          [-1.8399,  0.0554,  0.4481,  ...,  0.4108, -0.3850,  1.3142],
          ...,
          [-0.2016,  1.3433,  0.2349,  ..., -0.4109,  0.1253, -0.4852],
          [-1.5850, -1.1013, -0.0419,  ...,  0.1762,  0.6784,  0.2930],
          [ 0.0720,  0.3721,  0.0326,  ...,  1.1599,  0.4987, -0.5013]],

         [[-0.0373,  0.5452,  0.0831,  ...,  0.1498, -0.1385, -0.6001],
          [ 0.1562, -0.1105,  0.4271,  ..., -0.2205,  1.5424,  0.0594],
          [ 1.2115,  0.9042,  0.0587,  ...,  0.4819, -0.3149, -0.6231],
          ...,
          [ 0.3382,  0.6823, -0.3923,  ...,  0.7734,  1.4372,  0.7341],
          [ 0.7542, -0.2863, -1.7504,  ..., -0.1613,  0.7876,  0.4914],
          [ 1.8254, -0.5985, -0.1194,  ..., -0.7987,  1.4629, -0.0032]],

         [[ 0.0965, -0.2920,  1.5689,  ...,  0.6017,  0.1936,  0.0808],
          [ 0.3223, -2.7276, -0.2527,  ...,  0.1637, -0.6693,  2.2605],
          [-1.3121, -0.8490,  0.3743,  ..., -0.7534, -0.1417, -0.3322],
          ...,
          [-0.3216, -0.6738, -1.4055,  ..., -0.1455, -0.4482, -0.1758],
          [-0.2140,  0.2797, -1.3806,  ..., -0.2501, -0.3141,  0.3148],
          [ 1.1838,  0.4921, -1.3964,  ...,  0.0898,  0.6728,  0.8400]]]],
       grad_fn=&lt;SliceBackward0&gt;)), (tensor([[[[ 8.7279e-01, -1.8669e+00,  1.2895e+00,  ...,  5.5340e-01,
            2.8512e+00,  1.9400e+00],
          [ 2.3041e+00, -9.9872e-01,  1.3424e+00,  ...,  8.9107e-01,
            1.2164e+00,  3.3623e+00],
          [ 9.8977e-01, -1.1604e+00,  2.4187e+00,  ...,  4.8023e-02,
            8.1508e-01,  2.3484e+00],
          ...,
          [ 1.3349e+00, -1.8054e+00,  5.5525e-01,  ..., -1.5772e+00,
            2.9742e+00,  2.9511e+00],
          [ 1.2259e+00, -4.8160e-01,  2.3774e+00,  ..., -2.0600e+00,
            2.5700e+00,  2.5352e+00],
          [ 4.1806e-01, -4.5156e-01,  4.9842e-01,  ..., -2.1538e+00,
            1.7952e+00,  4.0545e+00]],

         [[ 8.4858e-01, -5.9154e-01, -3.1429e+00,  ...,  7.3793e-01,
           -1.4301e+00, -7.2242e-01],
          [-4.7002e-01,  6.7914e-01, -6.4752e-01,  ...,  9.5045e-02,
           -1.6059e+00, -6.4845e-02],
          [-5.5967e-01,  1.8206e+00,  2.3208e-01,  ..., -1.1715e+00,
            3.9623e-02,  1.4387e+00],
          ...,
          [-8.5131e-01,  1.7463e+00,  8.4403e-01,  ..., -4.3766e-01,
           -7.9882e-01, -7.7386e-01],
          [-1.1316e+00,  1.8305e+00,  3.6072e-01,  ..., -8.3013e-02,
           -5.0304e-01, -9.9935e-01],
          [-1.4669e+00,  5.0194e-01, -3.2037e-01,  ...,  4.1512e-01,
           -1.8080e+00, -1.4761e+00]],

         [[-9.8597e-02, -2.0646e+00,  1.6202e+00,  ..., -9.5067e-01,
           -7.8930e-01, -2.7709e-01],
          [-1.0284e+00,  7.5777e-01,  2.9962e-01,  ...,  1.5043e-01,
           -7.1235e-01,  2.4696e+00],
          [-1.5705e+00, -1.1510e+00,  1.3259e+00,  ...,  1.6194e+00,
           -5.4727e-01, -1.1000e+00],
          ...,
          [ 2.7340e+00, -5.4539e-01,  1.9299e-01,  ...,  1.7251e+00,
           -1.4626e+00, -1.1255e+00],
          [ 1.5557e+00,  6.3414e-01, -4.7717e-01,  ...,  2.4858e+00,
            4.0409e-01,  5.9399e-01],
          [ 1.1554e+00,  1.6953e-01,  7.1572e-01,  ...,  1.7382e+00,
           -3.3869e-01, -1.3037e-01]],

         ...,

         [[-1.2519e+00, -3.3704e-01, -4.8226e-01,  ...,  4.9037e-01,
            1.4004e+00, -3.1343e+00],
          [ 8.1329e-01,  5.0860e-01,  5.2677e-01,  ..., -9.9652e-02,
           -5.7859e-01, -1.1513e+00],
          [-5.3170e-01,  5.1329e-01,  5.9214e-01,  ..., -1.7929e+00,
           -8.0315e-01, -8.1210e-01],
          ...,
          [ 1.3832e+00,  1.2840e+00,  1.3516e-02,  ...,  2.4073e-01,
           -2.1075e+00,  4.7093e-01],
          [ 2.8048e+00,  2.0837e+00, -2.2269e-01,  ...,  2.1065e+00,
           -1.5506e+00,  7.3538e-01],
          [ 9.9569e-01,  7.5473e-01, -8.4061e-01,  ...,  1.2450e+00,
           -1.4089e+00,  1.0101e+00]],

         [[-2.9637e+00,  1.8501e+00, -2.4782e+00,  ..., -2.0563e+00,
            1.6072e+00, -1.3215e+00],
          [-1.0525e+00,  2.2062e+00, -9.1686e-01,  ..., -1.3727e+00,
            8.4448e-01, -3.8071e-01],
          [ 2.0581e-01,  5.7133e-01,  2.3498e-01,  ...,  6.0452e-01,
            1.3289e+00,  1.1514e+00],
          ...,
          [-1.2664e+00,  1.0287e+00, -8.3515e-04,  ..., -1.7256e+00,
            2.6914e+00, -5.8037e-01],
          [-7.6241e-02,  1.3187e+00,  4.3795e-01,  ..., -2.6527e+00,
            2.0314e+00,  2.2660e-03],
          [ 2.9732e-02,  7.1498e-01, -1.5204e-01,  ..., -2.3100e+00,
            2.2557e+00, -1.9645e+00]],

         [[-5.9909e-01,  2.1361e+00,  1.0222e+00,  ..., -2.2717e-01,
            1.0761e+00, -4.7851e-01],
          [ 5.2718e-01, -7.6050e-02,  2.2535e-01,  ..., -1.4448e+00,
            3.0147e-01,  4.4193e-02],
          [-7.2133e-01,  1.0601e+00,  3.7899e-01,  ..., -1.0069e+00,
            1.1857e+00,  9.2875e-02],
          ...,
          [-2.4073e-01,  1.3805e+00, -1.8545e+00,  ...,  1.5547e+00,
            1.7422e-01,  6.6320e-01],
          [ 1.8723e-01,  2.8018e+00, -1.2038e+00,  ...,  8.5038e-01,
           -4.1012e-01,  1.5213e+00],
          [ 9.0961e-01,  1.3538e+00, -8.7079e-01,  ...,  6.0819e-01,
           -3.7884e-01,  1.1892e+00]]],


        [[[ 1.6669e+00, -1.8501e+00,  1.4308e+00,  ...,  4.1753e-01,
            1.9483e+00,  1.9275e+00],
          [-2.3785e-01, -7.7026e-01,  1.9562e+00,  ..., -3.7962e-01,
            2.6637e-01,  1.3191e+00],
          [ 2.4564e+00, -1.8450e+00,  1.0067e+00,  ..., -3.6135e+00,
            1.4500e+00,  2.8052e+00],
          ...,
          [ 1.1277e+00, -2.4653e+00,  1.0832e+00,  ..., -2.5253e+00,
            2.3542e+00,  3.1071e+00],
          [ 1.7113e+00, -9.8745e-01,  1.7548e+00,  ..., -3.1073e+00,
            3.1550e+00,  2.7955e+00],
          [ 1.2080e+00, -1.7399e+00,  1.1851e+00,  ..., -3.4993e+00,
            1.4135e+00,  3.8717e+00]],

         [[ 1.0403e+00, -9.9108e-02, -3.3473e+00,  ...,  1.5053e+00,
           -1.1300e+00, -2.5673e-01],
          [-3.1376e-01,  3.6449e-01, -4.9221e-01,  ...,  2.5577e+00,
           -9.6436e-01, -4.8309e-01],
          [ 2.1749e-01, -1.6062e-01, -1.7114e-01,  ...,  4.7690e-01,
           -3.0907e+00, -4.9645e-01],
          ...,
          [-1.6150e+00,  1.6032e+00,  1.2201e+00,  ..., -1.2157e+00,
           -8.0938e-01, -6.8384e-01],
          [-8.6390e-01,  1.3590e+00,  8.9903e-01,  ..., -1.3808e+00,
           -5.9162e-01, -1.1228e+00],
          [-9.9955e-01,  1.7604e+00, -4.7334e-01,  ..., -1.6921e-01,
           -1.6569e+00, -3.4930e-01]],

         [[-4.9770e-01, -2.1766e+00,  1.9709e+00,  ..., -4.2964e-01,
           -7.7865e-02,  8.1405e-01],
          [-7.8203e-01,  1.4528e-01,  3.9470e-01,  ...,  1.1959e+00,
           -3.6432e-01,  1.0288e-01],
          [-1.9168e+00,  2.9120e-01,  1.5979e+00,  ..., -2.1788e+00,
            3.8412e-01,  1.3095e+00],
          ...,
          [ 2.2101e+00, -5.2600e-01,  6.8845e-01,  ...,  1.0079e+00,
           -1.4969e+00, -7.0351e-01],
          [ 1.5599e+00, -1.2452e-01,  1.0456e-01,  ...,  1.5902e+00,
            6.0410e-01,  1.4783e+00],
          [ 8.3950e-01, -2.5039e-01,  9.7492e-01,  ...,  1.0805e+00,
           -1.6106e-01, -4.5930e-01]],

         ...,

         [[-1.1499e+00, -2.2271e-01,  9.4263e-03,  ...,  8.5250e-01,
            8.4412e-01, -3.1145e+00],
          [ 1.7683e-01,  2.2275e+00,  5.6784e-01,  ...,  5.8687e-01,
            4.7845e-01, -8.5741e-01],
          [-1.0440e+00,  1.3014e+00, -3.4560e-02,  ...,  2.0609e-01,
           -1.4910e-01, -2.4508e+00],
          ...,
          [ 1.9286e+00,  1.9424e+00,  8.3068e-01,  ...,  1.2317e-01,
           -2.8947e+00,  9.4037e-01],
          [ 2.5176e+00,  2.7275e+00,  1.8978e-01,  ...,  1.5900e+00,
           -1.9992e+00,  8.6078e-01],
          [ 8.2274e-01,  9.2066e-01, -1.2891e+00,  ..., -2.6162e-01,
           -2.5449e+00,  9.4122e-01]],

         [[-1.9341e+00,  2.0135e+00, -2.5158e+00,  ..., -1.8366e+00,
            1.0649e+00, -1.1225e+00],
          [ 1.6675e-01,  1.5419e+00, -1.3663e+00,  ..., -6.7066e-01,
            1.9954e+00, -5.3438e-01],
          [-3.1475e+00,  1.4062e+00, -8.3577e-02,  ...,  7.4155e-01,
            2.1845e+00,  1.0725e+00],
          ...,
          [-5.2507e-01,  1.1642e+00, -4.5840e-01,  ..., -1.4052e+00,
            2.2491e+00, -1.1113e+00],
          [ 2.4747e-01,  1.7003e+00,  1.8734e-01,  ..., -2.5426e+00,
            1.6726e+00,  2.7934e-01],
          [ 3.3686e-01,  1.5049e+00, -9.5398e-01,  ..., -2.2124e+00,
            2.9722e+00, -1.8715e+00]],

         [[ 9.7262e-02,  1.6053e+00,  2.0556e+00,  ...,  1.0516e-01,
           -1.2624e-01, -5.3774e-01],
          [ 8.2493e-02,  1.2168e+00,  1.5191e+00,  ..., -6.2532e-01,
            6.7429e-01,  1.8565e+00],
          [ 5.5476e-01,  9.6250e-01,  1.6890e+00,  ..., -1.0226e+00,
            1.3656e+00, -4.3041e-01],
          ...,
          [-2.2784e-01,  5.9803e-01, -1.5708e+00,  ...,  1.3046e+00,
            3.4980e-01,  4.6931e-01],
          [-5.2425e-01,  2.2723e+00, -7.3145e-01,  ...,  2.7461e-01,
           -8.8354e-02,  1.6636e+00],
          [ 8.9370e-01,  7.4992e-01, -1.5916e+00,  ...,  8.6855e-01,
           -2.4942e-01,  1.1501e+00]]]], grad_fn=&lt;SliceBackward0&gt;), tensor([[[[ 2.8952e-01, -6.4382e-01,  3.2986e-01,  ..., -5.2403e-01,
           -2.8590e-01, -6.2083e-01],
          [ 1.1429e+00, -4.1795e-01,  8.4627e-01,  ..., -2.2508e-02,
           -9.1181e-01, -2.0787e+00],
          [ 6.6058e-01,  3.7406e-01,  2.9531e-01,  ...,  7.2738e-01,
            1.4301e+00,  2.6988e-01],
          ...,
          [ 1.2611e+00,  8.8039e-01,  1.4990e-01,  ..., -2.8498e-01,
            3.1009e-01,  9.7436e-01],
          [ 1.1608e+00,  6.7495e-01,  5.5866e-01,  ..., -1.9543e-01,
            7.2545e-01, -3.6961e-01],
          [ 4.5865e-01,  7.4160e-01, -3.4315e-01,  ..., -1.4572e+00,
           -4.3104e-01,  1.4238e+00]],

         [[ 1.2445e-01, -3.7778e-01,  2.1853e+00,  ...,  8.2206e-02,
            1.0600e-01,  3.4162e-01],
          [ 1.1997e+00,  4.4377e-01,  1.7299e+00,  ...,  8.7214e-02,
           -2.1824e-01,  1.7885e+00],
          [ 7.7694e-02, -2.2458e-01,  7.7808e-01,  ..., -4.5595e-01,
           -4.4570e-02,  1.0720e+00],
          ...,
          [ 1.5265e+00, -2.9716e-02, -2.9735e-01,  ...,  8.8054e-01,
           -3.6734e-01, -8.2532e-01],
          [ 3.3654e-01,  3.0853e-01,  1.0464e+00,  ...,  2.4605e-01,
           -4.7146e-01,  1.3476e+00],
          [-3.8977e-01,  2.9045e-01,  1.5186e-01,  ...,  1.5754e+00,
            3.2012e-01,  1.0656e+00]],

         [[ 2.0485e-01,  4.2644e-01, -9.7323e-01,  ...,  1.0637e+00,
           -1.5572e-02, -3.3069e-01],
          [-3.3333e-01, -4.3480e-01,  1.3119e+00,  ...,  2.8024e-01,
           -3.0539e-01,  2.2544e-01],
          [ 1.0216e+00,  2.9426e-01,  1.2721e+00,  ...,  4.4316e-01,
           -9.0968e-02,  7.4476e-01],
          ...,
          [ 4.0036e-01, -5.8537e-01,  1.2736e+00,  ...,  3.6682e-01,
            1.5884e+00, -3.5292e-01],
          [ 5.1243e-01, -1.8633e-01, -9.4888e-01,  ..., -1.3540e-02,
            5.2052e-01, -1.2666e-01],
          [-1.0933e+00, -2.0112e-01, -6.5764e-01,  ..., -5.2287e-01,
            3.7159e-01, -8.0517e-01]],

         ...,

         [[-9.4987e-01,  1.6079e-01,  1.1337e-03,  ..., -5.0119e-01,
           -3.0827e-01,  1.2040e+00],
          [ 2.4804e-01,  3.2949e-01, -9.1701e-01,  ...,  3.8526e-01,
           -2.4667e-01, -1.2610e+00],
          [ 2.2117e-01, -5.3121e-01, -6.0072e-01,  ..., -7.4094e-01,
           -7.5524e-02, -8.4752e-01],
          ...,
          [-1.8126e+00,  3.7551e-01,  5.7300e-01,  ..., -4.3399e-01,
            4.8101e-01, -1.7805e+00],
          [-3.8555e-02, -7.6775e-01,  9.0477e-02,  ...,  3.9599e-01,
            1.1186e-01, -1.3937e+00],
          [-6.2175e-01,  1.2654e-01,  1.3647e+00,  ...,  1.2250e+00,
            1.7875e-01, -1.0497e+00]],

         [[-2.7816e-01, -1.4586e+00, -6.9239e-01,  ...,  2.1520e-01,
            4.1796e-01,  6.6377e-01],
          [ 1.0344e+00, -6.5173e-01,  5.2647e-01,  ..., -6.2458e-01,
           -9.2487e-01, -1.8795e-01],
          [ 3.4914e-01, -4.1551e-01, -1.5848e-01,  ...,  1.6077e-01,
           -4.0010e-01, -1.9873e-01],
          ...,
          [ 7.0330e-01,  7.6771e-01, -8.8933e-01,  ..., -4.0876e-01,
            2.2557e-01, -8.4982e-01],
          [-7.6904e-01,  3.7294e-01,  4.3989e-01,  ..., -5.4007e-01,
            2.8897e-01,  1.3280e+00],
          [-1.3868e-01, -2.3874e-01, -8.5074e-01,  ...,  6.2550e-01,
           -2.2573e-01,  1.7588e-01]],

         [[ 5.8715e-01,  3.7840e-02, -4.0978e-01,  ...,  2.8332e-01,
           -8.2477e-01, -1.2469e+00],
          [ 1.4125e+00,  2.1530e-01, -7.8224e-02,  ..., -1.1658e+00,
           -7.3161e-01, -1.1083e+00],
          [ 1.8362e+00, -5.9247e-02, -1.2606e-01,  ..., -1.4079e+00,
           -3.4769e-01, -8.1547e-01],
          ...,
          [-7.2234e-01,  1.6048e+00,  8.0760e-01,  ...,  7.3131e-01,
           -1.7685e+00, -2.5603e-01],
          [ 2.5801e-01,  1.8852e+00, -2.3538e-01,  ...,  2.6060e-02,
           -1.0741e+00, -1.1594e+00],
          [ 9.9201e-01,  8.9670e-01,  6.8818e-01,  ...,  1.2335e+00,
           -2.2381e+00,  1.2492e+00]]],


        [[[-5.1932e-01, -1.0120e+00, -6.3757e-01,  ..., -5.2698e-01,
            1.1791e-01, -3.9322e-01],
          [-1.3266e+00, -4.7299e-01,  9.8332e-01,  ...,  6.7936e-01,
            1.2511e+00,  3.4607e-01],
          [-7.9852e-01, -4.8551e-01, -4.2337e-01,  ...,  2.7798e-02,
            1.4999e-01, -1.7081e-01],
          ...,
          [ 1.0002e+00,  7.8057e-01, -2.7067e-01,  ..., -1.3848e-01,
            3.9745e-01,  9.9260e-01],
          [ 1.0135e+00,  5.5383e-01, -1.3270e-01,  ...,  1.1301e-01,
            8.1704e-01, -2.2780e-01],
          [ 4.7314e-01,  6.0400e-01,  7.2996e-02,  ..., -6.9101e-01,
           -2.1028e-02,  1.7098e+00]],

         [[ 1.8622e-01, -6.0655e-03,  9.2662e-01,  ..., -6.4163e-02,
           -3.3526e-02,  8.5473e-01],
          [-6.0286e-02,  8.4166e-02,  8.0750e-01,  ..., -9.7806e-01,
            5.1077e-01,  4.8134e-01],
          [-8.0460e-01,  8.6719e-01, -7.0625e-01,  ..., -8.2155e-01,
           -3.6749e-01,  3.2476e-02],
          ...,
          [ 1.7080e+00,  8.0135e-01, -1.9663e-01,  ...,  3.3217e-01,
           -5.3714e-01, -3.0491e-01],
          [ 4.7838e-01,  7.5781e-01,  3.1947e-01,  ...,  3.7978e-01,
           -7.8066e-01,  9.9700e-01],
          [ 2.2446e-01,  1.3849e+00,  1.3510e-01,  ...,  9.1035e-01,
            5.5969e-01,  8.3091e-01]],

         [[ 1.2848e-01,  5.3296e-01, -4.0922e-01,  ...,  1.5496e+00,
            3.9283e-01, -2.5440e-01],
          [ 1.0187e+00,  8.6630e-01,  8.6427e-01,  ...,  9.2952e-01,
            8.2815e-01, -1.4864e-01],
          [ 1.1643e+00,  8.5072e-02,  4.7188e-01,  ...,  9.1260e-01,
            2.9074e-01, -1.1182e+00],
          ...,
          [ 1.1258e+00, -3.0072e-01,  1.0844e+00,  ..., -3.6805e-02,
            9.5885e-01, -7.5346e-01],
          [ 5.7076e-01,  8.8478e-01, -1.1397e+00,  ...,  9.3766e-01,
           -2.8151e-01, -2.6003e-01],
          [-5.2079e-01,  6.4501e-01, -9.1415e-01,  ..., -9.5849e-02,
            2.2447e-01, -3.6839e-01]],

         ...,

         [[-1.2917e+00,  8.4674e-01,  2.2891e-01,  ..., -8.3064e-01,
            6.5861e-01,  1.0849e+00],
          [-1.6843e+00,  9.7582e-01, -7.1436e-01,  ..., -2.0574e-01,
            1.1909e+00, -4.9044e-01],
          [-1.0281e+00,  8.5582e-01,  1.1391e-01,  ..., -6.9295e-01,
            9.9696e-01,  3.1951e-01],
          ...,
          [-2.2676e+00,  9.0251e-01,  1.2698e+00,  ..., -9.9420e-01,
            7.8261e-02, -1.5175e+00],
          [-2.9870e-01, -1.6122e-01,  9.6545e-01,  ..., -4.5410e-01,
            6.5692e-01, -1.4362e+00],
          [-3.8905e-02,  4.9968e-01,  1.3970e+00,  ...,  5.0103e-01,
           -1.2661e-02, -6.1598e-01]],

         [[-9.3853e-01, -2.7585e-01, -4.4926e-01,  ...,  4.4386e-01,
            1.1633e+00,  5.2601e-02],
          [-9.7259e-01,  1.0223e+00,  5.6555e-01,  ..., -1.0207e+00,
           -3.9981e-01,  2.8489e-01],
          [ 2.1814e-01,  7.2075e-01, -1.1349e+00,  ...,  8.1021e-01,
           -5.1962e-02,  6.6637e-01],
          ...,
          [ 8.6251e-01,  7.9718e-01, -1.6927e+00,  ...,  5.6659e-01,
            8.6506e-02, -5.9646e-01],
          [-7.8715e-01,  6.5772e-01, -8.8543e-02,  ..., -3.3618e-01,
            5.3098e-01,  1.3889e+00],
          [-8.5931e-01, -2.8142e-01, -9.6407e-01,  ...,  1.3700e+00,
           -1.3125e-01, -4.8602e-03]],

         [[ 2.4789e-01, -2.3040e-01, -3.8846e-01,  ...,  5.9574e-01,
            3.4077e-01, -8.0082e-01],
          [ 1.0117e-01,  4.8706e-01, -4.3937e-01,  ..., -4.2723e-01,
            1.1229e+00, -8.6230e-01],
          [ 1.3435e+00, -1.2326e-01, -1.1641e+00,  ..., -4.3204e-01,
           -2.4511e-01, -4.4421e-01],
          ...,
          [-1.6400e+00,  1.1313e+00,  7.1000e-01,  ..., -1.2789e-01,
           -1.3863e+00, -2.5915e-01],
          [ 4.1039e-01,  1.2734e+00, -4.3643e-01,  ..., -4.5243e-01,
           -6.4940e-01, -1.6472e+00],
          [ 1.5502e-01,  6.5864e-01,  5.7706e-01,  ...,  1.1956e+00,
           -1.5196e+00,  1.3601e+00]]]], grad_fn=&lt;SliceBackward0&gt;)), (tensor([[[[ 3.4894e-01,  1.7654e+00, -1.0722e+00,  ..., -1.0585e+00,
           -4.9655e-01, -3.1594e+00],
          [ 1.3257e+00,  4.9358e-01, -4.4935e-01,  ..., -1.4885e+00,
           -3.7677e-01, -1.5488e+00],
          [-2.0038e-01, -6.6280e-01,  3.0892e-01,  ...,  4.9696e-01,
           -1.4473e+00, -2.1529e+00],
          ...,
          [ 3.4416e+00, -7.0535e-01, -1.7485e-01,  ...,  2.3740e-01,
           -2.1059e+00,  3.0084e-01],
          [ 7.8641e-01, -1.1906e+00,  4.7018e-01,  ..., -8.8261e-01,
           -2.8178e+00, -1.7780e+00],
          [ 1.9930e+00, -1.0839e+00, -1.8683e+00,  ...,  9.5306e-02,
           -1.4537e+00, -2.7331e+00]],

         [[ 3.1085e-01,  9.3609e-01,  9.9733e-01,  ...,  1.7231e+00,
            6.0327e-02,  3.9927e-01],
          [ 3.9253e-01, -8.3591e-02,  1.8104e-01,  ...,  8.6428e-01,
           -4.9453e-01,  6.3948e-02],
          [ 1.5533e+00, -1.3121e+00,  1.0151e+00,  ...,  1.2414e-01,
           -9.6259e-01, -1.8879e+00],
          ...,
          [ 2.2631e+00,  1.9045e-01,  3.4054e-01,  ...,  8.5815e-01,
            2.2986e+00, -2.9616e-01],
          [ 2.5547e+00,  1.2559e+00,  3.8422e-01,  ..., -4.6086e-01,
            1.0001e+00, -1.9679e+00],
          [ 2.8015e+00,  5.5863e-01, -5.6224e-01,  ..., -3.3819e-01,
            7.0891e-01, -8.2956e-01]],

         [[-9.1190e-01,  4.4261e-01, -6.4411e-01,  ...,  7.8138e-01,
            9.0907e-02, -1.1635e+00],
          [-1.2460e+00, -6.1044e-01,  6.7122e-01,  ...,  8.5037e-01,
           -8.5593e-01, -1.1556e+00],
          [-6.3935e-01,  3.4963e-01,  4.4770e-01,  ...,  6.3966e-01,
           -1.6132e+00, -6.1717e-01],
          ...,
          [ 1.1298e+00, -4.7889e-01, -7.8828e-01,  ..., -1.7424e+00,
           -1.2224e-02, -1.1479e+00],
          [ 3.5075e-01, -9.3144e-01,  1.9899e-01,  ..., -8.2957e-01,
           -1.2269e+00, -5.6748e-01],
          [ 1.3093e+00,  1.6802e-01, -2.9828e-01,  ...,  2.1832e-01,
            3.4218e-01,  9.2298e-01]],

         ...,

         [[ 5.7010e-01, -1.6722e+00, -1.2795e+00,  ..., -1.2610e+00,
           -1.5263e+00, -7.0730e-01],
          [ 3.3003e-01, -7.3737e-01, -4.1251e-01,  ..., -5.7903e-01,
           -5.6256e-01,  4.6140e-01],
          [ 4.9959e-01,  1.3650e-02, -6.7706e-01,  ..., -3.3639e-01,
           -1.2455e+00, -1.0451e+00],
          ...,
          [-1.1339e+00,  2.6120e-01, -1.8464e+00,  ...,  2.0918e+00,
            4.1529e-01, -6.7061e-01],
          [-1.0719e+00,  1.1838e+00, -5.3580e-01,  ..., -3.3662e-01,
            2.0893e+00, -1.7033e-01],
          [ 1.8655e-01,  1.1527e+00, -8.4499e-01,  ...,  6.4336e-01,
            6.8658e-01,  2.6031e-01]],

         [[-3.0372e-01,  4.2905e-01, -1.6778e-01,  ...,  2.4370e-01,
            2.2553e-01,  1.3955e+00],
          [-4.7579e-01,  2.3696e-01, -8.7823e-01,  ..., -9.9869e-02,
           -1.9878e+00, -2.1669e-01],
          [ 1.0046e+00,  4.1853e-01, -6.9349e-02,  ...,  6.9838e-01,
           -2.6663e-01, -1.2499e+00],
          ...,
          [ 1.5899e+00,  1.9074e+00,  7.7458e-01,  ...,  1.2784e+00,
           -8.0532e-01,  4.5066e-01],
          [ 1.4258e+00,  2.4959e+00,  1.0059e+00,  ...,  1.4693e+00,
           -9.3738e-01,  1.7969e+00],
          [ 3.6120e+00,  1.6799e+00,  2.5542e+00,  ...,  1.5014e+00,
            3.1243e-01,  1.3588e+00]],

         [[ 9.7718e-01, -1.7966e+00, -2.3199e+00,  ...,  1.2368e+00,
            8.8546e-01,  1.3906e-01],
          [ 1.5209e+00, -1.7003e+00, -1.3379e+00,  ...,  9.5299e-01,
            2.1381e+00, -2.5078e-01],
          [-1.9147e-01, -5.8029e-01, -9.9455e-01,  ...,  6.4411e-01,
            6.9821e-01,  1.4383e+00],
          ...,
          [ 1.8841e-03, -1.7372e+00,  4.3079e-01,  ...,  2.8980e+00,
            1.0867e+00, -1.7410e-01],
          [ 1.1308e+00, -3.0841e+00, -5.0208e-01,  ...,  1.6645e+00,
            1.0042e+00, -1.9562e+00],
          [-6.9749e-01, -1.9495e+00, -2.3471e-01,  ...,  2.9899e+00,
            1.1112e+00, -2.0623e-01]]],


        [[[-5.5088e-01,  1.7214e+00, -1.8824e+00,  ..., -4.3810e-01,
           -8.8143e-03, -2.9855e+00],
          [ 6.8243e-03,  1.1636e-01,  2.3283e-02,  ...,  5.1566e-01,
           -6.0869e-01, -1.2139e-01],
          [-5.4510e-01,  1.0645e+00, -6.5329e-01,  ..., -1.2005e+00,
           -3.5477e-01, -2.7418e+00],
          ...,
          [ 3.3551e+00, -1.2367e+00, -2.7097e-02,  ...,  1.5653e+00,
           -1.5020e+00,  2.5607e-01],
          [ 3.8543e-01, -7.3751e-01, -3.9931e-01,  ...,  5.2852e-02,
           -1.6760e+00, -2.0991e+00],
          [ 2.0062e+00, -1.1429e+00, -1.7632e+00,  ...,  1.2502e+00,
           -1.8344e+00, -3.6829e+00]],

         [[ 6.5928e-01,  7.6887e-01,  5.5007e-01,  ...,  8.0142e-01,
            5.4408e-01,  8.4730e-01],
          [ 7.5579e-01,  5.5404e-01, -1.0046e+00,  ..., -8.5098e-01,
            3.8774e-01,  1.3883e-01],
          [-5.7683e-01,  2.6617e+00, -7.1145e-01,  ...,  1.3978e+00,
           -4.7459e-02,  3.8881e-01],
          ...,
          [ 1.5037e+00,  1.2800e-01,  1.6605e-01,  ...,  3.7348e-01,
            1.8904e+00, -3.2681e-01],
          [ 2.4561e+00,  2.0441e+00, -5.1748e-02,  ..., -2.6318e-02,
            8.0110e-01, -4.0271e-01],
          [ 2.9550e+00,  3.6720e-01,  2.8347e-01,  ..., -5.9172e-01,
            8.6535e-01, -2.5360e-01]],

         [[-9.6037e-01,  1.1286e-01,  2.7815e-01,  ...,  9.9199e-01,
           -4.4371e-01, -7.0070e-01],
          [-1.8010e+00, -5.2770e-01, -1.6072e-01,  ...,  1.4191e+00,
           -7.8236e-01, -7.7000e-01],
          [-1.0596e+00,  4.3514e-01, -2.8844e-01,  ...,  1.3556e+00,
           -5.9108e-01,  1.1380e+00],
          ...,
          [ 9.6382e-01, -7.7922e-01, -3.3403e-01,  ..., -2.0503e+00,
           -1.0107e+00, -1.3954e-01],
          [ 3.1380e-02, -1.4327e+00,  1.7934e-01,  ..., -2.1262e-01,
           -9.0917e-01,  3.7519e-01],
          [ 9.7014e-01, -9.8767e-01, -1.2182e-01,  ...,  7.1073e-01,
            4.6554e-02,  1.6608e+00]],

         ...,

         [[ 1.5017e+00, -1.2765e+00, -1.2539e+00,  ..., -9.1280e-01,
           -9.5563e-01, -1.2646e+00],
          [ 8.1204e-02, -6.6052e-01,  2.0744e-01,  ...,  1.7824e+00,
           -5.3716e-01, -1.1310e+00],
          [ 2.0661e+00, -2.7352e-01,  5.7637e-01,  ..., -7.6307e-01,
           -1.3981e+00, -1.3472e+00],
          ...,
          [-1.4310e+00, -1.3967e+00, -2.1985e+00,  ...,  1.3132e+00,
            8.2017e-01, -3.9425e-01],
          [-1.2430e+00, -6.8955e-02, -1.1704e+00,  ..., -8.7914e-01,
            1.1463e+00, -3.8531e-02],
          [-6.7105e-01,  7.1224e-01, -1.7802e+00,  ...,  7.6008e-01,
            9.1910e-01, -2.4516e-01]],

         [[ 1.0018e+00, -1.4358e-01, -9.8220e-02,  ..., -3.3486e-01,
           -1.2939e+00, -4.8447e-02],
          [ 1.0667e+00,  7.8533e-01,  1.5349e+00,  ..., -5.7476e-02,
           -2.7876e+00,  9.6016e-02],
          [ 9.6343e-01, -5.3017e-01, -1.1228e+00,  ..., -6.9199e-01,
            3.5023e-01,  1.1887e+00],
          ...,
          [ 7.8587e-01,  1.0126e+00,  4.6594e-01,  ...,  1.0136e+00,
           -8.6608e-01,  1.4922e+00],
          [ 3.2006e-01,  1.4067e+00,  1.0284e+00,  ...,  6.7490e-01,
           -1.9296e+00,  2.9977e+00],
          [ 3.4384e+00,  1.2096e+00,  1.9087e+00,  ...,  1.1060e+00,
            1.3020e-01,  1.6461e+00]],

         [[ 4.2910e-01, -1.8609e+00, -2.0925e+00,  ...,  8.6446e-01,
            1.7588e+00, -1.2647e+00],
          [ 8.4660e-01,  2.0940e-01, -2.8168e-01,  ..., -5.2735e-01,
            1.8402e+00,  3.3206e-01],
          [-1.5912e-01,  1.0535e-01, -2.2156e+00,  ...,  1.6145e+00,
            2.6035e+00,  2.0821e+00],
          ...,
          [ 2.5115e-01, -1.2054e+00,  3.1001e-01,  ...,  2.5248e+00,
            7.0739e-01,  1.5388e-01],
          [ 1.3285e+00, -3.9358e+00, -4.4803e-01,  ...,  1.1670e+00,
            1.6629e+00, -1.7696e+00],
          [ 3.5381e-01, -1.6038e+00,  2.4013e-01,  ...,  2.4457e+00,
            1.3817e+00,  2.3649e-01]]]], grad_fn=&lt;SliceBackward0&gt;), tensor([[[[ 1.6214, -0.3389,  0.7264,  ...,  0.3585,  1.5116, -0.4135],
          [ 0.0252, -0.1534,  1.0813,  ..., -0.1140,  0.9839, -0.3302],
          [-1.2801,  0.0497, -0.9782,  ...,  0.8277, -0.2273, -0.0150],
          ...,
          [-0.3353,  0.0851, -1.4897,  ...,  0.8126,  0.6627, -0.8213],
          [-0.8195, -0.5723, -1.4487,  ...,  0.8223,  0.3172, -1.1127],
          [-1.0426, -0.7606, -0.5854,  ..., -0.3179, -0.2345, -1.9173]],

         [[-0.8987, -0.0213,  0.7388,  ..., -0.7234,  0.4957,  0.2691],
          [ 0.9615, -0.3238,  0.2853,  ..., -1.0362,  0.4435, -0.2439],
          [ 0.7683, -0.0624,  0.3739,  ..., -0.7333,  0.4711,  0.1274],
          ...,
          [-0.3864,  0.3805, -0.1376,  ..., -1.0630, -0.0427, -0.7842],
          [ 0.6024,  0.7199,  0.6971,  ..., -0.1298,  1.1789, -1.2487],
          [ 0.8804,  1.1723,  0.1817,  ..., -0.1207, -0.4065, -0.8941]],

         [[-1.3334, -0.5165,  0.2383,  ...,  0.2446,  0.3842, -0.3134],
          [-1.0712,  1.0440, -0.3892,  ..., -0.0077, -0.0447, -0.6792],
          [-0.5285, -0.1014,  0.1823,  ..., -0.5521, -0.3100, -0.2431],
          ...,
          [-1.0951, -0.7560,  1.7665,  ..., -1.8153,  0.8830,  0.1725],
          [-0.2673,  1.1157, -0.2189,  ..., -0.8413,  0.3976, -0.9498],
          [-0.8103, -1.7514,  0.2228,  ..., -0.8821,  0.7319, -0.6408]],

         ...,

         [[-0.0825,  0.5630,  0.7478,  ..., -0.1176,  0.5361,  0.0443],
          [ 0.2400,  1.7017,  0.7862,  ...,  0.2494,  0.5908, -0.1538],
          [ 0.6709,  1.4979,  0.0236,  ...,  1.0636, -0.0102, -0.2125],
          ...,
          [-0.2727, -0.2310, -0.4999,  ...,  0.2130,  0.3775, -0.3199],
          [-0.7251, -0.3117, -0.7030,  ...,  0.2157,  0.0865, -0.3110],
          [ 0.1143, -1.1192,  0.4160,  ...,  0.2733,  0.0699,  0.2937]],

         [[-0.4918, -0.5305, -0.8115,  ..., -0.2139,  0.1239, -1.1484],
          [-0.6777, -1.7730,  0.1399,  ..., -0.1630,  0.7513, -1.8528],
          [ 0.5461, -0.3684, -0.9418,  ...,  0.3282,  0.4618, -0.8479],
          ...,
          [ 0.3724, -0.4271,  0.2359,  ...,  0.1534, -0.6970, -1.6400],
          [ 0.1255, -0.8991,  0.8731,  ...,  0.2835, -0.2864, -0.7266],
          [-0.2813, -0.0280, -0.8591,  ..., -0.4356, -0.5605, -0.9384]],

         [[-1.5683, -0.1141,  0.9272,  ...,  0.0087, -0.4693, -1.5562],
          [-0.6669,  0.1673,  1.0967,  ...,  0.3864, -0.5968, -1.8391],
          [ 0.4843,  0.9856,  1.0307,  ...,  1.0718, -0.3075, -0.5891],
          ...,
          [ 0.3304,  0.8342, -0.0677,  ...,  0.3616,  1.2245,  0.1298],
          [-0.5061,  0.5873, -0.2740,  ...,  1.0103, -0.8006, -0.1743],
          [-0.8446,  0.6496, -0.1484,  ...,  0.8487,  0.5043,  0.7168]]],


        [[[ 1.5782,  0.0494,  1.3314,  ...,  0.7404,  0.8916, -1.2870],
          [-1.5500,  0.0943,  1.0814,  ..., -0.2229, -0.0984, -2.2824],
          [ 0.4714, -0.4730,  1.0430,  ...,  0.5578,  1.5280,  0.3270],
          ...,
          [-1.1768,  0.0455, -0.3970,  ..., -0.5757,  1.1885, -0.2543],
          [-1.0677, -0.0520, -0.3137,  ..., -0.4949,  1.9866,  0.3187],
          [-1.6305, -0.5519,  0.0810,  ..., -0.7432,  0.3718, -0.5596]],

         [[-0.6208, -0.0878,  0.3002,  ..., -0.0865, -0.0569,  0.3461],
          [-1.1820, -0.8358, -0.6859,  ..., -1.2657, -0.5861, -0.0821],
          [-0.7943, -1.1279,  2.1442,  ..., -0.1944, -0.4100, -0.1070],
          ...,
          [-0.5993, -0.1326,  0.1372,  ..., -0.3593, -0.7175,  0.1243],
          [-0.1676,  0.3472,  1.5612,  ...,  0.8422, -0.4919, -1.4071],
          [ 1.1477,  0.9513,  0.4874,  ...,  0.2395, -1.5289, -0.9175]],

         [[-1.1873,  0.3368, -0.5558,  ...,  0.0745,  0.0773,  0.7180],
          [ 0.7362,  0.4700, -1.0437,  ...,  0.3082, -0.3208,  0.9671],
          [ 0.7077,  1.4243, -0.9921,  ..., -0.6353,  0.7772,  0.8759],
          ...,
          [-0.3227, -0.8056,  0.2890,  ..., -1.2678,  1.0167,  1.5307],
          [ 0.3397,  1.1832, -0.9427,  ..., -0.8188,  0.5906, -0.5440],
          [-0.0054, -1.0712, -0.3758,  ..., -0.2106,  0.3294,  0.3090]],

         ...,

         [[-0.7267,  0.4357, -0.0327,  ...,  0.0031,  1.2551, -0.0291],
          [-1.1054,  0.3650, -0.4062,  ..., -0.6102,  0.1459,  1.2387],
          [-0.3489, -0.5791, -0.0225,  ..., -0.9068, -0.0444, -0.0246],
          ...,
          [-0.6364, -0.0093, -0.4155,  ..., -0.3454,  0.4385,  0.5943],
          [-0.4286, -0.3971, -0.1525,  ..., -0.6994,  0.6141,  0.3621],
          [-1.0127, -0.7493,  0.2357,  ..., -0.4072, -0.1377,  1.2456]],

         [[ 0.1479,  0.5368, -0.5764,  ..., -0.6031,  0.9521,  0.4653],
          [ 0.4444,  0.4733, -0.1594,  ...,  0.1663,  1.1841, -0.0704],
          [ 0.4049,  0.7392, -0.3973,  ..., -1.6897,  1.6275,  0.7809],
          ...,
          [ 1.0994, -0.0743,  0.2638,  ...,  0.3485,  0.4219, -0.7487],
          [ 1.0350, -0.4627, -0.4259,  ..., -0.3616,  0.0872, -0.5485],
          [ 0.8100, -0.2973, -1.3108,  ..., -0.8102,  0.8096,  0.0282]],

         [[-1.8754,  0.1958,  0.4104,  ..., -1.1152,  0.1974, -1.2186],
          [-0.7184, -0.9829,  1.2670,  ..., -0.4101,  0.7931, -0.7214],
          [-0.7763, -0.7292,  0.3373,  ..., -0.6465,  1.3878,  0.3176],
          ...,
          [ 0.6310,  1.2395,  0.1874,  ..., -0.9609,  1.1079,  0.2369],
          [-0.6881,  1.0596,  0.1746,  ..., -0.2396,  0.3809, -0.0863],
          [-1.1473,  1.1557,  0.1818,  ..., -0.2950,  0.4975,  0.9475]]]],
       grad_fn=&lt;SliceBackward0&gt;))), hidden_states=None, attentions=None)</code></pre>
</div>
</div>
<div id="cell-24" class="cell" data-execution_count="121">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1"></a>[<span class="bu">len</span>(l) <span class="cf">for</span> l <span class="kw">in</span> _input_ids]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="121">
<pre><code>[512, 512]</code></pre>
</div>
</div>
<div id="cell-25" class="cell" data-execution_count="75">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1"></a>[url2tensor(url) <span class="cf">for</span> url <span class="kw">in</span> examples_dct[<span class="st">'image_url'</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="75">
<pre><code>['https://static1.squarespace.com/static/5864a522d1758e09281c7249/t/588567d3ebbd1a30e993ac41/1485138873686/?format=750w',
 'https://ak1.picdn.net/shutterstock/videos/24875111/thumb/1.jpg',
 'https://media.gettyimages.com/photos/actor-lee-ming-shun-and-actress-bianca-bai-attend-a-commercial-of-picture-id595911976?s=612x612',
 'https://us.123rf.com/450wm/jpgon/jpgon1704/jpgon170401613/76795298-illustration-of-an-isolated-female-head-with-a-lotus-flower.jpg?ver=6',
 'https://media.gettyimages.com/photos/clyde-during-a-military-exercise-to-show-the-governor-its-boats-picture-id138569967']</code></pre>
</div>
</div>
<div id="cell-26" class="cell" data-execution_count="78">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1"></a>url2tensor??</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Signature: url2tensor(url)
Docstring: &lt;no docstring&gt;
Source:   
def url2tensor(url):
    url = train_ds[0]['image_url']
    img = PIL.Image.open(io.BytesIO(requests.get(url).content))
    return 이미지전처리하기(img)
File:      /tmp/ipykernel_1414278/2182745578.py
Type:      function</code></pre>
</div>
</div>
<div id="cell-27" class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1"></a>examples_dct[<span class="st">'image_url'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-28" class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1"></a>test_ds_transformed[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>RecursionError: maximum recursion depth exceeded</code></pre>
</div>
</div>
<p>With the dataset ready, you can now set up the model for fine-tuning.</p>
</section>
<section id="load-a-base-model" class="level2">
<h2 class="anchored" data-anchor-id="load-a-base-model">Load a base model</h2>
<p>Load the <a href="https://huggingface.co/microsoft/git-base">“microsoft/git-base”</a> into a <a href="https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForCausalLM"><code>AutoModelForCausalLM</code></a> object.</p>
<div id="cell-32" class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForCausalLM</span>
<span id="cb34-2"><a href="#cb34-2"></a>model <span class="op">=</span> AutoModelForCausalLM.from_pretrained(checkpoint)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-33" class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1"></a>model??</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Signature:      model(*args, **kwargs)
Type:           GitForCausalLM
String form:   
GitForCausalLM(
  (git): GitModel(
    (embeddings): GitEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(1024, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (image_encoder): GitVisionModel(
      (vision_model): GitVisionTransformer(
        (embeddings): GitVisionEmbeddings(
          (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (position_embedding): Embedding(197, 768)
        )
        (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder): GitVisionEncoder(
          (layers): ModuleList(
            (0-11): 12 x GitVisionEncoderLayer(
              (self_attn): GitVisionAttention(
                (k_proj): Linear(in_features=768, out_features=768, bias=True)
                (v_proj): Linear(in_features=768, out_features=768, bias=True)
                (q_proj): Linear(in_features=768, out_features=768, bias=True)
                (out_proj): Linear(in_features=768, out_features=768, bias=True)
              )
              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): GitVisionMLP(
                (activation_fn): QuickGELUActivation()
                (fc1): Linear(in_features=768, out_features=3072, bias=True)
                (fc2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (encoder): GitEncoder(
      (layer): ModuleList(
        (0-5): 6 x GitLayer(
          (attention): GitAttention(
            (self): GitSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): GitSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): GitIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): GitOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (visual_projection): GitProjection(
      (visual_projection): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (output): Linear(in_features=768, out_features=30522, bias=True)
)
File:           ~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/models/git/modeling_git.py
Source:        
@add_start_docstrings(
    """GIT Model with a `language modeling` head on top for autoregressive language modeling.""", GIT_START_DOCSTRING
)
class GitForCausalLM(GitPreTrainedModel, GenerationMixin):
    _tied_weights_keys = ["output.weight"]

    def __init__(self, config):
        super().__init__(config)

        self.git = GitModel(config)
        self.output = nn.Linear(config.hidden_size, config.vocab_size)

        # Initialize weights and apply final processing
        self.post_init()

    def get_output_embeddings(self):
        return self.output

    def set_output_embeddings(self, new_embeddings):
        self.output = new_embeddings

    @add_start_docstrings_to_model_forward(GIT_INPUTS_DOCSTRING.format("batch_size, sequence_length"))
    @replace_return_docstrings(output_type=CausalLMOutputWithPast, config_class=_CONFIG_FOR_DOC)
    def forward(
        self,
        input_ids: Optional[torch.Tensor] = None,
        attention_mask: Optional[torch.Tensor] = None,
        position_ids: Optional[torch.Tensor] = None,
        pixel_values: Optional[torch.Tensor] = None,
        head_mask: Optional[torch.Tensor] = None,
        inputs_embeds: Optional[torch.Tensor] = None,
        labels: Optional[torch.Tensor] = None,
        past_key_values: Optional[Union[Cache, List[torch.Tensor]]] = None,
        use_cache: Optional[bool] = None,
        output_attentions: Optional[bool] = None,
        output_hidden_states: Optional[bool] = None,
        return_dict: Optional[bool] = None,
    ) -&gt; Union[Tuple[torch.Tensor], CausalLMOutputWithPast]:
        r"""
        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):
            Labels for computing the left-to-right language modeling loss (next word prediction). Indices should be in
            `[-100, 0, ..., config.vocab_size]` (see `input_ids` docstring) Tokens with indices set to `-100` are
            ignored (masked), the loss is only computed for the tokens with labels n `[0, ..., config.vocab_size]`
        use_cache (`bool`, *optional*):
            If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding (see
            `past_key_values`).

        Returns:

        Examples:

        Image captioning example:

        ```python
        &gt;&gt;&gt; from transformers import AutoProcessor, AutoModelForCausalLM
        &gt;&gt;&gt; import requests
        &gt;&gt;&gt; from PIL import Image

        &gt;&gt;&gt; processor = AutoProcessor.from_pretrained("microsoft/git-base-coco")
        &gt;&gt;&gt; model = AutoModelForCausalLM.from_pretrained("microsoft/git-base-coco")

        &gt;&gt;&gt; url = "http://images.cocodataset.org/val2017/000000039769.jpg"
        &gt;&gt;&gt; image = Image.open(requests.get(url, stream=True).raw)

        &gt;&gt;&gt; pixel_values = processor(images=image, return_tensors="pt").pixel_values

        &gt;&gt;&gt; generated_ids = model.generate(pixel_values=pixel_values, max_length=50)
        &gt;&gt;&gt; generated_caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
        &gt;&gt;&gt; print(generated_caption)
        two cats sleeping on a pink blanket next to remotes.
        ```

        Visual question answering (VQA) example:

        ```python
        &gt;&gt;&gt; from transformers import AutoProcessor, AutoModelForCausalLM
        &gt;&gt;&gt; from huggingface_hub import hf_hub_download
        &gt;&gt;&gt; from PIL import Image

        &gt;&gt;&gt; processor = AutoProcessor.from_pretrained("microsoft/git-base-textvqa")
        &gt;&gt;&gt; model = AutoModelForCausalLM.from_pretrained("microsoft/git-base-textvqa")

        &gt;&gt;&gt; file_path = hf_hub_download(repo_id="nielsr/textvqa-sample", filename="bus.png", repo_type="dataset")
        &gt;&gt;&gt; image = Image.open(file_path).convert("RGB")

        &gt;&gt;&gt; pixel_values = processor(images=image, return_tensors="pt").pixel_values

        &gt;&gt;&gt; question = "what does the front of the bus say at the top?"

        &gt;&gt;&gt; input_ids = processor(text=question, add_special_tokens=False).input_ids
        &gt;&gt;&gt; input_ids = [processor.tokenizer.cls_token_id] + input_ids
        &gt;&gt;&gt; input_ids = torch.tensor(input_ids).unsqueeze(0)

        &gt;&gt;&gt; generated_ids = model.generate(pixel_values=pixel_values, input_ids=input_ids, max_length=50)
        &gt;&gt;&gt; print(processor.batch_decode(generated_ids, skip_special_tokens=True))
        ['what does the front of the bus say at the top? special']
        ```

        Video captioning example:

        ```python
        &gt;&gt;&gt; import av
        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; from PIL import Image
        &gt;&gt;&gt; from huggingface_hub import hf_hub_download
        &gt;&gt;&gt; from transformers import AutoProcessor, AutoModelForCausalLM

        &gt;&gt;&gt; processor = AutoProcessor.from_pretrained("microsoft/git-base-vatex")
        &gt;&gt;&gt; model = AutoModelForCausalLM.from_pretrained("microsoft/git-base-vatex")

        &gt;&gt;&gt; # set seed for reproducability
        &gt;&gt;&gt; np.random.seed(45)


        &gt;&gt;&gt; def read_video_pyav(container, indices):
        ...     '''
        ...     Decode the video with PyAV decoder.
        ...     Args:
        ...         container (`av.container.input.InputContainer`): PyAV container.
        ...         indices (`List[int]`): List of frame indices to decode.
        ...     Returns:
        ...         result (np.ndarray): np array of decoded frames of shape (num_frames, height, width, 3).
        ...     '''
        ...     frames = []
        ...     container.seek(0)
        ...     start_index = indices[0]
        ...     end_index = indices[-1]
        ...     for i, frame in enumerate(container.decode(video=0)):
        ...         if i &gt; end_index:
        ...             break
        ...         if i &gt;= start_index and i in indices:
        ...             frames.append(frame)
        ...     return np.stack([x.to_ndarray(format="rgb24") for x in frames])


        &gt;&gt;&gt; def sample_frame_indices(clip_len, frame_sample_rate, seg_len):
        ...     '''
        ...     Sample a given number of frame indices from the video.
        ...     Args:
        ...         clip_len (`int`): Total number of frames to sample.
        ...         frame_sample_rate (`int`): Sample every n-th frame.
        ...         seg_len (`int`): Maximum allowed index of sample's last frame.
        ...     Returns:
        ...         indices (`List[int]`): List of sampled frame indices
        ...     '''
        ...     converted_len = int(clip_len * frame_sample_rate)
        ...     end_idx = np.random.randint(converted_len, seg_len)
        ...     start_idx = end_idx - converted_len
        ...     indices = np.linspace(start_idx, end_idx, num=clip_len)
        ...     indices = np.clip(indices, start_idx, end_idx - 1).astype(np.int64)
        ...     return indices


        &gt;&gt;&gt; # load video
        &gt;&gt;&gt; file_path = hf_hub_download(
        ...     repo_id="nielsr/video-demo", filename="eating_spaghetti.mp4", repo_type="dataset"
        ... )
        &gt;&gt;&gt; container = av.open(file_path)

        &gt;&gt;&gt; # sample frames
        &gt;&gt;&gt; num_frames = model.config.num_image_with_embedding
        &gt;&gt;&gt; indices = sample_frame_indices(
        ...     clip_len=num_frames, frame_sample_rate=4, seg_len=container.streams.video[0].frames
        ... )
        &gt;&gt;&gt; frames = read_video_pyav(container, indices)

        &gt;&gt;&gt; pixel_values = processor(images=list(frames), return_tensors="pt").pixel_values

        &gt;&gt;&gt; generated_ids = model.generate(pixel_values=pixel_values, max_length=50)

        &gt;&gt;&gt; print("Generated caption:", processor.batch_decode(generated_ids, skip_special_tokens=True))
        Generated caption: ['a woman is sitting at a table and she is talking about the food she is holding.']
        ```
        """
        return_dict = return_dict if return_dict is not None else self.config.use_return_dict
        if labels is not None:
            use_cache = False

        outputs = self.git(
            input_ids,
            attention_mask=attention_mask,
            position_ids=position_ids,
            pixel_values=pixel_values,
            head_mask=head_mask,
            inputs_embeds=inputs_embeds,
            past_key_values=past_key_values,
            use_cache=use_cache,
            output_attentions=output_attentions,
            output_hidden_states=output_hidden_states,
            return_dict=return_dict,
        )

        sequence_output = outputs[0]
        logits = self.output(sequence_output)

        loss = None
        if labels is not None:
            # we are doing next-token prediction; shift prediction scores and input ids by one
            num_image_tokens = self.git.encoder.layer[0].attention.self.image_patch_tokens
            shifted_logits = logits[:, num_image_tokens:-1, :].contiguous()
            labels = labels[:, 1:].contiguous()
            loss_fct = CrossEntropyLoss()
            loss = loss_fct(shifted_logits.view(-1, self.config.vocab_size), labels.view(-1))

        if not return_dict:
            output = (logits,) + outputs[1:]
            return ((loss,) + output) if loss is not None else output

        return CausalLMOutputWithPast(
            loss=loss,
            logits=logits,
            past_key_values=outputs.past_key_values,
            hidden_states=outputs.hidden_states,
            attentions=outputs.attentions,
        )

    def prepare_inputs_for_generation(
        self, input_ids, past_key_values=None, attention_mask=None, use_cache=None, **kwargs
    ):
        # cut decoder_input_ids if past_key_values is used
        if past_key_values is not None:
            past_length = past_key_values.get_seq_length()

            # Some generation methods already pass only the last input ID
            if input_ids.shape[1] &gt; past_length:
                remove_prefix_length = past_length
            else:
                # Default to old behavior: keep only final ID
                remove_prefix_length = input_ids.shape[1] - 1

            input_ids = input_ids[:, remove_prefix_length:]

        # if model is used as a decoder in encoder-decoder model, the decoder attention mask is created on the fly
        input_shape = input_ids.shape
        if attention_mask is None:
            attention_mask = input_ids.new_ones(input_shape)

        return {
            "input_ids": input_ids,
            "attention_mask": attention_mask,
            "pixel_values": kwargs.get("pixel_values", None),
            "past_key_values": past_key_values,
            "use_cache": use_cache,
        }

    def _reorder_cache(self, past_key_values, beam_idx):
        reordered_past = ()
        for layer_past in past_key_values:
            reordered_past += (
                tuple(past_state.index_select(0, beam_idx.to(past_state.device)) for past_state in layer_past),
            )
        return reordered_past
Init docstring: Initialize internal Module state, shared by both nn.Module and ScriptModule.</code></pre>
</div>
</div>
</section>
<section id="evaluate" class="level2">
<h2 class="anchored" data-anchor-id="evaluate">Evaluate</h2>
<p>Image captioning models are typically evaluated with the <a href="https://huggingface.co/spaces/evaluate-metric/rouge">Rouge Score</a> or <a href="https://huggingface.co/spaces/evaluate-metric/wer">Word Error Rate</a>. For this guide, you will use the Word Error Rate (WER).</p>
<p>We use the 🤗 Evaluate library to do so. For potential limitations and other gotchas of the WER, refer to <a href="https://huggingface.co/spaces/evaluate-metric/wer">this guide</a>.</p>
<div id="cell-36" class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1"></a><span class="im">from</span> evaluate <span class="im">import</span> load</span>
<span id="cb37-2"><a href="#cb37-2"></a><span class="im">import</span> torch</span>
<span id="cb37-3"><a href="#cb37-3"></a></span>
<span id="cb37-4"><a href="#cb37-4"></a>wer <span class="op">=</span> load(<span class="st">"wer"</span>)</span>
<span id="cb37-5"><a href="#cb37-5"></a></span>
<span id="cb37-6"><a href="#cb37-6"></a></span>
<span id="cb37-7"><a href="#cb37-7"></a><span class="kw">def</span> compute_metrics(eval_pred):</span>
<span id="cb37-8"><a href="#cb37-8"></a>    logits, labels <span class="op">=</span> eval_pred</span>
<span id="cb37-9"><a href="#cb37-9"></a>    predicted <span class="op">=</span> logits.argmax(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb37-10"><a href="#cb37-10"></a>    decoded_labels <span class="op">=</span> processor.batch_decode(labels, skip_special_tokens<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb37-11"><a href="#cb37-11"></a>    decoded_predictions <span class="op">=</span> processor.batch_decode(predicted, skip_special_tokens<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb37-12"><a href="#cb37-12"></a>    wer_score <span class="op">=</span> wer.compute(predictions<span class="op">=</span>decoded_predictions, references<span class="op">=</span>decoded_labels)</span>
<span id="cb37-13"><a href="#cb37-13"></a>    <span class="cf">return</span> {<span class="st">"wer_score"</span>: wer_score}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="train" class="level2">
<h2 class="anchored" data-anchor-id="train">Train!</h2>
<p>Now, you are ready to start fine-tuning the model. You will use the 🤗 <a href="https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer">Trainer</a> for this.</p>
<p>First, define the training arguments using <a href="https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a>.</p>
<div id="cell-39" class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1"></a><span class="im">from</span> transformers <span class="im">import</span> TrainingArguments, Trainer</span>
<span id="cb38-2"><a href="#cb38-2"></a></span>
<span id="cb38-3"><a href="#cb38-3"></a>model_name <span class="op">=</span> checkpoint.split(<span class="st">"/"</span>)[<span class="dv">1</span>]</span>
<span id="cb38-4"><a href="#cb38-4"></a></span>
<span id="cb38-5"><a href="#cb38-5"></a>training_args <span class="op">=</span> TrainingArguments(</span>
<span id="cb38-6"><a href="#cb38-6"></a>    output_dir<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss">-pokemon"</span>,</span>
<span id="cb38-7"><a href="#cb38-7"></a>    learning_rate<span class="op">=</span><span class="fl">5e-5</span>,</span>
<span id="cb38-8"><a href="#cb38-8"></a>    num_train_epochs<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb38-9"><a href="#cb38-9"></a>    fp16<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb38-10"><a href="#cb38-10"></a>    per_device_train_batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb38-11"><a href="#cb38-11"></a>    per_device_eval_batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb38-12"><a href="#cb38-12"></a>    gradient_accumulation_steps<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb38-13"><a href="#cb38-13"></a>    save_total_limit<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb38-14"><a href="#cb38-14"></a>    evaluation_strategy<span class="op">=</span><span class="st">"steps"</span>,</span>
<span id="cb38-15"><a href="#cb38-15"></a>    eval_steps<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb38-16"><a href="#cb38-16"></a>    save_strategy<span class="op">=</span><span class="st">"steps"</span>,</span>
<span id="cb38-17"><a href="#cb38-17"></a>    save_steps<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb38-18"><a href="#cb38-18"></a>    logging_steps<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb38-19"><a href="#cb38-19"></a>    remove_unused_columns<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb38-20"><a href="#cb38-20"></a>    push_to_hub<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb38-21"><a href="#cb38-21"></a>    label_names<span class="op">=</span>[<span class="st">"labels"</span>],</span>
<span id="cb38-22"><a href="#cb38-22"></a>    load_best_model_at_end<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb38-23"><a href="#cb38-23"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then pass them along with the datasets and the model to 🤗 Trainer.</p>
<div id="cell-41" class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1"></a>trainer <span class="op">=</span> Trainer(</span>
<span id="cb39-2"><a href="#cb39-2"></a>    model<span class="op">=</span>model,</span>
<span id="cb39-3"><a href="#cb39-3"></a>    args<span class="op">=</span>training_args,</span>
<span id="cb39-4"><a href="#cb39-4"></a>    train_dataset<span class="op">=</span>train_ds,</span>
<span id="cb39-5"><a href="#cb39-5"></a>    eval_dataset<span class="op">=</span>test_ds,</span>
<span id="cb39-6"><a href="#cb39-6"></a>    compute_metrics<span class="op">=</span>compute_metrics,</span>
<span id="cb39-7"><a href="#cb39-7"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To start training, simply call <a href="https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train">train()</a> on the <a href="https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer">Trainer</a> object.</p>
<div id="cell-43" class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1"></a>trainer.train()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>You should see the training loss drop smoothly as training progresses.</p>
<p>Once training is completed, share your model to the Hub with the <a href="https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.push_to_hub">push_to_hub()</a> method so everyone can use your model:</p>
<div id="cell-45" class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1"></a>trainer.push_to_hub()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="inference" class="level2">
<h2 class="anchored" data-anchor-id="inference">Inference</h2>
<p>Take a sample image from <code>test_ds</code> to test the model.</p>
<div id="cell-48" class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb42-2"><a href="#cb42-2"></a><span class="im">import</span> requests</span>
<span id="cb42-3"><a href="#cb42-3"></a></span>
<span id="cb42-4"><a href="#cb42-4"></a>url <span class="op">=</span> <span class="st">"https://huggingface.co/datasets/sayakpaul/sample-datasets/resolve/main/pokemon.png"</span></span>
<span id="cb42-5"><a href="#cb42-5"></a>image <span class="op">=</span> Image.<span class="bu">open</span>(requests.get(url, stream<span class="op">=</span><span class="va">True</span>).raw)</span>
<span id="cb42-6"><a href="#cb42-6"></a>image</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="flex justify-center">
<pre><code>&lt;img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/test_image_image_cap.png" alt="Test image"/&gt;</code></pre>
</div>
<p>Prepare image for the model.</p>
<div id="cell-50" class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1"></a>device <span class="op">=</span> <span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span></span>
<span id="cb44-2"><a href="#cb44-2"></a></span>
<span id="cb44-3"><a href="#cb44-3"></a>inputs <span class="op">=</span> processor(images<span class="op">=</span>image, return_tensors<span class="op">=</span><span class="st">"pt"</span>).to(device)</span>
<span id="cb44-4"><a href="#cb44-4"></a>pixel_values <span class="op">=</span> inputs.pixel_values</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Call <code>generate</code> and decode the predictions.</p>
<div id="cell-52" class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1"></a>generated_ids <span class="op">=</span> model.generate(pixel_values<span class="op">=</span>pixel_values, max_length<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb45-2"><a href="#cb45-2"></a>generated_caption <span class="op">=</span> processor.batch_decode(generated_ids, skip_special_tokens<span class="op">=</span><span class="va">True</span>)[<span class="dv">0</span>]</span>
<span id="cb45-3"><a href="#cb45-3"></a><span class="bu">print</span>(generated_caption)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="sourceCode" id="cb46"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb46-1"><a href="#cb46-1"></a><span class="ex">a</span> drawing of a pink and blue pokemon</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Looks like the fine-tuned model generated a pretty good caption!</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="miruetoto/yechan3" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->




</body></html>