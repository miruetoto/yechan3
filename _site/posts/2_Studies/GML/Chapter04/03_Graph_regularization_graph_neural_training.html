<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="신록예찬">
<meta name="dcterms.date" content="2023-02-10">

<title>신록예찬’s Blog - [GML] Chap4: 지도 그래프 학습 - 그래프 정규화 방법</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="../../../../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../../index.html">
    <span class="navbar-title">신록예찬’s Blog</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://guebin.github.io/DL2022/">
 <span class="menu-text">DL2022</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://guebin.github.io/DV2022/">
 <span class="menu-text">DV2022</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://guebin.github.io/IP2022/">
 <span class="menu-text">IP2022</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://guebin.github.io/SC2022/">
 <span class="menu-text">SC2022</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://guebin.github.io/DS2022/">
 <span class="menu-text">DS2022</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://guebin.github.io/IR2021/">
 <span class="menu-text">IR2021</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://miruetoto.github.io/yechan/">
 <span class="menu-text">yechan</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://miruetoto.github.io/yechan2/">
 <span class="menu-text">yechan2</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/miruetoto/yechan3"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><strong>[GML]</strong> Chap4: 지도 그래프 학습 - 그래프 정규화 방법</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title d-none d-lg-block"><strong>[GML]</strong> Chap4: 지도 그래프 학습 - 그래프 정규화 방법</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>신록예찬 </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 10, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../1_essays.html" class="sidebar-item-text sidebar-link"><strong>Essays</strong></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true"><strong>Studies</strong></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../2_cgsp.html" class="sidebar-item-text sidebar-link">CGSP</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../2_gml.html" class="sidebar-item-text sidebar-link">GML</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../2_python.html" class="sidebar-item-text sidebar-link">Python</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../2_pl.html" class="sidebar-item-text sidebar-link">PyTorch Lightning</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../2_reviews.html" class="sidebar-item-text sidebar-link">Reviews</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true"><strong>Researches</strong></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../3_hst.html" class="sidebar-item-text sidebar-link">HST</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../3_itstgcn.html" class="sidebar-item-text sidebar-link">IT-STGCN</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../4_notes.html" class="sidebar-item-text sidebar-link"><strong><em>Notes</em></strong></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#neural-graph-learning-and-graph-regularization" id="toc-neural-graph-learning-and-graph-regularization" class="nav-link active" data-scroll-target="#neural-graph-learning-and-graph-regularization">Neural Graph Learning and Graph Regularization</a>
  <ul class="collapse">
  <li><a href="#load-dataset" id="toc-load-dataset" class="nav-link" data-scroll-target="#load-dataset">Load Dataset</a></li>
  <li><a href="#creating-the-model" id="toc-creating-the-model" class="nav-link" data-scroll-target="#creating-the-model">Creating the model</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="neural-graph-learning-and-graph-regularization" class="level1">
<h1>Neural Graph Learning and Graph Regularization</h1>
<p>In this tutorial, we will be creating a graph regularized version for a topic classification task. The task is to classify paper depending on their content. However in order to do so, we will also use the information encoded in the citation network that relates documents among each other. Of course, we do know that this kind of information is indeed powerful as papers belonging to the same subject tend to reference each other.</p>
<section id="load-dataset" class="level3">
<h3 class="anchored" data-anchor-id="load-dataset">Load Dataset</h3>
<p>For this tutorial we will be using the Cora dataset available in the stellargraph library</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">from</span> stellargraph <span class="im">import</span> datasets</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a>dataset <span class="op">=</span> datasets.Cora()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="op">%</span>config Completer.use_jedi <span class="op">=</span> <span class="va">False</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a>dataset.download()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a>label_index <span class="op">=</span> {</span>
<span id="cb5-2"><a href="#cb5-2"></a>      <span class="st">'Case_Based'</span>: <span class="dv">0</span>,</span>
<span id="cb5-3"><a href="#cb5-3"></a>      <span class="st">'Genetic_Algorithms'</span>: <span class="dv">1</span>,</span>
<span id="cb5-4"><a href="#cb5-4"></a>      <span class="st">'Neural_Networks'</span>: <span class="dv">2</span>,</span>
<span id="cb5-5"><a href="#cb5-5"></a>      <span class="st">'Probabilistic_Methods'</span>: <span class="dv">3</span>,</span>
<span id="cb5-6"><a href="#cb5-6"></a>      <span class="st">'Reinforcement_Learning'</span>: <span class="dv">4</span>,</span>
<span id="cb5-7"><a href="#cb5-7"></a>      <span class="st">'Rule_Learning'</span>: <span class="dv">5</span>,</span>
<span id="cb5-8"><a href="#cb5-8"></a>      <span class="st">'Theory'</span>: <span class="dv">6</span>,</span>
<span id="cb5-9"><a href="#cb5-9"></a>  }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a>G, labels <span class="op">=</span> dataset.load()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We now create the Dataset object where we will both include information of the targeted sample (node) and its neighbors. In the following we will also allow to control the number of labelling instances to be used, in order to reproduce and evaluate the classification performance in a semi-supervised setting.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="im">from</span> sklearn <span class="im">import</span> preprocessing, feature_extraction, model_selection</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb8-2"><a href="#cb8-2"></a><span class="im">from</span> tensorflow.train <span class="im">import</span> Example, Features, Feature, Int64List, BytesList, FloatList</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a>GRAPH_PREFIX<span class="op">=</span><span class="st">"NL_nbr"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a><span class="kw">def</span> _int64_feature(<span class="op">*</span>value):</span>
<span id="cb10-2"><a href="#cb10-2"></a>    <span class="co">"""Returns int64 tf.train.Feature from a bool / enum / int / uint."""</span></span>
<span id="cb10-3"><a href="#cb10-3"></a>    <span class="cf">return</span> Feature(int64_list<span class="op">=</span>Int64List(value<span class="op">=</span><span class="bu">list</span>(value)))</span>
<span id="cb10-4"><a href="#cb10-4"></a></span>
<span id="cb10-5"><a href="#cb10-5"></a><span class="kw">def</span> _bytes_feature(value):</span>
<span id="cb10-6"><a href="#cb10-6"></a>    <span class="co">"""Returns bytes tf.train.Feature from a string."""</span></span>
<span id="cb10-7"><a href="#cb10-7"></a>    <span class="cf">return</span> Feature(</span>
<span id="cb10-8"><a href="#cb10-8"></a>        bytes_list<span class="op">=</span>BytesList(value<span class="op">=</span>[value.encode(<span class="st">'utf-8'</span>)])</span>
<span id="cb10-9"><a href="#cb10-9"></a>    )</span>
<span id="cb10-10"><a href="#cb10-10"></a></span>
<span id="cb10-11"><a href="#cb10-11"></a><span class="kw">def</span> _float_feature(<span class="op">*</span>value):</span>
<span id="cb10-12"><a href="#cb10-12"></a>    <span class="cf">return</span> Feature(float_list<span class="op">=</span>FloatList(value<span class="op">=</span><span class="bu">list</span>(value)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1"></a><span class="im">from</span> functools <span class="im">import</span> <span class="bu">reduce</span></span>
<span id="cb11-2"><a href="#cb11-2"></a><span class="im">from</span> typing <span class="im">import</span> List, Tuple</span>
<span id="cb11-3"><a href="#cb11-3"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb11-4"><a href="#cb11-4"></a><span class="im">import</span> six</span>
<span id="cb11-5"><a href="#cb11-5"></a></span>
<span id="cb11-6"><a href="#cb11-6"></a><span class="kw">def</span> addFeatures(x, y):</span>
<span id="cb11-7"><a href="#cb11-7"></a>    res <span class="op">=</span> Features()</span>
<span id="cb11-8"><a href="#cb11-8"></a>    res.CopyFrom(x)</span>
<span id="cb11-9"><a href="#cb11-9"></a>    res.MergeFrom(y)</span>
<span id="cb11-10"><a href="#cb11-10"></a>    <span class="cf">return</span> res</span>
<span id="cb11-11"><a href="#cb11-11"></a></span>
<span id="cb11-12"><a href="#cb11-12"></a><span class="kw">def</span> neighborFeatures(features: Features, weight: <span class="bu">float</span>, prefix: <span class="bu">str</span>):</span>
<span id="cb11-13"><a href="#cb11-13"></a>    data <span class="op">=</span> {<span class="ss">f"</span><span class="sc">{</span>prefix<span class="sc">}</span><span class="ss">_weight"</span>: _float_feature(weight)}</span>
<span id="cb11-14"><a href="#cb11-14"></a>    <span class="cf">for</span> name, feature <span class="kw">in</span> six.iteritems(features.feature):</span>
<span id="cb11-15"><a href="#cb11-15"></a>        data[<span class="ss">f"</span><span class="sc">{</span>prefix<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">"</span>] <span class="op">=</span> feature </span>
<span id="cb11-16"><a href="#cb11-16"></a>    <span class="cf">return</span> Features(feature<span class="op">=</span>data)</span>
<span id="cb11-17"><a href="#cb11-17"></a></span>
<span id="cb11-18"><a href="#cb11-18"></a><span class="kw">def</span> neighborsFeatures(neighbors: List[Tuple[Features, <span class="bu">float</span>]]):</span>
<span id="cb11-19"><a href="#cb11-19"></a>    <span class="cf">return</span> <span class="bu">reduce</span>(</span>
<span id="cb11-20"><a href="#cb11-20"></a>        addFeatures, </span>
<span id="cb11-21"><a href="#cb11-21"></a>        [neighborFeatures(sample, weight, <span class="ss">f"</span><span class="sc">{</span>GRAPH_PREFIX<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>ith<span class="sc">}</span><span class="ss">"</span>) <span class="cf">for</span> ith, (sample, weight) <span class="kw">in</span> <span class="bu">enumerate</span>(neighbors)],</span>
<span id="cb11-22"><a href="#cb11-22"></a>        Features()</span>
<span id="cb11-23"><a href="#cb11-23"></a>    )</span>
<span id="cb11-24"><a href="#cb11-24"></a></span>
<span id="cb11-25"><a href="#cb11-25"></a><span class="kw">def</span> getNeighbors(idx, adjMatrix, topn<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb11-26"><a href="#cb11-26"></a>    weights <span class="op">=</span> adjMatrix.loc[idx]</span>
<span id="cb11-27"><a href="#cb11-27"></a>    <span class="cf">return</span> weights[weights<span class="op">&gt;</span><span class="dv">0</span>].sort_values(ascending<span class="op">=</span><span class="va">False</span>).head(topn).to_dict()</span>
<span id="cb11-28"><a href="#cb11-28"></a>    </span>
<span id="cb11-29"><a href="#cb11-29"></a></span>
<span id="cb11-30"><a href="#cb11-30"></a><span class="kw">def</span> semisupervisedDataset(G, labels, ratio<span class="op">=</span><span class="fl">0.2</span>, topn<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb11-31"><a href="#cb11-31"></a>    n <span class="op">=</span> <span class="bu">int</span>(np.<span class="bu">round</span>(<span class="bu">len</span>(labels)<span class="op">*</span>ratio))</span>
<span id="cb11-32"><a href="#cb11-32"></a>    </span>
<span id="cb11-33"><a href="#cb11-33"></a>    labelled, unlabelled <span class="op">=</span> model_selection.train_test_split(</span>
<span id="cb11-34"><a href="#cb11-34"></a>        labels, train_size<span class="op">=</span>n, test_size<span class="op">=</span><span class="va">None</span>, stratify<span class="op">=</span>labels</span>
<span id="cb11-35"><a href="#cb11-35"></a>    )</span>
<span id="cb11-36"><a href="#cb11-36"></a>    </span>
<span id="cb11-37"><a href="#cb11-37"></a>    adjMatrix <span class="op">=</span> pd.DataFrame.sparse.from_spmatrix(G.to_adjacency_matrix(), index<span class="op">=</span>G.nodes(), columns<span class="op">=</span>G.nodes())</span>
<span id="cb11-38"><a href="#cb11-38"></a>    </span>
<span id="cb11-39"><a href="#cb11-39"></a>    features <span class="op">=</span> pd.DataFrame(G.node_features(), index<span class="op">=</span>G.nodes())</span>
<span id="cb11-40"><a href="#cb11-40"></a>    </span>
<span id="cb11-41"><a href="#cb11-41"></a>    dataset <span class="op">=</span> {</span>
<span id="cb11-42"><a href="#cb11-42"></a>        index: Features(feature <span class="op">=</span> {</span>
<span id="cb11-43"><a href="#cb11-43"></a>            <span class="co">#"id": _bytes_feature(str(index)), </span></span>
<span id="cb11-44"><a href="#cb11-44"></a>            <span class="st">"id"</span>: _int64_feature(index),</span>
<span id="cb11-45"><a href="#cb11-45"></a>            <span class="st">"words"</span>: _float_feature(<span class="op">*</span>[<span class="bu">float</span>(x) <span class="cf">for</span> x <span class="kw">in</span> features.loc[index].values]), </span>
<span id="cb11-46"><a href="#cb11-46"></a>            <span class="st">"label"</span>: _int64_feature(label_index[label])</span>
<span id="cb11-47"><a href="#cb11-47"></a>        })</span>
<span id="cb11-48"><a href="#cb11-48"></a>        <span class="cf">for</span> index, label <span class="kw">in</span> pd.concat([labelled, unlabelled]).items()</span>
<span id="cb11-49"><a href="#cb11-49"></a>    }</span>
<span id="cb11-50"><a href="#cb11-50"></a>    </span>
<span id="cb11-51"><a href="#cb11-51"></a>    trainingSet <span class="op">=</span> [</span>
<span id="cb11-52"><a href="#cb11-52"></a>        Example(features<span class="op">=</span>addFeatures(</span>
<span id="cb11-53"><a href="#cb11-53"></a>            dataset[exampleId], </span>
<span id="cb11-54"><a href="#cb11-54"></a>            neighborsFeatures(</span>
<span id="cb11-55"><a href="#cb11-55"></a>                [(dataset[nodeId], weight) <span class="cf">for</span> nodeId, weight <span class="kw">in</span> getNeighbors(exampleId, adjMatrix, topn).items()]</span>
<span id="cb11-56"><a href="#cb11-56"></a>            )</span>
<span id="cb11-57"><a href="#cb11-57"></a>        ))</span>
<span id="cb11-58"><a href="#cb11-58"></a>        <span class="cf">for</span> exampleId <span class="kw">in</span> labelled.index</span>
<span id="cb11-59"><a href="#cb11-59"></a>    ]</span>
<span id="cb11-60"><a href="#cb11-60"></a>    </span>
<span id="cb11-61"><a href="#cb11-61"></a>    testSet <span class="op">=</span> [Example(features<span class="op">=</span>dataset[exampleId]) <span class="cf">for</span> exampleId <span class="kw">in</span> unlabelled.index]</span>
<span id="cb11-62"><a href="#cb11-62"></a></span>
<span id="cb11-63"><a href="#cb11-63"></a>    serializer <span class="op">=</span> <span class="kw">lambda</span> _list: [e.SerializeToString() <span class="cf">for</span> e <span class="kw">in</span> _list]</span>
<span id="cb11-64"><a href="#cb11-64"></a>    </span>
<span id="cb11-65"><a href="#cb11-65"></a>    <span class="cf">return</span> serializer(trainingSet), serializer(testSet)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We split the dataset into a training set and a test set</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a>trainingSet, testSet <span class="op">=</span> semisupervisedDataset(G, labels)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a><span class="im">from</span> tensorflow.data <span class="im">import</span> Dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1"></a>vocabularySize <span class="op">=</span> <span class="dv">1433</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1"></a>neighbors<span class="op">=</span><span class="dv">2</span></span>
<span id="cb16-2"><a href="#cb16-2"></a>defaultWord <span class="op">=</span> tf.constant(<span class="dv">0</span>, dtype<span class="op">=</span>tf.float32, shape<span class="op">=</span>[vocabularySize])</span>
<span id="cb16-3"><a href="#cb16-3"></a></span>
<span id="cb16-4"><a href="#cb16-4"></a><span class="kw">def</span> parseExample(example, training<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb16-5"><a href="#cb16-5"></a>    schema <span class="op">=</span> {</span>
<span id="cb16-6"><a href="#cb16-6"></a>        <span class="st">'words'</span>: tf.io.FixedLenFeature([vocabularySize], tf.float32, default_value<span class="op">=</span>defaultWord),</span>
<span id="cb16-7"><a href="#cb16-7"></a>        <span class="st">'label'</span>: tf.io.FixedLenFeature((), tf.int64, default_value<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb16-8"><a href="#cb16-8"></a>    }</span>
<span id="cb16-9"><a href="#cb16-9"></a>    </span>
<span id="cb16-10"><a href="#cb16-10"></a>    <span class="cf">if</span> training <span class="kw">is</span> <span class="va">True</span>:</span>
<span id="cb16-11"><a href="#cb16-11"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(neighbors):</span>
<span id="cb16-12"><a href="#cb16-12"></a>            name <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>GRAPH_PREFIX<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb16-13"><a href="#cb16-13"></a>            schema[<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">_weight"</span>] <span class="op">=</span> tf.io.FixedLenFeature([<span class="dv">1</span>], tf.float32, default_value<span class="op">=</span>[<span class="fl">0.0</span>])</span>
<span id="cb16-14"><a href="#cb16-14"></a>            schema[<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">_words"</span>] <span class="op">=</span> tf.io.FixedLenFeature([vocabularySize], tf.float32, default_value<span class="op">=</span>defaultWord)</span>
<span id="cb16-15"><a href="#cb16-15"></a>    </span>
<span id="cb16-16"><a href="#cb16-16"></a>    features <span class="op">=</span> tf.io.parse_single_example(example, schema)</span>
<span id="cb16-17"><a href="#cb16-17"></a>    </span>
<span id="cb16-18"><a href="#cb16-18"></a>    label <span class="op">=</span> features.pop(<span class="st">"label"</span>)</span>
<span id="cb16-19"><a href="#cb16-19"></a>    <span class="cf">return</span> features, label</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1"></a><span class="kw">def</span> sampleGenerator(dataset):</span>
<span id="cb17-2"><a href="#cb17-2"></a>    <span class="kw">def</span> wrapper():</span>
<span id="cb17-3"><a href="#cb17-3"></a>        <span class="cf">for</span> example <span class="kw">in</span> dataset:</span>
<span id="cb17-4"><a href="#cb17-4"></a>            <span class="cf">yield</span> example</span>
<span id="cb17-5"><a href="#cb17-5"></a>    <span class="cf">return</span> wrapper</span>
<span id="cb17-6"><a href="#cb17-6"></a>            </span>
<span id="cb17-7"><a href="#cb17-7"></a>myTrain <span class="op">=</span> Dataset <span class="op">\</span></span>
<span id="cb17-8"><a href="#cb17-8"></a>    .from_generator(sampleGenerator(trainingSet), output_types<span class="op">=</span>tf.string, output_shapes<span class="op">=</span>()) <span class="op">\</span></span>
<span id="cb17-9"><a href="#cb17-9"></a>    .<span class="bu">map</span>(<span class="kw">lambda</span> x: parseExample(x, <span class="va">True</span>))</span>
<span id="cb17-10"><a href="#cb17-10"></a></span>
<span id="cb17-11"><a href="#cb17-11"></a>myTest <span class="op">=</span> Dataset <span class="op">\</span></span>
<span id="cb17-12"><a href="#cb17-12"></a>    .from_generator(sampleGenerator(testSet), output_types<span class="op">=</span>tf.string, output_shapes<span class="op">=</span>()) <span class="op">\</span></span>
<span id="cb17-13"><a href="#cb17-13"></a>    .<span class="bu">map</span>(<span class="kw">lambda</span> x: parseExample(x, <span class="va">False</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1"></a><span class="cf">for</span> features, labels <span class="kw">in</span> myTrain.batch(<span class="dv">10</span>).take(<span class="dv">1</span>):</span>
<span id="cb18-2"><a href="#cb18-2"></a>    <span class="bu">print</span>(features)</span>
<span id="cb18-3"><a href="#cb18-3"></a>    <span class="bu">print</span>(labels)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'NL_nbr_0_weight': &lt;tf.Tensor: shape=(10, 1), dtype=float32, numpy=
array([[2.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [2.],
       [1.],
       [1.]], dtype=float32)&gt;, 'NL_nbr_0_words': &lt;tf.Tensor: shape=(10, 1433), dtype=float32, numpy=
array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       ...,
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 1., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)&gt;, 'NL_nbr_1_weight': &lt;tf.Tensor: shape=(10, 1), dtype=float32, numpy=
array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]], dtype=float32)&gt;, 'NL_nbr_1_words': &lt;tf.Tensor: shape=(10, 1433), dtype=float32, numpy=
array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       ...,
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)&gt;, 'words': &lt;tf.Tensor: shape=(10, 1433), dtype=float32, numpy=
array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       ...,
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)&gt;}
tf.Tensor([1 1 4 1 0 5 2 1 6 3], shape=(10,), dtype=int64)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1"></a><span class="cf">for</span> features, labels <span class="kw">in</span> myTest.batch(<span class="dv">10</span>).take(<span class="dv">1</span>):</span>
<span id="cb20-2"><a href="#cb20-2"></a>    <span class="bu">print</span>(features)</span>
<span id="cb20-3"><a href="#cb20-3"></a>    <span class="bu">print</span>(labels)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'words': &lt;tf.Tensor: shape=(10, 1433), dtype=float32, numpy=
array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       ...,
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)&gt;}
tf.Tensor([1 1 3 3 2 4 5 3 2 6], shape=(10,), dtype=int64)</code></pre>
</div>
</div>
</section>
<section id="creating-the-model" class="level3">
<h3 class="anchored" data-anchor-id="creating-the-model">Creating the model</h3>
<p>We now create the model that we will use to classify the documents</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1"></a>layers <span class="op">=</span> [<span class="dv">50</span>, <span class="dv">50</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1"></a><span class="co">"""Creates a functional API-based multi-layer perceptron model."""</span></span>
<span id="cb23-2"><a href="#cb23-2"></a><span class="kw">def</span> create_model(num_units):</span>
<span id="cb23-3"><a href="#cb23-3"></a>    inputs <span class="op">=</span> tf.keras.Input(</span>
<span id="cb23-4"><a href="#cb23-4"></a>          shape<span class="op">=</span>(vocabularySize,), dtype<span class="op">=</span><span class="st">'float32'</span>, name<span class="op">=</span><span class="st">'words'</span></span>
<span id="cb23-5"><a href="#cb23-5"></a>    )</span>
<span id="cb23-6"><a href="#cb23-6"></a></span>
<span id="cb23-7"><a href="#cb23-7"></a>    <span class="co"># outputs = tf.keras.layers.Dense(len(label_index), activation='softmax')(inputs)</span></span>
<span id="cb23-8"><a href="#cb23-8"></a></span>
<span id="cb23-9"><a href="#cb23-9"></a>    cur_layer <span class="op">=</span>  inputs</span>
<span id="cb23-10"><a href="#cb23-10"></a></span>
<span id="cb23-11"><a href="#cb23-11"></a>    <span class="cf">for</span> num_units <span class="kw">in</span> layers:</span>
<span id="cb23-12"><a href="#cb23-12"></a>        cur_layer <span class="op">=</span> tf.keras.layers.Dense(num_units, activation<span class="op">=</span><span class="st">'relu'</span>)(cur_layer)</span>
<span id="cb23-13"><a href="#cb23-13"></a>        cur_layer <span class="op">=</span> tf.keras.layers.Dropout(<span class="fl">0.8</span>)(cur_layer)</span>
<span id="cb23-14"><a href="#cb23-14"></a></span>
<span id="cb23-15"><a href="#cb23-15"></a>    outputs <span class="op">=</span> tf.keras.layers.Dense(<span class="bu">len</span>(label_index), activation<span class="op">=</span><span class="st">'softmax'</span>)(cur_layer)</span>
<span id="cb23-16"><a href="#cb23-16"></a></span>
<span id="cb23-17"><a href="#cb23-17"></a>    <span class="cf">return</span> tf.keras.Model(inputs, outputs<span class="op">=</span>outputs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1"></a><span class="im">from</span> tensorflow.keras.callbacks <span class="im">import</span> TensorBoard</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="vanilla-model" class="level4">
<h4 class="anchored" data-anchor-id="vanilla-model">Vanilla Model</h4>
<p>We first train a simple, vanilla version that does not use the citation network information</p>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1"></a>model <span class="op">=</span> create_model([<span class="dv">50</span>, <span class="dv">50</span>])</span>
<span id="cb25-2"><a href="#cb25-2"></a></span>
<span id="cb25-3"><a href="#cb25-3"></a>model.<span class="bu">compile</span>(</span>
<span id="cb25-4"><a href="#cb25-4"></a>    optimizer<span class="op">=</span><span class="st">'adam'</span>,</span>
<span id="cb25-5"><a href="#cb25-5"></a>    loss<span class="op">=</span><span class="st">'sparse_categorical_crossentropy'</span>,</span>
<span id="cb25-6"><a href="#cb25-6"></a>    metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1"></a>model.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
words (InputLayer)           [(None, 1433)]            0         
_________________________________________________________________
dense (Dense)                (None, 50)                71700     
_________________________________________________________________
dropout (Dropout)            (None, 50)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 50)                2550      
_________________________________________________________________
dropout_1 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 7)                 357       
=================================================================
Total params: 74,607
Trainable params: 74,607
Non-trainable params: 0
_________________________________________________________________</code></pre>
</div>
</div>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1"></a>model.fit(myTrain.batch(<span class="dv">128</span>), epochs<span class="op">=</span><span class="dv">200</span>, verbose<span class="op">=</span><span class="dv">1</span>, validation_data<span class="op">=</span>myTest.batch(<span class="dv">128</span>),</span>
<span id="cb28-2"><a href="#cb28-2"></a>          callbacks<span class="op">=</span>[TensorBoard(log_dir<span class="op">=</span><span class="st">'/tmp/noRegularization'</span>)])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/200</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/deusebio/.pyenv/versions/3.7.6/envs/ml-book-4/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['NL_nbr_0_weight', 'NL_nbr_0_words', 'NL_nbr_1_weight', 'NL_nbr_1_words'] which did not match any model input. They will be ignored by the model.
  [n for n in tensors.keys() if n not in ref_input_names])</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>5/5 [==============================] - 2s 323ms/step - loss: 1.9820 - accuracy: 0.1390 - val_loss: 1.9311 - val_accuracy: 0.2022
Epoch 2/200
5/5 [==============================] - 0s 114ms/step - loss: 1.9699 - accuracy: 0.1779 - val_loss: 1.9219 - val_accuracy: 0.2373
Epoch 3/200
5/5 [==============================] - 0s 117ms/step - loss: 1.9632 - accuracy: 0.1964 - val_loss: 1.9135 - val_accuracy: 0.2742
Epoch 4/200
5/5 [==============================] - 0s 106ms/step - loss: 2.0003 - accuracy: 0.1981 - val_loss: 1.9071 - val_accuracy: 0.2886
Epoch 5/200
5/5 [==============================] - 1s 117ms/step - loss: 1.9681 - accuracy: 0.1810 - val_loss: 1.9010 - val_accuracy: 0.2941
Epoch 6/200
5/5 [==============================] - 0s 117ms/step - loss: 1.8860 - accuracy: 0.2400 - val_loss: 1.8951 - val_accuracy: 0.3010
Epoch 7/200
5/5 [==============================] - 1s 124ms/step - loss: 1.8809 - accuracy: 0.2603 - val_loss: 1.8888 - val_accuracy: 0.3052
Epoch 8/200
5/5 [==============================] - 0s 111ms/step - loss: 1.8710 - accuracy: 0.2564 - val_loss: 1.8819 - val_accuracy: 0.3038
Epoch 9/200
5/5 [==============================] - 1s 130ms/step - loss: 1.8745 - accuracy: 0.2519 - val_loss: 1.8754 - val_accuracy: 0.3015
Epoch 10/200
5/5 [==============================] - 0s 111ms/step - loss: 1.8847 - accuracy: 0.2621 - val_loss: 1.8691 - val_accuracy: 0.3024
Epoch 11/200
5/5 [==============================] - 1s 117ms/step - loss: 1.8810 - accuracy: 0.2581 - val_loss: 1.8633 - val_accuracy: 0.3029
Epoch 12/200
5/5 [==============================] - 1s 124ms/step - loss: 1.8815 - accuracy: 0.2402 - val_loss: 1.8580 - val_accuracy: 0.3024
Epoch 13/200
5/5 [==============================] - 0s 109ms/step - loss: 1.8592 - accuracy: 0.2660 - val_loss: 1.8530 - val_accuracy: 0.3024
Epoch 14/200
5/5 [==============================] - 0s 106ms/step - loss: 1.8818 - accuracy: 0.2764 - val_loss: 1.8481 - val_accuracy: 0.3024
Epoch 15/200
5/5 [==============================] - 0s 112ms/step - loss: 1.8602 - accuracy: 0.2645 - val_loss: 1.8436 - val_accuracy: 0.3029
Epoch 16/200
5/5 [==============================] - 0s 110ms/step - loss: 1.8200 - accuracy: 0.2913 - val_loss: 1.8386 - val_accuracy: 0.3024
Epoch 17/200
5/5 [==============================] - 0s 105ms/step - loss: 1.7878 - accuracy: 0.2694 - val_loss: 1.8328 - val_accuracy: 0.3024
Epoch 18/200
5/5 [==============================] - 0s 104ms/step - loss: 1.8208 - accuracy: 0.2823 - val_loss: 1.8262 - val_accuracy: 0.3019
Epoch 19/200
5/5 [==============================] - 0s 116ms/step - loss: 1.8273 - accuracy: 0.2808 - val_loss: 1.8200 - val_accuracy: 0.3019
Epoch 20/200
5/5 [==============================] - 1s 122ms/step - loss: 1.8076 - accuracy: 0.2861 - val_loss: 1.8137 - val_accuracy: 0.3019
Epoch 21/200
5/5 [==============================] - 0s 112ms/step - loss: 1.7817 - accuracy: 0.2773 - val_loss: 1.8071 - val_accuracy: 0.3019
Epoch 22/200
5/5 [==============================] - 1s 148ms/step - loss: 1.7817 - accuracy: 0.2879 - val_loss: 1.7996 - val_accuracy: 0.3019
Epoch 23/200
5/5 [==============================] - 0s 106ms/step - loss: 1.8022 - accuracy: 0.2694 - val_loss: 1.7920 - val_accuracy: 0.3019
Epoch 24/200
5/5 [==============================] - 0s 113ms/step - loss: 1.7664 - accuracy: 0.2857 - val_loss: 1.7837 - val_accuracy: 0.3019
Epoch 25/200
5/5 [==============================] - 1s 118ms/step - loss: 1.7413 - accuracy: 0.3139 - val_loss: 1.7750 - val_accuracy: 0.3019
Epoch 26/200
5/5 [==============================] - 0s 111ms/step - loss: 1.7423 - accuracy: 0.2957 - val_loss: 1.7673 - val_accuracy: 0.3019
Epoch 27/200
5/5 [==============================] - 0s 104ms/step - loss: 1.7182 - accuracy: 0.3222 - val_loss: 1.7600 - val_accuracy: 0.3019
Epoch 28/200
5/5 [==============================] - 0s 109ms/step - loss: 1.7282 - accuracy: 0.3140 - val_loss: 1.7521 - val_accuracy: 0.3019
Epoch 29/200
5/5 [==============================] - 1s 132ms/step - loss: 1.7342 - accuracy: 0.2928 - val_loss: 1.7451 - val_accuracy: 0.3019
Epoch 30/200
5/5 [==============================] - 0s 116ms/step - loss: 1.6762 - accuracy: 0.3217 - val_loss: 1.7368 - val_accuracy: 0.3019
Epoch 31/200
5/5 [==============================] - 0s 106ms/step - loss: 1.7440 - accuracy: 0.2937 - val_loss: 1.7286 - val_accuracy: 0.3019
Epoch 32/200
5/5 [==============================] - 1s 119ms/step - loss: 1.7002 - accuracy: 0.2902 - val_loss: 1.7214 - val_accuracy: 0.3024
Epoch 33/200
5/5 [==============================] - 0s 106ms/step - loss: 1.6856 - accuracy: 0.3105 - val_loss: 1.7143 - val_accuracy: 0.3029
Epoch 34/200
5/5 [==============================] - 1s 120ms/step - loss: 1.6947 - accuracy: 0.2990 - val_loss: 1.7079 - val_accuracy: 0.3033
Epoch 35/200
5/5 [==============================] - 0s 107ms/step - loss: 1.6785 - accuracy: 0.3159 - val_loss: 1.7024 - val_accuracy: 0.3038
Epoch 36/200
5/5 [==============================] - 0s 117ms/step - loss: 1.6167 - accuracy: 0.3351 - val_loss: 1.6960 - val_accuracy: 0.3052
Epoch 37/200
5/5 [==============================] - 0s 114ms/step - loss: 1.6379 - accuracy: 0.3163 - val_loss: 1.6889 - val_accuracy: 0.3056
Epoch 38/200
5/5 [==============================] - 0s 117ms/step - loss: 1.6286 - accuracy: 0.3426 - val_loss: 1.6814 - val_accuracy: 0.3066
Epoch 39/200
5/5 [==============================] - 1s 118ms/step - loss: 1.6328 - accuracy: 0.3559 - val_loss: 1.6738 - val_accuracy: 0.3084
Epoch 40/200
5/5 [==============================] - 1s 118ms/step - loss: 1.6194 - accuracy: 0.3266 - val_loss: 1.6667 - val_accuracy: 0.3126
Epoch 41/200
5/5 [==============================] - 1s 117ms/step - loss: 1.5999 - accuracy: 0.3031 - val_loss: 1.6612 - val_accuracy: 0.3181
Epoch 42/200
5/5 [==============================] - 0s 111ms/step - loss: 1.6033 - accuracy: 0.3178 - val_loss: 1.6555 - val_accuracy: 0.3246
Epoch 43/200
5/5 [==============================] - 0s 111ms/step - loss: 1.6016 - accuracy: 0.3283 - val_loss: 1.6490 - val_accuracy: 0.3338
Epoch 44/200
5/5 [==============================] - 0s 107ms/step - loss: 1.5466 - accuracy: 0.3435 - val_loss: 1.6403 - val_accuracy: 0.3430
Epoch 45/200
5/5 [==============================] - 0s 107ms/step - loss: 1.5700 - accuracy: 0.3411 - val_loss: 1.6300 - val_accuracy: 0.3500
Epoch 46/200
5/5 [==============================] - 1s 152ms/step - loss: 1.5677 - accuracy: 0.3146 - val_loss: 1.6208 - val_accuracy: 0.3587
Epoch 47/200
5/5 [==============================] - 1s 163ms/step - loss: 1.5848 - accuracy: 0.3527 - val_loss: 1.6121 - val_accuracy: 0.3652
Epoch 48/200
5/5 [==============================] - 1s 159ms/step - loss: 1.5458 - accuracy: 0.3726 - val_loss: 1.6040 - val_accuracy: 0.3703
Epoch 49/200
5/5 [==============================] - 1s 128ms/step - loss: 1.5457 - accuracy: 0.3176 - val_loss: 1.5965 - val_accuracy: 0.3758
Epoch 50/200
5/5 [==============================] - 1s 143ms/step - loss: 1.5226 - accuracy: 0.3776 - val_loss: 1.5889 - val_accuracy: 0.3804
Epoch 51/200
5/5 [==============================] - 0s 113ms/step - loss: 1.5445 - accuracy: 0.3343 - val_loss: 1.5813 - val_accuracy: 0.3869
Epoch 52/200
5/5 [==============================] - 1s 127ms/step - loss: 1.5416 - accuracy: 0.3672 - val_loss: 1.5740 - val_accuracy: 0.3938
Epoch 53/200
5/5 [==============================] - 0s 113ms/step - loss: 1.4925 - accuracy: 0.3735 - val_loss: 1.5666 - val_accuracy: 0.3984
Epoch 54/200
5/5 [==============================] - 1s 120ms/step - loss: 1.4956 - accuracy: 0.3615 - val_loss: 1.5591 - val_accuracy: 0.4035
Epoch 55/200
5/5 [==============================] - 0s 108ms/step - loss: 1.5306 - accuracy: 0.3399 - val_loss: 1.5520 - val_accuracy: 0.4090
Epoch 56/200
5/5 [==============================] - 0s 115ms/step - loss: 1.4512 - accuracy: 0.3820 - val_loss: 1.5445 - val_accuracy: 0.4155
Epoch 57/200
5/5 [==============================] - 1s 131ms/step - loss: 1.4307 - accuracy: 0.3891 - val_loss: 1.5374 - val_accuracy: 0.4183
Epoch 58/200
5/5 [==============================] - 1s 120ms/step - loss: 1.4430 - accuracy: 0.3657 - val_loss: 1.5300 - val_accuracy: 0.4247
Epoch 59/200
5/5 [==============================] - 1s 143ms/step - loss: 1.4438 - accuracy: 0.3667 - val_loss: 1.5221 - val_accuracy: 0.4280
Epoch 60/200
5/5 [==============================] - 0s 112ms/step - loss: 1.4592 - accuracy: 0.3633 - val_loss: 1.5149 - val_accuracy: 0.4326
Epoch 61/200
5/5 [==============================] - 1s 182ms/step - loss: 1.4056 - accuracy: 0.3988 - val_loss: 1.5073 - val_accuracy: 0.4367
Epoch 62/200
5/5 [==============================] - 1s 125ms/step - loss: 1.4253 - accuracy: 0.3948 - val_loss: 1.5000 - val_accuracy: 0.4414
Epoch 63/200
5/5 [==============================] - 1s 149ms/step - loss: 1.3744 - accuracy: 0.4412 - val_loss: 1.4925 - val_accuracy: 0.4460
Epoch 64/200
5/5 [==============================] - 1s 133ms/step - loss: 1.3908 - accuracy: 0.4052 - val_loss: 1.4845 - val_accuracy: 0.4478
Epoch 65/200
5/5 [==============================] - 1s 119ms/step - loss: 1.3819 - accuracy: 0.4087 - val_loss: 1.4763 - val_accuracy: 0.4538
Epoch 66/200
5/5 [==============================] - 1s 130ms/step - loss: 1.3798 - accuracy: 0.4137 - val_loss: 1.4688 - val_accuracy: 0.4566
Epoch 67/200
5/5 [==============================] - 1s 125ms/step - loss: 1.3816 - accuracy: 0.4319 - val_loss: 1.4618 - val_accuracy: 0.4580
Epoch 68/200
5/5 [==============================] - 1s 122ms/step - loss: 1.3548 - accuracy: 0.4387 - val_loss: 1.4549 - val_accuracy: 0.4594
Epoch 69/200
5/5 [==============================] - 1s 144ms/step - loss: 1.3364 - accuracy: 0.4546 - val_loss: 1.4484 - val_accuracy: 0.4608
Epoch 70/200
5/5 [==============================] - 1s 137ms/step - loss: 1.3729 - accuracy: 0.4436 - val_loss: 1.4427 - val_accuracy: 0.4612
Epoch 71/200
5/5 [==============================] - 1s 142ms/step - loss: 1.3252 - accuracy: 0.4525 - val_loss: 1.4366 - val_accuracy: 0.4658
Epoch 72/200
5/5 [==============================] - 1s 125ms/step - loss: 1.3500 - accuracy: 0.4421 - val_loss: 1.4302 - val_accuracy: 0.4695
Epoch 73/200
5/5 [==============================] - 1s 121ms/step - loss: 1.2927 - accuracy: 0.4529 - val_loss: 1.4238 - val_accuracy: 0.4718
Epoch 74/200
5/5 [==============================] - 1s 129ms/step - loss: 1.2843 - accuracy: 0.4799 - val_loss: 1.4185 - val_accuracy: 0.4760
Epoch 75/200
5/5 [==============================] - 1s 140ms/step - loss: 1.2724 - accuracy: 0.5005 - val_loss: 1.4128 - val_accuracy: 0.4829
Epoch 76/200
5/5 [==============================] - 1s 119ms/step - loss: 1.3129 - accuracy: 0.4651 - val_loss: 1.4083 - val_accuracy: 0.4848
Epoch 77/200
5/5 [==============================] - 1s 121ms/step - loss: 1.2618 - accuracy: 0.4697 - val_loss: 1.4047 - val_accuracy: 0.4861
Epoch 78/200
5/5 [==============================] - 1s 140ms/step - loss: 1.2413 - accuracy: 0.5125 - val_loss: 1.4003 - val_accuracy: 0.4885
Epoch 79/200
5/5 [==============================] - 1s 118ms/step - loss: 1.2087 - accuracy: 0.5341 - val_loss: 1.3955 - val_accuracy: 0.4903
Epoch 80/200
5/5 [==============================] - 0s 117ms/step - loss: 1.2851 - accuracy: 0.4639 - val_loss: 1.3900 - val_accuracy: 0.4935
Epoch 81/200
5/5 [==============================] - 1s 155ms/step - loss: 1.2209 - accuracy: 0.5177 - val_loss: 1.3837 - val_accuracy: 0.4986
Epoch 82/200
5/5 [==============================] - 1s 165ms/step - loss: 1.1996 - accuracy: 0.5319 - val_loss: 1.3780 - val_accuracy: 0.5005
Epoch 83/200
5/5 [==============================] - 1s 136ms/step - loss: 1.2368 - accuracy: 0.4949 - val_loss: 1.3740 - val_accuracy: 0.5046
Epoch 84/200
5/5 [==============================] - 1s 128ms/step - loss: 1.2231 - accuracy: 0.5320 - val_loss: 1.3710 - val_accuracy: 0.5069
Epoch 85/200
5/5 [==============================] - 1s 124ms/step - loss: 1.2342 - accuracy: 0.5022 - val_loss: 1.3667 - val_accuracy: 0.5106
Epoch 86/200
5/5 [==============================] - 1s 121ms/step - loss: 1.2375 - accuracy: 0.4890 - val_loss: 1.3614 - val_accuracy: 0.5125
Epoch 87/200
5/5 [==============================] - 1s 126ms/step - loss: 1.2203 - accuracy: 0.5061 - val_loss: 1.3577 - val_accuracy: 0.5162
Epoch 88/200
5/5 [==============================] - 1s 120ms/step - loss: 1.2521 - accuracy: 0.5327 - val_loss: 1.3570 - val_accuracy: 0.5185
Epoch 89/200
5/5 [==============================] - 0s 117ms/step - loss: 1.1961 - accuracy: 0.5341 - val_loss: 1.3572 - val_accuracy: 0.5194
Epoch 90/200
5/5 [==============================] - 1s 123ms/step - loss: 1.1892 - accuracy: 0.5204 - val_loss: 1.3551 - val_accuracy: 0.5226
Epoch 91/200
5/5 [==============================] - 1s 137ms/step - loss: 1.1887 - accuracy: 0.5302 - val_loss: 1.3544 - val_accuracy: 0.5268
Epoch 92/200
5/5 [==============================] - 1s 125ms/step - loss: 1.1729 - accuracy: 0.5289 - val_loss: 1.3553 - val_accuracy: 0.5254
Epoch 93/200
5/5 [==============================] - 1s 129ms/step - loss: 1.1671 - accuracy: 0.5114 - val_loss: 1.3555 - val_accuracy: 0.5277
Epoch 94/200
5/5 [==============================] - 1s 121ms/step - loss: 1.1611 - accuracy: 0.5413 - val_loss: 1.3543 - val_accuracy: 0.5277
Epoch 95/200
5/5 [==============================] - 1s 156ms/step - loss: 1.1913 - accuracy: 0.5282 - val_loss: 1.3525 - val_accuracy: 0.5259
Epoch 96/200
5/5 [==============================] - 1s 168ms/step - loss: 1.1435 - accuracy: 0.5480 - val_loss: 1.3524 - val_accuracy: 0.5263
Epoch 97/200
5/5 [==============================] - 1s 130ms/step - loss: 1.1390 - accuracy: 0.5413 - val_loss: 1.3516 - val_accuracy: 0.5295
Epoch 98/200
5/5 [==============================] - 1s 120ms/step - loss: 1.1598 - accuracy: 0.5492 - val_loss: 1.3472 - val_accuracy: 0.5328
Epoch 99/200
5/5 [==============================] - 1s 122ms/step - loss: 1.1754 - accuracy: 0.4923 - val_loss: 1.3409 - val_accuracy: 0.5360
Epoch 100/200
5/5 [==============================] - 1s 126ms/step - loss: 1.1441 - accuracy: 0.5521 - val_loss: 1.3364 - val_accuracy: 0.5397
Epoch 101/200
5/5 [==============================] - 1s 140ms/step - loss: 1.1213 - accuracy: 0.5697 - val_loss: 1.3323 - val_accuracy: 0.5416
Epoch 102/200
5/5 [==============================] - 1s 125ms/step - loss: 1.1414 - accuracy: 0.5274 - val_loss: 1.3311 - val_accuracy: 0.5420
Epoch 103/200
5/5 [==============================] - 1s 151ms/step - loss: 1.0863 - accuracy: 0.5567 - val_loss: 1.3315 - val_accuracy: 0.5439
Epoch 104/200
5/5 [==============================] - 1s 132ms/step - loss: 1.0917 - accuracy: 0.5921 - val_loss: 1.3338 - val_accuracy: 0.5439
Epoch 105/200
5/5 [==============================] - 1s 130ms/step - loss: 1.1084 - accuracy: 0.5622 - val_loss: 1.3379 - val_accuracy: 0.5416
Epoch 106/200
5/5 [==============================] - 1s 130ms/step - loss: 1.0470 - accuracy: 0.5800 - val_loss: 1.3419 - val_accuracy: 0.5425
Epoch 107/200
5/5 [==============================] - 1s 124ms/step - loss: 1.0953 - accuracy: 0.5640 - val_loss: 1.3420 - val_accuracy: 0.5429
Epoch 108/200
5/5 [==============================] - 1s 133ms/step - loss: 1.0905 - accuracy: 0.5702 - val_loss: 1.3417 - val_accuracy: 0.5434
Epoch 109/200
5/5 [==============================] - 1s 140ms/step - loss: 1.1185 - accuracy: 0.5661 - val_loss: 1.3425 - val_accuracy: 0.5457
Epoch 110/200
5/5 [==============================] - 1s 129ms/step - loss: 1.0886 - accuracy: 0.5817 - val_loss: 1.3417 - val_accuracy: 0.5466
Epoch 111/200
5/5 [==============================] - 1s 132ms/step - loss: 1.0223 - accuracy: 0.6096 - val_loss: 1.3427 - val_accuracy: 0.5476
Epoch 112/200
5/5 [==============================] - 1s 130ms/step - loss: 1.0619 - accuracy: 0.5801 - val_loss: 1.3440 - val_accuracy: 0.5485
Epoch 113/200
5/5 [==============================] - 1s 125ms/step - loss: 1.0970 - accuracy: 0.5693 - val_loss: 1.3435 - val_accuracy: 0.5489
Epoch 114/200
5/5 [==============================] - 1s 122ms/step - loss: 1.0307 - accuracy: 0.5842 - val_loss: 1.3434 - val_accuracy: 0.5503
Epoch 115/200
5/5 [==============================] - 1s 128ms/step - loss: 1.0729 - accuracy: 0.5749 - val_loss: 1.3409 - val_accuracy: 0.5512
Epoch 116/200
5/5 [==============================] - 1s 132ms/step - loss: 1.0652 - accuracy: 0.5892 - val_loss: 1.3405 - val_accuracy: 0.5526
Epoch 117/200
5/5 [==============================] - 1s 146ms/step - loss: 1.0331 - accuracy: 0.5950 - val_loss: 1.3448 - val_accuracy: 0.5531
Epoch 118/200
5/5 [==============================] - 1s 137ms/step - loss: 1.0661 - accuracy: 0.6041 - val_loss: 1.3518 - val_accuracy: 0.5536
Epoch 119/200
5/5 [==============================] - 1s 127ms/step - loss: 1.0243 - accuracy: 0.6106 - val_loss: 1.3588 - val_accuracy: 0.5512
Epoch 120/200
5/5 [==============================] - 1s 129ms/step - loss: 0.9959 - accuracy: 0.6434 - val_loss: 1.3643 - val_accuracy: 0.5508
Epoch 121/200
5/5 [==============================] - 1s 127ms/step - loss: 1.0377 - accuracy: 0.6012 - val_loss: 1.3699 - val_accuracy: 0.5503
Epoch 122/200
5/5 [==============================] - 1s 129ms/step - loss: 1.0587 - accuracy: 0.5726 - val_loss: 1.3722 - val_accuracy: 0.5512
Epoch 123/200
5/5 [==============================] - 1s 137ms/step - loss: 1.0212 - accuracy: 0.5867 - val_loss: 1.3694 - val_accuracy: 0.5536
Epoch 124/200
5/5 [==============================] - 1s 189ms/step - loss: 1.0011 - accuracy: 0.6239 - val_loss: 1.3711 - val_accuracy: 0.5522
Epoch 125/200
5/5 [==============================] - 1s 141ms/step - loss: 0.9889 - accuracy: 0.6348 - val_loss: 1.3728 - val_accuracy: 0.5536
Epoch 126/200
5/5 [==============================] - 1s 181ms/step - loss: 1.0428 - accuracy: 0.5786 - val_loss: 1.3751 - val_accuracy: 0.5522
Epoch 127/200
5/5 [==============================] - 1s 135ms/step - loss: 0.9908 - accuracy: 0.6201 - val_loss: 1.3732 - val_accuracy: 0.5545
Epoch 128/200
5/5 [==============================] - 1s 181ms/step - loss: 1.0277 - accuracy: 0.5775 - val_loss: 1.3710 - val_accuracy: 0.5572
Epoch 129/200
5/5 [==============================] - 1s 165ms/step - loss: 0.9862 - accuracy: 0.6151 - val_loss: 1.3746 - val_accuracy: 0.5568
Epoch 130/200
5/5 [==============================] - 1s 167ms/step - loss: 0.9637 - accuracy: 0.6345 - val_loss: 1.3762 - val_accuracy: 0.5572
Epoch 131/200
5/5 [==============================] - 1s 140ms/step - loss: 0.9107 - accuracy: 0.6454 - val_loss: 1.3763 - val_accuracy: 0.5591
Epoch 132/200
5/5 [==============================] - 1s 137ms/step - loss: 1.0057 - accuracy: 0.6081 - val_loss: 1.3782 - val_accuracy: 0.5605
Epoch 133/200
5/5 [==============================] - 1s 128ms/step - loss: 0.9786 - accuracy: 0.6209 - val_loss: 1.3788 - val_accuracy: 0.5623
Epoch 134/200
5/5 [==============================] - 1s 123ms/step - loss: 1.0011 - accuracy: 0.5990 - val_loss: 1.3778 - val_accuracy: 0.5651
Epoch 135/200
5/5 [==============================] - 1s 125ms/step - loss: 0.9755 - accuracy: 0.6250 - val_loss: 1.3808 - val_accuracy: 0.5660
Epoch 136/200
5/5 [==============================] - 1s 126ms/step - loss: 0.9770 - accuracy: 0.6175 - val_loss: 1.3842 - val_accuracy: 0.5660
Epoch 137/200
5/5 [==============================] - 1s 127ms/step - loss: 0.9876 - accuracy: 0.6137 - val_loss: 1.3843 - val_accuracy: 0.5679
Epoch 138/200
5/5 [==============================] - 1s 136ms/step - loss: 0.9466 - accuracy: 0.6355 - val_loss: 1.3863 - val_accuracy: 0.5683
Epoch 139/200
5/5 [==============================] - 1s 130ms/step - loss: 0.9569 - accuracy: 0.6377 - val_loss: 1.3873 - val_accuracy: 0.5679
Epoch 140/200
5/5 [==============================] - 1s 129ms/step - loss: 0.9659 - accuracy: 0.6065 - val_loss: 1.3893 - val_accuracy: 0.5693
Epoch 141/200
5/5 [==============================] - 1s 139ms/step - loss: 0.9756 - accuracy: 0.6249 - val_loss: 1.3956 - val_accuracy: 0.5674
Epoch 142/200
5/5 [==============================] - 1s 131ms/step - loss: 0.9219 - accuracy: 0.6481 - val_loss: 1.4022 - val_accuracy: 0.5674
Epoch 143/200
5/5 [==============================] - 1s 130ms/step - loss: 0.9725 - accuracy: 0.6032 - val_loss: 1.4084 - val_accuracy: 0.5683
Epoch 144/200
5/5 [==============================] - 1s 138ms/step - loss: 0.9968 - accuracy: 0.6080 - val_loss: 1.4106 - val_accuracy: 0.5693
Epoch 145/200
5/5 [==============================] - 1s 129ms/step - loss: 0.9467 - accuracy: 0.6306 - val_loss: 1.4139 - val_accuracy: 0.5688
Epoch 146/200
5/5 [==============================] - 1s 130ms/step - loss: 0.9845 - accuracy: 0.5994 - val_loss: 1.4185 - val_accuracy: 0.5683
Epoch 147/200
5/5 [==============================] - 1s 127ms/step - loss: 0.9523 - accuracy: 0.6219 - val_loss: 1.4186 - val_accuracy: 0.5702
Epoch 148/200
5/5 [==============================] - 1s 129ms/step - loss: 0.8707 - accuracy: 0.6598 - val_loss: 1.4205 - val_accuracy: 0.5716
Epoch 149/200
5/5 [==============================] - 1s 123ms/step - loss: 0.8485 - accuracy: 0.6838 - val_loss: 1.4247 - val_accuracy: 0.5716
Epoch 150/200
5/5 [==============================] - 1s 135ms/step - loss: 0.9404 - accuracy: 0.6376 - val_loss: 1.4308 - val_accuracy: 0.5702
Epoch 151/200
5/5 [==============================] - 1s 128ms/step - loss: 0.9460 - accuracy: 0.6284 - val_loss: 1.4369 - val_accuracy: 0.5697
Epoch 152/200
5/5 [==============================] - 1s 132ms/step - loss: 0.9460 - accuracy: 0.6174 - val_loss: 1.4409 - val_accuracy: 0.5725
Epoch 153/200
5/5 [==============================] - 1s 128ms/step - loss: 0.9012 - accuracy: 0.6378 - val_loss: 1.4443 - val_accuracy: 0.5716
Epoch 154/200
5/5 [==============================] - 1s 128ms/step - loss: 0.9226 - accuracy: 0.6226 - val_loss: 1.4550 - val_accuracy: 0.5720
Epoch 155/200
5/5 [==============================] - 1s 130ms/step - loss: 0.9105 - accuracy: 0.6375 - val_loss: 1.4706 - val_accuracy: 0.5697
Epoch 156/200
5/5 [==============================] - 1s 157ms/step - loss: 0.8782 - accuracy: 0.6690 - val_loss: 1.4826 - val_accuracy: 0.5683
Epoch 157/200
5/5 [==============================] - 1s 129ms/step - loss: 0.9039 - accuracy: 0.6218 - val_loss: 1.4903 - val_accuracy: 0.5674
Epoch 158/200
5/5 [==============================] - 1s 135ms/step - loss: 0.9291 - accuracy: 0.6337 - val_loss: 1.4911 - val_accuracy: 0.5697
Epoch 159/200
5/5 [==============================] - 1s 122ms/step - loss: 0.9176 - accuracy: 0.6366 - val_loss: 1.4898 - val_accuracy: 0.5693
Epoch 160/200
5/5 [==============================] - 1s 134ms/step - loss: 0.8564 - accuracy: 0.6516 - val_loss: 1.4861 - val_accuracy: 0.5706
Epoch 161/200
5/5 [==============================] - 1s 127ms/step - loss: 0.8857 - accuracy: 0.6542 - val_loss: 1.4837 - val_accuracy: 0.5739
Epoch 162/200
5/5 [==============================] - 1s 128ms/step - loss: 0.8963 - accuracy: 0.6515 - val_loss: 1.4879 - val_accuracy: 0.5748
Epoch 163/200
5/5 [==============================] - 1s 125ms/step - loss: 0.8920 - accuracy: 0.6548 - val_loss: 1.4925 - val_accuracy: 0.5753
Epoch 164/200
5/5 [==============================] - 1s 123ms/step - loss: 0.8300 - accuracy: 0.6915 - val_loss: 1.5003 - val_accuracy: 0.5753
Epoch 165/200
5/5 [==============================] - 1s 133ms/step - loss: 0.9243 - accuracy: 0.6382 - val_loss: 1.5114 - val_accuracy: 0.5720
Epoch 166/200
5/5 [==============================] - 1s 122ms/step - loss: 0.8374 - accuracy: 0.6702 - val_loss: 1.5212 - val_accuracy: 0.5716
Epoch 167/200
5/5 [==============================] - 1s 127ms/step - loss: 0.8366 - accuracy: 0.6680 - val_loss: 1.5251 - val_accuracy: 0.5702
Epoch 168/200
5/5 [==============================] - 1s 130ms/step - loss: 0.8265 - accuracy: 0.6612 - val_loss: 1.5247 - val_accuracy: 0.5734
Epoch 169/200
5/5 [==============================] - 1s 138ms/step - loss: 0.8960 - accuracy: 0.6386 - val_loss: 1.5208 - val_accuracy: 0.5757
Epoch 170/200
5/5 [==============================] - 1s 144ms/step - loss: 0.8747 - accuracy: 0.6373 - val_loss: 1.5191 - val_accuracy: 0.5771
Epoch 171/200
5/5 [==============================] - 1s 214ms/step - loss: 0.8566 - accuracy: 0.6471 - val_loss: 1.5159 - val_accuracy: 0.5803
Epoch 172/200
5/5 [==============================] - 1s 143ms/step - loss: 0.8520 - accuracy: 0.6547 - val_loss: 1.5122 - val_accuracy: 0.5799
Epoch 173/200
5/5 [==============================] - 1s 241ms/step - loss: 0.8766 - accuracy: 0.6567 - val_loss: 1.5082 - val_accuracy: 0.5822
Epoch 174/200
5/5 [==============================] - 1s 219ms/step - loss: 0.7819 - accuracy: 0.7044 - val_loss: 1.5063 - val_accuracy: 0.5822
Epoch 175/200
5/5 [==============================] - 1s 184ms/step - loss: 0.8579 - accuracy: 0.6566 - val_loss: 1.5071 - val_accuracy: 0.5822
Epoch 176/200
5/5 [==============================] - 1s 186ms/step - loss: 0.8649 - accuracy: 0.6656 - val_loss: 1.5106 - val_accuracy: 0.5813
Epoch 177/200
5/5 [==============================] - 1s 193ms/step - loss: 0.8462 - accuracy: 0.6377 - val_loss: 1.5143 - val_accuracy: 0.5826
Epoch 178/200
5/5 [==============================] - 1s 175ms/step - loss: 0.8405 - accuracy: 0.6676 - val_loss: 1.5171 - val_accuracy: 0.5845
Epoch 179/200
5/5 [==============================] - 1s 183ms/step - loss: 0.8065 - accuracy: 0.6713 - val_loss: 1.5199 - val_accuracy: 0.5831
Epoch 180/200
5/5 [==============================] - 1s 162ms/step - loss: 0.8850 - accuracy: 0.6369 - val_loss: 1.5232 - val_accuracy: 0.5831
Epoch 181/200
5/5 [==============================] - 1s 216ms/step - loss: 0.8796 - accuracy: 0.6546 - val_loss: 1.5259 - val_accuracy: 0.5826
Epoch 182/200
5/5 [==============================] - 1s 162ms/step - loss: 0.7898 - accuracy: 0.6730 - val_loss: 1.5311 - val_accuracy: 0.5826
Epoch 183/200
5/5 [==============================] - 1s 159ms/step - loss: 0.7982 - accuracy: 0.6828 - val_loss: 1.5380 - val_accuracy: 0.5836
Epoch 184/200
5/5 [==============================] - 1s 156ms/step - loss: 0.8291 - accuracy: 0.6792 - val_loss: 1.5468 - val_accuracy: 0.5836
Epoch 185/200
5/5 [==============================] - 1s 144ms/step - loss: 0.8375 - accuracy: 0.6788 - val_loss: 1.5529 - val_accuracy: 0.5840
Epoch 186/200
5/5 [==============================] - 1s 143ms/step - loss: 0.8144 - accuracy: 0.6788 - val_loss: 1.5538 - val_accuracy: 0.5840
Epoch 187/200
5/5 [==============================] - 1s 130ms/step - loss: 0.8369 - accuracy: 0.6873 - val_loss: 1.5555 - val_accuracy: 0.5836
Epoch 188/200
5/5 [==============================] - 1s 130ms/step - loss: 0.8426 - accuracy: 0.6679 - val_loss: 1.5574 - val_accuracy: 0.5849
Epoch 189/200
5/5 [==============================] - 1s 144ms/step - loss: 0.7954 - accuracy: 0.6879 - val_loss: 1.5557 - val_accuracy: 0.5863
Epoch 190/200
5/5 [==============================] - 1s 131ms/step - loss: 0.7880 - accuracy: 0.6742 - val_loss: 1.5611 - val_accuracy: 0.5854
Epoch 191/200
5/5 [==============================] - 1s 172ms/step - loss: 0.8489 - accuracy: 0.6390 - val_loss: 1.5656 - val_accuracy: 0.5863
Epoch 192/200
5/5 [==============================] - 1s 175ms/step - loss: 0.8292 - accuracy: 0.6736 - val_loss: 1.5664 - val_accuracy: 0.5854
Epoch 193/200
5/5 [==============================] - 1s 151ms/step - loss: 0.7881 - accuracy: 0.6958 - val_loss: 1.5735 - val_accuracy: 0.5854
Epoch 194/200
5/5 [==============================] - 1s 145ms/step - loss: 0.8304 - accuracy: 0.6515 - val_loss: 1.5778 - val_accuracy: 0.5845
Epoch 195/200
5/5 [==============================] - 1s 217ms/step - loss: 0.7969 - accuracy: 0.6696 - val_loss: 1.5797 - val_accuracy: 0.5840
Epoch 196/200
5/5 [==============================] - 1s 183ms/step - loss: 0.7856 - accuracy: 0.6726 - val_loss: 1.5763 - val_accuracy: 0.5854
Epoch 197/200
5/5 [==============================] - 1s 170ms/step - loss: 0.7966 - accuracy: 0.6883 - val_loss: 1.5783 - val_accuracy: 0.5859
Epoch 198/200
5/5 [==============================] - 1s 147ms/step - loss: 0.8072 - accuracy: 0.6626 - val_loss: 1.5819 - val_accuracy: 0.5854
Epoch 199/200
5/5 [==============================] - 1s 135ms/step - loss: 0.7893 - accuracy: 0.6858 - val_loss: 1.5884 - val_accuracy: 0.5849
Epoch 200/200
5/5 [==============================] - 1s 154ms/step - loss: 0.7798 - accuracy: 0.6795 - val_loss: 1.5948 - val_accuracy: 0.5873</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>&lt;tensorflow.python.keras.callbacks.History at 0x14e4a9290&gt;</code></pre>
</div>
</div>
</section>
<section id="graph-regularized-version" class="level4">
<h4 class="anchored" data-anchor-id="graph-regularized-version">Graph Regularized Version</h4>
<p>We now create the graph-regularized version that uses the citation network information</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1"></a>base_model <span class="op">=</span> create_model([<span class="dv">50</span>, <span class="dv">50</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1"></a><span class="im">import</span> neural_structured_learning <span class="im">as</span> nsl</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1"></a>graph_reg_config <span class="op">=</span> nsl.configs.make_graph_reg_config(</span>
<span id="cb35-2"><a href="#cb35-2"></a>    max_neighbors<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb35-3"><a href="#cb35-3"></a>    multiplier<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb35-4"><a href="#cb35-4"></a>    distance_type<span class="op">=</span>nsl.configs.DistanceType.L2,</span>
<span id="cb35-5"><a href="#cb35-5"></a>    sum_over_axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb35-6"><a href="#cb35-6"></a>graph_reg_model <span class="op">=</span> nsl.keras.GraphRegularization(base_model,</span>
<span id="cb35-7"><a href="#cb35-7"></a>                                                graph_reg_config)</span>
<span id="cb35-8"><a href="#cb35-8"></a>graph_reg_model.<span class="bu">compile</span>(</span>
<span id="cb35-9"><a href="#cb35-9"></a>    optimizer<span class="op">=</span><span class="st">'adam'</span>,</span>
<span id="cb35-10"><a href="#cb35-10"></a>    loss<span class="op">=</span><span class="st">'sparse_categorical_crossentropy'</span>,</span>
<span id="cb35-11"><a href="#cb35-11"></a>    metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span>
<span id="cb35-12"><a href="#cb35-12"></a><span class="co">#graph_reg_model.fit(train_dataset, epochs=200, verbose=1)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1"></a>graph_reg_model.fit(myTrain.batch(<span class="dv">128</span>), epochs<span class="op">=</span><span class="dv">200</span>, verbose<span class="op">=</span><span class="dv">1</span>, validation_data<span class="op">=</span>myTest.batch(<span class="dv">128</span>),</span>
<span id="cb36-2"><a href="#cb36-2"></a>          callbacks<span class="op">=</span>[TensorBoard(log_dir<span class="op">=</span><span class="st">'/tmp/regularization'</span>)])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/200</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/deusebio/.pyenv/versions/3.7.6/envs/ml-book-4/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("gradient_tape/GraphRegularization/graph_loss/Reshape_1:0", shape=(None,), dtype=int32), values=Tensor("gradient_tape/GraphRegularization/graph_loss/Reshape:0", shape=(None, 7), dtype=float32), dense_shape=Tensor("gradient_tape/GraphRegularization/graph_loss/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "shape. This may consume a large amount of memory." % value)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>5/5 [==============================] - 4s 328ms/step - loss: 2.1052 - accuracy: 0.1049 - scaled_graph_loss: 0.0056 - val_loss: 1.9455 - val_accuracy: 0.1440
Epoch 2/200
5/5 [==============================] - 1s 179ms/step - loss: 2.0342 - accuracy: 0.1722 - scaled_graph_loss: 0.0047 - val_loss: 1.9367 - val_accuracy: 0.1934
Epoch 3/200
5/5 [==============================] - 1s 156ms/step - loss: 1.9881 - accuracy: 0.1603 - scaled_graph_loss: 0.0039 - val_loss: 1.9293 - val_accuracy: 0.2355
Epoch 4/200
5/5 [==============================] - 1s 178ms/step - loss: 1.9918 - accuracy: 0.1816 - scaled_graph_loss: 0.0035 - val_loss: 1.9224 - val_accuracy: 0.2770
Epoch 5/200
5/5 [==============================] - 1s 162ms/step - loss: 1.9551 - accuracy: 0.1983 - scaled_graph_loss: 0.0029 - val_loss: 1.9165 - val_accuracy: 0.2978
Epoch 6/200
5/5 [==============================] - 1s 156ms/step - loss: 1.9745 - accuracy: 0.1918 - scaled_graph_loss: 0.0028 - val_loss: 1.9113 - val_accuracy: 0.3033
Epoch 7/200
5/5 [==============================] - 1s 170ms/step - loss: 1.9490 - accuracy: 0.1762 - scaled_graph_loss: 0.0023 - val_loss: 1.9068 - val_accuracy: 0.3075
Epoch 8/200
5/5 [==============================] - 1s 218ms/step - loss: 1.9262 - accuracy: 0.2016 - scaled_graph_loss: 0.0025 - val_loss: 1.9025 - val_accuracy: 0.3112
Epoch 9/200
5/5 [==============================] - 1s 208ms/step - loss: 1.9413 - accuracy: 0.2383 - scaled_graph_loss: 0.0023 - val_loss: 1.8983 - val_accuracy: 0.3066
Epoch 10/200
5/5 [==============================] - 1s 170ms/step - loss: 1.9136 - accuracy: 0.2278 - scaled_graph_loss: 0.0022 - val_loss: 1.8942 - val_accuracy: 0.3061
Epoch 11/200
5/5 [==============================] - 1s 154ms/step - loss: 1.9232 - accuracy: 0.2413 - scaled_graph_loss: 0.0022 - val_loss: 1.8900 - val_accuracy: 0.3066
Epoch 12/200
5/5 [==============================] - 1s 157ms/step - loss: 1.8885 - accuracy: 0.2682 - scaled_graph_loss: 0.0022 - val_loss: 1.8857 - val_accuracy: 0.3052
Epoch 13/200
5/5 [==============================] - 1s 192ms/step - loss: 1.8657 - accuracy: 0.2789 - scaled_graph_loss: 0.0021 - val_loss: 1.8813 - val_accuracy: 0.3052
Epoch 14/200
5/5 [==============================] - 1s 178ms/step - loss: 1.9115 - accuracy: 0.2158 - scaled_graph_loss: 0.0022 - val_loss: 1.8771 - val_accuracy: 0.3033
Epoch 15/200
5/5 [==============================] - 1s 174ms/step - loss: 1.8700 - accuracy: 0.2652 - scaled_graph_loss: 0.0020 - val_loss: 1.8725 - val_accuracy: 0.3029
Epoch 16/200
5/5 [==============================] - 1s 154ms/step - loss: 1.8883 - accuracy: 0.2607 - scaled_graph_loss: 0.0026 - val_loss: 1.8676 - val_accuracy: 0.3024
Epoch 17/200
5/5 [==============================] - 1s 141ms/step - loss: 1.8588 - accuracy: 0.2631 - scaled_graph_loss: 0.0025 - val_loss: 1.8625 - val_accuracy: 0.3019
Epoch 18/200
5/5 [==============================] - 1s 152ms/step - loss: 1.8774 - accuracy: 0.2593 - scaled_graph_loss: 0.0026 - val_loss: 1.8577 - val_accuracy: 0.3019
Epoch 19/200
5/5 [==============================] - 1s 187ms/step - loss: 1.8376 - accuracy: 0.2726 - scaled_graph_loss: 0.0028 - val_loss: 1.8530 - val_accuracy: 0.3019
Epoch 20/200
5/5 [==============================] - 1s 146ms/step - loss: 1.8590 - accuracy: 0.3045 - scaled_graph_loss: 0.0030 - val_loss: 1.8485 - val_accuracy: 0.3019
Epoch 21/200
5/5 [==============================] - 1s 204ms/step - loss: 1.8240 - accuracy: 0.2647 - scaled_graph_loss: 0.0028 - val_loss: 1.8439 - val_accuracy: 0.3019
Epoch 22/200
5/5 [==============================] - 1s 159ms/step - loss: 1.8541 - accuracy: 0.2940 - scaled_graph_loss: 0.0032 - val_loss: 1.8397 - val_accuracy: 0.3019
Epoch 23/200
5/5 [==============================] - 1s 208ms/step - loss: 1.8121 - accuracy: 0.3230 - scaled_graph_loss: 0.0034 - val_loss: 1.8350 - val_accuracy: 0.3019
Epoch 24/200
5/5 [==============================] - 1s 189ms/step - loss: 1.8325 - accuracy: 0.2986 - scaled_graph_loss: 0.0032 - val_loss: 1.8304 - val_accuracy: 0.3019
Epoch 25/200
5/5 [==============================] - 1s 170ms/step - loss: 1.8066 - accuracy: 0.2818 - scaled_graph_loss: 0.0032 - val_loss: 1.8254 - val_accuracy: 0.3019
Epoch 26/200
5/5 [==============================] - 1s 204ms/step - loss: 1.8389 - accuracy: 0.2880 - scaled_graph_loss: 0.0036 - val_loss: 1.8211 - val_accuracy: 0.3019
Epoch 27/200
5/5 [==============================] - 1s 208ms/step - loss: 1.8070 - accuracy: 0.3068 - scaled_graph_loss: 0.0034 - val_loss: 1.8168 - val_accuracy: 0.3024
Epoch 28/200
5/5 [==============================] - 1s 171ms/step - loss: 1.8070 - accuracy: 0.2909 - scaled_graph_loss: 0.0038 - val_loss: 1.8122 - val_accuracy: 0.3024
Epoch 29/200
5/5 [==============================] - 1s 167ms/step - loss: 1.7793 - accuracy: 0.2947 - scaled_graph_loss: 0.0046 - val_loss: 1.8069 - val_accuracy: 0.3024
Epoch 30/200
5/5 [==============================] - 1s 168ms/step - loss: 1.7738 - accuracy: 0.2886 - scaled_graph_loss: 0.0048 - val_loss: 1.8016 - val_accuracy: 0.3024
Epoch 31/200
5/5 [==============================] - 1s 156ms/step - loss: 1.7596 - accuracy: 0.3011 - scaled_graph_loss: 0.0043 - val_loss: 1.7957 - val_accuracy: 0.3024
Epoch 32/200
5/5 [==============================] - 1s 261ms/step - loss: 1.7768 - accuracy: 0.3165 - scaled_graph_loss: 0.0053 - val_loss: 1.7900 - val_accuracy: 0.3024
Epoch 33/200
5/5 [==============================] - 1s 196ms/step - loss: 1.7419 - accuracy: 0.3019 - scaled_graph_loss: 0.0052 - val_loss: 1.7840 - val_accuracy: 0.3024
Epoch 34/200
5/5 [==============================] - 1s 177ms/step - loss: 1.7615 - accuracy: 0.2834 - scaled_graph_loss: 0.0060 - val_loss: 1.7783 - val_accuracy: 0.3024
Epoch 35/200
5/5 [==============================] - 1s 168ms/step - loss: 1.7419 - accuracy: 0.3210 - scaled_graph_loss: 0.0057 - val_loss: 1.7730 - val_accuracy: 0.3024
Epoch 36/200
5/5 [==============================] - 1s 179ms/step - loss: 1.7253 - accuracy: 0.3277 - scaled_graph_loss: 0.0061 - val_loss: 1.7670 - val_accuracy: 0.3024
Epoch 37/200
5/5 [==============================] - 1s 212ms/step - loss: 1.7170 - accuracy: 0.3362 - scaled_graph_loss: 0.0061 - val_loss: 1.7608 - val_accuracy: 0.3024
Epoch 38/200
5/5 [==============================] - 1s 212ms/step - loss: 1.7038 - accuracy: 0.3185 - scaled_graph_loss: 0.0064 - val_loss: 1.7548 - val_accuracy: 0.3024
Epoch 39/200
5/5 [==============================] - 1s 207ms/step - loss: 1.7044 - accuracy: 0.3301 - scaled_graph_loss: 0.0065 - val_loss: 1.7491 - val_accuracy: 0.3024
Epoch 40/200
5/5 [==============================] - 1s 152ms/step - loss: 1.7011 - accuracy: 0.3390 - scaled_graph_loss: 0.0069 - val_loss: 1.7428 - val_accuracy: 0.3029
Epoch 41/200
5/5 [==============================] - 1s 192ms/step - loss: 1.6931 - accuracy: 0.3415 - scaled_graph_loss: 0.0075 - val_loss: 1.7368 - val_accuracy: 0.3042
Epoch 42/200
5/5 [==============================] - 1s 159ms/step - loss: 1.7035 - accuracy: 0.3211 - scaled_graph_loss: 0.0074 - val_loss: 1.7310 - val_accuracy: 0.3038
Epoch 43/200
5/5 [==============================] - 1s 151ms/step - loss: 1.6884 - accuracy: 0.3293 - scaled_graph_loss: 0.0075 - val_loss: 1.7258 - val_accuracy: 0.3047
Epoch 44/200
5/5 [==============================] - 1s 148ms/step - loss: 1.7046 - accuracy: 0.3319 - scaled_graph_loss: 0.0079 - val_loss: 1.7206 - val_accuracy: 0.3047
Epoch 45/200
5/5 [==============================] - 1s 151ms/step - loss: 1.6325 - accuracy: 0.3369 - scaled_graph_loss: 0.0082 - val_loss: 1.7141 - val_accuracy: 0.3052
Epoch 46/200
5/5 [==============================] - 1s 167ms/step - loss: 1.6682 - accuracy: 0.3413 - scaled_graph_loss: 0.0082 - val_loss: 1.7070 - val_accuracy: 0.3061
Epoch 47/200
5/5 [==============================] - 1s 164ms/step - loss: 1.5976 - accuracy: 0.3434 - scaled_graph_loss: 0.0094 - val_loss: 1.6997 - val_accuracy: 0.3066
Epoch 48/200
5/5 [==============================] - 1s 183ms/step - loss: 1.6572 - accuracy: 0.3536 - scaled_graph_loss: 0.0093 - val_loss: 1.6933 - val_accuracy: 0.3084
Epoch 49/200
5/5 [==============================] - 1s 159ms/step - loss: 1.6508 - accuracy: 0.3540 - scaled_graph_loss: 0.0098 - val_loss: 1.6861 - val_accuracy: 0.3112
Epoch 50/200
5/5 [==============================] - 1s 148ms/step - loss: 1.6408 - accuracy: 0.3250 - scaled_graph_loss: 0.0097 - val_loss: 1.6793 - val_accuracy: 0.3149
Epoch 51/200
5/5 [==============================] - 1s 181ms/step - loss: 1.6336 - accuracy: 0.3462 - scaled_graph_loss: 0.0092 - val_loss: 1.6736 - val_accuracy: 0.3190
Epoch 52/200
5/5 [==============================] - 1s 227ms/step - loss: 1.6309 - accuracy: 0.3321 - scaled_graph_loss: 0.0103 - val_loss: 1.6677 - val_accuracy: 0.3236
Epoch 53/200
5/5 [==============================] - 1s 271ms/step - loss: 1.6388 - accuracy: 0.3596 - scaled_graph_loss: 0.0111 - val_loss: 1.6628 - val_accuracy: 0.3287
Epoch 54/200
5/5 [==============================] - 1s 178ms/step - loss: 1.5818 - accuracy: 0.3541 - scaled_graph_loss: 0.0103 - val_loss: 1.6570 - val_accuracy: 0.3338
Epoch 55/200
5/5 [==============================] - 1s 272ms/step - loss: 1.5723 - accuracy: 0.3685 - scaled_graph_loss: 0.0109 - val_loss: 1.6503 - val_accuracy: 0.3398
Epoch 56/200
5/5 [==============================] - 1s 220ms/step - loss: 1.5742 - accuracy: 0.3803 - scaled_graph_loss: 0.0103 - val_loss: 1.6434 - val_accuracy: 0.3467
Epoch 57/200
5/5 [==============================] - 1s 200ms/step - loss: 1.5509 - accuracy: 0.3862 - scaled_graph_loss: 0.0114 - val_loss: 1.6370 - val_accuracy: 0.3578
Epoch 58/200
5/5 [==============================] - 1s 168ms/step - loss: 1.5821 - accuracy: 0.3674 - scaled_graph_loss: 0.0117 - val_loss: 1.6305 - val_accuracy: 0.3638
Epoch 59/200
5/5 [==============================] - 1s 151ms/step - loss: 1.5852 - accuracy: 0.3616 - scaled_graph_loss: 0.0118 - val_loss: 1.6237 - val_accuracy: 0.3698
Epoch 60/200
5/5 [==============================] - 1s 140ms/step - loss: 1.5499 - accuracy: 0.3611 - scaled_graph_loss: 0.0115 - val_loss: 1.6169 - val_accuracy: 0.3726
Epoch 61/200
5/5 [==============================] - 1s 156ms/step - loss: 1.5457 - accuracy: 0.3744 - scaled_graph_loss: 0.0142 - val_loss: 1.6107 - val_accuracy: 0.3795
Epoch 62/200
5/5 [==============================] - 1s 132ms/step - loss: 1.5397 - accuracy: 0.3819 - scaled_graph_loss: 0.0127 - val_loss: 1.6045 - val_accuracy: 0.3892
Epoch 63/200
5/5 [==============================] - 1s 153ms/step - loss: 1.5438 - accuracy: 0.4087 - scaled_graph_loss: 0.0136 - val_loss: 1.5984 - val_accuracy: 0.3947
Epoch 64/200
5/5 [==============================] - 1s 162ms/step - loss: 1.5161 - accuracy: 0.3815 - scaled_graph_loss: 0.0135 - val_loss: 1.5919 - val_accuracy: 0.4017
Epoch 65/200
5/5 [==============================] - 1s 143ms/step - loss: 1.5581 - accuracy: 0.3713 - scaled_graph_loss: 0.0134 - val_loss: 1.5854 - val_accuracy: 0.4086
Epoch 66/200
5/5 [==============================] - 1s 138ms/step - loss: 1.5347 - accuracy: 0.3858 - scaled_graph_loss: 0.0122 - val_loss: 1.5794 - val_accuracy: 0.4197
Epoch 67/200
5/5 [==============================] - 1s 204ms/step - loss: 1.4917 - accuracy: 0.4024 - scaled_graph_loss: 0.0141 - val_loss: 1.5733 - val_accuracy: 0.4326
Epoch 68/200
5/5 [==============================] - 1s 223ms/step - loss: 1.4804 - accuracy: 0.3927 - scaled_graph_loss: 0.0129 - val_loss: 1.5658 - val_accuracy: 0.4483
Epoch 69/200
5/5 [==============================] - 1s 252ms/step - loss: 1.4751 - accuracy: 0.4093 - scaled_graph_loss: 0.0138 - val_loss: 1.5586 - val_accuracy: 0.4575
Epoch 70/200
5/5 [==============================] - 1s 192ms/step - loss: 1.4870 - accuracy: 0.4230 - scaled_graph_loss: 0.0140 - val_loss: 1.5514 - val_accuracy: 0.4645
Epoch 71/200
5/5 [==============================] - 1s 213ms/step - loss: 1.4541 - accuracy: 0.4380 - scaled_graph_loss: 0.0146 - val_loss: 1.5447 - val_accuracy: 0.4686
Epoch 72/200
5/5 [==============================] - 1s 264ms/step - loss: 1.4528 - accuracy: 0.4193 - scaled_graph_loss: 0.0141 - val_loss: 1.5373 - val_accuracy: 0.4765
Epoch 73/200
5/5 [==============================] - 1s 199ms/step - loss: 1.4318 - accuracy: 0.4144 - scaled_graph_loss: 0.0177 - val_loss: 1.5302 - val_accuracy: 0.4820
Epoch 74/200
5/5 [==============================] - 1s 210ms/step - loss: 1.4495 - accuracy: 0.4282 - scaled_graph_loss: 0.0161 - val_loss: 1.5239 - val_accuracy: 0.4926
Epoch 75/200
5/5 [==============================] - 1s 164ms/step - loss: 1.4085 - accuracy: 0.4447 - scaled_graph_loss: 0.0161 - val_loss: 1.5170 - val_accuracy: 0.4958
Epoch 76/200
5/5 [==============================] - 1s 171ms/step - loss: 1.3982 - accuracy: 0.4639 - scaled_graph_loss: 0.0155 - val_loss: 1.5103 - val_accuracy: 0.5000
Epoch 77/200
5/5 [==============================] - 1s 186ms/step - loss: 1.3995 - accuracy: 0.4773 - scaled_graph_loss: 0.0168 - val_loss: 1.5037 - val_accuracy: 0.5037
Epoch 78/200
5/5 [==============================] - 1s 179ms/step - loss: 1.4244 - accuracy: 0.4426 - scaled_graph_loss: 0.0185 - val_loss: 1.4985 - val_accuracy: 0.5074
Epoch 79/200
5/5 [==============================] - 1s 194ms/step - loss: 1.4186 - accuracy: 0.4440 - scaled_graph_loss: 0.0163 - val_loss: 1.4933 - val_accuracy: 0.5102
Epoch 80/200
5/5 [==============================] - 1s 212ms/step - loss: 1.3805 - accuracy: 0.4560 - scaled_graph_loss: 0.0170 - val_loss: 1.4872 - val_accuracy: 0.5115
Epoch 81/200
5/5 [==============================] - 1s 204ms/step - loss: 1.3641 - accuracy: 0.4687 - scaled_graph_loss: 0.0173 - val_loss: 1.4800 - val_accuracy: 0.5166
Epoch 82/200
5/5 [==============================] - 1s 207ms/step - loss: 1.3796 - accuracy: 0.4717 - scaled_graph_loss: 0.0164 - val_loss: 1.4728 - val_accuracy: 0.5249
Epoch 83/200
5/5 [==============================] - 1s 203ms/step - loss: 1.4130 - accuracy: 0.4492 - scaled_graph_loss: 0.0177 - val_loss: 1.4667 - val_accuracy: 0.5314
Epoch 84/200
5/5 [==============================] - 1s 222ms/step - loss: 1.3239 - accuracy: 0.4916 - scaled_graph_loss: 0.0197 - val_loss: 1.4608 - val_accuracy: 0.5369
Epoch 85/200
5/5 [==============================] - 1s 220ms/step - loss: 1.3893 - accuracy: 0.4488 - scaled_graph_loss: 0.0186 - val_loss: 1.4551 - val_accuracy: 0.5434
Epoch 86/200
5/5 [==============================] - 1s 236ms/step - loss: 1.3161 - accuracy: 0.4909 - scaled_graph_loss: 0.0204 - val_loss: 1.4490 - val_accuracy: 0.5466
Epoch 87/200
5/5 [==============================] - 1s 179ms/step - loss: 1.3434 - accuracy: 0.4966 - scaled_graph_loss: 0.0200 - val_loss: 1.4419 - val_accuracy: 0.5476
Epoch 88/200
5/5 [==============================] - 1s 250ms/step - loss: 1.3027 - accuracy: 0.5098 - scaled_graph_loss: 0.0196 - val_loss: 1.4357 - val_accuracy: 0.5489
Epoch 89/200
5/5 [==============================] - 1s 230ms/step - loss: 1.3019 - accuracy: 0.4970 - scaled_graph_loss: 0.0201 - val_loss: 1.4293 - val_accuracy: 0.5526
Epoch 90/200
5/5 [==============================] - 1s 248ms/step - loss: 1.2992 - accuracy: 0.4944 - scaled_graph_loss: 0.0205 - val_loss: 1.4230 - val_accuracy: 0.5559
Epoch 91/200
5/5 [==============================] - 1s 231ms/step - loss: 1.3239 - accuracy: 0.4901 - scaled_graph_loss: 0.0179 - val_loss: 1.4171 - val_accuracy: 0.5619
Epoch 92/200
5/5 [==============================] - 1s 221ms/step - loss: 1.3136 - accuracy: 0.5136 - scaled_graph_loss: 0.0196 - val_loss: 1.4112 - val_accuracy: 0.5669
Epoch 93/200
5/5 [==============================] - 1s 183ms/step - loss: 1.2639 - accuracy: 0.5288 - scaled_graph_loss: 0.0209 - val_loss: 1.4053 - val_accuracy: 0.5665
Epoch 94/200
5/5 [==============================] - 1s 205ms/step - loss: 1.2763 - accuracy: 0.5047 - scaled_graph_loss: 0.0209 - val_loss: 1.3995 - val_accuracy: 0.5665
Epoch 95/200
5/5 [==============================] - 1s 238ms/step - loss: 1.2617 - accuracy: 0.5052 - scaled_graph_loss: 0.0207 - val_loss: 1.3948 - val_accuracy: 0.5656
Epoch 96/200
5/5 [==============================] - 1s 218ms/step - loss: 1.2874 - accuracy: 0.5022 - scaled_graph_loss: 0.0226 - val_loss: 1.3906 - val_accuracy: 0.5697
Epoch 97/200
5/5 [==============================] - 1s 256ms/step - loss: 1.2262 - accuracy: 0.5307 - scaled_graph_loss: 0.0216 - val_loss: 1.3858 - val_accuracy: 0.5702
Epoch 98/200
5/5 [==============================] - 1s 197ms/step - loss: 1.2362 - accuracy: 0.5532 - scaled_graph_loss: 0.0216 - val_loss: 1.3793 - val_accuracy: 0.5725
Epoch 99/200
5/5 [==============================] - 1s 262ms/step - loss: 1.2081 - accuracy: 0.5314 - scaled_graph_loss: 0.0236 - val_loss: 1.3731 - val_accuracy: 0.5748
Epoch 100/200
5/5 [==============================] - 1s 160ms/step - loss: 1.2115 - accuracy: 0.5213 - scaled_graph_loss: 0.0224 - val_loss: 1.3678 - val_accuracy: 0.5780
Epoch 101/200
5/5 [==============================] - 1s 153ms/step - loss: 1.1994 - accuracy: 0.5480 - scaled_graph_loss: 0.0230 - val_loss: 1.3620 - val_accuracy: 0.5785
Epoch 102/200
5/5 [==============================] - 1s 144ms/step - loss: 1.1956 - accuracy: 0.5351 - scaled_graph_loss: 0.0240 - val_loss: 1.3569 - val_accuracy: 0.5799
Epoch 103/200
5/5 [==============================] - 1s 154ms/step - loss: 1.2904 - accuracy: 0.4833 - scaled_graph_loss: 0.0225 - val_loss: 1.3529 - val_accuracy: 0.5803
Epoch 104/200
5/5 [==============================] - 1s 210ms/step - loss: 1.1866 - accuracy: 0.5519 - scaled_graph_loss: 0.0241 - val_loss: 1.3486 - val_accuracy: 0.5799
Epoch 105/200
5/5 [==============================] - 1s 184ms/step - loss: 1.2259 - accuracy: 0.5028 - scaled_graph_loss: 0.0225 - val_loss: 1.3449 - val_accuracy: 0.5822
Epoch 106/200
5/5 [==============================] - 1s 218ms/step - loss: 1.2135 - accuracy: 0.5383 - scaled_graph_loss: 0.0246 - val_loss: 1.3409 - val_accuracy: 0.5826
Epoch 107/200
5/5 [==============================] - 1s 215ms/step - loss: 1.1978 - accuracy: 0.5241 - scaled_graph_loss: 0.0244 - val_loss: 1.3366 - val_accuracy: 0.5831
Epoch 108/200
5/5 [==============================] - 1s 214ms/step - loss: 1.1885 - accuracy: 0.5566 - scaled_graph_loss: 0.0250 - val_loss: 1.3322 - val_accuracy: 0.5845
Epoch 109/200
5/5 [==============================] - 1s 168ms/step - loss: 1.1876 - accuracy: 0.5501 - scaled_graph_loss: 0.0258 - val_loss: 1.3270 - val_accuracy: 0.5877
Epoch 110/200
5/5 [==============================] - 1s 172ms/step - loss: 1.1515 - accuracy: 0.5736 - scaled_graph_loss: 0.0251 - val_loss: 1.3238 - val_accuracy: 0.5896
Epoch 111/200
5/5 [==============================] - 1s 166ms/step - loss: 1.1388 - accuracy: 0.5336 - scaled_graph_loss: 0.0248 - val_loss: 1.3204 - val_accuracy: 0.5910
Epoch 112/200
5/5 [==============================] - 1s 176ms/step - loss: 1.1100 - accuracy: 0.5436 - scaled_graph_loss: 0.0266 - val_loss: 1.3165 - val_accuracy: 0.5928
Epoch 113/200
5/5 [==============================] - 1s 158ms/step - loss: 1.1504 - accuracy: 0.5861 - scaled_graph_loss: 0.0254 - val_loss: 1.3145 - val_accuracy: 0.5910
Epoch 114/200
5/5 [==============================] - 1s 214ms/step - loss: 1.1706 - accuracy: 0.5344 - scaled_graph_loss: 0.0262 - val_loss: 1.3123 - val_accuracy: 0.5905
Epoch 115/200
5/5 [==============================] - 1s 164ms/step - loss: 1.1645 - accuracy: 0.5694 - scaled_graph_loss: 0.0257 - val_loss: 1.3099 - val_accuracy: 0.5905
Epoch 116/200
5/5 [==============================] - 1s 227ms/step - loss: 1.1480 - accuracy: 0.5713 - scaled_graph_loss: 0.0249 - val_loss: 1.3066 - val_accuracy: 0.5919
Epoch 117/200
5/5 [==============================] - 1s 194ms/step - loss: 1.1302 - accuracy: 0.5679 - scaled_graph_loss: 0.0253 - val_loss: 1.3026 - val_accuracy: 0.5937
Epoch 118/200
5/5 [==============================] - 1s 137ms/step - loss: 1.1127 - accuracy: 0.5759 - scaled_graph_loss: 0.0240 - val_loss: 1.3002 - val_accuracy: 0.5942
Epoch 119/200
5/5 [==============================] - 1s 209ms/step - loss: 1.1154 - accuracy: 0.5697 - scaled_graph_loss: 0.0271 - val_loss: 1.2991 - val_accuracy: 0.5942
Epoch 120/200
5/5 [==============================] - 1s 187ms/step - loss: 1.0834 - accuracy: 0.5843 - scaled_graph_loss: 0.0245 - val_loss: 1.2963 - val_accuracy: 0.5951
Epoch 121/200
5/5 [==============================] - 1s 156ms/step - loss: 1.1061 - accuracy: 0.5903 - scaled_graph_loss: 0.0258 - val_loss: 1.2935 - val_accuracy: 0.5965
Epoch 122/200
5/5 [==============================] - 1s 167ms/step - loss: 1.0833 - accuracy: 0.5821 - scaled_graph_loss: 0.0254 - val_loss: 1.2900 - val_accuracy: 0.5970
Epoch 123/200
5/5 [==============================] - 1s 175ms/step - loss: 1.1348 - accuracy: 0.5637 - scaled_graph_loss: 0.0248 - val_loss: 1.2858 - val_accuracy: 0.5988
Epoch 124/200
5/5 [==============================] - 1s 170ms/step - loss: 1.0713 - accuracy: 0.5912 - scaled_graph_loss: 0.0252 - val_loss: 1.2819 - val_accuracy: 0.5997
Epoch 125/200
5/5 [==============================] - 1s 176ms/step - loss: 1.0583 - accuracy: 0.5960 - scaled_graph_loss: 0.0277 - val_loss: 1.2799 - val_accuracy: 0.6006
Epoch 126/200
5/5 [==============================] - 1s 179ms/step - loss: 1.0950 - accuracy: 0.6009 - scaled_graph_loss: 0.0253 - val_loss: 1.2770 - val_accuracy: 0.5993
Epoch 127/200
5/5 [==============================] - 1s 163ms/step - loss: 1.1018 - accuracy: 0.5771 - scaled_graph_loss: 0.0259 - val_loss: 1.2736 - val_accuracy: 0.6020
Epoch 128/200
5/5 [==============================] - 1s 147ms/step - loss: 1.1109 - accuracy: 0.5796 - scaled_graph_loss: 0.0273 - val_loss: 1.2704 - val_accuracy: 0.6016
Epoch 129/200
5/5 [==============================] - 1s 142ms/step - loss: 1.0983 - accuracy: 0.5808 - scaled_graph_loss: 0.0266 - val_loss: 1.2668 - val_accuracy: 0.6034
Epoch 130/200
5/5 [==============================] - 1s 135ms/step - loss: 1.1054 - accuracy: 0.5490 - scaled_graph_loss: 0.0296 - val_loss: 1.2626 - val_accuracy: 0.6066
Epoch 131/200
5/5 [==============================] - 1s 136ms/step - loss: 1.0896 - accuracy: 0.6092 - scaled_graph_loss: 0.0295 - val_loss: 1.2595 - val_accuracy: 0.6080
Epoch 132/200
5/5 [==============================] - 1s 148ms/step - loss: 1.0911 - accuracy: 0.5874 - scaled_graph_loss: 0.0292 - val_loss: 1.2571 - val_accuracy: 0.6076
Epoch 133/200
5/5 [==============================] - 1s 149ms/step - loss: 1.1144 - accuracy: 0.5697 - scaled_graph_loss: 0.0279 - val_loss: 1.2532 - val_accuracy: 0.6094
Epoch 134/200
5/5 [==============================] - 1s 140ms/step - loss: 1.0619 - accuracy: 0.5921 - scaled_graph_loss: 0.0314 - val_loss: 1.2494 - val_accuracy: 0.6103
Epoch 135/200
5/5 [==============================] - 1s 152ms/step - loss: 1.0882 - accuracy: 0.5957 - scaled_graph_loss: 0.0283 - val_loss: 1.2506 - val_accuracy: 0.6094
Epoch 136/200
5/5 [==============================] - 1s 181ms/step - loss: 1.0127 - accuracy: 0.6250 - scaled_graph_loss: 0.0296 - val_loss: 1.2510 - val_accuracy: 0.6090
Epoch 137/200
5/5 [==============================] - 1s 157ms/step - loss: 1.0254 - accuracy: 0.6049 - scaled_graph_loss: 0.0278 - val_loss: 1.2501 - val_accuracy: 0.6103
Epoch 138/200
5/5 [==============================] - 1s 145ms/step - loss: 1.0017 - accuracy: 0.6117 - scaled_graph_loss: 0.0298 - val_loss: 1.2472 - val_accuracy: 0.6108
Epoch 139/200
5/5 [==============================] - 1s 155ms/step - loss: 1.0102 - accuracy: 0.6226 - scaled_graph_loss: 0.0277 - val_loss: 1.2472 - val_accuracy: 0.6117
Epoch 140/200
5/5 [==============================] - 1s 187ms/step - loss: 1.0174 - accuracy: 0.6061 - scaled_graph_loss: 0.0314 - val_loss: 1.2470 - val_accuracy: 0.6127
Epoch 141/200
5/5 [==============================] - 1s 175ms/step - loss: 1.0487 - accuracy: 0.6027 - scaled_graph_loss: 0.0279 - val_loss: 1.2464 - val_accuracy: 0.6131
Epoch 142/200
5/5 [==============================] - 1s 164ms/step - loss: 1.0059 - accuracy: 0.5976 - scaled_graph_loss: 0.0290 - val_loss: 1.2446 - val_accuracy: 0.6131
Epoch 143/200
5/5 [==============================] - 1s 209ms/step - loss: 0.9457 - accuracy: 0.6522 - scaled_graph_loss: 0.0272 - val_loss: 1.2440 - val_accuracy: 0.6131
Epoch 144/200
5/5 [==============================] - 1s 176ms/step - loss: 1.0196 - accuracy: 0.6143 - scaled_graph_loss: 0.0281 - val_loss: 1.2449 - val_accuracy: 0.6136
Epoch 145/200
5/5 [==============================] - 1s 222ms/step - loss: 1.0264 - accuracy: 0.6045 - scaled_graph_loss: 0.0281 - val_loss: 1.2458 - val_accuracy: 0.6136
Epoch 146/200
5/5 [==============================] - 1s 181ms/step - loss: 0.9464 - accuracy: 0.6266 - scaled_graph_loss: 0.0315 - val_loss: 1.2463 - val_accuracy: 0.6136
Epoch 147/200
5/5 [==============================] - 1s 191ms/step - loss: 1.0403 - accuracy: 0.5913 - scaled_graph_loss: 0.0275 - val_loss: 1.2475 - val_accuracy: 0.6127
Epoch 148/200
5/5 [==============================] - 1s 231ms/step - loss: 1.0299 - accuracy: 0.6055 - scaled_graph_loss: 0.0302 - val_loss: 1.2493 - val_accuracy: 0.6127
Epoch 149/200
5/5 [==============================] - 1s 174ms/step - loss: 1.0777 - accuracy: 0.5722 - scaled_graph_loss: 0.0313 - val_loss: 1.2508 - val_accuracy: 0.6127
Epoch 150/200
5/5 [==============================] - 1s 265ms/step - loss: 1.0012 - accuracy: 0.6296 - scaled_graph_loss: 0.0288 - val_loss: 1.2516 - val_accuracy: 0.6131
Epoch 151/200
5/5 [==============================] - 1s 256ms/step - loss: 0.9506 - accuracy: 0.6113 - scaled_graph_loss: 0.0292 - val_loss: 1.2499 - val_accuracy: 0.6136
Epoch 152/200
5/5 [==============================] - 1s 250ms/step - loss: 1.0039 - accuracy: 0.6003 - scaled_graph_loss: 0.0286 - val_loss: 1.2448 - val_accuracy: 0.6145
Epoch 153/200
5/5 [==============================] - 1s 239ms/step - loss: 0.9514 - accuracy: 0.6343 - scaled_graph_loss: 0.0299 - val_loss: 1.2397 - val_accuracy: 0.6154
Epoch 154/200
5/5 [==============================] - 1s 199ms/step - loss: 0.9848 - accuracy: 0.6177 - scaled_graph_loss: 0.0309 - val_loss: 1.2356 - val_accuracy: 0.6177
Epoch 155/200
5/5 [==============================] - 1s 163ms/step - loss: 0.9157 - accuracy: 0.6665 - scaled_graph_loss: 0.0314 - val_loss: 1.2342 - val_accuracy: 0.6177
Epoch 156/200
5/5 [==============================] - 1s 160ms/step - loss: 0.9497 - accuracy: 0.6200 - scaled_graph_loss: 0.0301 - val_loss: 1.2320 - val_accuracy: 0.6177
Epoch 157/200
5/5 [==============================] - 1s 172ms/step - loss: 0.9808 - accuracy: 0.6151 - scaled_graph_loss: 0.0309 - val_loss: 1.2295 - val_accuracy: 0.6200
Epoch 158/200
5/5 [==============================] - 1s 181ms/step - loss: 0.9169 - accuracy: 0.6518 - scaled_graph_loss: 0.0283 - val_loss: 1.2264 - val_accuracy: 0.6219
Epoch 159/200
5/5 [==============================] - 1s 168ms/step - loss: 1.0104 - accuracy: 0.6188 - scaled_graph_loss: 0.0289 - val_loss: 1.2250 - val_accuracy: 0.6228
Epoch 160/200
5/5 [==============================] - 1s 180ms/step - loss: 0.9568 - accuracy: 0.5875 - scaled_graph_loss: 0.0311 - val_loss: 1.2251 - val_accuracy: 0.6219
Epoch 161/200
5/5 [==============================] - 1s 162ms/step - loss: 0.9131 - accuracy: 0.6352 - scaled_graph_loss: 0.0303 - val_loss: 1.2244 - val_accuracy: 0.6219
Epoch 162/200
5/5 [==============================] - 1s 168ms/step - loss: 0.9322 - accuracy: 0.6390 - scaled_graph_loss: 0.0308 - val_loss: 1.2250 - val_accuracy: 0.6223
Epoch 163/200
5/5 [==============================] - 1s 191ms/step - loss: 0.9138 - accuracy: 0.6420 - scaled_graph_loss: 0.0309 - val_loss: 1.2265 - val_accuracy: 0.6223
Epoch 164/200
5/5 [==============================] - 1s 161ms/step - loss: 0.9189 - accuracy: 0.6483 - scaled_graph_loss: 0.0310 - val_loss: 1.2288 - val_accuracy: 0.6214
Epoch 165/200
5/5 [==============================] - 1s 167ms/step - loss: 0.9210 - accuracy: 0.6330 - scaled_graph_loss: 0.0331 - val_loss: 1.2299 - val_accuracy: 0.6228
Epoch 166/200
5/5 [==============================] - 1s 201ms/step - loss: 0.9685 - accuracy: 0.6292 - scaled_graph_loss: 0.0329 - val_loss: 1.2324 - val_accuracy: 0.6251
Epoch 167/200
5/5 [==============================] - 1s 260ms/step - loss: 0.9593 - accuracy: 0.6231 - scaled_graph_loss: 0.0320 - val_loss: 1.2372 - val_accuracy: 0.6251
Epoch 168/200
5/5 [==============================] - 1s 186ms/step - loss: 0.9453 - accuracy: 0.6082 - scaled_graph_loss: 0.0301 - val_loss: 1.2409 - val_accuracy: 0.6260
Epoch 169/200
5/5 [==============================] - 1s 174ms/step - loss: 1.0013 - accuracy: 0.6015 - scaled_graph_loss: 0.0313 - val_loss: 1.2456 - val_accuracy: 0.6247
Epoch 170/200
5/5 [==============================] - 1s 225ms/step - loss: 0.9140 - accuracy: 0.6605 - scaled_graph_loss: 0.0311 - val_loss: 1.2488 - val_accuracy: 0.6228
Epoch 171/200
5/5 [==============================] - 1s 184ms/step - loss: 0.8999 - accuracy: 0.6485 - scaled_graph_loss: 0.0295 - val_loss: 1.2475 - val_accuracy: 0.6237
Epoch 172/200
5/5 [==============================] - 1s 163ms/step - loss: 0.9913 - accuracy: 0.6180 - scaled_graph_loss: 0.0299 - val_loss: 1.2500 - val_accuracy: 0.6242
Epoch 173/200
5/5 [==============================] - 1s 229ms/step - loss: 0.9542 - accuracy: 0.6138 - scaled_graph_loss: 0.0290 - val_loss: 1.2513 - val_accuracy: 0.6237
Epoch 174/200
5/5 [==============================] - 1s 283ms/step - loss: 0.9251 - accuracy: 0.6392 - scaled_graph_loss: 0.0309 - val_loss: 1.2524 - val_accuracy: 0.6247
Epoch 175/200
5/5 [==============================] - 1s 277ms/step - loss: 0.9016 - accuracy: 0.6572 - scaled_graph_loss: 0.0321 - val_loss: 1.2525 - val_accuracy: 0.6260
Epoch 176/200
5/5 [==============================] - 1s 271ms/step - loss: 0.9267 - accuracy: 0.6182 - scaled_graph_loss: 0.0311 - val_loss: 1.2514 - val_accuracy: 0.6260
Epoch 177/200
5/5 [==============================] - 1s 231ms/step - loss: 0.8702 - accuracy: 0.6715 - scaled_graph_loss: 0.0307 - val_loss: 1.2500 - val_accuracy: 0.6265
Epoch 178/200
5/5 [==============================] - 1s 179ms/step - loss: 0.8859 - accuracy: 0.6498 - scaled_graph_loss: 0.0300 - val_loss: 1.2444 - val_accuracy: 0.6260
Epoch 179/200
5/5 [==============================] - 1s 232ms/step - loss: 0.9165 - accuracy: 0.6484 - scaled_graph_loss: 0.0306 - val_loss: 1.2410 - val_accuracy: 0.6265
Epoch 180/200
5/5 [==============================] - 1s 269ms/step - loss: 0.8989 - accuracy: 0.6480 - scaled_graph_loss: 0.0308 - val_loss: 1.2395 - val_accuracy: 0.6260
Epoch 181/200
5/5 [==============================] - 1s 280ms/step - loss: 0.9084 - accuracy: 0.6570 - scaled_graph_loss: 0.0303 - val_loss: 1.2380 - val_accuracy: 0.6270
Epoch 182/200
5/5 [==============================] - 1s 184ms/step - loss: 0.8927 - accuracy: 0.6529 - scaled_graph_loss: 0.0321 - val_loss: 1.2398 - val_accuracy: 0.6293
Epoch 183/200
5/5 [==============================] - 1s 269ms/step - loss: 0.9331 - accuracy: 0.6413 - scaled_graph_loss: 0.0324 - val_loss: 1.2425 - val_accuracy: 0.6274
Epoch 184/200
5/5 [==============================] - 1s 232ms/step - loss: 0.8546 - accuracy: 0.6809 - scaled_graph_loss: 0.0297 - val_loss: 1.2477 - val_accuracy: 0.6283
Epoch 185/200
5/5 [==============================] - 1s 195ms/step - loss: 0.8826 - accuracy: 0.6345 - scaled_graph_loss: 0.0327 - val_loss: 1.2524 - val_accuracy: 0.6274
Epoch 186/200
5/5 [==============================] - 1s 234ms/step - loss: 0.8374 - accuracy: 0.6524 - scaled_graph_loss: 0.0321 - val_loss: 1.2602 - val_accuracy: 0.6288
Epoch 187/200
5/5 [==============================] - 1s 240ms/step - loss: 0.9199 - accuracy: 0.6291 - scaled_graph_loss: 0.0331 - val_loss: 1.2633 - val_accuracy: 0.6279
Epoch 188/200
5/5 [==============================] - 1s 198ms/step - loss: 0.8474 - accuracy: 0.6932 - scaled_graph_loss: 0.0315 - val_loss: 1.2667 - val_accuracy: 0.6270
Epoch 189/200
5/5 [==============================] - 1s 162ms/step - loss: 0.8857 - accuracy: 0.6527 - scaled_graph_loss: 0.0326 - val_loss: 1.2682 - val_accuracy: 0.6251
Epoch 190/200
5/5 [==============================] - 1s 167ms/step - loss: 0.8189 - accuracy: 0.6870 - scaled_graph_loss: 0.0335 - val_loss: 1.2717 - val_accuracy: 0.6251
Epoch 191/200
5/5 [==============================] - 1s 157ms/step - loss: 0.9053 - accuracy: 0.6332 - scaled_graph_loss: 0.0321 - val_loss: 1.2757 - val_accuracy: 0.6233
Epoch 192/200
5/5 [==============================] - 1s 156ms/step - loss: 0.9003 - accuracy: 0.6519 - scaled_graph_loss: 0.0333 - val_loss: 1.2747 - val_accuracy: 0.6256
Epoch 193/200
5/5 [==============================] - 1s 165ms/step - loss: 0.8634 - accuracy: 0.6420 - scaled_graph_loss: 0.0301 - val_loss: 1.2704 - val_accuracy: 0.6270
Epoch 194/200
5/5 [==============================] - 1s 164ms/step - loss: 0.8267 - accuracy: 0.6727 - scaled_graph_loss: 0.0314 - val_loss: 1.2641 - val_accuracy: 0.6274
Epoch 195/200
5/5 [==============================] - 1s 172ms/step - loss: 0.8430 - accuracy: 0.6941 - scaled_graph_loss: 0.0338 - val_loss: 1.2606 - val_accuracy: 0.6283
Epoch 196/200
5/5 [==============================] - 1s 177ms/step - loss: 0.8967 - accuracy: 0.6375 - scaled_graph_loss: 0.0320 - val_loss: 1.2575 - val_accuracy: 0.6316
Epoch 197/200
5/5 [==============================] - 1s 164ms/step - loss: 0.8748 - accuracy: 0.6446 - scaled_graph_loss: 0.0315 - val_loss: 1.2558 - val_accuracy: 0.6320
Epoch 198/200
5/5 [==============================] - 1s 190ms/step - loss: 0.9019 - accuracy: 0.6390 - scaled_graph_loss: 0.0323 - val_loss: 1.2531 - val_accuracy: 0.6316
Epoch 199/200
5/5 [==============================] - 1s 139ms/step - loss: 0.7997 - accuracy: 0.6777 - scaled_graph_loss: 0.0342 - val_loss: 1.2514 - val_accuracy: 0.6325
Epoch 200/200
5/5 [==============================] - 1s 247ms/step - loss: 0.9136 - accuracy: 0.6405 - scaled_graph_loss: 0.0328 - val_loss: 1.2526 - val_accuracy: 0.6320</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>&lt;tensorflow.python.keras.callbacks.History at 0x14fe35610&gt;</code></pre>
</div>
</div>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="miruetoto/yechan3" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->



</body></html>