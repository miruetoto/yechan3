{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **\\[Essays\\]** 강화학습강의(1)\n",
        "\n",
        "신록예찬  \n",
        "2023-08-02\n",
        "\n",
        "## imports"
      ],
      "id": "ee34fcb6-12d7-4dc1-bcb9-032d2fd1fd8b"
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import torch\n",
        "import collections\n",
        "import IPython"
      ],
      "id": "df6688cb-b243-4e39-80c3-3886d1481186"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Intro\n",
        "\n",
        "`-` 강화학습(대충설명): 어떠한 “(게임)환경”이 있을때 거기서 “뭘 할지”를\n",
        "학습하는 과업\n",
        "\n",
        "# Game1: 벤딧문제\n",
        "\n",
        "`-` 문제설명: 두개의 버튼이 있다. 버튼0을 누르면 1의 보상을, 버튼1를\n",
        "누르면 100의 보상을 준다고 가정\n",
        "\n",
        "`-` 어떤 행동을 해야할까? –\\> ?? 아는게없음 –\\> 일단 “아무거나” 눌러보자"
      ],
      "id": "5c3f1803-f665-40ea-866c-8264f0dc8873"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "action_space = ['button0','button1']\n",
        "action = np.random.choice(action_space)\n",
        "action"
      ],
      "id": "d771a51a-0733-42df-bf20-b06444164b35"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 보상은 아래와 같은 방식으로 받을 것이다."
      ],
      "id": "1e54d0b5-b83d-4490-8f72-3f6d424c762b"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "if action == 'button0': \n",
        "    reward = 1 \n",
        "else:\n",
        "    reward = 100"
      ],
      "id": "97ab8e9f-5d74-4600-bbc9-64ed47fec6d9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 아무거나 10번 버튼을 눌러보면 다음과 같은 결과가 나온다."
      ],
      "id": "816a7f98-a933-4a8d-9e2f-9b35eb63725f"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "button1 100\n",
            "button0 1\n",
            "button1 100\n",
            "button1 100\n",
            "button0 1\n",
            "button0 1\n",
            "button1 100\n",
            "button1 100\n",
            "button0 1\n",
            "button0 1"
          ]
        }
      ],
      "source": [
        "for _ in range(10):\n",
        "    action = np.random.choice(action_space)\n",
        "    if action == 'button0': \n",
        "        reward = 1 \n",
        "    else:\n",
        "        reward = 100\n",
        "    print(action,reward)"
      ],
      "id": "afb693ba-a1f0-4886-88f2-093c8c632cbb"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 깨달았음: `button0`을 누르면 1점을 받고, `button1`을 누르면 100점을\n",
        "받는 “환경”이구나? $\\to$ `button1`을 누르는 “동작”을 해야하는\n",
        "상황이구나?\n",
        "\n",
        "-   여기에서 $\\to$ 의 과정을 체계화 시킨 학문이 강화학습이다."
      ],
      "id": "06b86b63-b85b-4ad2-ba18-167dd3edfa01"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100"
          ]
        }
      ],
      "source": [
        "action_space = ['button0','button1']\n",
        "for _ in range(10):\n",
        "    #action = np.random.choice(action_space) # 무지한자의 행동 (찍어)\n",
        "    action = action_space[1] # 깨달은자의 행동 (button1을 눌러)\n",
        "    if action == 'button0': \n",
        "        reward = 1 \n",
        "    else:\n",
        "        reward = 100\n",
        "    print(action,reward)"
      ],
      "id": "0a189b7f-eaaf-4d7e-b2a9-b9742ab245d4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 강화학습: 환경의 이해 $\\to$ 뭘 해야 하는지 깨달음\n",
        "\n",
        "**위의 과정이 잘 되었다는 의미로 사용하는 문장들**\n",
        "\n",
        "-   강화학습이 성공적으로 잘 되었다.\n",
        "-   환경이 해결되었다.\n",
        "-   에이전트가 환경의 과제를 완료했다.\n",
        "-   에이전트가 환경에서 성공적으로 학습했다.\n",
        "-   에이전트가 올바른 행동을 학습했다.\n",
        "-   게임 클리어 (비공식)\n",
        "\n",
        "`-` 환경이 해결되었는지 나타내는 지표를 정해야겠다 $\\to$ 주어진 상황을\n",
        "게임처럼 이해하고, 게임의 클리어조건을 설정\n",
        "\n",
        "-   첫 생각: `button1`을 누르면 클리어 아니야?\n",
        "-   두번째 생각: 아니지? 우연히 누를수도 있잖아.\n",
        "-   게임클리어조건: 최근 20번의 보상이 1900 이상이면 게임이 클리어\n",
        "    되었다고 보자![1]\n",
        "\n",
        "`-` 무지한자 – 게임을 클리어 할 수 없다.\n",
        "\n",
        "[1] `button1`을 눌러야하는건 맞지만 20번에 실수한번정도는 눈감아 주자"
      ],
      "id": "97c5864c-53f0-4f3d-b4b9-03133a98d042"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_try = 1    action = button0    reward = 1  cum_score = 1\n",
            "n_try = 2    action = button0    reward = 1  cum_score = 2\n",
            "n_try = 3    action = button0    reward = 1  cum_score = 3\n",
            "n_try = 4    action = button1    reward = 100    cum_score = 103\n",
            "n_try = 5    action = button0    reward = 1  cum_score = 104\n",
            "n_try = 6    action = button0    reward = 1  cum_score = 105\n",
            "n_try = 7    action = button0    reward = 1  cum_score = 106\n",
            "n_try = 8    action = button0    reward = 1  cum_score = 107\n",
            "n_try = 9    action = button0    reward = 1  cum_score = 108\n",
            "n_try = 10   action = button1    reward = 100    cum_score = 208\n",
            "n_try = 11   action = button0    reward = 1  cum_score = 209\n",
            "n_try = 12   action = button0    reward = 1  cum_score = 210\n",
            "n_try = 13   action = button1    reward = 100    cum_score = 310\n",
            "n_try = 14   action = button0    reward = 1  cum_score = 311\n",
            "n_try = 15   action = button0    reward = 1  cum_score = 312\n",
            "n_try = 16   action = button1    reward = 100    cum_score = 412\n",
            "n_try = 17   action = button0    reward = 1  cum_score = 413\n",
            "n_try = 18   action = button1    reward = 100    cum_score = 513\n",
            "n_try = 19   action = button1    reward = 100    cum_score = 613\n",
            "n_try = 20   action = button1    reward = 100    cum_score = 713\n",
            "n_try = 21   action = button0    reward = 1  cum_score = 713\n",
            "n_try = 22   action = button1    reward = 100    cum_score = 812\n",
            "n_try = 23   action = button1    reward = 100    cum_score = 911\n",
            "n_try = 24   action = button1    reward = 100    cum_score = 911\n",
            "n_try = 25   action = button1    reward = 100    cum_score = 1010\n",
            "n_try = 26   action = button1    reward = 100    cum_score = 1109\n",
            "n_try = 27   action = button0    reward = 1  cum_score = 1109\n",
            "n_try = 28   action = button0    reward = 1  cum_score = 1109\n",
            "n_try = 29   action = button1    reward = 100    cum_score = 1208\n",
            "n_try = 30   action = button0    reward = 1  cum_score = 1109\n",
            "n_try = 31   action = button1    reward = 100    cum_score = 1208\n",
            "n_try = 32   action = button0    reward = 1  cum_score = 1208\n",
            "n_try = 33   action = button1    reward = 100    cum_score = 1208\n",
            "n_try = 34   action = button1    reward = 100    cum_score = 1307\n",
            "n_try = 35   action = button1    reward = 100    cum_score = 1406\n",
            "n_try = 36   action = button0    reward = 1  cum_score = 1307\n",
            "n_try = 37   action = button1    reward = 100    cum_score = 1406\n",
            "n_try = 38   action = button1    reward = 100    cum_score = 1406\n",
            "n_try = 39   action = button1    reward = 100    cum_score = 1406\n",
            "n_try = 40   action = button0    reward = 1  cum_score = 1307\n",
            "n_try = 41   action = button1    reward = 100    cum_score = 1406\n",
            "n_try = 42   action = button1    reward = 100    cum_score = 1406\n",
            "n_try = 43   action = button0    reward = 1  cum_score = 1307\n",
            "n_try = 44   action = button0    reward = 1  cum_score = 1208\n",
            "n_try = 45   action = button0    reward = 1  cum_score = 1109\n",
            "n_try = 46   action = button1    reward = 100    cum_score = 1109\n",
            "n_try = 47   action = button1    reward = 100    cum_score = 1208\n",
            "n_try = 48   action = button0    reward = 1  cum_score = 1208\n",
            "n_try = 49   action = button1    reward = 100    cum_score = 1208\n",
            "n_try = 50   action = button0    reward = 1  cum_score = 1208"
          ]
        }
      ],
      "source": [
        "action_space = ['button0','button1']\n",
        "scores = []\n",
        "for i in range(50): # 1000번해도 못깸\n",
        "    action = np.random.choice(action_space) # 무지한자의 행동 (찍어)\n",
        "    #action = action_space[1] # 깨달은자의 행동 (button1을 눌러)\n",
        "    if action == 'button0': \n",
        "        reward = 1 \n",
        "        scores.append(reward)\n",
        "    else:\n",
        "        reward = 100\n",
        "        scores.append(reward)\n",
        "    print(f\"n_try = {i+1}\\t action = {action}\\t reward = {reward}\\t cum_score = {np.sum(scores[-20:])}\")\n",
        "    if np.sum(scores[-20:])>1900:\n",
        "        break\n",
        "    "
      ],
      "id": "cd7ee8d2-4bef-4901-98a3-766efc21c600"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 깨달은자 – 게임 클리어"
      ],
      "id": "013a9c6a-7f11-4d61-b32b-43d029036da3"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_try = 1    action = button1    reward = 100    cum_score = 100\n",
            "n_try = 2    action = button1    reward = 100    cum_score = 200\n",
            "n_try = 3    action = button1    reward = 100    cum_score = 300\n",
            "n_try = 4    action = button1    reward = 100    cum_score = 400\n",
            "n_try = 5    action = button1    reward = 100    cum_score = 500\n",
            "n_try = 6    action = button1    reward = 100    cum_score = 600\n",
            "n_try = 7    action = button1    reward = 100    cum_score = 700\n",
            "n_try = 8    action = button1    reward = 100    cum_score = 800\n",
            "n_try = 9    action = button1    reward = 100    cum_score = 900\n",
            "n_try = 10   action = button1    reward = 100    cum_score = 1000\n",
            "n_try = 11   action = button1    reward = 100    cum_score = 1100\n",
            "n_try = 12   action = button1    reward = 100    cum_score = 1200\n",
            "n_try = 13   action = button1    reward = 100    cum_score = 1300\n",
            "n_try = 14   action = button1    reward = 100    cum_score = 1400\n",
            "n_try = 15   action = button1    reward = 100    cum_score = 1500\n",
            "n_try = 16   action = button1    reward = 100    cum_score = 1600\n",
            "n_try = 17   action = button1    reward = 100    cum_score = 1700\n",
            "n_try = 18   action = button1    reward = 100    cum_score = 1800\n",
            "n_try = 19   action = button1    reward = 100    cum_score = 1900\n",
            "n_try = 20   action = button1    reward = 100    cum_score = 2000"
          ]
        }
      ],
      "source": [
        "action_space = ['button0','button1']\n",
        "scores = []\n",
        "for i in range(50): # 1000번해도 못깸\n",
        "    #action = np.random.choice(action_space) # 무지한자의 행동 (찍어)\n",
        "    action = action_space[1] # 깨달은자의 행동 (button1을 눌러)\n",
        "    if action == 'button0': \n",
        "        reward = 1 \n",
        "        scores.append(reward)\n",
        "    else:\n",
        "        reward = 100\n",
        "        scores.append(reward)\n",
        "    print(f\"n_try = {i+1}\\t action = {action}\\t reward = {reward}\\t cum_score = {np.sum(scores[-20:])}\")\n",
        "    if np.sum(scores[-20:])>1900:\n",
        "        break"
      ],
      "id": "a47f0eea-5688-454a-8c9d-9e4c6d5552fe"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Game1: 벤딧문제 – 예쁜코드\n",
        "\n",
        "## 수정1: `action_space`의 수정"
      ],
      "id": "5c29459c-f105-4eae-9846-fe2bd24d40e6"
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "action_space =  gym.spaces.Discrete(2)\n",
        "action_space"
      ],
      "id": "4b1d0578-eb81-4dc3-a1ba-1653e7e73aa3"
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1"
          ]
        }
      ],
      "source": [
        "for _ in range(10):\n",
        "    print(action_space.sample())"
      ],
      "id": "1c796bc8-d37c-4b05-8ee1-14c5bb6f177d"
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_try = 1    action = 0  reward = 1  cum_score = 1\n",
            "n_try = 2    action = 1  reward = 100    cum_score = 101\n",
            "n_try = 3    action = 0  reward = 1  cum_score = 102\n",
            "n_try = 4    action = 0  reward = 1  cum_score = 103\n",
            "n_try = 5    action = 1  reward = 100    cum_score = 203\n",
            "n_try = 6    action = 1  reward = 100    cum_score = 303\n",
            "n_try = 7    action = 1  reward = 100    cum_score = 403\n",
            "n_try = 8    action = 0  reward = 1  cum_score = 404\n",
            "n_try = 9    action = 0  reward = 1  cum_score = 405\n",
            "n_try = 10   action = 0  reward = 1  cum_score = 406\n",
            "n_try = 11   action = 0  reward = 1  cum_score = 407\n",
            "n_try = 12   action = 0  reward = 1  cum_score = 408\n",
            "n_try = 13   action = 0  reward = 1  cum_score = 409\n",
            "n_try = 14   action = 1  reward = 100    cum_score = 509\n",
            "n_try = 15   action = 1  reward = 100    cum_score = 609\n",
            "n_try = 16   action = 0  reward = 1  cum_score = 610\n",
            "n_try = 17   action = 1  reward = 100    cum_score = 710\n",
            "n_try = 18   action = 1  reward = 100    cum_score = 810\n",
            "n_try = 19   action = 0  reward = 1  cum_score = 811\n",
            "n_try = 20   action = 0  reward = 1  cum_score = 812\n",
            "n_try = 21   action = 0  reward = 1  cum_score = 812\n",
            "n_try = 22   action = 0  reward = 1  cum_score = 713\n",
            "n_try = 23   action = 1  reward = 100    cum_score = 812\n",
            "n_try = 24   action = 1  reward = 100    cum_score = 911\n",
            "n_try = 25   action = 0  reward = 1  cum_score = 812\n",
            "n_try = 26   action = 1  reward = 100    cum_score = 812\n",
            "n_try = 27   action = 1  reward = 100    cum_score = 812\n",
            "n_try = 28   action = 0  reward = 1  cum_score = 812\n",
            "n_try = 29   action = 1  reward = 100    cum_score = 911\n",
            "n_try = 30   action = 0  reward = 1  cum_score = 911\n",
            "n_try = 31   action = 1  reward = 100    cum_score = 1010\n",
            "n_try = 32   action = 0  reward = 1  cum_score = 1010\n",
            "n_try = 33   action = 0  reward = 1  cum_score = 1010\n",
            "n_try = 34   action = 0  reward = 1  cum_score = 911\n",
            "n_try = 35   action = 0  reward = 1  cum_score = 812\n",
            "n_try = 36   action = 0  reward = 1  cum_score = 812\n",
            "n_try = 37   action = 0  reward = 1  cum_score = 713\n",
            "n_try = 38   action = 0  reward = 1  cum_score = 614\n",
            "n_try = 39   action = 1  reward = 100    cum_score = 713\n",
            "n_try = 40   action = 1  reward = 100    cum_score = 812\n",
            "n_try = 41   action = 1  reward = 100    cum_score = 911\n",
            "n_try = 42   action = 1  reward = 100    cum_score = 1010\n",
            "n_try = 43   action = 0  reward = 1  cum_score = 911\n",
            "n_try = 44   action = 1  reward = 100    cum_score = 911\n",
            "n_try = 45   action = 0  reward = 1  cum_score = 911\n",
            "n_try = 46   action = 1  reward = 100    cum_score = 911\n",
            "n_try = 47   action = 0  reward = 1  cum_score = 812\n",
            "n_try = 48   action = 1  reward = 100    cum_score = 911\n",
            "n_try = 49   action = 1  reward = 100    cum_score = 911\n",
            "n_try = 50   action = 0  reward = 1  cum_score = 911"
          ]
        }
      ],
      "source": [
        "action_space = gym.spaces.Discrete(2)\n",
        "scores = []\n",
        "for i in range(50): # 1000번해도 못깸\n",
        "    action = action_space.sample() # 무지한자의 행동 (찍어)\n",
        "    #action = 1 # 깨달은자의 행동 (button1을 눌러)\n",
        "    if action == 0: \n",
        "        reward = 1 \n",
        "        scores.append(reward)\n",
        "    else:\n",
        "        reward = 100\n",
        "        scores.append(reward)\n",
        "    print(f\"n_try = {i+1}\\t action = {action}\\t reward = {reward}\\t cum_score = {np.sum(scores[-20:])}\")\n",
        "    if np.sum(scores[-20:])>1900:\n",
        "        break"
      ],
      "id": "4d4e9079-5aff-468a-8037-b1a19e8e1bfa"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 수정2: Env 클래스"
      ],
      "id": "df4869d3-08a5-4b2a-9c4e-7359540f8897"
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Game1Env:\n",
        "    def step(self,action):\n",
        "        if action == 0: \n",
        "            return 1\n",
        "        else:\n",
        "            return 100"
      ],
      "id": "0f8150e2-9959-4020-9414-e82e6b3795c3"
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_try = 1    action = 1  reward = 100    cum_score = 100\n",
            "n_try = 2    action = 1  reward = 100    cum_score = 200\n",
            "n_try = 3    action = 1  reward = 100    cum_score = 300\n",
            "n_try = 4    action = 1  reward = 100    cum_score = 400\n",
            "n_try = 5    action = 1  reward = 100    cum_score = 500\n",
            "n_try = 6    action = 1  reward = 100    cum_score = 600\n",
            "n_try = 7    action = 1  reward = 100    cum_score = 700\n",
            "n_try = 8    action = 1  reward = 100    cum_score = 800\n",
            "n_try = 9    action = 1  reward = 100    cum_score = 900\n",
            "n_try = 10   action = 1  reward = 100    cum_score = 1000\n",
            "n_try = 11   action = 1  reward = 100    cum_score = 1100\n",
            "n_try = 12   action = 1  reward = 100    cum_score = 1200\n",
            "n_try = 13   action = 1  reward = 100    cum_score = 1300\n",
            "n_try = 14   action = 1  reward = 100    cum_score = 1400\n",
            "n_try = 15   action = 1  reward = 100    cum_score = 1500\n",
            "n_try = 16   action = 1  reward = 100    cum_score = 1600\n",
            "n_try = 17   action = 1  reward = 100    cum_score = 1700\n",
            "n_try = 18   action = 1  reward = 100    cum_score = 1800\n",
            "n_try = 19   action = 1  reward = 100    cum_score = 1900\n",
            "n_try = 20   action = 1  reward = 100    cum_score = 2000"
          ]
        }
      ],
      "source": [
        "env = Game1Env()\n",
        "scores = []\n",
        "for i in range(50): # 1000번해도 못깸\n",
        "    #action = action_space.sample() # 무지한자의 행동 (찍어)\n",
        "    action = 1 # 깨달은자의 행동 (button1을 눌러)\n",
        "    reward = env.step(action)\n",
        "    scores.append(reward)\n",
        "    print(f\"n_try = {i+1}\\t action = {action}\\t reward = {reward}\\t cum_score = {np.sum(scores[-20:])}\")\n",
        "    if np.sum(scores[-20:])>1900:\n",
        "        break"
      ],
      "id": "2af252df-c080-412f-b549-084f8721d507"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 수정3: Agent 클래스\n",
        "\n",
        "`-` Agent 클래스를 만들자 (액션을 하고, 환경에서 받은 reward를\n",
        "간직하도록)"
      ],
      "id": "9f386dca-61c5-4096-9f3f-0b5c53b7d5f9"
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Agent1:\n",
        "    def __init__(self):\n",
        "        self.action_space = gym.spaces.Discrete(2)\n",
        "        self.action = None\n",
        "        self.reward = None\n",
        "        self.actions = []\n",
        "        self.rewards = []\n",
        "    def act(self):\n",
        "        # self.action = self.action_space.sample() # 무지한 자\n",
        "        self.action = 1 # 깨달은 자 \n",
        "    def save_experience(self): \n",
        "        self.actions.append(self.action)\n",
        "        self.rewards.append(self.reward)"
      ],
      "id": "3a8a43e7-3975-487b-a643-8c7266112c9b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "— 대충 아래와 같은 느낌으로 돌아가요 —\n",
        "\n",
        "**시점0**: init"
      ],
      "id": "c6aa4080-fb19-4b85-96c7-04a2ae62c533"
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = Game1Env()\n",
        "agent = Agent1()"
      ],
      "id": "8e3fa8f0-b41f-4d92-9477-1f6725c4e831"
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.action, agent.reward"
      ],
      "id": "7b528099-158b-4e65-8181-92d1a6372d40"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**시점1**: agent \\>\\> env"
      ],
      "id": "10344a1b-d199-41e9-ac78-d01970a58b20"
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.act()"
      ],
      "id": "545483f3-e2e3-4fd5-9009-f22df31761aa"
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.action, agent.reward"
      ],
      "id": "a7b88291-b73b-4deb-9469-0b50e06a0d7f"
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [],
      "source": [
        "env.received_action = agent.action "
      ],
      "id": "c1cc49b4-180f-4ac6-8322-82bc0d36dc04"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**시점2**: agent \\<\\< env"
      ],
      "id": "1d0f0fcc-bb06-4d8a-9dd8-32c85becee42"
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.reward = env.step(env.received_action) \n",
        "# agent.reward = env.step(agent.action) 도 같은 결과를 주는 코드임!!"
      ],
      "id": "dd742d0b-e19c-4194-b581-5aa0cac4a12a"
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.action, agent.reward, env.received_action"
      ],
      "id": "d3b53960-00d4-4652-9500-dc3860688ea5"
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.actions, agent.rewards"
      ],
      "id": "55df6ce8-fc00-42be-a880-ab486a16c469"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**시점3**: agent: `save_experience`"
      ],
      "id": "595094c6-02b0-4e61-a36d-159085904469"
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.save_experience()"
      ],
      "id": "10070384-7964-4cae-bffb-516ab570b98d"
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.actions, agent.rewards"
      ],
      "id": "9f1024c0-f468-41cc-8f62-52811b1fc8fe"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "— 전체코드 —"
      ],
      "id": "3460d4e4-f7b3-40e7-8aac-ea6744bacd19"
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_try = 20   action = 1  reward = 100    cum_score = 100\n",
            "n_try = 20   action = 1  reward = 100    cum_score = 200\n",
            "n_try = 20   action = 1  reward = 100    cum_score = 300\n",
            "n_try = 20   action = 1  reward = 100    cum_score = 400\n",
            "n_try = 20   action = 1  reward = 100    cum_score = 500\n",
            "n_try = 20   action = 1  reward = 100    cum_score = 600\n",
            "n_try = 20   action = 1  reward = 100    cum_score = 700\n",
            "n_try = 20   action = 1  reward = 100    cum_score = 800\n",
            "n_try = 20   action = 1  reward = 100    cum_score = 900\n",
            "n_try = 20   action = 1  reward = 100    cum_score = 1000\n",
            "n_try = 20   action = 1  reward = 100    cum_score = 1100\n",
            "n_try = 20   action = 1  reward = 100    cum_score = 1200\n",
            "n_try = 20   action = 1  reward = 100    cum_score = 1300\n",
            "n_try = 20   action = 1  reward = 100    cum_score = 1400\n",
            "n_try = 20   action = 1  reward = 100    cum_score = 1500\n",
            "n_try = 20   action = 1  reward = 100    cum_score = 1600\n",
            "n_try = 20   action = 1  reward = 100    cum_score = 1700\n",
            "n_try = 20   action = 1  reward = 100    cum_score = 1800\n",
            "n_try = 20   action = 1  reward = 100    cum_score = 1900\n",
            "n_try = 20   action = 1  reward = 100    cum_score = 2000"
          ]
        }
      ],
      "source": [
        "env = Game1Env()\n",
        "agent = Agent1()\n",
        "for _ in range(50):\n",
        "    ## 본질적인 코드\n",
        "    # step1: agent >> env \n",
        "    agent.act()\n",
        "    env.received_action = agent.action \n",
        "    # step2: agnet << env \n",
        "    agent.reward = env.step(env.received_action) \n",
        "    # step3: save \n",
        "    agent.save_experience()\n",
        "    \n",
        "    ## 비본질적 코드 \n",
        "    print(f\"n_try = {i+1}\\t action = {agent.action}\\t reward = {agent.reward}\\t cum_score = {np.sum(agent.rewards[-20:])}\")\n",
        "    if np.sum(agent.rewards[-20:])>1900:\n",
        "        break"
      ],
      "id": "bd8ebd38-0b87-47f5-bf32-141a42388734"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   위의 코드를 거의 뼈대로 사용합니당!\n",
        "\n",
        "# Game1: 벤딧문제 – 학습과정 포함\n",
        "\n",
        "`-` Game1에 대한 생각:\n",
        "\n",
        "-   사실 강화학습은 “환경을 이해 $\\to$ 뭘 해야 하는지 깨달음” 의\n",
        "    과정에서 화살표를 수식화 하는 과정이다.\n",
        "-   지금까지 살펴보면 Game1은 환경(env)을 이해하는 순간 에이전트가\n",
        "    최적의 행동(action)[1]을 직관적으로 결정하였으므로 학습의 과정이\n",
        "    포함되었다고 볼 수 없다.\n",
        "\n",
        "`-` 지금까지의 코드 복습\n",
        "\n",
        "1.  클래스를 선언하는 부분\n",
        "    -   `Env`클래스의 선언\n",
        "    -   `Agent`클래스의 선언\n",
        "2.  환경과 에이전트를 인스턴스화 (초기화)\n",
        "3.  for loop를 반복하며 게임을 진행\n",
        "    -   메인코드: (1) agent \\>\\> env (2) agent \\<\\< env (3) 데이터저장\n",
        "    -   비본질적코드: 학습과정 display, 학습종료조건\n",
        "\n",
        "`-` 앞으로 구성할 코드의 형태: 에이전트가 데이터를 보고 스스로\n",
        "`button1`을 눌러야 한다는 것을 추론하면 좋겠음\n",
        "\n",
        "1.  클래스를 선언하는 부분\n",
        "    -   `Env`클래스의 선언\n",
        "    -   **`Agent`클래스의 선언**: **학습의 과정 포함 $\\to$ act함수\n",
        "        수정**\n",
        "2.  환경과 에이전트를 인스턴스화 (초기화)\n",
        "3.  for loop를 반복하며 게임을 진행\n",
        "    -   메인코드: (1) agent \\>\\> env (2) agent \\<\\< env (3) 데이터저장\n",
        "        **(4) 학습**\n",
        "    -   비본질적코드: 학습과정 display, 학습종료조건\n",
        "\n",
        "`-` 에이전트가 학습을 어떻게 하는가?[2]\n",
        "\n",
        "-   $\\pi(0) = \\frac{Q_t(1)}{Q_t(1)+Q_t(0)}$\n",
        "-   $\\pi(1) = \\frac{Q_t(0)}{Q_t(1)+Q_t(0)}$\n",
        "\n",
        "여기에서 각각의 기호는 아래를 의미한다.\n",
        "\n",
        "-   $\\pi(0)$: 에이전트가 action = 0 을 할 확률, 즉 에이전트가\n",
        "    `button0`을 누를 확률\n",
        "-   $\\pi(1)$: 에이전트가 action = 1 을 할 확률, 즉 에이전트가\n",
        "    `button1`을 누를 확률\n",
        "-   $Q_t(0)$: ($t$시점까지 파악한) action = 0 을 하였을 경우 에이전트가\n",
        "    환경으로 받은 보상의 평균값\n",
        "-   $Q_t(1)$: ($t$시점까지 파악한) action = 1 을 하였을 경우 에이전트가\n",
        "    환경으로 받은 보상의 평균값\n",
        "\n",
        "`-` 걱정: $t=0$이면 어쩌지? $t=1$이면 어쩌지?.. $\\to$ 잡기술1: 일정\n",
        "시간동안은 랜덤액션을 하면서 데이터를 쌓자.\n",
        "\n",
        "`-` 코드를 구현해보자.\n",
        "\n",
        "[1] `button1`을 누른다\n",
        "\n",
        "[2] 행동을 이런식으로 하도록 “전략(=정책)”을 설정하는 것은 상식적이다.\n",
        "그렇지만 유일한 해결책은 아님!!"
      ],
      "id": "63e11419-53d8-4b82-a51b-c7d585c295dc"
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 게임을 푸는 전략을 바꾸는 것이지 게임자체를 바꿀게 아니니까 수정할게 없죠?\n",
        "class Game1Env:\n",
        "    def step(self,action):\n",
        "        if action == 0: \n",
        "            return 1\n",
        "        else:\n",
        "            return 100"
      ],
      "id": "67665c93-1cd4-4dc5-b577-2de0ebc5cfb3"
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {},
      "outputs": [],
      "source": [
        "# learn 추가\n",
        "class Agent1:\n",
        "    def __init__(self):\n",
        "        self.action_space = gym.spaces.Discrete(2)\n",
        "        self.action = None\n",
        "        self.reward = None\n",
        "        self.actions = []\n",
        "        self.rewards = []\n",
        "        self.n_experiences = 0\n",
        "        self.qnet = {'button0':0, 'button1':0}\n",
        "    def act(self):\n",
        "        if self.n_experiences > 100:\n",
        "            pass\n",
        "        else:\n",
        "            self.action = self.action_space.sample() # 무지한 자\n",
        "        self.action = 1 # 깨달은 자 \n",
        "    def save_experience(self): \n",
        "        self.actions.append(self.action)\n",
        "        self.rewards.append(self.reward)\n",
        "        self.n_experiences = len(self.actions)\n",
        "    def learn(self):\n",
        "        pass"
      ],
      "id": "b87cd3f2-fc9a-4b0a-a0b3-cf350c19de61"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 다른방식도 가능함\n",
        "\n",
        "-   (Sutton and Barto 2018, p27, (2.1))"
      ],
      "id": "c52f55fc-bd77-4dd7-925f-e7aaadfb7348"
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Game1Env:\n",
        "    def step(self,action):\n",
        "        if action == 0: \n",
        "            return 1\n",
        "        else:\n",
        "            return 100"
      ],
      "id": "471a58c0-f35f-4d09-833d-89f48ed37e94"
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Agent1:\n",
        "    def __init__(self):\n",
        "        self.action_space = gym.spaces.Discrete(2)\n",
        "        self.action = None\n",
        "        self.reward = None\n",
        "        self.actions = []\n",
        "        self.rewards = []\n",
        "    def act(self):\n",
        "        # self.action = self.action_space.sample() # 무지한 자\n",
        "        self.action = 1 # 깨달은 자 \n",
        "    def save_experience(self): \n",
        "        self.actions.append(self.action)\n",
        "        self.rewards.append(self.reward)\n",
        "    def "
      ],
      "id": "2f8fb69b-a96d-4196-a2b6-f2f578560fae"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Game2: 4 $\\times$ 4 그리드\n",
        "\n",
        "## Game1\n",
        "\n",
        "`-` 강화학습의 기본개념"
      ],
      "id": "b0211d1a-c886-4e10-ab83-1790c415a0c9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scores = []\n",
        "for _ in range(1000):\n",
        "    action = np.random.choice(action_space)\n",
        "    #action = action_space[1] # 잘 배웠다면 이렇게 행동해야함 \n",
        "    if action == 'button0': \n",
        "        reward = 1 \n",
        "        scores.append(reward)\n",
        "    else:\n",
        "        reward = 100\n",
        "        scores.append(reward)\n",
        "    print(action,reward,np.sum(scores[-20:]))\n",
        "    if np.sum(scores[-20:])>1900:\n",
        "        break"
      ],
      "id": "b6d3a418-b07d-48d5-b94d-8a2ab941386b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   어떤 동작을 하느냐에 따라서 게임을 풀수도 있고 그렇지 못할 수도\n",
        "    있다.\n",
        "\n",
        "`-` 용어 정리 - Agent = 버튼을 누르는 사람 - Action = 에이전트가 할 수\n",
        "있는 행동 (현재는 2개의 action이 가능) - Env = Agent의 action을 보고\n",
        "reward를 주는 존재 - 게임의 종료 = 버튼을 누르면 게임이 종료 - 게임을\n",
        "푸는 방법 = reward를 최대화하는 action을 선택\n",
        "\n",
        "`-` 코드의 수정"
      ],
      "id": "7f221853-d163-4562-8f59-e7fe4a423aeb"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "action_space = ["
      ],
      "id": "53bab7a3-17c2-49ba-8322-d85dce045b57"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` construct ENV"
      ],
      "id": "3d722953-3a6a-4206-850c-29724bb4d623"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Game1(gym.Env):\n",
        "    def __init__(self):\n",
        "        self.action_space = gym.spaces.Discrete(2,start=0)\n",
        "        self.observation_space = gym.spaces.Discrete(1,start=0)\n",
        "        self.state = 0 \n",
        "    def step(self,action):\n",
        "        if action == 1:\n",
        "            self.reward = 100 \n",
        "            return self.state, self.reward \n",
        "        else: \n",
        "            self.reward = 0 \n",
        "            return self.state, self.reward\n",
        "    def render(self):\n",
        "        return f'state: {self.state}'\n",
        "    def reset(self):\n",
        "        None, self.state\n",
        "    def close(self):\n",
        "        pass"
      ],
      "id": "7ec1ed5b-5846-4a8d-98ee-cee5c04e2429"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = Game1()"
      ],
      "id": "f75bda59-e112-4aed-9689-977a50b0a4a8"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "env.render()"
      ],
      "id": "72694d4a-ecd4-4082-ba9d-d20908c0dc11"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "env.step(1)"
      ],
      "id": "605b2696-fd43-46c3-8c42-fec3f43331fd"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "gym.spaces.Discrete?"
      ],
      "id": "0db4f0e2-4cd7-4017-9368-b6efb63c18cf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Game1(gym.Env):\n",
        "    def __init__(self):\n",
        "        self.action_space = gym.spaces.Discrete(2,start=0)\n",
        "        self.observation_space = gym.spaces.Discrete(1,start=0)\n",
        "        self.state = 0 \n",
        "    def step(self,action):\n",
        "        if action == 1:\n",
        "            self.reward = 100 \n",
        "            return self.state, self.reward \n",
        "        else: \n",
        "            self.reward = 0 \n",
        "            return self.state, self.reward\n",
        "    def render(self):\n",
        "        return f'state: {self.state}'\n",
        "    def reset(self):\n",
        "        None, self.state\n",
        "    def close(self):\n",
        "        pass"
      ],
      "id": "50adec81-ce99-4004-80db-eb2605ca3fe6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Game3: 한칸 or 두칸\n",
        "\n",
        "`-` $q$-value\n",
        "\n",
        "# Game4: 소탐대실\n",
        "\n",
        "`-` epsilon decay\n",
        "\n",
        "`-` 문제설명: 에이전트는 현재 0의 위치에 있다. 에이전트는 (1) 정지 (2)\n",
        "왼쪽으로 이동 (3) 오른쪽으로 이동 하는 3개의 행동을 할 수 있다.\n",
        "에이전트가 +2의 위치에 도달하면 100의 보상을 얻고 게임이 종료된다.\n",
        "에이전트가 -2의 위치에 도달하면 보상없이 게임이 종료된다.\n",
        "\n",
        "`-` 에이전트와 환경의 상호작용 구현1"
      ],
      "id": "aa641095-dd62-4869-9297-566f20eb6691"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "state = 0"
      ],
      "id": "d753194b-c29d-408d-bbb4-6e82d6455be7"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "action = np.random.choice([-1,0,1])"
      ],
      "id": "49be0f5a-2337-454b-ae5b-973628356a35"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 -1"
          ]
        }
      ],
      "source": [
        "print(state,action)"
      ],
      "id": "13527401-e8e7-4ded-be35-f6b25c83bc41"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 -1\n",
            "-1 1\n",
            "0 0\n",
            "0 -1\n",
            "-1 0\n",
            "-1 1\n",
            "0 -1\n",
            "-1 -1\n",
            "-2\n",
            "-2의 위치에 도달, 보상 0점 획득"
          ]
        }
      ],
      "source": [
        "for _ in range(9): \n",
        "    if state == 2:\n",
        "        print(state)\n",
        "        reward = 200         \n",
        "        print(\"2의 위치에 도달, 보상 {}점 획득\".format(reward))\n",
        "        break \n",
        "    elif state == -2:\n",
        "        print(state)\n",
        "        reward = 0 \n",
        "        print(\"-2의 위치에 도달, 보상 {}점 획득\".format(reward))\n",
        "        break\n",
        "    else:\n",
        "        print(state,action)\n",
        "        state = state + action \n",
        "        action = np.random.choice([-1,0,1])"
      ],
      "id": "1e6c4ab7-15e9-491e-8b44-392491213600"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 에이전트와 환경의 상호작용 구현2"
      ],
      "id": "aaa34d34-ba6d-4e09-b3cc-e493557fc65d"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "observation_space = gym.spaces.Discrete(5,start=-2)"
      ],
      "id": "982dc58a-b969-4086-8f3a-994467a0899e"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "observation_space.sample()"
      ],
      "id": "33b84075-ad4f-4d8f-8757-9332ffc45b30"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "observation_space.shape"
      ],
      "id": "9addcb23-27b9-4fb5-82ac-8386337054cf"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "observation_space.contains(-3),observation_space.contains(-2)"
      ],
      "id": "fc7b0d94-3fff-44dc-be2a-6cdded371de0"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "action_space = gym.spaces.Discrete(3,start=-1)"
      ],
      "id": "44a3bacd-7fe7-4988-9edc-ac37d5e59dd4"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "action_space"
      ],
      "id": "d03dd2d8-470d-4099-aad5-76bb3c4a208b"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Game2(gym.Env):\n",
        "    def __init__(self):\n",
        "        self.action_space = gym.spaces.Discrete(3,start=-1) # Acition = {-1,0,1}  \n",
        "        self.observation_space = gym.spaces.Discrete(5,start=-2) # State = {-2,-1,0,1,2} \n",
        "        self.state = 0 \n",
        "        self.t = 0\n",
        "    def step(self,action):\n",
        "        self.state = self.state + action\n",
        "        self.t = self.t + 1 \n",
        "        if self.state == 2:\n",
        "            reward = 100\n",
        "        else:\n",
        "            reward = -1\n",
        "        info = {}\n",
        "        if self.state == -2 or self.state==2: \n",
        "            done = True\n",
        "        else: \n",
        "            done = False\n",
        "        return self.state, reward, terminated, truncated, info\n",
        "    def render(self):\n",
        "        print('state: {}'.format(self.state))\n",
        "    def reset(self):\n",
        "        self.state = 0 \n",
        "        return self.state"
      ],
      "id": "943478ae-efb4-461e-9ec8-47b48c1050bf"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "env=Game2()"
      ],
      "id": "fa6c4fa4-f2bc-416d-9b2d-e635cfcff6ab"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Game5: 연속형 상태공간"
      ],
      "id": "46761edf-c9b0-4072-829f-62162167c33a"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pygame\n",
        "\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "\n",
        "class GridWorldEnv(gym.Env):\n",
        "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 4}\n",
        "\n",
        "    def __init__(self, render_mode=None, size=5):\n",
        "        self.size = size  # The size of the square grid\n",
        "        self.window_size = 512  # The size of the PyGame window\n",
        "\n",
        "        # Observations are dictionaries with the agent's and the target's location.\n",
        "        # Each location is encoded as an element of {0, ..., `size`}^2, i.e. MultiDiscrete([size, size]).\n",
        "        self.observation_space = spaces.Dict(\n",
        "            {\n",
        "                \"agent\": spaces.Box(0, size - 1, shape=(2,), dtype=int),\n",
        "                \"target\": spaces.Box(0, size - 1, shape=(2,), dtype=int),\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # We have 4 actions, corresponding to \"right\", \"up\", \"left\", \"down\"\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "\n",
        "        \"\"\"\n",
        "        The following dictionary maps abstract actions from `self.action_space` to\n",
        "        the direction we will walk in if that action is taken.\n",
        "        I.e. 0 corresponds to \"right\", 1 to \"up\" etc.\n",
        "        \"\"\"\n",
        "        self._action_to_direction = {\n",
        "            0: np.array([1, 0]),\n",
        "            1: np.array([0, 1]),\n",
        "            2: np.array([-1, 0]),\n",
        "            3: np.array([0, -1]),\n",
        "        }\n",
        "\n",
        "        assert render_mode is None or render_mode in self.metadata[\"render_modes\"]\n",
        "        self.render_mode = render_mode\n",
        "\n",
        "        \"\"\"\n",
        "        If human-rendering is used, `self.window` will be a reference\n",
        "        to the window that we draw to. `self.clock` will be a clock that is used\n",
        "        to ensure that the environment is rendered at the correct framerate in\n",
        "        human-mode. They will remain `None` until human-mode is used for the\n",
        "        first time.\n",
        "        \"\"\"\n",
        "        self.window = None\n",
        "        self.clock = None\n",
        "    def _get_obs(self):\n",
        "        return {\"agent\": self._agent_location, \"target\": self._target_location}        \n",
        "    def _get_info(self):\n",
        "        return {\n",
        "            \"distance\": np.linalg.norm(\n",
        "                self._agent_location - self._target_location, ord=1\n",
        "            )\n",
        "        }\n",
        "    def reset(self, seed=None, options=None):\n",
        "        # We need the following line to seed self.np_random\n",
        "        super().reset(seed=seed)\n",
        "    \n",
        "        # Choose the agent's location uniformly at random\n",
        "        self._agent_location = self.np_random.integers(0, self.size, size=2, dtype=int)\n",
        "    \n",
        "        # We will sample the target's location randomly until it does not coincide with the agent's location\n",
        "        self._target_location = self._agent_location\n",
        "        while np.array_equal(self._target_location, self._agent_location):\n",
        "            self._target_location = self.np_random.integers(\n",
        "                0, self.size, size=2, dtype=int\n",
        "            )\n",
        "    \n",
        "        observation = self._get_obs()\n",
        "        info = self._get_info()\n",
        "    \n",
        "        if self.render_mode == \"human\":\n",
        "            self._render_frame()\n",
        "    \n",
        "        return observation, info\n",
        "    def step(self, action):\n",
        "        # Map the action (element of {0,1,2,3}) to the direction we walk in\n",
        "        direction = self._action_to_direction[action]\n",
        "        # We use `np.clip` to make sure we don't leave the grid\n",
        "        self._agent_location = np.clip(\n",
        "            self._agent_location + direction, 0, self.size - 1\n",
        "        )\n",
        "        # An episode is done iff the agent has reached the target\n",
        "        terminated = np.array_equal(self._agent_location, self._target_location)\n",
        "        reward = 1 if terminated else 0  # Binary sparse rewards\n",
        "        observation = self._get_obs()\n",
        "        info = self._get_info()\n",
        "    \n",
        "        if self.render_mode == \"human\":\n",
        "            self._render_frame()\n",
        "    \n",
        "        return observation, reward, terminated, False, info\n",
        "    def render(self):\n",
        "        if self.render_mode == \"rgb_array\":\n",
        "            return self._render_frame()\n",
        "    \n",
        "    def _render_frame(self):\n",
        "        if self.window is None and self.render_mode == \"human\":\n",
        "            pygame.init()\n",
        "            pygame.display.init()\n",
        "            self.window = pygame.display.set_mode(\n",
        "                (self.window_size, self.window_size)\n",
        "            )\n",
        "        if self.clock is None and self.render_mode == \"human\":\n",
        "            self.clock = pygame.time.Clock()\n",
        "    \n",
        "        canvas = pygame.Surface((self.window_size, self.window_size))\n",
        "        canvas.fill((255, 255, 255))\n",
        "        pix_square_size = (\n",
        "            self.window_size / self.size\n",
        "        )  # The size of a single grid square in pixels\n",
        "    \n",
        "        # First we draw the target\n",
        "        pygame.draw.rect(\n",
        "            canvas,\n",
        "            (255, 0, 0),\n",
        "            pygame.Rect(\n",
        "                pix_square_size * self._target_location,\n",
        "                (pix_square_size, pix_square_size),\n",
        "            ),\n",
        "        )\n",
        "        # Now we draw the agent\n",
        "        pygame.draw.circle(\n",
        "            canvas,\n",
        "            (0, 0, 255),\n",
        "            (self._agent_location + 0.5) * pix_square_size,\n",
        "            pix_square_size / 3,\n",
        "        )\n",
        "    \n",
        "        # Finally, add some gridlines\n",
        "        for x in range(self.size + 1):\n",
        "            pygame.draw.line(\n",
        "                canvas,\n",
        "                0,\n",
        "                (0, pix_square_size * x),\n",
        "                (self.window_size, pix_square_size * x),\n",
        "                width=3,\n",
        "            )\n",
        "            pygame.draw.line(\n",
        "                canvas,\n",
        "                0,\n",
        "                (pix_square_size * x, 0),\n",
        "                (pix_square_size * x, self.window_size),\n",
        "                width=3,\n",
        "            )\n",
        "    \n",
        "        if self.render_mode == \"human\":\n",
        "            # The following line copies our drawings from `canvas` to the visible window\n",
        "            self.window.blit(canvas, canvas.get_rect())\n",
        "            pygame.event.pump()\n",
        "            pygame.display.update()\n",
        "    \n",
        "            # We need to ensure that human-rendering occurs at the predefined framerate.\n",
        "            # The following line will automatically add a delay to keep the framerate stable.\n",
        "            self.clock.tick(self.metadata[\"render_fps\"])\n",
        "        else:  # rgb_array\n",
        "            return np.transpose(\n",
        "                np.array(pygame.surfarray.pixels3d(canvas)), axes=(1, 0, 2)\n",
        "            )\n",
        "    def close(self):\n",
        "        if self.window is not None:\n",
        "            pygame.display.quit()\n",
        "            pygame.quit()            "
      ],
      "id": "a94554fe-b0f9-4bc0-b7a5-dba900312a36"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = GridWorldEnv()"
      ],
      "id": "ab3800a3-6937-497c-9f5a-62cc76d265b6"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "env.observation_space"
      ],
      "id": "851fe51b-44aa-41bb-a2d4-94fd2eb67423"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "env.action_space"
      ],
      "id": "63c56269-14b1-406d-bf37-27f4773ac2ac"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "env.reset()"
      ],
      "id": "00160498-163e-46bf-a06f-5cd6af4c93b6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Game6: LunarLander\n",
        "\n",
        "### 환경만들기\n",
        "\n",
        "`-` 환경을 만드는 방법은 아래와 같다."
      ],
      "id": "beedee05-3956-4182-b780-a962a20c4e44"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = gym.make('LunarLander-v2',render_mode='rgb_array')"
      ],
      "id": "3e085d50-9d39-4e75-9151-843deb6ee4e6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 환경에 대한 기본 정보를 조사하여 보자."
      ],
      "id": "46e1ec06-a91f-445f-90e6-379749df0d9f"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "env.observation_space"
      ],
      "id": "49e5d1b8-e68d-41da-9c08-26530b8fdacd"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "env.action_space"
      ],
      "id": "cfde2681-4846-4aa0-87ce-66333cd7485a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 환경관찰\n",
        "\n",
        "`-` 환경관찰"
      ],
      "id": "f1dcba9e-926b-48e3-bf9a-77d97879e201"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "env.reset(seed=0)"
      ],
      "id": "35312d3e-1276-4895-b94a-224a0053089b"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAF7CAYAAAD4/3BBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\nH7kJ4OtxxtjyAAAAAElFTkSuQmCC\n"
          }
        }
      ],
      "source": [
        "plt.imshow(env.render())"
      ],
      "id": "eb749f7b-5efe-4646-a8d6-ae8e2e2c2af6"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "env.step(2) # observation, reward, terminated, truncated, info"
      ],
      "id": "9fa82115-7a62-4916-b62c-76548737af76"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAF7CAYAAAD4/3BBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\ndr4d4kIAAAAASUVORK5CYII=\n"
          }
        }
      ],
      "source": [
        "plt.imshow(env.render())"
      ],
      "id": "1bc00880-e619-42f5-9317-7faf4d22c3f7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` action"
      ],
      "id": "da3015e3-5a01-4486-b815-d689ac724753"
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [],
      "source": [
        "env.action_space.sample()"
      ],
      "id": "37dafca5-cbbc-4b88-96a7-a180f77d9023"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   int형으로 전달\n",
        "\n",
        "`-` action -\\> nextstate, reward, done"
      ],
      "id": "0976a719-5f57-4671-8b30-31155b289b49"
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [],
      "source": [
        "env.step(env.action_space.sample())"
      ],
      "id": "23f3049d-0c1d-438f-8fcc-3854ee723c10"
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "frames = []\n",
        "env.reset()\n",
        "for _ in range(300):\n",
        "    frames.append(env.render())\n",
        "    env.step(env.action_space.sample())\n",
        "env.close()"
      ],
      "id": "3cb75d3b-016b-42ce-8497-93120341a230"
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAF7CAYAAAD4/3BBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\nACyHgAIAACyHgAIAACyHgAIAACzn/wMf58/7Q/TYGQAAAABJRU5ErkJggg==\n"
          }
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ani = FuncAnimation(fig,lambda i: ax.imshow(frames[::10][i]),frames=len(frames[::10]))"
      ],
      "id": "9ceab5f9-1e5a-457b-8464-20c9db84d769"
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !conda install -c conda-forge ffmpeg"
      ],
      "id": "bd4071f6-8541-46c2-8120-4e6fe196bf09"
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [],
      "source": [
        "IPython.display.HTML(ani.to_jshtml())"
      ],
      "id": "6fad79d6-2d16-49d1-b425-d2f7ad74896d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Replay Buffer\n",
        "\n",
        "`-` 랜덤액션을 연속적으로 생성하고 그 결과를 기록해보자."
      ],
      "id": "a77ae377-f27c-4316-be19-0e872f4638e5"
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {},
      "outputs": [],
      "source": [
        "states = []\n",
        "actions = []\n",
        "rewards = []\n",
        "next_states = []\n",
        "terminateds = []"
      ],
      "id": "ae71b487-9754-4f06-ba45-2acb2bdefda4"
    },
    {
      "cell_type": "code",
      "execution_count": 335,
      "metadata": {},
      "outputs": [],
      "source": [
        "_state1, _ = env.reset()\n",
        "for t in range(1500):\n",
        "    _action = env.action_space.sample() \n",
        "    _state2, _reward, _terminated, _truncated, _info = env.step(_action)\n",
        "    ## save code \n",
        "    states.append(_state1) \n",
        "    actions.append(_action)\n",
        "    rewards.append(_reward)\n",
        "    next_states.append(_state2)\n",
        "    terminateds.append(_terminated)\n",
        "    ## save code end \n",
        "    _state1 = _state2 \n",
        "    if _terminated:\n",
        "        break"
      ],
      "id": "6b950bc8-0ae9-461e-ba22-0e9e6139c4db"
    },
    {
      "cell_type": "code",
      "execution_count": 336,
      "metadata": {},
      "outputs": [],
      "source": [
        "env.reset()"
      ],
      "id": "58710491-4c49-4740-9823-818daf83d927"
    },
    {
      "cell_type": "code",
      "execution_count": 337,
      "metadata": {},
      "outputs": [],
      "source": [
        "env.step(_action)"
      ],
      "id": "01bdd075-1288-480b-aa1e-8204da75bf53"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 모인 히스토리를 확인해보자."
      ],
      "id": "775d9179-402e-4303-b079-921240a10ada"
    },
    {
      "cell_type": "code",
      "execution_count": 338,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(states), len(actions), len(next_states), len(rewards), len(terminateds)"
      ],
      "id": "58524369-1817-4ee5-84ae-b05dfb323b81"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Qnetwork 설계\n",
        "\n",
        "`-` 네트워크의 목적: 내가 여기서 뭘 해야하는지 알려줘! = 내가 이\n",
        "상태에서, 어떠한 액션을 해야하는지 알려줘 $\\to$ 8개의 상태를 입력으로\n",
        "받으면 4개의 액션에 대한 좋은 정도를 숫자로 표현하는 어떠한 함수를\n",
        "만들자.\n",
        "\n",
        "`-` net 설계"
      ],
      "id": "e8832775-6b81-4718-a741-e6827cda300e"
    },
    {
      "cell_type": "code",
      "execution_count": 339,
      "metadata": {},
      "outputs": [],
      "source": [
        "net = torch.nn.Sequential(\n",
        "    torch.nn.Linear(in_features=8, out_features=128),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(in_features=128, out_features=64),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(in_features=64, out_features=32),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(in_features=32, out_features=4)\n",
        ")\n",
        "net"
      ],
      "id": "54860fb4-9cbd-4aab-9ce7-d716d07e0e7d"
    },
    {
      "cell_type": "code",
      "execution_count": 340,
      "metadata": {},
      "outputs": [],
      "source": [
        "net(torch.tensor(states))"
      ],
      "id": "ab62e365-d629-42c6-91e0-f492ff3a99d0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Policy 설계\n",
        "\n",
        "`-` 네트워크의 의미"
      ],
      "id": "8c2f7c24-4a90-4780-ad17-1d8f6efec156"
    },
    {
      "cell_type": "code",
      "execution_count": 341,
      "metadata": {},
      "outputs": [],
      "source": [
        "states[0],states[1]"
      ],
      "id": "78306592-ca58-4621-8e21-1acd4941278a"
    },
    {
      "cell_type": "code",
      "execution_count": 342,
      "metadata": {},
      "outputs": [],
      "source": [
        "net(torch.tensor(states[0:2]))"
      ],
      "id": "4ba397f6-33b6-429c-b718-321f69c1f765"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   상태0에서는 액션0이, 상태1에서도 액션0이 가장 좋다는 의미 (왜?\n",
        "    q-value가 젤 높으니까..)\n",
        "\n",
        "`-` 따라서 Agent는 아래와 같이 행동해야 한다. (네트워크가 잘\n",
        "학습되었다는 전제가 필요함) - state\\[0\\] -\\> action = 0 - state\\[1\\] -\\>\n",
        "action = 0"
      ],
      "id": "c491fe8d-44ab-48ba-bd54-88f8bd6598bd"
    },
    {
      "cell_type": "code",
      "execution_count": 343,
      "metadata": {},
      "outputs": [],
      "source": [
        "net(torch.tensor(states[0:2])).max(axis=1)"
      ],
      "id": "5b630b0e-bf3b-48a3-bce5-7fd135237ef5"
    },
    {
      "cell_type": "code",
      "execution_count": 344,
      "metadata": {},
      "outputs": [],
      "source": [
        "net(torch.tensor(states[0:2])).max(axis=1)[1]"
      ],
      "id": "4cbfbbec-8253-46de-8a60-de5ae1bb8e19"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 네트워크가 있으므로 이제 어떠한 state에 대해서도 뭘 해야할지 (=어떤\n",
        "액션을 해야할지) 알 수 있다."
      ],
      "id": "60656d7d-ee05-4d55-bc41-f1a6a82b9462"
    },
    {
      "cell_type": "code",
      "execution_count": 347,
      "metadata": {},
      "outputs": [],
      "source": [
        "_state1 # 어떤 state에 대해서도.. "
      ],
      "id": "5f604754-d57a-41b4-a1cb-387cd21a4311"
    },
    {
      "cell_type": "code",
      "execution_count": 348,
      "metadata": {},
      "outputs": [],
      "source": [
        "int(torch.argmax(net(torch.tensor(_state1)))) # 그래서 다음에 우리가 어떤행동을 해야할 지 알 수 있음"
      ],
      "id": "7beb3de0-1ead-4e15-b15d-4ca6be971d75"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 학습\n",
        "\n",
        "`-` 네트워크를 학습시키자."
      ],
      "id": "708b384a-a3af-4834-8539-5efbbdd53cea"
    },
    {
      "cell_type": "code",
      "execution_count": 353,
      "metadata": {},
      "outputs": [],
      "source": [
        "net"
      ],
      "id": "2c71eee5-de1f-41c9-ab1b-23a8ba923a18"
    },
    {
      "cell_type": "code",
      "execution_count": 379,
      "metadata": {},
      "outputs": [],
      "source": [
        "scores=[]\n",
        "playtimes=[] \n",
        "eps = 0\n",
        "opt = torch.optim.Adam(net.parameters(),lr=0.01)"
      ],
      "id": "9e0e9cba-2f10-4f55-bc0a-d20a6177725c"
    },
    {
      "cell_type": "code",
      "execution_count": 380,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 100 Score: -387.24  Playtime: 80.000\n",
            "Episode 200 Score: -290.72  Playtime: 61.000\n",
            "Episode 300 Score: -290.32  Playtime: 82.0000\n",
            "Episode 400 Score: -321.50  Playtime: 158.00\n",
            "Episode 500 Score: -345.35  Playtime: 78.0000\n",
            "Episode 600 Score: -347.79  Playtime: 56.0000\n",
            "Episode 700 Score: -187.64  Playtime: 61.000\n",
            "Episode 800 Score: -206.72  Playtime: 51.000\n",
            "Episode 900 Score: -242.74  Playtime: 82.0000\n",
            "Episode 1000    Score: -270.24  Playtime: 172.00\n",
            "Episode 1100    Score: -239.00  Playtime: 88.0000\n",
            "Episode 1200    Score: -256.10  Playtime: 136.00\n",
            "Episode 1300    Score: -261.52  Playtime: 77.000\n",
            "Episode 1400    Score: -310.77  Playtime: 110.00\n",
            "Episode 1500    Score: -443.30  Playtime: 99.0000\n",
            "Episode 1600    Score: -553.26  Playtime: 68.0000\n",
            "Episode 1700    Score: -571.14  Playtime: 51.000\n",
            "Episode 1800    Score: -592.59  Playtime: 82.0000\n",
            "Episode 1900    Score: -606.76  Playtime: 66.0000\n",
            "Episode 2000    Score: -679.92  Playtime: 83.0000"
          ]
        }
      ],
      "source": [
        "for epsd in range(1,2001): # 게임 2000판 시켜줌.. \n",
        "    state1,_  = env.reset() # 환경리셋 + 초기화된 환경을 state라는 변수에 저장 \n",
        "    score = 0 \n",
        "    for t in range(1000): # 게임1판당 max 1000프레임만 할 수 있음\n",
        "        action = int(torch.argmax(net(torch.tensor(state1)))) # 네트워크가 알려주는 action을 뽑음 \n",
        "        \n",
        "        # (step2) Agent -> Env // Env -> Agent \n",
        "        state2, reward, terminated, truncated, info = env.step(action) # 액션을 환경에 전달 -> (next_state, reward, done) 을 받음 \n",
        "        \n",
        "        # (step3) Agnet: save data and learn \n",
        "        ## save data \n",
        "        states.append(state1)\n",
        "        actions.append(action)\n",
        "        rewards.append(reward)\n",
        "        next_states.append(state2)\n",
        "        terminateds.append(terminated)\n",
        "    \n",
        "        ## 최근 500개의 자료만 준비함. \n",
        "        if len(states)>500:\n",
        "            _states = torch.tensor(states[-500:])\n",
        "            _actions = torch.tensor(actions[-500:]).reshape(-1,1)\n",
        "            _next_states = torch.tensor(next_states[-500:])\n",
        "            _rewards = torch.tensor(rewards[-500:]).reshape(-1,1)\n",
        "            _terminateds = torch.tensor(terminateds[-500:]).to(torch.float).reshape(-1,1) \n",
        "        else:\n",
        "            _states = torch.tensor(states)\n",
        "            _actions = torch.tensor(actions).reshape(-1,1)\n",
        "            _next_states = torch.tensor(next_states)\n",
        "            _rewards = torch.tensor(rewards).reshape(-1,1)\n",
        "            _terminateds = torch.tensor(terminateds).to(torch.float).reshape(-1,1)\n",
        "\n",
        "        ## 최근 50000개의 자료에서 8개를 임의로 추출함. \n",
        "        _n = len(_states)\n",
        "        _index = np.random.choice(_n,64) # 128 is batch_size \n",
        "        _states = _states[_index]\n",
        "        _actions = _actions[_index]\n",
        "        _next_states = _next_states[_index]\n",
        "        _rewards = _rewards[_index]\n",
        "        _terminateds = _terminateds[_index]\n",
        "        \n",
        "        ## leanrn with pytorch \n",
        "        yhat = net(_states).gather(1,_actions).squeeze() ## (s,a) -> q(s,a) // 내가 현재상태 state에서, 현재 action을 하여 얻을 것이라 예상하는 보상 (net가 알려주는) \n",
        "        y = _rewards.squeeze() #+ 0.99 * net(_next_states).detach().max(1)[0] * (1-_terminateds.squeeze()) ## 그런데 실제로는 이게 맞다고 봐야지~ \n",
        "        loss = torch.mean((y-yhat)**2)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        # (step4) Agent: prepare next steps \n",
        "        state1 = state2  \n",
        "        #eps = max(0.05, 0.99*eps) \n",
        "        score = score + reward\n",
        "        \n",
        "        # terminate \n",
        "        if terminated:\n",
        "            scores.append(score)\n",
        "            playtimes.append(t)\n",
        "            break\n",
        "            \n",
        "    print('\\rEpisode {}\\tScore: {:.2f}\\tPlaytime: {:.2f}'.format(epsd, scores[-1],playtimes[-1]), end=\"\")\n",
        "    if epsd % 100 == 0:\n",
        "        print('\\rEpisode {}\\tScore: {:.2f}\\tPlaytime: {:.2f}'.format(epsd, np.mean(scores[-100:]),np.mean(playtimes[-100])))"
      ],
      "id": "5c18836f-283b-4455-828b-847dec289dfe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# for epsd in range(1,2001): # 게임 2000판 시켜줌.. \n",
        "#     state1,_  = env.reset() # 환경리셋 + 초기화된 환경을 state라는 변수에 저장 \n",
        "#     score = 0 \n",
        "#     for t in range(1000): # 게임1판당 max 1000프레임만 할 수 있음\n",
        "#         # (step1) Agent: action \n",
        "#         if np.random.rand() < eps: \n",
        "#             action = env.action_space.sample() # 랜덤액션을 뽑음 \n",
        "#         else:\n",
        "#             action = int(torch.argmax(net(torch.tensor(state1).to(\"cuda:0\")))) # 네트워크가 알려주는 action을 뽑음 \n",
        "        \n",
        "#         # (step2) Agent -> Env // Env -> Agent \n",
        "#         state2, reward, terminated, truncated, info = env.step(action) # 액션을 환경에 전달 -> (next_state, reward, done) 을 받음 \n",
        "        \n",
        "#         # (step3) Agnet: save data and learn \n",
        "#         ## save data \n",
        "#         states.append(state1)\n",
        "#         actions.append(action)\n",
        "#         rewards.append(reward)\n",
        "#         next_states.append(state2)\n",
        "#         terminateds.append(terminated)\n",
        "    \n",
        "#         ## 최근 50000개의 자료만 준비함. \n",
        "#         if len(states)>50000:\n",
        "#             _states = torch.tensor(states[-50000:])\n",
        "#             _actions = torch.tensor(actions[-50000:]).reshape(-1,1)\n",
        "#             _next_states = torch.tensor(next_states[-50000:])\n",
        "#             _rewards = torch.tensor(rewards[-50000:]).reshape(-1,1)\n",
        "#             _terminateds = torch.tensor(terminateds[-50000:]).to(torch.float).reshape(-1,1) \n",
        "#         else:\n",
        "#             _states = torch.tensor(states)\n",
        "#             _actions = torch.tensor(actions).reshape(-1,1)\n",
        "#             _next_states = torch.tensor(next_states)\n",
        "#             _rewards = torch.tensor(rewards).reshape(-1,1)\n",
        "#             _terminateds = torch.tensor(terminateds).to(torch.float).reshape(-1,1)\n",
        "\n",
        "#         ## 최근 50000개의 자료에서 128개를 임의로 추출함. \n",
        "#         _n = len(_states)\n",
        "#         _index = np.random.choice(_n,128) # 128 is batch_size \n",
        "#         _states = _states[_index]\n",
        "#         _actions = _actions[_index]\n",
        "#         _next_states = _next_states[_index]\n",
        "#         _rewards = _rewards[_index]\n",
        "#         _terminateds = _terminateds[_index]\n",
        "        \n",
        "#         ## GPU로 이동 \n",
        "#         _states = _states.to(\"cuda:0\")\n",
        "#         _actions = _actions.to(\"cuda:0\")\n",
        "#         _next_states = _next_states.to(\"cuda:0\")\n",
        "#         _rewards = _rewards.to(\"cuda:0\")\n",
        "#         _terminateds = _terminateds.to(\"cuda:0\")\n",
        "        \n",
        "#         ## leanrn with pytorch \n",
        "#         yhat = net(_states).gather(1,_actions) ## (s,a) -> q(s,a) // 내가 현재상태 state에서, 현재 action을 하여 얻을 것이라 예상하는 보상 (net가 알려주는) \n",
        "#         y = _rewards + 0.99 * net(_next_states).detach().max(1)[0].reshape(-1,1)*(1-_terminateds) ## 그런데 실제로는 이게 맞다고 봐야지~ \n",
        "#         loss = torch.mean((y-yhat)**2)\n",
        "#         loss.backward()\n",
        "        \n",
        "#         opt.step()\n",
        "#         opt.zero_grad()\n",
        "\n",
        "#         # (step4) Agent: prepare next steps \n",
        "#         state1 = state2  \n",
        "#         eps = max(0.05, 0.99*eps) \n",
        "#         score = score + reward\n",
        "        \n",
        "#         # terminate \n",
        "#         if terminated:\n",
        "#             scores.append(score)\n",
        "#             playtimes.append(t)\n",
        "#             break\n",
        "            \n",
        "#     print('\\rEpisode {}\\tScore: {:.2f}\\tPlaytime: {:.2f}'.format(epsd, scores[-1],playtimes[-1]), end=\"\")\n",
        "#     if epsd % 100 == 0:\n",
        "#         print('\\rEpisode {}\\tScore: {:.2f}\\tPlaytime: {:.2f}'.format(epsd, np.mean(scores[-100:]),np.mean(playtimes[-100])))"
      ],
      "id": "54ac5087-13fb-443b-8fe5-68e7a7fc774c"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "1+2="
      ],
      "id": "c0cd95c0-baa3-4d05-b954-c96a1c90de46"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sutton, Richard S, and Andrew G Barto. 2018. *Reinforcement Learning: An\n",
        "Introduction*. MIT press."
      ],
      "id": "1ec252e3-911b-475b-9c82-1469a3234946"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  }
}