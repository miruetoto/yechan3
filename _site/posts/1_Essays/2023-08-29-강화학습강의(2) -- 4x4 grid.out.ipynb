{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **\\[Essays\\]** 강화학습강의(2) – 4x4 grid\n",
        "\n",
        "신록예찬  \n",
        "2023-08-23\n",
        "\n",
        "## Game2: 4 $\\times$ 4 그리드\n",
        "\n",
        "## imports"
      ],
      "id": "99ce895c-d3c2-458c-a55a-e6a51bbe9166"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import torch\n",
        "import collections\n",
        "import IPython"
      ],
      "id": "a0aa2ea8-f975-4718-b614-4bcca0497a4f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 예비학습: 시각화"
      ],
      "id": "3b80cb95-0f2c-4a20-8069-72775a9c72ac"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def render(state): \n",
        "    x,y = state\n",
        "    fig = plt.Figure()\n",
        "    ax = fig.subplots()\n",
        "    im = ax.matshow(np.zeros((4,4)), cmap='bwr')\n",
        "    ax.scatter(x, y, color='red', s=500,alpha=0.3)  # s is the size of the point    \n",
        "    fig.colorbar(im, ax=ax)\n",
        "    ax.text(0, 0, 'start', ha='center', va='center')\n",
        "    ax.text(3, 3, 'end', ha='center', va='center')\n",
        "    # Adding grid lines to the plot\n",
        "    ax.set_xticks(np.arange(-.5, 4, 1), minor=True)\n",
        "    ax.set_yticks(np.arange(-.5, 4, 1), minor=True)\n",
        "    ax.grid(which='minor', color='black', linestyle='-', linewidth=2)\n",
        "    return fig"
      ],
      "id": "664dcc82-0c4d-41fb-84eb-ae85685a8d16"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAGlCAYAAACMQU46AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\nAAAAAElFTkSuQmCC\n"
          }
        }
      ],
      "source": [
        "fig = render([0,0])\n",
        "fig"
      ],
      "id": "b4bdefc6-4c48-4af2-a32d-2932c2fff21f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Env 클래스 구현\n",
        "\n",
        "`-` GridWorld: 강화학습에서 많이 사용되는 기본적인 시뮬레이션 환경\n",
        "\n",
        "1.  **State**: 각 격자 셀이 하나의 상태이며, 에이전트는 이러한 상태 중\n",
        "    하나에 있을 수 있음.\n",
        "2.  **Action**: 에이전트는 상태에서 다른 상태로 이동하기 위해 상, 하,\n",
        "    좌, 우로 이동하는 행동을 할 수 있음.\n",
        "3.  **Reward**: 에이전트가 특정 행동을 취할 때 환경에서 보상이 주어짐.\n",
        "4.  **Terminal State**: 일반적으로 하나 또는 그 이상의 종료 상태가\n",
        "    있으며, 에이전트가 이 상태에 도달하면 에피소드가 종료됨.\n",
        "\n",
        "`-` 환경과 에이전트\n",
        "\n",
        "-   env: $(S_t,A_t) \\to (S_{t+1}, R_t)$\n",
        "\n",
        "`-` 수학기호들\n",
        "\n",
        "-   `state_space`: ${\\cal S}=\\{1,\\dots,16\\}=\\{(0,0)\\dots,(3,3)\\}$\n",
        "-   `action_space`:\n",
        "    ${\\cal A} = \\{0,1,2,3\\} = \\{\\text{right}, \\text{up}, \\text{left}, \\text{down}\\}$\n",
        "-   `current_state`: $S_t \\in {\\cal S}$\n",
        "-   `next_state`: $S_{t+1} \\in {\\cal S}$\n",
        "-   `action`: $A_t \\in {\\cal A}$\n",
        "-   `reward`: $R_t \\in {\\cal R}=\\{-1,-100,100\\}$"
      ],
      "id": "8be0b78a-cdd6-42d5-93f1-18a900c97a3e"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GridWorld:\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "        self._action_to_direction = {\n",
        "            0: np.array([1, 0]), # x+ \n",
        "            1: np.array([0, 1]), # y+\n",
        "            2: np.array([-1, 0]), # x-  \n",
        "            3: np.array([0, -1]), # y-\n",
        "        }\n",
        "        self.state_space = gym.spaces.MultiDiscrete([4, 4])\n",
        "        self.action_space = gym.spaces.Discrete(4)\n",
        "    def reset(self):\n",
        "        self.agent_action = None\n",
        "        self.agent_state = np.array([0, 0])\n",
        "        return self.agent_state\n",
        "    def step(self,action):\n",
        "        direction = self._action_to_direction[action]\n",
        "        self.agent_state = self.agent_state + direction\n",
        "        # 목표지점에 도달 \n",
        "        if np.array_equal(np.array([3,3]), self.agent_state):\n",
        "            reward = 100\n",
        "            terminated = True\n",
        "        else:\n",
        "            reward = -1\n",
        "            terminated = False\n",
        "        # 4*4밖에 있을 경우 \n",
        "        if self.agent_state not in self.state_space:\n",
        "            reward = -100\n",
        "            terminated = True\n",
        "            self.agent_state = self.agent_state - 1/2*direction\n",
        "        return self.agent_state, reward, terminated"
      ],
      "id": "3a5fea73-af23-4dc9-be0c-d083122175cc"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = GridWorld()\n",
        "env.reset()\n",
        "states = []\n",
        "rewards = [] \n",
        "terminations = [] \n",
        "for t in range(500):\n",
        "    action = env.action_space.sample()\n",
        "    state, reward, terminated = env.step(action)\n",
        "    states.append(state)\n",
        "    rewards.append(reward)\n",
        "    terminations.append(terminated)\n",
        "    if terminated: \n",
        "        break "
      ],
      "id": "0c9492ff-1979-4b2d-8a04-f656bc030df3"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = render([0,0])\n",
        "ax = fig.gca()"
      ],
      "id": "e78cc49b-1f29-4ac4-aa4c-3345cc839777"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def update(i):\n",
        "    ax.scatter(states[i][0],states[i][1],color='red',s=500,alpha=0.3)"
      ],
      "id": "9c842582-c3a0-4b0b-bf2f-251b07512579"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "ani = FuncAnimation(fig,update,frames=len(states))"
      ],
      "id": "76121084-2cb8-49e9-b8bd-2a987e08f4ba"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "IPython.display.HTML(ani.to_jshtml())"
      ],
      "id": "c6add38d-03ac-45e3-b27f-dca6e7dbe695"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Agent 클래스 구현1\n",
        "\n",
        "`-` 첫번째 시도"
      ],
      "id": "2030b6f0-eb21-43a5-9ad4-a34c9fa49abc"
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [],
      "source": [
        "# learn 추가\n",
        "class Agent2_v1:\n",
        "    def __init__(self,env):\n",
        "        self.action_space = env.action_space\n",
        "        self.state_space = env.state_space\n",
        "        self.n_experiences = 0\n",
        "        self.n_episode = 0 \n",
        "        \n",
        "        ## episode info \n",
        "        self.scores = [] \n",
        "        self.playtimes = [] \n",
        "\n",
        "        ## sars\n",
        "        self.current_state = None \n",
        "        self.action = None\n",
        "        self.reward = None        \n",
        "        self.next_state = None \n",
        "        \n",
        "        ## ReplayBuffer\n",
        "        self.actions = []\n",
        "        self.rewards = []\n",
        "        self.current_states = []\n",
        "        self.next_states = [] \n",
        "        self.terminations = []\n",
        "        \n",
        "    def act(self):\n",
        "        self.action = self.action_space.sample()\n",
        "        \n",
        "    def save_experience(self): \n",
        "        self.actions.append(self.action)\n",
        "        self.current_states.append(self.current_state)\n",
        "        self.next_states.append(self.next_state)\n",
        "        self.rewards.append(self.reward)\n",
        "        self.terminations.append(self.terminated)\n",
        "        self.n_experiences = len(self.actions)"
      ],
      "id": "8fce5e60-18f1-4e4b-9ebb-0ec2f047514b"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = GridWorld()\n",
        "agent = Agent2_v1(env)"
      ],
      "id": "4c53b588-de35-4224-bd77-f55dc56ec675"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "env.reset()"
      ],
      "id": "d0887951-0460-4530-adad-03ad26b76c43"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1   Score: -104 Playtime: 5\n",
            "Episode 2   Score: -104 Playtime: 5\n",
            "Episode 3   Score: -100 Playtime: 1\n",
            "Episode 4   Score: -100 Playtime: 1\n",
            "Episode 5   Score: -100 Playtime: 1\n",
            "Episode 6   Score: -105 Playtime: 6\n",
            "Episode 7   Score: -100 Playtime: 1\n",
            "Episode 8   Score: -101 Playtime: 2\n",
            "Episode 9   Score: -100 Playtime: 1\n",
            "Episode 10  Score: -101 Playtime: 2\n",
            "Episode 11  Score: -100 Playtime: 1\n",
            "Episode 12  Score: -102 Playtime: 3\n",
            "Episode 13  Score: -103 Playtime: 4\n",
            "Episode 14  Score: -102 Playtime: 3\n",
            "Episode 15  Score: -102 Playtime: 3\n",
            "Episode 16  Score: -105 Playtime: 6\n",
            "Episode 17  Score: -104 Playtime: 5\n",
            "Episode 18  Score: -102 Playtime: 3\n",
            "Episode 19  Score: -100 Playtime: 1\n",
            "Episode 20  Score: -101 Playtime: 2"
          ]
        }
      ],
      "source": [
        "for _ in range(20):\n",
        "    ### 1. 본질적인 코드\n",
        "    agent.current_state = env.reset() \n",
        "    agent.terminated = False\n",
        "    agent.score = 0 \n",
        "    for t in range(50):\n",
        "        # step1: agent >> env \n",
        "        agent.act()\n",
        "        env.agent_action = agent.action\n",
        "        # step2: env << agent \n",
        "        agent.next_state, agent.reward, agent.terminated = env.step(env.agent_action)\n",
        "        # step3: 데이터저장 및 학습\n",
        "        agent.save_experience()\n",
        "        # step4: 다음 iteration 준비 + 종료조건체크\n",
        "        agent.current_state = agent.next_state \n",
        "        agent.score += agent.reward\n",
        "        if agent.terminated: break \n",
        "    agent.scores.append(agent.score) \n",
        "    agent.playtimes.append(t+1)\n",
        "    agent.n_episode = agent.n_episode + 1 \n",
        "    ## 2. 비본질적 코드\n",
        "    print(\n",
        "        f'Episode {agent.n_episode}\\t'\n",
        "        f'Score: {agent.scores[-1]}\\t'\n",
        "        f'Playtime: {agent.playtimes[-1]}'\n",
        "    )"
      ],
      "id": "c2577e9d-b45a-4e04-bb4f-f8df81cc7b9b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 어떻게 학습을 할까? 즉 어떻게 “환경의 이해 $\\to$ 행동의 결정” 의\n",
        "과정을 수행할까?\n",
        "\n",
        "1.  어떠한 상태에서, 어떠한 행동을 했을때, 어떠한 보상과 어떠한\n",
        "    다음상태를 받았는지 기록하자.\n",
        "2.  1을 바탕으로 다음행동을 어떻게 할지 판단하자.\n",
        "\n",
        "## 환경의 이해 (1차원적 이해)\n",
        "\n",
        "`-` 무작위로 10000판을 진행하여 보자."
      ],
      "id": "64d42ebb-e136-4004-ba16-47fdf64e9baf"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = GridWorld()\n",
        "agent = Agent2_v1(env)\n",
        "env.reset()\n",
        "\n",
        "for _ in range(10000):\n",
        "    ### 1. 본질적인 코드\n",
        "    agent.current_state = env.reset() \n",
        "    agent.terminated = False\n",
        "    agent.score = 0 \n",
        "    for t in range(50):\n",
        "        # step1: agent >> env \n",
        "        agent.act()\n",
        "        env.agent_action = agent.action\n",
        "        # step2: env << agent \n",
        "        agent.next_state, agent.reward, agent.terminated = env.step(env.agent_action)\n",
        "        # step3: 데이터저장 및 학습\n",
        "        agent.save_experience()\n",
        "        # step4: 다음 iteration 준비 + 종료조건체크\n",
        "        agent.current_state = agent.next_state \n",
        "        agent.score += agent.reward\n",
        "        if agent.terminated: break \n",
        "    agent.scores.append(agent.score) \n",
        "    agent.playtimes.append(t+1)\n",
        "    agent.n_episode = agent.n_episode + 1 \n",
        "    # ## 2. 비본질적 코드\n",
        "    # print(\n",
        "    #     f'Episode {agent.n_episode}\\t'\n",
        "    #     f'Score: {agent.scores[-1]}\\t'\n",
        "    #     f'Playtime: {agent.playtimes[-1]}'\n",
        "    # )"
      ],
      "id": "80e04276-c30d-44de-a3e3-6985a4832589"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.n_experiences"
      ],
      "id": "cff1062b-f5de-4897-bec9-0d7b7b636c44"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 데이터관찰"
      ],
      "id": "e644ecca-621d-463f-97df-5509419c6819"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.current_states[0], agent.actions[0], agent.rewards[0]"
      ],
      "id": "9ee8fdd8-a045-4e0f-a898-9ffee4609551"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.current_states[1], agent.actions[1], agent.rewards[1]"
      ],
      "id": "085336fb-f8c5-4d9a-aa93-c22cdfae20d0"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.current_states[2], agent.actions[2], agent.rewards[2]"
      ],
      "id": "d2d9ffdf-6eb6-4aba-8109-b62e924d6a36"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.current_states[3], agent.actions[3], agent.rewards[3]"
      ],
      "id": "6253a16c-a396-4837-b643-d74aaa414297"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 환경을 이해하기 위한 기록 (1)"
      ],
      "id": "20e082eb-0447-42ae-80aa-516a54b83922"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "q = np.zeros([4,4,4])\n",
        "count = np.zeros([4,4,4])\n",
        "for i in range(agent.n_experiences):\n",
        "    x,y = agent.current_states[i]\n",
        "    a = agent.actions[i]\n",
        "    q[x,y,a] = q[x,y,a] + agent.rewards[i]\n",
        "    count[x,y,a] = count[x,y,a] + 1 "
      ],
      "id": "237d6e30-0c45-432b-90db-a92eec386b19"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "count[count==0] = 0.1\n",
        "count"
      ],
      "id": "06270762-0bd6-4e5b-878e-48b044310761"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "q = (q/count).round(2)\n",
        "q"
      ],
      "id": "127edf98-279a-4bc4-9c77-b6c3dd74c834"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action = 0\n",
            "action-value function =\n",
            " [[  -1.   -1.   -1.   -1.]\n",
            " [  -1.   -1.   -1.   -1.]\n",
            " [  -1.   -1.   -1.  100.]\n",
            " [-100. -100. -100.    0.]]\n",
            "\n",
            "action = 1\n",
            "action-value function =\n",
            " [[  -1.   -1.   -1. -100.]\n",
            " [  -1.   -1.   -1. -100.]\n",
            " [  -1.   -1.   -1. -100.]\n",
            " [  -1.   -1.  100.    0.]]\n",
            "\n",
            "action = 2\n",
            "action-value function =\n",
            " [[-100. -100. -100. -100.]\n",
            " [  -1.   -1.   -1.   -1.]\n",
            " [  -1.   -1.   -1.   -1.]\n",
            " [  -1.   -1.   -1.    0.]]\n",
            "\n",
            "action = 3\n",
            "action-value function =\n",
            " [[-100.   -1.   -1.   -1.]\n",
            " [-100.   -1.   -1.   -1.]\n",
            " [-100.   -1.   -1.   -1.]\n",
            " [-100.   -1.   -1.    0.]]\n"
          ]
        }
      ],
      "source": [
        "for i in range(4):\n",
        "    print(f\"action = {i}\\n\"\n",
        "          f\"action-value function =\\n {q[:,:,i]}\\n\"\n",
        "          )"
      ],
      "id": "b467c815-99c7-411e-8153-d36904abd880"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 환경을 이해하기 위한 기록 (2) – 이렇게하면 count를 따로 기록할 필요\n",
        "없음"
      ],
      "id": "8dd2fef4-c7e4-4dd0-92a3-1e655e0c2099"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "q = np.zeros([4,4,4])\n",
        "for i in range(agent.n_experiences):\n",
        "    x,y = agent.current_states[i]\n",
        "    a = agent.actions[i]\n",
        "    q_estimated = q[x,y,a] # 풀이한 답\n",
        "    q_observed = agent.rewards[i] # 실제 답\n",
        "    diff = q_observed - q_estimated # 실제답과 풀이한값의 차이 = 오차피드백값이라고 하자\n",
        "    q[x,y,a] = q_estimated + 0.05 * diff ## 새로운답 = 원래답 + 오차피드백 * 학습률"
      ],
      "id": "3e5dddde-9d7f-4973-bc94-ce426c636188"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action = 0\n",
            "action-value function =\n",
            " [[ -1.   -1.   -1.   -1. ]\n",
            " [ -1.   -1.   -1.   -1. ]\n",
            " [ -1.   -1.   -1.   98.9]\n",
            " [-99.5 -99.9 -99.3   0. ]]\n",
            "\n",
            "action = 1\n",
            "action-value function =\n",
            " [[  -1.    -1.    -1.  -100. ]\n",
            " [  -1.    -1.    -1.   -99.9]\n",
            " [  -1.    -1.    -1.   -99.6]\n",
            " [  -1.    -1.    99.6    0. ]]\n",
            "\n",
            "action = 2\n",
            "action-value function =\n",
            " [[-100.  -100.  -100.   -99.9]\n",
            " [  -1.    -1.    -1.    -1. ]\n",
            " [  -1.    -1.    -1.    -1. ]\n",
            " [  -1.    -1.    -1.     0. ]]\n",
            "\n",
            "action = 3\n",
            "action-value function =\n",
            " [[-100.    -1.    -1.    -1. ]\n",
            " [-100.    -1.    -1.    -1. ]\n",
            " [-100.    -1.    -1.    -1. ]\n",
            " [ -99.9   -1.    -1.     0. ]]\n"
          ]
        }
      ],
      "source": [
        "for i in range(4):\n",
        "    print(\n",
        "        f\"action = {i}\\n\"\n",
        "        f\"action-value function =\\n {q[:,:,i].round(1)}\\n\"\n",
        "    )"
      ],
      "id": "24909698-cb58-4520-b80b-82f0c6070003"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 환경의 깊은 이해 (좀 더 고차원적인 이해)\n",
        "\n",
        "`-` action=1 일때 각 state의 가치 (=기대보상)"
      ],
      "id": "ff3eda65-5e17-463b-8b21-f84b4685f172"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "q[:,:,1]"
      ],
      "id": "2f86c9f7-41e0-4865-aecd-08ea1bcda5ff"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 분석1"
      ],
      "id": "d0f3bbae-4b00-4a18-9f40-1d94f4dd22c0"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "q[3,2,1] "
      ],
      "id": "f939b243-6bab-4143-a14b-c47102c2e93c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   상태 (3,2)에서 행동 1을 하게 되면 100의 보상을 얻으므로 기대보상값은\n",
        "    100근처 -\\> 합리적임\n",
        "\n",
        "`-` 분석2"
      ],
      "id": "29a2227e-e0a3-4385-8204-4b30d27b2207"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "q[3,1,1] "
      ],
      "id": "74d617aa-45e6-4d88-9c7c-d8e0d6961737"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   상태 (3,1)에서 행동1을 하게 되면 -1의 보상을 얻으므로 기대보상값은\n",
        "    -1 근처 -\\> 합리적일까?\n",
        "\n",
        "`-` 비판: 분석2는 합리적인듯 하지만 data를 분석한뒤는 그다지 합리적이지\n",
        "못함\n",
        "\n",
        "`-` 상황상상\n",
        "\n",
        "-   빈 종이를 줌\n",
        "-   빈 종이에는 0 또는 1을 쓸 수 있음 (action = 0 or 1)\n",
        "-   0을 쓸 때와 1을 쓸 때의 보상은 다름\n",
        "-   그런데 무수히 많은 데이터를 분석한 결과 0을 쓰면 0원을 보상으로\n",
        "    주고, 1을 쓰면 10만원을 보상으로 준다는 것을 “알게 되었음”\n",
        "-   빈 종이의 가치는 5만원인가? 아니면 10만원인가? –\\> 10만원 아니야?\n",
        "\n",
        "`-` 직관: 생각해보니 `q[3,1,1]`에서는 실제보상(-1)과 잠재적보상(100)을\n",
        "동시에 고려해야하는게 합리적인듯"
      ],
      "id": "70a6e7ae-d514-4aa1-be88-b7bb7be1236d"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "q[3,1,1] = (-1) + 0.99 * (100) "
      ],
      "id": "bdcb9da2-8ac5-4972-8567-a9bc11d1d206"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "q[:,:,1]"
      ],
      "id": "d9dad524-5cb1-4a23-ab7c-b81ce8c6abea"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   여기에서 0.99 는 “미래에 받을 보상이 현재에 비해 얼마나 중요한지를\n",
        "    결정하는 가중치” 이다.\n",
        "-   1에 가까울수록 미래에 받을 보상을 매우 중시한다는 의미 (즉 빈종이 =\n",
        "    십만원 으로 생각한다는 의미)\n",
        "\n",
        "`-` 수식화: `q[3,1,1] = (-1) + 0.99 * (100)`를 수식화하면 아래와 같다.\n",
        "\n",
        "$$q(s,a) = r(s,a) + 0.99\\times \\max_{a} q(s',a)$$\n",
        "\n",
        "좀 더 정확하게는 아래와 같이 볼 수 있다.\n",
        "\n",
        "$$q(s,a)= \\begin{cases} r(s,a) & \\text{terminated}  \\\\ r(s,a)+ 0.99\\times \\max_{a} q(s',a) & \\text{not terminated} \\end{cases} $$"
      ],
      "id": "61f59794-1fff-479a-b7bd-c0a46b0e1717"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "q = np.zeros([4,4,4])\n",
        "for i in range(agent.n_experiences):\n",
        "    x,y = agent.current_states[i]\n",
        "    xx,yy = agent.next_states[i]\n",
        "    a = agent.actions[i]\n",
        "    q_estimated = q[x,y,a]\n",
        "    if agent.terminations[i]:\n",
        "        q_observed = agent.rewards[i] \n",
        "    else:\n",
        "        q_observed = agent.rewards[i] + 0.99*(q[xx,yy,:].max()) # 이걸 관측했다고 치는거임\n",
        "    diff = q_observed - q_estimated \n",
        "    q[x,y,a] = q_estimated + 0.1 * diff"
      ],
      "id": "c0055150-d5de-4560-b0a2-458b663457ce"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action = 0\n",
            "action-value function =\n",
            " [[  90.2   92.1   94.1   96. ]\n",
            " [  92.1   94.1   96.    98. ]\n",
            " [  94.    96.    98.   100. ]\n",
            " [-100.  -100.  -100.     0. ]]\n",
            "\n",
            "action = 1\n",
            "action-value function =\n",
            " [[  90.2   92.1   94.  -100. ]\n",
            " [  92.1   94.1   96.  -100. ]\n",
            " [  94.1   96.    98.  -100. ]\n",
            " [  96.    98.   100.     0. ]]\n",
            "\n",
            "action = 2\n",
            "action-value function =\n",
            " [[-100.  -100.  -100.  -100. ]\n",
            " [  88.3   90.2   92.1   93.9]\n",
            " [  90.2   92.1   94.1   95.9]\n",
            " [  92.1   94.1   96.     0. ]]\n",
            "\n",
            "action = 3\n",
            "action-value function =\n",
            " [[-100.    88.3   90.2   92.1]\n",
            " [-100.    90.2   92.1   94.1]\n",
            " [-100.    92.1   94.1   95.9]\n",
            " [-100.    94.    95.9    0. ]]\n"
          ]
        }
      ],
      "source": [
        "for i in range(4):\n",
        "    print(\n",
        "        f\"action = {i}\\n\"\n",
        "        f\"action-value function =\\n {q[:,:,i].round(1)}\\n\"\n",
        "    )"
      ],
      "id": "0a86c9c0-43b9-495f-968f-876f3220c356"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 행동전략\n",
        "\n",
        "`-` 상태 (0,0)에 있다고 가정해보자."
      ],
      "id": "631164a1-b393-45d9-9adf-47b1aaffd96d"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "q[0,0,:]"
      ],
      "id": "887300ae-49de-4b85-b3e5-85c5fa552c4f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   행동 0 혹은 1을 하는게 유리함.\n",
        "\n",
        "`-` 상태 (2,3)에 있다고 가정해보자."
      ],
      "id": "2aed114f-b43b-4e08-9889-df247a9b47bd"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "q[2,3,:]"
      ],
      "id": "b2c26efc-0fab-4fa6-a589-7b0527485aa3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   행동 0을 하는게 유리함.\n",
        "\n",
        "`-` 상태 (3,2)에 있다고 가정해보자."
      ],
      "id": "9bd632d2-a9d1-48db-82c0-bee2e142de18"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "q[3,2,:] "
      ],
      "id": "9e2123b6-1be2-4c67-83ec-46d1659fe720"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   행동 1을 하는게 유리함.\n",
        "\n",
        "`-` 각 상태에서 최적은 action은 아래와 같다."
      ],
      "id": "5ceedd8b-1779-4423-8110-ca3d1919d534"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "q[0,0,:].argmax()"
      ],
      "id": "dbcbb679-b8d8-4f28-899a-c5b0e3cb246e"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "q[2,3,:].argmax()"
      ],
      "id": "fcdbb861-1c06-4d03-b6bf-5ceee5c737a9"
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "q[3,2,:].argmax()"
      ],
      "id": "47e2694b-b9ae-4a82-a63d-db4c17a10ac3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 전략(=정책)을 정리해보자."
      ],
      "id": "65564bd4-e4d6-401b-b2dd-a35279fa19a6"
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "policy = np.array(['?????']*16).reshape(4,4)\n",
        "policy"
      ],
      "id": "1a696d2e-8202-499d-8aeb-e1d529a230b8"
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "directions = {0: 'down', 1: 'right', 2:'up', 3:'left'}"
      ],
      "id": "6adc009d-79b3-45e4-9495-679a10b086fa"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(4):\n",
        "    for j in range(4):\n",
        "        policy[i,j] = directions[q[i,j,:].argmax()]\n",
        "policy"
      ],
      "id": "ce7065e8-5fca-4335-84c2-b2a1631c72ba"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Agent 클래스 구현2"
      ],
      "id": "91bb4087-60c7-4c54-b0da-789c4dab2912"
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {},
      "outputs": [],
      "source": [
        "# learn 추가\n",
        "class Agent2_v2:\n",
        "    def __init__(self,env):\n",
        "        self.action_space = env.action_space\n",
        "        self.state_space = env.state_space\n",
        "        self.n_experiences = 0\n",
        "        self.n_episode = 0 \n",
        "        \n",
        "        ## episode info \n",
        "        self.scores = [] \n",
        "        self.playtimes = [] \n",
        "\n",
        "        ## sars\n",
        "        self.current_state = None \n",
        "        self.action = None\n",
        "        self.reward = None        \n",
        "        self.next_state = None \n",
        "        \n",
        "        ## ReplayBuffer\n",
        "        self.actions = []\n",
        "        self.rewards = []\n",
        "        self.current_states = []\n",
        "        self.next_states = [] \n",
        "        self.terminations = []\n",
        "\n",
        "        ## q\n",
        "        self.q = np.zeros([4,4,4])\n",
        "    def act(self):\n",
        "        if self.n_experiences < 3000: \n",
        "            self.action = self.action_space.sample()\n",
        "        else: \n",
        "            x,y = self.current_state\n",
        "            self.action = self.q[x,y,:].argmax()\n",
        "    def save_experience(self): \n",
        "        self.actions.append(self.action)\n",
        "        self.current_states.append(self.current_state)\n",
        "        self.next_states.append(self.next_state)\n",
        "        self.rewards.append(self.reward)\n",
        "        self.terminations.append(self.terminated)\n",
        "        self.n_experiences = len(self.actions)\n",
        "\n",
        "    def learn(self): # make q\n",
        "        x,y = agent.current_state\n",
        "        xx,yy = agent.next_state\n",
        "        a = agent.action\n",
        "        q_estimated = self.q[x,y,a]\n",
        "        if agent.terminated:\n",
        "            q_observed = agent.reward\n",
        "        else:\n",
        "            q_observed = agent.reward + 0.99*(q[xx,yy,:].max()) \n",
        "        # q_observed 와 q_estimated를 점점 비슷하게 만들어주는 역할\n",
        "        diff = q_observed - q_estimated\n",
        "        self.q[x,y,a] = q_estimated + 0.1 * diff   "
      ],
      "id": "fd0d1b87-11c0-4f7e-bdea-fee402f05c6d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 구현코드"
      ],
      "id": "7de2dfc4-0a5c-405f-ba73-798c7ee70988"
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 100 Score: -96.70   Playtime:  3.70 n_experiences: 370\n",
            "Episode 200 Score: -95.73   Playtime:  2.73 n_experiences: 643\n",
            "Episode 300 Score: -100.20  Playtime:  3.20 n_experiences: 963\n",
            "Episode 400 Score: -98.45   Playtime:  3.45 n_experiences: 1308\n",
            "Episode 500 Score: -96.14   Playtime:  3.14 n_experiences: 1622\n",
            "Episode 600 Score: -98.05   Playtime:  3.05 n_experiences: 1927\n",
            "Episode 700 Score: -98.84   Playtime:  3.84 n_experiences: 2311\n",
            "Episode 800 Score: -94.49   Playtime:  3.49 n_experiences: 2660\n",
            "Episode 900 Score: -95.98   Playtime:  2.98 n_experiences: 2958\n",
            "Episode 1000    Score:  37.16   Playtime:  19.78    n_experiences: 4936\n",
            "Episode 1100    Score:  77.04   Playtime:  21.94    n_experiences: 7130\n",
            "Episode 1200    Score:  81.98   Playtime:  19.02    n_experiences: 9032\n",
            "Episode 1300    Score:  86.84   Playtime:  14.16    n_experiences: 10448\n",
            "Episode 1400    Score:  89.32   Playtime:  11.68    n_experiences: 11616\n",
            "Episode 1500    Score:  92.10   Playtime:  8.90 n_experiences: 12506\n",
            "Episode 1600    Score:  95.00   Playtime:  6.00 n_experiences: 13106\n",
            "Episode 1700    Score:  95.00   Playtime:  6.00 n_experiences: 13706\n",
            "Episode 1800    Score:  95.00   Playtime:  6.00 n_experiences: 14306\n",
            "Episode 1900    Score:  95.00   Playtime:  6.00 n_experiences: 14906\n",
            "Episode 2000    Score:  95.00   Playtime:  6.00 n_experiences: 15506"
          ]
        }
      ],
      "source": [
        "env = GridWorld()\n",
        "agent = Agent2_v2(env)\n",
        "for _ in range(2000):\n",
        "    ### 1. 본질적인 코드\n",
        "    agent.current_state = env.reset() \n",
        "    agent.terminated = False\n",
        "    agent.score = 0 \n",
        "    for t in range(50):\n",
        "        # step1: agent >> env \n",
        "        agent.act()\n",
        "        env.agent_action = agent.action\n",
        "        # step2: env << agent \n",
        "        agent.next_state, agent.reward, agent.terminated = env.step(env.agent_action)\n",
        "        # step3: 데이터저장 및 학습\n",
        "        agent.save_experience()\n",
        "        agent.learn()        \n",
        "        # step4: 다음 iteration 준비 + 종료조건체크\n",
        "        agent.current_state = agent.next_state \n",
        "        agent.score += agent.reward\n",
        "        if agent.terminated: break \n",
        "    agent.scores.append(agent.score) \n",
        "    agent.playtimes.append(t+1)\n",
        "    agent.n_episode = agent.n_episode + 1 \n",
        "    ## 2. 비본질적 코드\n",
        "    if (agent.n_episode % 100) == 0:\n",
        "        print(\n",
        "            f'Episode {agent.n_episode}\\t'\n",
        "            f'Score: {np.mean(agent.scores[-100:]) : .2f}\\t'\n",
        "            f'Playtime: {np.mean(agent.playtimes[-100:]) : .2f}\\t'\n",
        "            f'n_experiences: {agent.n_experiences}'\n",
        "        )"
      ],
      "id": "9b9c36b8-3040-415d-93cb-890199998bba"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  }
}