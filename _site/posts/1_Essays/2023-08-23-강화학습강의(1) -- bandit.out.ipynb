{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **\\[Essays\\]** 강화학습(1) – bandit\n",
        "\n",
        "신록예찬  \n",
        "2023-08-23\n",
        "\n",
        "## imports"
      ],
      "id": "a65f9533-7539-441c-bb51-d42f85b7fc0b"
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import torch\n",
        "import collections\n",
        "import IPython"
      ],
      "id": "df6688cb-b243-4e39-80c3-3886d1481186"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Intro\n",
        "\n",
        "`-` 강화학습(대충설명): 어떠한 “(게임)환경”이 있을때 거기서 “뭘 할지”를\n",
        "학습하는 과업\n",
        "\n",
        "# Game1: 벤딧문제\n",
        "\n",
        "`-` 문제설명: 두개의 버튼이 있다. 버튼0을 누르면 1의 보상을, 버튼1를\n",
        "누르면 100의 보상을 준다고 가정\n",
        "\n",
        "`-` 어떤 행동을 해야할까? –\\> ?? 아는게없음 –\\> 일단 “아무거나” 눌러보자"
      ],
      "id": "7642f480-085f-4487-9ebf-eacbc63e481c"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "action_space = ['button0','button1']\n",
        "action = np.random.choice(action_space)\n",
        "action"
      ],
      "id": "d771a51a-0733-42df-bf20-b06444164b35"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 보상은 아래와 같은 방식으로 받을 것이다."
      ],
      "id": "630add37-7144-4375-82ea-fc90bdcff69b"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "if action == 'button0': \n",
        "    reward = 1 \n",
        "else:\n",
        "    reward = 100"
      ],
      "id": "97ab8e9f-5d74-4600-bbc9-64ed47fec6d9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 아무거나 10번 버튼을 눌러보면 다음과 같은 결과가 나온다."
      ],
      "id": "ea95f46d-a348-4a5a-8551-5f77647fcf0c"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "button0 1\n",
            "button0 1\n",
            "button1 100\n",
            "button1 100\n",
            "button0 1\n",
            "button0 1\n",
            "button1 100\n",
            "button1 100\n",
            "button0 1\n",
            "button0 1"
          ]
        }
      ],
      "source": [
        "for _ in range(10):\n",
        "    action = np.random.choice(action_space)\n",
        "    if action == 'button0': \n",
        "        reward = 1 \n",
        "    else:\n",
        "        reward = 100\n",
        "    print(action,reward)"
      ],
      "id": "afb693ba-a1f0-4886-88f2-093c8c632cbb"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 깨달았음: `button0`을 누르면 1점을 받고, `button1`을 누르면 100점을\n",
        "받는 “환경”이구나? $\\to$ `button1`을 누르는 “동작”을 해야하는\n",
        "상황이구나?\n",
        "\n",
        "-   여기에서 $\\to$ 의 과정을 체계화 시킨 학문이 강화학습이다."
      ],
      "id": "7b3e86fb-9b79-4343-998c-ccdb81082e11"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100"
          ]
        }
      ],
      "source": [
        "action_space = ['button0','button1']\n",
        "for _ in range(10):\n",
        "    #action = np.random.choice(action_space) # 무지한자의 행동 (찍어)\n",
        "    action = action_space[1] # 깨달은자의 행동 (button1을 눌러)\n",
        "    if action == 'button0': \n",
        "        reward = 1 \n",
        "    else:\n",
        "        reward = 100\n",
        "    print(action,reward)"
      ],
      "id": "0a189b7f-eaaf-4d7e-b2a9-b9742ab245d4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 강화학습: 환경의 이해 $\\to$ 뭘 해야 하는지 깨달음\n",
        "\n",
        "**위의 과정이 잘 되었다는 의미로 사용하는 문장들**\n",
        "\n",
        "-   강화학습이 성공적으로 잘 되었다.\n",
        "-   환경이 해결되었다.\n",
        "-   에이전트가 환경의 과제를 완료했다.\n",
        "-   에이전트가 환경에서 성공적으로 학습했다.\n",
        "-   에이전트가 올바른 행동을 학습했다.\n",
        "-   게임 클리어 (비공식)\n",
        "\n",
        "`-` 환경이 해결되었는지 나타내는 지표를 정해야겠다 $\\to$ 주어진 상황을\n",
        "게임처럼 이해하고, 게임의 클리어조건을 설정\n",
        "\n",
        "-   첫 생각: `button1`을 누르면 클리어 아니야?\n",
        "-   두번째 생각: 아니지? 우연히 누를수도 있잖아.\n",
        "-   게임클리어조건: 최근 20번의 보상이 1900 이상이면 게임이 클리어\n",
        "    되었다고 보자![1]\n",
        "\n",
        "`-` 무지한자 – 게임을 클리어 할 수 없다.\n",
        "\n",
        "[1] `button1`을 눌러야하는건 맞지만 20번에 실수한번정도는 눈감아 주자"
      ],
      "id": "83e0f5e1-8560-4dfd-86cb-b230d12d9022"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_try = 1   action = button1    reward = 100    rwd20 = 100\n",
            "n_try = 2   action = button1    reward = 100    rwd20 = 200\n",
            "n_try = 3   action = button0    reward = 1  rwd20 = 201\n",
            "n_try = 4   action = button0    reward = 1  rwd20 = 202\n",
            "n_try = 5   action = button0    reward = 1  rwd20 = 203\n",
            "n_try = 6   action = button0    reward = 1  rwd20 = 204\n",
            "n_try = 7   action = button0    reward = 1  rwd20 = 205\n",
            "n_try = 8   action = button0    reward = 1  rwd20 = 206\n",
            "n_try = 9   action = button0    reward = 1  rwd20 = 207\n",
            "n_try = 10  action = button0    reward = 1  rwd20 = 208\n",
            "n_try = 11  action = button1    reward = 100    rwd20 = 308\n",
            "n_try = 12  action = button0    reward = 1  rwd20 = 309\n",
            "n_try = 13  action = button1    reward = 100    rwd20 = 409\n",
            "n_try = 14  action = button0    reward = 1  rwd20 = 410\n",
            "n_try = 15  action = button1    reward = 100    rwd20 = 510\n",
            "n_try = 16  action = button1    reward = 100    rwd20 = 610\n",
            "n_try = 17  action = button1    reward = 100    rwd20 = 710\n",
            "n_try = 18  action = button0    reward = 1  rwd20 = 711\n",
            "n_try = 19  action = button0    reward = 1  rwd20 = 712\n",
            "n_try = 20  action = button0    reward = 1  rwd20 = 713\n",
            "n_try = 21  action = button0    reward = 1  rwd20 = 614\n",
            "n_try = 22  action = button1    reward = 100    rwd20 = 614\n",
            "n_try = 23  action = button0    reward = 1  rwd20 = 614\n",
            "n_try = 24  action = button1    reward = 100    rwd20 = 713\n",
            "n_try = 25  action = button1    reward = 100    rwd20 = 812\n",
            "n_try = 26  action = button0    reward = 1  rwd20 = 812\n",
            "n_try = 27  action = button0    reward = 1  rwd20 = 812\n",
            "n_try = 28  action = button0    reward = 1  rwd20 = 812\n",
            "n_try = 29  action = button0    reward = 1  rwd20 = 812\n",
            "n_try = 30  action = button1    reward = 100    rwd20 = 911\n",
            "n_try = 31  action = button0    reward = 1  rwd20 = 812\n",
            "n_try = 32  action = button1    reward = 100    rwd20 = 911\n",
            "n_try = 33  action = button0    reward = 1  rwd20 = 812\n",
            "n_try = 34  action = button0    reward = 1  rwd20 = 812\n",
            "n_try = 35  action = button1    reward = 100    rwd20 = 812\n",
            "n_try = 36  action = button1    reward = 100    rwd20 = 812\n",
            "n_try = 37  action = button1    reward = 100    rwd20 = 812\n",
            "n_try = 38  action = button1    reward = 100    rwd20 = 911\n",
            "n_try = 39  action = button1    reward = 100    rwd20 = 1010\n",
            "n_try = 40  action = button0    reward = 1  rwd20 = 1010\n",
            "n_try = 41  action = button0    reward = 1  rwd20 = 1010\n",
            "n_try = 42  action = button1    reward = 100    rwd20 = 1010\n",
            "n_try = 43  action = button1    reward = 100    rwd20 = 1109\n",
            "n_try = 44  action = button1    reward = 100    rwd20 = 1109\n",
            "n_try = 45  action = button1    reward = 100    rwd20 = 1109\n",
            "n_try = 46  action = button1    reward = 100    rwd20 = 1208\n",
            "n_try = 47  action = button0    reward = 1  rwd20 = 1208\n",
            "n_try = 48  action = button1    reward = 100    rwd20 = 1307\n",
            "n_try = 49  action = button1    reward = 100    rwd20 = 1406\n",
            "n_try = 50  action = button0    reward = 1  rwd20 = 1307"
          ]
        }
      ],
      "source": [
        "action_space = ['button0','button1']\n",
        "rewards = []\n",
        "for i in range(50): # 1000번해도 못깸\n",
        "    action = np.random.choice(action_space) # 무지한자의 행동 (찍어)\n",
        "    #action = action_space[1] # 깨달은자의 행동 (button1을 눌러)\n",
        "    if action == 'button0': \n",
        "        reward = 1 \n",
        "        rewards.append(reward)\n",
        "    else:\n",
        "        reward = 100\n",
        "        rewards.append(reward)\n",
        "    print(\n",
        "        f\"n_try = {i+1}\\t\"\n",
        "        f\"action = {action}\\t\"\n",
        "        f\"reward = {reward}\\t\"\n",
        "        f\"rwd20 = {sum(rewards[-20:])}\"\n",
        "    )\n",
        "    if np.sum(rewards[-20:])>1900:\n",
        "        break\n",
        "    "
      ],
      "id": "cd7ee8d2-4bef-4901-98a3-766efc21c600"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 깨달은자 – 게임 클리어"
      ],
      "id": "d6516a84-3700-421e-be27-2198231ff9db"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_try = 1   action = button1    reward = 100    rwd20 = 100\n",
            "n_try = 2   action = button1    reward = 100    rwd20 = 200\n",
            "n_try = 3   action = button1    reward = 100    rwd20 = 300\n",
            "n_try = 4   action = button1    reward = 100    rwd20 = 400\n",
            "n_try = 5   action = button1    reward = 100    rwd20 = 500\n",
            "n_try = 6   action = button1    reward = 100    rwd20 = 600\n",
            "n_try = 7   action = button1    reward = 100    rwd20 = 700\n",
            "n_try = 8   action = button1    reward = 100    rwd20 = 800\n",
            "n_try = 9   action = button1    reward = 100    rwd20 = 900\n",
            "n_try = 10  action = button1    reward = 100    rwd20 = 1000\n",
            "n_try = 11  action = button1    reward = 100    rwd20 = 1100\n",
            "n_try = 12  action = button1    reward = 100    rwd20 = 1200\n",
            "n_try = 13  action = button1    reward = 100    rwd20 = 1300\n",
            "n_try = 14  action = button1    reward = 100    rwd20 = 1400\n",
            "n_try = 15  action = button1    reward = 100    rwd20 = 1500\n",
            "n_try = 16  action = button1    reward = 100    rwd20 = 1600\n",
            "n_try = 17  action = button1    reward = 100    rwd20 = 1700\n",
            "n_try = 18  action = button1    reward = 100    rwd20 = 1800\n",
            "n_try = 19  action = button1    reward = 100    rwd20 = 1900\n",
            "n_try = 20  action = button1    reward = 100    rwd20 = 2000"
          ]
        }
      ],
      "source": [
        "action_space = ['button0','button1']\n",
        "rewards = []\n",
        "for i in range(50): # 1000번해도 못깸\n",
        "    #action = np.random.choice(action_space) # 무지한자의 행동 (찍어)\n",
        "    action = action_space[1] # 깨달은자의 행동 (button1을 눌러)\n",
        "    if action == 'button0': \n",
        "        reward = 1 \n",
        "        rewards.append(reward)\n",
        "    else:\n",
        "        reward = 100\n",
        "        rewards.append(reward)\n",
        "    print(\n",
        "        f\"n_try = {i+1}\\t\"\n",
        "        f\"action = {action}\\t\"\n",
        "        f\"reward = {reward}\\t\"\n",
        "        f\"rwd20 = {sum(rewards[-20:])}\"\n",
        "    )\n",
        "    if np.sum(rewards[-20:])>1900:\n",
        "        break"
      ],
      "id": "a47f0eea-5688-454a-8c9d-9e4c6d5552fe"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Game1: 벤딧문제 – 예쁜코드\n",
        "\n",
        "## 수정1: `action_space`의 수정"
      ],
      "id": "607fe05a-b18b-4588-85ea-98738f2559d4"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "action_space =  gym.spaces.Discrete(2)\n",
        "action_space"
      ],
      "id": "4b1d0578-eb81-4dc3-a1ba-1653e7e73aa3"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1"
          ]
        }
      ],
      "source": [
        "for _ in range(10):\n",
        "    print(action_space.sample())"
      ],
      "id": "1c796bc8-d37c-4b05-8ee1-14c5bb6f177d"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_try = 1   action = 1  reward = 100    rwd20 = 100\n",
            "n_try = 2   action = 1  reward = 100    rwd20 = 200\n",
            "n_try = 3   action = 0  reward = 1  rwd20 = 201\n",
            "n_try = 4   action = 0  reward = 1  rwd20 = 202\n",
            "n_try = 5   action = 0  reward = 1  rwd20 = 203\n",
            "n_try = 6   action = 1  reward = 100    rwd20 = 303\n",
            "n_try = 7   action = 1  reward = 100    rwd20 = 403\n",
            "n_try = 8   action = 1  reward = 100    rwd20 = 503\n",
            "n_try = 9   action = 1  reward = 100    rwd20 = 603\n",
            "n_try = 10  action = 0  reward = 1  rwd20 = 604\n",
            "n_try = 11  action = 1  reward = 100    rwd20 = 704\n",
            "n_try = 12  action = 1  reward = 100    rwd20 = 804\n",
            "n_try = 13  action = 0  reward = 1  rwd20 = 805\n",
            "n_try = 14  action = 0  reward = 1  rwd20 = 806\n",
            "n_try = 15  action = 0  reward = 1  rwd20 = 807\n",
            "n_try = 16  action = 1  reward = 100    rwd20 = 907\n",
            "n_try = 17  action = 0  reward = 1  rwd20 = 908\n",
            "n_try = 18  action = 1  reward = 100    rwd20 = 1008\n",
            "n_try = 19  action = 0  reward = 1  rwd20 = 1009\n",
            "n_try = 20  action = 0  reward = 1  rwd20 = 1010\n",
            "n_try = 21  action = 0  reward = 1  rwd20 = 911\n",
            "n_try = 22  action = 1  reward = 100    rwd20 = 911\n",
            "n_try = 23  action = 1  reward = 100    rwd20 = 1010\n",
            "n_try = 24  action = 0  reward = 1  rwd20 = 1010\n",
            "n_try = 25  action = 1  reward = 100    rwd20 = 1109\n",
            "n_try = 26  action = 0  reward = 1  rwd20 = 1010\n",
            "n_try = 27  action = 1  reward = 100    rwd20 = 1010\n",
            "n_try = 28  action = 1  reward = 100    rwd20 = 1010\n",
            "n_try = 29  action = 0  reward = 1  rwd20 = 911\n",
            "n_try = 30  action = 0  reward = 1  rwd20 = 911\n",
            "n_try = 31  action = 0  reward = 1  rwd20 = 812\n",
            "n_try = 32  action = 0  reward = 1  rwd20 = 713\n",
            "n_try = 33  action = 0  reward = 1  rwd20 = 713\n",
            "n_try = 34  action = 0  reward = 1  rwd20 = 713\n",
            "n_try = 35  action = 1  reward = 100    rwd20 = 812\n",
            "n_try = 36  action = 0  reward = 1  rwd20 = 713\n",
            "n_try = 37  action = 0  reward = 1  rwd20 = 713\n",
            "n_try = 38  action = 0  reward = 1  rwd20 = 614\n",
            "n_try = 39  action = 1  reward = 100    rwd20 = 713\n",
            "n_try = 40  action = 1  reward = 100    rwd20 = 812\n",
            "n_try = 41  action = 0  reward = 1  rwd20 = 812\n",
            "n_try = 42  action = 0  reward = 1  rwd20 = 713\n",
            "n_try = 43  action = 0  reward = 1  rwd20 = 614\n",
            "n_try = 44  action = 1  reward = 100    rwd20 = 713\n",
            "n_try = 45  action = 0  reward = 1  rwd20 = 614\n",
            "n_try = 46  action = 0  reward = 1  rwd20 = 614\n",
            "n_try = 47  action = 1  reward = 100    rwd20 = 614\n",
            "n_try = 48  action = 1  reward = 100    rwd20 = 614\n",
            "n_try = 49  action = 0  reward = 1  rwd20 = 614\n",
            "n_try = 50  action = 0  reward = 1  rwd20 = 614"
          ]
        }
      ],
      "source": [
        "action_space = gym.spaces.Discrete(2)\n",
        "rewards = []\n",
        "for i in range(50): # 1000번해도 못깸\n",
        "    action = action_space.sample() # 무지한자의 행동 (찍어)\n",
        "    #action = 1 # 깨달은자의 행동 (button1을 눌러)\n",
        "    if action == 0: \n",
        "        reward = 1 \n",
        "        rewards.append(reward)\n",
        "    else:\n",
        "        reward = 100\n",
        "        rewards.append(reward)\n",
        "    print(\n",
        "        f\"n_try = {i+1}\\t\"\n",
        "        f\"action = {action}\\t\"\n",
        "        f\"reward = {reward}\\t\"\n",
        "        f\"rwd20 = {sum(rewards[-20:])}\"\n",
        "    )\n",
        "    if np.sum(rewards[-20:])>1900:\n",
        "        break"
      ],
      "id": "4d4e9079-5aff-468a-8037-b1a19e8e1bfa"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 수정2: Env 클래스"
      ],
      "id": "789b5c00-4bc7-4a19-a01b-a56618107143"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Bandit:\n",
        "    def step(self,action):\n",
        "        if action == 0: \n",
        "            return 1\n",
        "        else:\n",
        "            return 100"
      ],
      "id": "0f8150e2-9959-4020-9414-e82e6b3795c3"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_try = 1   action = 1  reward = 100    rwd20 = 100\n",
            "n_try = 2   action = 1  reward = 100    rwd20 = 200\n",
            "n_try = 3   action = 1  reward = 100    rwd20 = 300\n",
            "n_try = 4   action = 1  reward = 100    rwd20 = 400\n",
            "n_try = 5   action = 1  reward = 100    rwd20 = 500\n",
            "n_try = 6   action = 1  reward = 100    rwd20 = 600\n",
            "n_try = 7   action = 1  reward = 100    rwd20 = 700\n",
            "n_try = 8   action = 1  reward = 100    rwd20 = 800\n",
            "n_try = 9   action = 1  reward = 100    rwd20 = 900\n",
            "n_try = 10  action = 1  reward = 100    rwd20 = 1000\n",
            "n_try = 11  action = 1  reward = 100    rwd20 = 1100\n",
            "n_try = 12  action = 1  reward = 100    rwd20 = 1200\n",
            "n_try = 13  action = 1  reward = 100    rwd20 = 1300\n",
            "n_try = 14  action = 1  reward = 100    rwd20 = 1400\n",
            "n_try = 15  action = 1  reward = 100    rwd20 = 1500\n",
            "n_try = 16  action = 1  reward = 100    rwd20 = 1600\n",
            "n_try = 17  action = 1  reward = 100    rwd20 = 1700\n",
            "n_try = 18  action = 1  reward = 100    rwd20 = 1800\n",
            "n_try = 19  action = 1  reward = 100    rwd20 = 1900\n",
            "n_try = 20  action = 1  reward = 100    rwd20 = 2000"
          ]
        }
      ],
      "source": [
        "env = Bandit()\n",
        "rewards = []\n",
        "for i in range(50): # 1000번해도 못깸\n",
        "    #action = action_space.sample() # 무지한자의 행동 (찍어)\n",
        "    action = 1 # 깨달은자의 행동 (button1을 눌러)\n",
        "    reward = env.step(action)\n",
        "    rewards.append(reward)\n",
        "    print(\n",
        "        f\"n_try = {i+1}\\t\"\n",
        "        f\"action = {action}\\t\"\n",
        "        f\"reward = {reward}\\t\"\n",
        "        f\"rwd20 = {sum(rewards[-20:])}\"\n",
        "    )\n",
        "    if np.sum(rewards[-20:])>1900:\n",
        "        break"
      ],
      "id": "2af252df-c080-412f-b549-084f8721d507"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 수정3: Agent 클래스\n",
        "\n",
        "`-` Agent 클래스를 만들자 (액션을 하고, 환경에서 받은 reward를\n",
        "간직하도록)"
      ],
      "id": "cd19430f-f5d3-4cd8-a2d1-2f74f0bd828b"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Agent1:\n",
        "    def __init__(self):\n",
        "        self.action_space = gym.spaces.Discrete(2)\n",
        "        self.action = None\n",
        "        self.reward = None\n",
        "        self.actions = []\n",
        "        self.rewards = []\n",
        "    def act(self):\n",
        "        # self.action = self.action_space.sample() # 무지한 자\n",
        "        self.action = 1 # 깨달은 자 \n",
        "    def save_experience(self): \n",
        "        self.actions.append(self.action)\n",
        "        self.rewards.append(self.reward)"
      ],
      "id": "3a8a43e7-3975-487b-a643-8c7266112c9b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "— 대충 아래와 같은 느낌으로 돌아가요 —\n",
        "\n",
        "**시점0**: init"
      ],
      "id": "b74b502c-3fac-49e3-9091-25f645e21bfb"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = Bandit()\n",
        "agent = Agent1()"
      ],
      "id": "8e3fa8f0-b41f-4d92-9477-1f6725c4e831"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.action, agent.reward"
      ],
      "id": "7b528099-158b-4e65-8181-92d1a6372d40"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**시점1**: agent \\>\\> env"
      ],
      "id": "c0a798b2-7eea-4621-932e-66ce0b03ccce"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.act()"
      ],
      "id": "545483f3-e2e3-4fd5-9009-f22df31761aa"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.action, agent.reward"
      ],
      "id": "a7b88291-b73b-4deb-9469-0b50e06a0d7f"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "env.agent_action = agent.action "
      ],
      "id": "c1cc49b4-180f-4ac6-8322-82bc0d36dc04"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**시점2**: agent \\<\\< env"
      ],
      "id": "ed0ba54d-90b2-4771-bfc0-6924c4c28899"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.reward = env.step(env.agent_action) \n",
        "# agent.reward = env.step(agent.action) 도 같은 결과를 주는 코드임!!"
      ],
      "id": "dd742d0b-e19c-4194-b581-5aa0cac4a12a"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.action, agent.reward, env.agent_action"
      ],
      "id": "d3b53960-00d4-4652-9500-dc3860688ea5"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.actions, agent.rewards"
      ],
      "id": "55df6ce8-fc00-42be-a880-ab486a16c469"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**시점3**: agent: `save_experience`"
      ],
      "id": "ae207c9c-6199-48f6-9fb7-3c04e79b5a60"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.save_experience()"
      ],
      "id": "10070384-7964-4cae-bffb-516ab570b98d"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.actions, agent.rewards"
      ],
      "id": "9f1024c0-f468-41cc-8f62-52811b1fc8fe"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "— 전체코드 —"
      ],
      "id": "e6b4d2b3-0cc6-425c-b583-4dbdc7a63647"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_try = 1   action = 1  reward = 100    rwd20 = 100\n",
            "n_try = 2   action = 1  reward = 100    rwd20 = 200\n",
            "n_try = 3   action = 1  reward = 100    rwd20 = 300\n",
            "n_try = 4   action = 1  reward = 100    rwd20 = 400\n",
            "n_try = 5   action = 1  reward = 100    rwd20 = 500\n",
            "n_try = 6   action = 1  reward = 100    rwd20 = 600\n",
            "n_try = 7   action = 1  reward = 100    rwd20 = 700\n",
            "n_try = 8   action = 1  reward = 100    rwd20 = 800\n",
            "n_try = 9   action = 1  reward = 100    rwd20 = 900\n",
            "n_try = 10  action = 1  reward = 100    rwd20 = 1000\n",
            "n_try = 11  action = 1  reward = 100    rwd20 = 1100\n",
            "n_try = 12  action = 1  reward = 100    rwd20 = 1200\n",
            "n_try = 13  action = 1  reward = 100    rwd20 = 1300\n",
            "n_try = 14  action = 1  reward = 100    rwd20 = 1400\n",
            "n_try = 15  action = 1  reward = 100    rwd20 = 1500\n",
            "n_try = 16  action = 1  reward = 100    rwd20 = 1600\n",
            "n_try = 17  action = 1  reward = 100    rwd20 = 1700\n",
            "n_try = 18  action = 1  reward = 100    rwd20 = 1800\n",
            "n_try = 19  action = 1  reward = 100    rwd20 = 1900\n",
            "n_try = 20  action = 1  reward = 100    rwd20 = 2000"
          ]
        }
      ],
      "source": [
        "env = Bandit()\n",
        "agent = Agent1()\n",
        "for i in range(50):\n",
        "    ## 본질적인 코드\n",
        "    # step1: agent >> env \n",
        "    agent.act()\n",
        "    env.agent_action = agent.action \n",
        "    # step2: agnet << env \n",
        "    agent.reward = env.step(env.agent_action) \n",
        "    # step3: save \n",
        "    agent.save_experience()\n",
        "    \n",
        "    ## 비본질적 코드 \n",
        "    print(\n",
        "        f\"n_try = {i+1}\\t\"\n",
        "        f\"action = {agent.action}\\t\"\n",
        "        f\"reward = {agent.reward}\\t\"\n",
        "        f\"rwd20 = {sum(agent.rewards[-20:])}\"\n",
        "    )\n",
        "    if np.sum(agent.rewards[-20:])>1900:\n",
        "        break"
      ],
      "id": "bd8ebd38-0b87-47f5-bf32-141a42388734"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   위의 코드를 거의 뼈대로 사용합니당!\n",
        "\n",
        "# Game1: 벤딧문제 – 학습과정 포함\n",
        "\n",
        "`-` Game1에 대한 생각:\n",
        "\n",
        "-   사실 강화학습은 “환경을 이해 $\\to$ 뭘 해야 하는지 깨달음” 의\n",
        "    과정에서 화살표를 수식화 하는 과정이다.\n",
        "-   지금까지 살펴보면 Game1은 환경(env)을 이해하는 순간 에이전트가\n",
        "    최적의 행동(action)[1]을 직관적으로 결정하였으므로 학습의 과정이\n",
        "    포함되었다고 볼 수 없다.\n",
        "\n",
        "`-` 지금까지의 코드 복습\n",
        "\n",
        "1.  클래스를 선언하는 부분\n",
        "    -   `Env`클래스의 선언\n",
        "    -   `Agent`클래스의 선언\n",
        "2.  환경과 에이전트를 인스턴스화 (초기화)\n",
        "3.  for loop를 반복하며 게임을 진행\n",
        "    -   메인코드: (1) agent \\>\\> env (2) agent \\<\\< env (3) 데이터저장\n",
        "    -   비본질적코드: 학습과정 display, 학습종료조건\n",
        "\n",
        "`-` 앞으로 구성할 코드의 형태: 에이전트가 데이터를 보고 스스로\n",
        "`button1`을 눌러야 한다는 것을 추론하면 좋겠음\n",
        "\n",
        "1.  클래스를 선언하는 부분\n",
        "    -   `Env`클래스의 선언\n",
        "    -   **`Agent`클래스의 선언**: **학습의 과정 포함 $\\to$ act함수\n",
        "        수정**\n",
        "2.  환경과 에이전트를 인스턴스화 (초기화)\n",
        "3.  for loop를 반복하며 게임을 진행\n",
        "    -   메인코드: (1) agent \\>\\> env (2) agent \\<\\< env (3) 데이터저장\n",
        "        **(4) 학습**\n",
        "    -   비본질적코드: 학습과정 display, 학습종료조건\n",
        "\n",
        "`-` 에이전트가 학습을 어떻게 하는가?[2]\n",
        "\n",
        "-   $\\pi(0) = \\frac{Q_t(1)}{Q_t(1)+Q_t(0)}$\n",
        "-   $\\pi(1) = \\frac{Q_t(0)}{Q_t(1)+Q_t(0)}$\n",
        "\n",
        "여기에서 각각의 기호는 아래를 의미한다.\n",
        "\n",
        "-   $\\pi(0)$: 에이전트가 action = 0 을 할 확률, 즉 에이전트가\n",
        "    `button0`을 누를 확률\n",
        "-   $\\pi(1)$: 에이전트가 action = 1 을 할 확률, 즉 에이전트가\n",
        "    `button1`을 누를 확률\n",
        "-   $Q_t(0)$: ($t$시점까지 파악한) action = 0 을 하였을 경우 에이전트가\n",
        "    환경으로 받은 보상의 평균값\n",
        "-   $Q_t(1)$: ($t$시점까지 파악한) action = 1 을 하였을 경우 에이전트가\n",
        "    환경으로 받은 보상의 평균값\n",
        "\n",
        "`-` 걱정: $t=0$이면 어쩌지? $t=1$이면 어쩌지?.. $\\to$ 잡기술1: 일정\n",
        "시간동안은 랜덤액션을 하면서 데이터를 쌓자.\n",
        "\n",
        "`-` 쌓은 데이터를 바탕으로 환경을 이해하고 action을 뽑는 코드\n",
        "\n",
        "[1] `button1`을 누른다\n",
        "\n",
        "[2] 행동을 이런식으로 하도록 “전략(=정책)”을 설정하는 것은 상식적이다.\n",
        "그렇지만 유일한 해결책은 아님!!"
      ],
      "id": "df4f8298-3e8b-4b50-90d7-fea0c589f8e5"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "actions = np.array([0,0,1,0,0,1,1,1,1,0])\n",
        "actions "
      ],
      "id": "ad0bddcd-a6a6-4ff9-bf74-6e65210cba68"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "rewards = np.array([1,0.9,105,1.2,1,95,100,101,90,1])\n",
        "rewards"
      ],
      "id": "5ad6ae8e-9ff1-4bc9-bcb8-230177d572bf"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "q = np.array([rewards[actions==0].mean(),rewards[actions==1].mean()])\n",
        "q"
      ],
      "id": "02f5a801-b7f0-4647-999d-eab0f35cfe91"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "action = np.random.choice([0,1],p=q/q.sum())\n",
        "action"
      ],
      "id": "988ff6d7-8370-4d44-9afa-3bfe2a25693f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 코드를 구현해보자."
      ],
      "id": "caeaa160-4c2d-4b25-8087-befafe4f69c7"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 게임을 푸는 전략을 바꾸는 것이지 게임자체를 바꿀게 아니니까 수정할게 없죠?\n",
        "class Bandit():\n",
        "    def step(self,action):\n",
        "        if action == 0: \n",
        "            return 1\n",
        "        else:\n",
        "            return 100"
      ],
      "id": "67665c93-1cd4-4dc5-b577-2de0ebc5cfb3"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# learn 추가\n",
        "class Agent1:\n",
        "    def __init__(self):\n",
        "        self.action_space = gym.spaces.Discrete(2)\n",
        "        self.action = None\n",
        "        self.reward = None\n",
        "        self.actions = []\n",
        "        self.rewards = []\n",
        "        self.n_experiences = 0\n",
        "        self.q = np.array([0.001,0.001]) # 사실 [0,0] 을 넣고싶음\n",
        "    def act(self):\n",
        "        self.action = np.random.choice([0, 1], p=self.q/self.q.sum())\n",
        "    def save_experience(self): \n",
        "        self.actions.append(self.action)\n",
        "        self.rewards.append(self.reward)\n",
        "        self.n_experiences = len(self.actions)\n",
        "    def learn(self):\n",
        "        if self.n_experiences < 30:\n",
        "            pass \n",
        "        else:\n",
        "            actions = np.array(self.actions)\n",
        "            rewards = np.array(self.rewards)\n",
        "            self.q[0] = rewards[actions==0].mean()\n",
        "            self.q[1] = rewards[actions==1].mean()"
      ],
      "id": "b87cd3f2-fc9a-4b0a-a0b3-cf350c19de61"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_try = 1   action = 1  reward = 100    rwd20 = 100 q = [0.001 0.001]\n",
            "n_try = 2   action = 0  reward = 1  rwd20 = 101 q = [0.001 0.001]\n",
            "n_try = 3   action = 0  reward = 1  rwd20 = 102 q = [0.001 0.001]\n",
            "n_try = 4   action = 0  reward = 1  rwd20 = 103 q = [0.001 0.001]\n",
            "n_try = 5   action = 0  reward = 1  rwd20 = 104 q = [0.001 0.001]\n",
            "n_try = 6   action = 1  reward = 100    rwd20 = 204 q = [0.001 0.001]\n",
            "n_try = 7   action = 1  reward = 100    rwd20 = 304 q = [0.001 0.001]\n",
            "n_try = 8   action = 1  reward = 100    rwd20 = 404 q = [0.001 0.001]\n",
            "n_try = 9   action = 0  reward = 1  rwd20 = 405 q = [0.001 0.001]\n",
            "n_try = 10  action = 0  reward = 1  rwd20 = 406 q = [0.001 0.001]\n",
            "n_try = 11  action = 1  reward = 100    rwd20 = 506 q = [0.001 0.001]\n",
            "n_try = 12  action = 0  reward = 1  rwd20 = 507 q = [0.001 0.001]\n",
            "n_try = 13  action = 0  reward = 1  rwd20 = 508 q = [0.001 0.001]\n",
            "n_try = 14  action = 0  reward = 1  rwd20 = 509 q = [0.001 0.001]\n",
            "n_try = 15  action = 1  reward = 100    rwd20 = 609 q = [0.001 0.001]\n",
            "n_try = 16  action = 0  reward = 1  rwd20 = 610 q = [0.001 0.001]\n",
            "n_try = 17  action = 0  reward = 1  rwd20 = 611 q = [0.001 0.001]\n",
            "n_try = 18  action = 0  reward = 1  rwd20 = 612 q = [0.001 0.001]\n",
            "n_try = 19  action = 0  reward = 1  rwd20 = 613 q = [0.001 0.001]\n",
            "n_try = 20  action = 0  reward = 1  rwd20 = 614 q = [0.001 0.001]\n",
            "n_try = 21  action = 0  reward = 1  rwd20 = 515 q = [0.001 0.001]\n",
            "n_try = 22  action = 1  reward = 100    rwd20 = 614 q = [0.001 0.001]\n",
            "n_try = 23  action = 1  reward = 100    rwd20 = 713 q = [0.001 0.001]\n",
            "n_try = 24  action = 1  reward = 100    rwd20 = 812 q = [0.001 0.001]\n",
            "n_try = 25  action = 1  reward = 100    rwd20 = 911 q = [0.001 0.001]\n",
            "n_try = 26  action = 1  reward = 100    rwd20 = 911 q = [0.001 0.001]\n",
            "n_try = 27  action = 0  reward = 1  rwd20 = 812 q = [0.001 0.001]\n",
            "n_try = 28  action = 1  reward = 100    rwd20 = 812 q = [0.001 0.001]\n",
            "n_try = 29  action = 1  reward = 100    rwd20 = 911 q = [0.001 0.001]\n",
            "n_try = 30  action = 1  reward = 100    rwd20 = 1010    q = [  1. 100.]\n",
            "n_try = 31  action = 1  reward = 100    rwd20 = 1010    q = [  1. 100.]\n",
            "n_try = 32  action = 1  reward = 100    rwd20 = 1109    q = [  1. 100.]\n",
            "n_try = 33  action = 1  reward = 100    rwd20 = 1208    q = [  1. 100.]\n",
            "n_try = 34  action = 1  reward = 100    rwd20 = 1307    q = [  1. 100.]\n",
            "n_try = 35  action = 1  reward = 100    rwd20 = 1307    q = [  1. 100.]\n",
            "n_try = 36  action = 1  reward = 100    rwd20 = 1406    q = [  1. 100.]\n",
            "n_try = 37  action = 1  reward = 100    rwd20 = 1505    q = [  1. 100.]\n",
            "n_try = 38  action = 1  reward = 100    rwd20 = 1604    q = [  1. 100.]\n",
            "n_try = 39  action = 1  reward = 100    rwd20 = 1703    q = [  1. 100.]\n",
            "n_try = 40  action = 1  reward = 100    rwd20 = 1802    q = [  1. 100.]\n",
            "n_try = 41  action = 1  reward = 100    rwd20 = 1901    q = [  1. 100.]"
          ]
        }
      ],
      "source": [
        "env = Bandit()\n",
        "agent = Agent1()\n",
        "for i in range(60):\n",
        "    ## 본질적인 코드b\n",
        "    # step1: agent >> env \n",
        "    agent.act()\n",
        "    env.agent_action = agent.action \n",
        "    # step2: agnet << env \n",
        "    agent.reward = env.step(env.agent_action) \n",
        "    # step3: save \n",
        "    agent.save_experience()\n",
        "    agent.learn()\n",
        "    \n",
        "    ## 비본질적 코드 \n",
        "    print(\n",
        "        f\"n_try = {agent.n_experiences}\\t\"\n",
        "        f\"action = {agent.action}\\t\"\n",
        "        f\"reward = {agent.reward}\\t\"\n",
        "        f\"rwd20 = {np.sum(agent.rewards[-20:])}\\t\"\n",
        "        f\"q = {agent.q}\"\n",
        "    )\n",
        "    if np.sum(agent.rewards[-20:])>1900:\n",
        "        break"
      ],
      "id": "63a98fa1-f6b1-43e1-a037-c5662d904bb1"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  }
}