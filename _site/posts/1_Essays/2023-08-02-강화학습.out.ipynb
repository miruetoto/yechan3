{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **\\[Essays\\]** 강화학습\n",
        "\n",
        "신록예찬  \n",
        "2023-08-02\n",
        "\n",
        "## imports"
      ],
      "id": "f0666cb7-e159-4865-93cf-47d16f0dda14"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import torch "
      ],
      "id": "df6688cb-b243-4e39-80c3-3886d1481186"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Game1\n",
        "\n",
        "`-` 문제설명: 두개의 버튼이 있다. 버튼1을 누르면 1의 보상을, 버튼2를\n",
        "누르면 100의 보상을 준다고 가정"
      ],
      "id": "63963514-fce8-4549-a1c9-ce149028ed18"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "action = np.random.choice(['button1','button2'])\n",
        "action"
      ],
      "id": "d771a51a-0733-42df-bf20-b06444164b35"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "if action == 'button1': \n",
        "    reward = 1 \n",
        "else:\n",
        "    reward = 100"
      ],
      "id": "97ab8e9f-5d74-4600-bbc9-64ed47fec6d9"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "button2 100\n",
            "button2 100\n",
            "button2 100\n",
            "button2 100\n",
            "button2 100\n",
            "button2 100\n",
            "button2 100\n",
            "button1 1\n",
            "button1 1\n",
            "button2 100"
          ]
        }
      ],
      "source": [
        "for _ in range(10):\n",
        "    action = np.random.choice(['button1','button2'])\n",
        "    if action == 'button1': \n",
        "        reward = 1 \n",
        "    else:\n",
        "        reward = 100\n",
        "    print(action,reward)"
      ],
      "id": "afb693ba-a1f0-4886-88f2-093c8c632cbb"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 게임을 푸는 방법? 버튼2를 누른다.\n",
        "\n",
        "`-` 용어 정리 - Agent = 버튼을 누르는 사람 - Action = 에이전트가 할 수\n",
        "있는 행동 (현재는 2개의 action이 가능) - Env = Agent의 action을 보고\n",
        "reward를 주는 존재 - 게임의 종료 = 버튼을 누르면 게임이 종료 - 게임을\n",
        "푸는 방법 = reward를 최대화하는 action을 선택\n",
        "\n",
        "## Game2\n",
        "\n",
        "`-` 문제설명: 에이전트는 현재 2의 위치에 있다. 에이전트는 (1) 정지 (2)\n",
        "왼쪽으로 이동 (3) 오른쪽으로 이동 하는 3개의 행동을 할 수 있다.\n",
        "에이전트가 4의 위치에 도달하면 100의 보상을 얻고 게임이 종료된다.\n",
        "에이전트가 0의 위치에 도달하면 보상없이 게임이 종료된다.\n",
        "\n",
        "`-` 에이전트와 환경의 상호작용 구현1"
      ],
      "id": "b370f1ac-03de-4f14-94b2-12ee6171617c"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "state = 2"
      ],
      "id": "d753194b-c29d-408d-bbb4-6e82d6455be7"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "action = np.random.choice([0,1,2])"
      ],
      "id": "49be0f5a-2337-454b-ae5b-973628356a35"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 2"
          ]
        }
      ],
      "source": [
        "print(state,action)"
      ],
      "id": "13527401-e8e7-4ded-be35-f6b25c83bc41"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "2의 위치에 도달, 보상 200점 획득"
          ]
        }
      ],
      "source": [
        "for _ in range(9999): \n",
        "    if state == 2:\n",
        "        print(state)\n",
        "        reward = 200         \n",
        "        print(\"2의 위치에 도달, 보상 {}점 획득\".format(reward))\n",
        "        break \n",
        "    elif state == -2:\n",
        "        print(state)\n",
        "        reward = 0 \n",
        "        print(\"-2의 위치에 도달, 보상 {}점 획득\".format(reward))\n",
        "        break\n",
        "    else:\n",
        "        print(state,action)        \n",
        "        state = state + action \n",
        "        action = np.random.choice(['<-','.','->'])\n",
        "        "
      ],
      "id": "1e6c4ab7-15e9-491e-8b44-392491213600"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 에이전트와 환경의 상호작용 구현2"
      ],
      "id": "99eecb64-bcac-49f1-ab4a-ad44b66c51e5"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "gym.spaces.Discrete(3)"
      ],
      "id": "982dc58a-b969-4086-8f3a-994467a0899e"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "gym.spaces.Discrete?"
      ],
      "id": "0577c8dd-546c-47e2-b6e8-86c4e3522e17"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Game2(gym.Env):\n",
        "    def __init__(self):\n",
        "        self.action_space = gym.spaces.Discrete(3,start=-1) # Acition = {-1,0,1}  \n",
        "        self.observation_space = gym.spaces.Discrete(5,start=-2) # State = {-2,-1,0,1,2} \n",
        "        self.state = 0 \n",
        "        self.t = 0\n",
        "    def step(self,action):\n",
        "        self.state = self.state + action\n",
        "        self.t = self.t + 1 \n",
        "        if self.state == 2:\n",
        "            reward = 100\n",
        "        else:\n",
        "            reward = -1\n",
        "        info = {}\n",
        "        if self.state == -2 or self.state==2: \n",
        "            done = True\n",
        "        else: \n",
        "            done = False\n",
        "        return self.state, reward, done, info\n",
        "    def render(self):\n",
        "        print('state: {}'.format(self.state))\n",
        "    def reset(self):\n",
        "        self.state = 0 \n",
        "        return self.state"
      ],
      "id": "943478ae-efb4-461e-9ec8-47b48c1050bf"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "env=Game2()"
      ],
      "id": "fa6c4fa4-f2bc-416d-9b2d-e635cfcff6ab"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Game3\n",
        "\n",
        "## Game4: LunarLander\n",
        "\n",
        "### 환경만들기\n",
        "\n",
        "`-` 환경을 만드는 방법은 아래와 같다."
      ],
      "id": "f1f836f9-9997-45da-9c5c-a144c2a41c59"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = gym.make('LunarLander-v2',render_mode='rgb_array')"
      ],
      "id": "3e085d50-9d39-4e75-9151-843deb6ee4e6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 환경에 대한 기본 정보를 조사하여 보자."
      ],
      "id": "47f345f3-8049-41aa-83ca-0f7d1d89ca28"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "env.observation_space"
      ],
      "id": "49e5d1b8-e68d-41da-9c08-26530b8fdacd"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "env.action_space"
      ],
      "id": "cfde2681-4846-4aa0-87ce-66333cd7485a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 환경관찰\n",
        "\n",
        "`-` 환경관찰"
      ],
      "id": "5a17fd97-c1ef-4987-bc59-5886fb1fd26c"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "env.reset()"
      ],
      "id": "35312d3e-1276-4895-b94a-224a0053089b"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "env.step(0) # state, reward, done, _ "
      ],
      "id": "9fa82115-7a62-4916-b62c-76548737af76"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` action"
      ],
      "id": "c4a96064-09b9-4bc6-91ea-737846276cb7"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "env.action_space.sample()"
      ],
      "id": "37dafca5-cbbc-4b88-96a7-a180f77d9023"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   int형으로 전달\n",
        "\n",
        "`-` action -\\> nextstate, reward, done"
      ],
      "id": "b7aa674f-f433-4642-b176-2747179f140a"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "env.step(env.action_space.sample())"
      ],
      "id": "23f3049d-0c1d-438f-8fcc-3854ee723c10"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "frames = []\n",
        "env.reset()\n",
        "for _ in range(300):\n",
        "    frames.append(env.render())\n",
        "    env.step(env.action_space.sample())\n",
        "env.close()"
      ],
      "id": "3cb75d3b-016b-42ce-8497-93120341a230"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAF7CAYAAAD4/3BBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\n"
          }
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ani = FuncAnimation(fig,lambda i: ax.imshow(frames[::100][i]),frames=len(frames[::100]))"
      ],
      "id": "9ceab5f9-1e5a-457b-8464-20c9db84d769"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "ani"
      ],
      "id": "6fad79d6-2d16-49d1-b425-d2f7ad74896d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Replay Buffer\n",
        "\n",
        "`-` 랜덤액션을 연속적으로 생성하고 그 결과를 기록해보자."
      ],
      "id": "4df6d5ce-82f4-48c6-b57c-583cdcdd2882"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "states = []\n",
        "actions = []\n",
        "rewards = []\n",
        "next_states = []\n",
        "dones = []"
      ],
      "id": "ae71b487-9754-4f06-ba45-2acb2bdefda4"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "_state1 = env.reset()\n",
        "for t in range(1500):\n",
        "    _action = env.action_space.sample() \n",
        "    _state2, _reward, _done, _ = env.step(_action) \n",
        "    ## save code \n",
        "    states.append(_state1.tolist()) \n",
        "    actions.append(_action)\n",
        "    rewards.append(_reward)\n",
        "    next_states.append(_state2.tolist())\n",
        "    dones.append(_done)\n",
        "    ## save code end \n",
        "    _state1 = _state2 \n",
        "    if _done:\n",
        "        break"
      ],
      "id": "6b950bc8-0ae9-461e-ba22-0e9e6139c4db"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 모인 히스토리를 확인해보자."
      ],
      "id": "c2c97ec3-5167-4245-812e-f618e5f32591"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(states), len(actions), len(next_states), len(rewards), len(dones)"
      ],
      "id": "58524369-1817-4ee5-84ae-b05dfb323b81"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Qnetwork 설계\n",
        "\n",
        "`-` 네트워크의 목적: 내가 여기서 뭘 해야하는지 알려줘! = 내가 이\n",
        "상태에서, 어떠한 액션을 해야하는지 알려줘 $\\to$ 8개의 상태를 입력으로\n",
        "받으면 4개의 액션에 대한 좋은 정도를 숫자로 표현하는 어떠한 함수를\n",
        "만들자.\n",
        "\n",
        "`-` net 설계"
      ],
      "id": "5a6a4914-f2d7-48b7-a035-ddc7f90ce3e7"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "net = torch.nn.Sequential(\n",
        "    torch.nn.Linear(in_features=8, out_features=128),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(in_features=128, out_features=64),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(in_features=64, out_features=32),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(in_features=32, out_features=4)\n",
        ")\n",
        "net"
      ],
      "id": "54860fb4-9cbd-4aab-9ce7-d716d07e0e7d"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "net(torch.tensor(states))"
      ],
      "id": "ab62e365-d629-42c6-91e0-f492ff3a99d0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Policy 설계\n",
        "\n",
        "`-` 네트워크의 의미"
      ],
      "id": "6d34eb1d-91e2-4781-b9db-37da2fa4e1fd"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "states[0],states[1]"
      ],
      "id": "78306592-ca58-4621-8e21-1acd4941278a"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "net(torch.tensor(states[0:2]))"
      ],
      "id": "4ba397f6-33b6-429c-b718-321f69c1f765"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   상태0에서는 액션0이, 상태1에서도 액션0이 가장 좋다는 의미 (왜?\n",
        "    q-value가 젤 높으니까..)\n",
        "\n",
        "`-` 따라서 Agent는 아래와 같이 행동해야 한다. (네트워크가 잘\n",
        "학습되었다는 전제가 필요함) - state\\[0\\] -\\> action = 0 - state\\[1\\] -\\>\n",
        "action = 0"
      ],
      "id": "e1ddaba1-ef94-4871-ad33-8fa30d8e4df3"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "net(torch.tensor(states[0:2])).max(axis=1)"
      ],
      "id": "5b630b0e-bf3b-48a3-bce5-7fd135237ef5"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "net(torch.tensor(states[0:2])).max(axis=1)[1]"
      ],
      "id": "4cbfbbec-8253-46de-8a60-de5ae1bb8e19"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 네트워크가 있으므로 이제 어떠한 state에 대해서도 뭘 해야할지 (=어떤\n",
        "액션을 해야할지) 알 수 있다."
      ],
      "id": "5f6ee8c7-aee9-4234-98e1-061913ea7f01"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "_state1 # 어떤 state에 대해서도.. "
      ],
      "id": "5f604754-d57a-41b4-a1cb-387cd21a4311"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "net(torch.tensor(_state1)) # q-value를 계산할 수 있고 "
      ],
      "id": "078f79b8-a357-4bea-be91-e7213beede86"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "int(torch.argmax(net(torch.tensor(_state1)))) # 그래서 다음에 우리가 어떤행동을 해야할 지 알 수 있음"
      ],
      "id": "7beb3de0-1ead-4e15-b15d-4ca6be971d75"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 학습\n",
        "\n",
        "`-` 네트워크를 학습시키자."
      ],
      "id": "255e777b-319b-4659-af54-5b28a176427e"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "net.to(\"cuda:0\")"
      ],
      "id": "2c71eee5-de1f-41c9-ab1b-23a8ba923a18"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "scores=[]\n",
        "playtimes=[] \n",
        "eps = 1\n",
        "opt = torch.optim.Adam(net.parameters(),lr=0.0001)"
      ],
      "id": "9e0e9cba-2f10-4f55-bc0a-d20a6177725c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 94  Score: -117.16  Playtime: 999.00"
          ]
        }
      ],
      "source": [
        "for epsd in range(1,2001): # 게임 2000판 시켜줌.. \n",
        "    state1 = env.reset() # 환경리셋 + 초기화된 환경을 state라는 변수에 저장 \n",
        "    score = 0 \n",
        "    for t in range(1000): # 게임1판당 max 1000프레임만 할 수 있음\n",
        "        # (step1) Agent: action \n",
        "        if np.random.rand() < eps: \n",
        "            action = env.action_space.sample() # 랜덤액션을 뽑음 \n",
        "        else:\n",
        "            action = int(torch.argmax(net(torch.tensor(state1).to(\"cuda:0\")))) # 네트워크가 알려주는 action을 뽑음 \n",
        "        \n",
        "        # (step2) Agent -> Env // Env -> Agent \n",
        "        state2, reward, done, _ = env.step(action) # 액션을 환경에 전달 -> (next_state, reward, done) 을 받음 \n",
        "        \n",
        "        # (step3) Agnet: save data and learn \n",
        "        ## save data \n",
        "        states.append(state1.tolist())\n",
        "        actions.append(action)\n",
        "        rewards.append(reward)\n",
        "        next_states.append(state2.tolist())\n",
        "        dones.append(done)\n",
        "    \n",
        "        ## 최근 5000개의 자료만 준비함. \n",
        "        if len(states)>5000:\n",
        "            _states = torch.tensor(states[-5000:])\n",
        "            _actions = torch.tensor(actions[-5000:]).reshape(-1,1)\n",
        "            _next_states = torch.tensor(next_states[-5000:])\n",
        "            _rewards = torch.tensor(rewards[-5000:]).reshape(-1,1)\n",
        "            _dones = torch.tensor(dones[-5000:]).to(torch.float).reshape(-1,1) \n",
        "        else:\n",
        "            _states = torch.tensor(states)\n",
        "            _actions = torch.tensor(actions).reshape(-1,1)\n",
        "            _next_states = torch.tensor(next_states)\n",
        "            _rewards = torch.tensor(rewards).reshape(-1,1)\n",
        "            _dones = torch.tensor(dones).to(torch.float).reshape(-1,1)\n",
        "\n",
        "        ## 최근 5000개의 자료에서 128개를 임의로 추출함. \n",
        "        _n = len(_states)\n",
        "        _index = np.random.choice(_n,128) # 128 is batch_size \n",
        "        _states = _states[_index]\n",
        "        _actions = _actions[_index]\n",
        "        _next_states = _next_states[_index]\n",
        "        _rewards = _rewards[_index]\n",
        "        _dones = _dones[_index]\n",
        "        \n",
        "        ## GPU로 이동 \n",
        "        _states = _states.to(\"cuda:0\")\n",
        "        _actions = _actions.to(\"cuda:0\")\n",
        "        _next_states = _next_states.to(\"cuda:0\")\n",
        "        _rewards = _rewards.to(\"cuda:0\")\n",
        "        _dones = _dones.to(\"cuda:0\")\n",
        "        \n",
        "        ## leanrn with pytorch \n",
        "        yhat = net(_states).gather(1,_actions) ## (s,a) -> q(s,a) // 내가 현재상태 state에서, 현재 action을 하여 얻을 것이라 예상하는 보상 (net가 알려주는) \n",
        "        y = _rewards + 0.99 * net(_next_states).detach().max(1)[0].reshape(-1,1)*(1-_dones) ## 그런데 실제로는 이게 맞다고 봐야지~ \n",
        "        loss = torch.mean((y-yhat)**2)\n",
        "        loss.backward()\n",
        "        \n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        # (step4) Agent: prepare next steps \n",
        "        state1 = state2  \n",
        "        eps = max(0.05, 0.99*eps) \n",
        "        score += reward\n",
        "        \n",
        "        # terminate \n",
        "        if done:\n",
        "            scores.append(score)\n",
        "            playtimes.append(t)\n",
        "            break\n",
        "            \n",
        "    print('\\rEpisode {}\\tScore: {:.2f}\\tPlaytime: {:.2f}'.format(epsd, scores[-1],playtimes[-1]), end=\"\")\n",
        "    if epsd % 100 == 0:\n",
        "        print('\\rEpisode {}\\tScore: {:.2f}\\tPlaytime: {:.2f}'.format(epsd, np.mean(scores[-100:]),np.mean(playtimes[-100])))"
      ],
      "id": "54ac5087-13fb-443b-8fe5-68e7a7fc774c"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  }
}