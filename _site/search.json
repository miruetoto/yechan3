[
  {
    "objectID": "posts/2022-12-23-Ebayesthresh.html",
    "href": "posts/2022-12-23-Ebayesthresh.html",
    "title": "[논문리뷰] EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "",
    "text": "ref: https://www.jstatsoft.org/article/view/v012i08"
  },
  {
    "objectID": "posts/2022-12-23-Ebayesthresh.html#ebayesthresh로-무엇을-할-수-있는가",
    "href": "posts/2022-12-23-Ebayesthresh.html#ebayesthresh로-무엇을-할-수-있는가",
    "title": "[논문리뷰] EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "Ebayesthresh로 무엇을 할 수 있는가?",
    "text": "Ebayesthresh로 무엇을 할 수 있는가?\n아래와 같은 상황을 가정하자.\n\\[X_i = \\mu_i +\\epsilon_i.\\]\n여기에서 아래를 가정한다.\n\n\\(\\epsilon_i \\overset{iid}{\\sim} N(0,1)\\)\neach \\(\\mu_i\\) is zero with probability \\((1−w)\\), while, with probability \\(w\\), \\(\\mu_i\\) is drawn from a symmetric heavy-tailed density \\(\\gamma\\).\n\n일반적으로 \\(w\\), 즉 \\(\\mu_i\\)가 0이 아닐 확률은 매우 작은값으로 설정된다. 따라서 위와 같은 구조로 \\(\\epsilon_i\\)와 \\(\\mu_i\\)를 생성하면 아래와 같이 된다.\n\n\\(\\epsilon_i\\): 절대값이 작은 신호들이 dense하게 있음.\n\\(\\mu_i\\): 절대값이 큰 신호들이 sparse하게 있음. (sparse한 이유는 \\(w\\)가 작으므로)\n\n따라서 \\(X_i\\)의 모양은 아래의 그림의 왼쪽과 같다.\n\n이 논문의 목표는 왼쪽의 그림 \\(X_i= \\mu_i +\\epsilon_i\\)로부터 오른쪽의 그림 \\(\\hat{\\mu}_i\\)을 구하는 것이다. 즉 작은 절대값의 노이즈 \\(\\epsilon_i\\)에서 큰 절대값의 신호 \\(\\mu_i\\)를 골라내는 일을 목표로 한다. 저자들은 이러한 작업을 “건초더미에서 바늘찾기”라는 말로 비유하였다. 이러한 “건초더미에서 바늘찾기”는 여러 분야에 응용될 수 있다. 구체적으로는 천문학, 이미지프로세싱, 데이터마이닝, 모형선택등에 사용될 수 있다고 한다. 언급한 분야에 대한 자세한 discussion은 Johnstone and Silverman (2004)에서 찾을 수 있다. 또한 “건초더미에서 바늘찾기”는 위에서 언급한 분야 이외에 퓨리에, 웨이블릿 혹은 다른 dictionaries에 의한 함수추정문제를 해결할 수 있다. 이는 퓨리에나 웨이블릿변환과 같은 multiscale trasnform이 원래 신호를 sparese한 구조로 바꾸기 때문이다. 즉 퓨리에변환 웨이블릿변환으로 underlying function을 추정할 수 있다는 의미이다. 우리는 이러한 접근법에 좀 더 초점을 맞추도록 하겠다."
  },
  {
    "objectID": "posts/2022-12-23-Ebayesthresh.html#간단한-사용법",
    "href": "posts/2022-12-23-Ebayesthresh.html#간단한-사용법",
    "title": "[논문리뷰] EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "간단한 사용법",
    "text": "간단한 사용법\nR을 이용하여 Ebayesthresh를 사용하는 간단한 방법을 살펴보도록 하자. 논문에 표현된 그림1을 재현하여 보자.\n\nlibrary(EbayesThresh)\n\n\nset.seed(1)\nx <- rnorm(1000) + sample(c( runif(25,-7,7), rep(0,975)))\nplot(x,type='l',lwd=0.2)\n\n\n\n\n위와 같은 자료 \\(X_i\\)를 관측하였다고 가정하자. 이 신호에는 “건초(\\(\\epsilon_i\\))”더미에 25개의 “바늘(\\(\\mu_i\\))”이 섞여있다. 여기에서 “바늘”만 골라내는 코드는 아래와 같이 작성할 수 있다.\n\nmuhat <- ebayesthresh(x, sdev=1)\n\n결과를 시각화하면 아래와 같다.\n\nplot(x,type='l',lwd=0.2)\nlines(muhat,col=2,lwd=2)"
  },
  {
    "objectID": "posts/2022-12-23-Ebayesthresh.html#arguments",
    "href": "posts/2022-12-23-Ebayesthresh.html#arguments",
    "title": "[논문리뷰] EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "arguments",
    "text": "arguments\n일반적으로 ebayesthresh 함수를 사용하는 방법은 아래와 같다.\n\nmuhat <- ebayesthresh(\n    x,\n    prior = \"laplace\", \n    a = 0.5, \n    bayesfac = FALSE, \n    sdev = NA, \n    verbose = FALSE, \n    threshrule = \"median\"\n)\n\nprior, a: \\(\\mu_i\\)의 density. 보통 \\(\\frac{1}{2}a \\exp(-a|u|)\\)라고 가정한다. parameter \\(a\\)는 Section 2.1에서 자시해 나옴.\nbayesfac, threshrule: Section 2.2, 2.3에 자세히 나온다.\nsdev: \\(\\epsilon_i\\)의 sd를 의미한다. 이 값을 알고 있다면 설정하면 되지만 보통은 이 값을 모른다고 가정한다. \\(\\epsilon_i\\)의 sd를 모르는 경우는 observed data로 부터 추정하는데 보통 \\({\\tt median}(|X_i|)\\)로 추정한다.\n\\(\\epsilon_i\\)의 sd를 \\({\\tt median}(|X_i|)\\)로 추정하는 motivation을 이해하는 것이 중요하다. 이는 sparse assumption of \\(\\mu_i\\)에서 시작한다. 신호 \\(\\mu_i\\)가 합리적인 수준에서 sparse하다면 median absolute value of \\(X_i\\)는 \\(\\mu_i\\)의 값들과 상관이 없을 것이다. 하지만 당연히 신호가 sparse하지 않다면 이러한 방식으로 sdev를 추정하는 것은 매우 조심스럽게 수행되어야 할 것이다.\n\nn <- 1000\nx <- rnorm(n) + sample(c(runif(25,-7,7), rep(0,n-25)))\nprint(sd(x))\nprint(median(abs(x)))\n\n[1] 1.117016\n[1] 0.6787613\n\n\n\n실제로는 잘 추론하지 못하는 것 같다?"
  },
  {
    "objectID": "posts/2022-12-23-Ebayesthresh.html#원리",
    "href": "posts/2022-12-23-Ebayesthresh.html#원리",
    "title": "[논문리뷰] EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "원리",
    "text": "원리\n어떻게 \\(\\hat{\\mu}_i\\)를 추정할 수 있을까? 가장 간단한 방법은 thresholding이다.\n많은 실제예제에서 \\(\\mu_i\\)는 어떤 의미에서 (in some sense) sparse하다고 여길 수 있다. EbayesThresh 패키지는 이처럼 \\(\\mu_i\\)가 sparse하다는 구조 (혹은 가정)을 이용하여 \\(\\mu_i\\)를 적절하게 추정한다.\nSparsity를 이용하는 자연스러운 방법은 threshoding이다: 여기에서 threshold의 값 \\(t\\)를 너무 크게 잡으면 신호를 잡음으로 잘못 판단할 것이고 \\(t\\)의 값이 너무 작다면 잡음을 신호로 잘못 판단할 수 있다. 따라서 \\(t\\)의 선택은 이 양쪽 기준사이의 tradeoff가 있는데 EbayesThresh는 이러한 tradeoff를 자동으로 조정하는 효과가 있다.\n\n\\(\\mu_i\\)는 \\(w\\)의 확률로 0 이며 \\((1-w)\\)의 확률로 0이 아니다. \\(\\mu_i\\)가 0이 아닐경우에는 symmetric heavy-tailed density \\(\\gamma\\)에서 추출된다고 가정한다. 여기에서 prior에 대한 key parameter인 \\(w\\)는 데이터로부터 자동으로 추정된다. (marginal maximum likelihood 를 이용한다) 그리고 추정된 \\(w\\)는 Bayesian model로 다시 대입된다.\n\\(w\\)가 추정되면 Bayesian model은 thresholding procedure를 수행할 수 있다. 왜냐하면 \\(w\\)를 추정하면 \\(t(w)\\)를 선택한다는 말과 같은말이기 때문이다.\n\nargument"
  },
  {
    "objectID": "posts/2022-12-23-Ebayesthresh.html#the-bayesian-model",
    "href": "posts/2022-12-23-Ebayesthresh.html#the-bayesian-model",
    "title": "[논문리뷰] EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "The Bayesian model",
    "text": "The Bayesian model\n\\[X_i \\sim N(\\mu_i,1)\\]\n\\(f_{\\text{prior}}(\\mu)=(1-w)\\delta_0(\\mu)+w \\gamma_a(\\mu), \\quad \\gamma_a(\\mu)=\\frac{1}{2}a\\exp(-a|\\mu|)\\)\n여기에서 \\(\\gamma_a(\\mu)\\)는 하나의 예시일 뿐이다. Ebayesthresh에 디폴트로 설정된 prior=\"laplace\"를 셋팅하면 \\(\\gamma_a(\\mu)\\)가 사용된다. \\(\\gamma\\)의 선택은 tail이 polynomial rates로 줄어드는 어떠한 분포를 사용해도 무방하다. 저자들은 quasi-Cauchy분포를 제안하였는데 이는 Johnstone and Sliverman이 만든 theoretical assumption을 만족하는 분포중 가장 꼬리가 두꺼운 분포이다."
  },
  {
    "objectID": "posts/2022-12-23-Ebayesthresh.html#thresholding-rules",
    "href": "posts/2022-12-23-Ebayesthresh.html#thresholding-rules",
    "title": "[논문리뷰] EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "Thresholding rules",
    "text": "Thresholding rules\n모수 \\(\\mu\\)는 사전분포(prior distribution)를 가진다고 가정하고 \\(X \\sim N(\\mu,1)\\)이라고 가정하자. 이 경우 \\(X=x\\)가 given되었을 경우 \\(\\mu\\)의 사후분포(posterior distribution)를 구할 수 있다. (자세한 내용은 Section 6을 참고해야함) 사후분포의 중앙값을 \\(\\hat{\\mu}(x;w)\\)라고 하자. (사후분포의 중앙값이 \\(w\\)에 영향받는 이유는 사전분포가 \\(w\\)에 depend하기 때문이다. 여기에서 \\(w\\)는 marginal MLE로 적절히 추론한다고 가정한다)\n\\(X_i\\)는 독립이라고 가정한다. 여기에서 \\(X_i\\)가 독립이 아니라면 약간의 정보손실이 있을 수 있다. 하지만 \\(X_i\\) 사이에 너무 많은 dependency가 존재하는 경우가 아니라면 Ebayesthresh는 어느정도 합리적인 결과를 제공한다.\n만약에 bayesfac=TRUE를 사용하면 \\(\\mu\\)의 사후분포의 중앙값 대신에 Bayes factor threshold 를 쓸 수도 있다."
  },
  {
    "objectID": "posts/2022-12-23-Ebayesthresh.html#choosing-the-threshold",
    "href": "posts/2022-12-23-Ebayesthresh.html#choosing-the-threshold",
    "title": "[논문리뷰] EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "Choosing the threshold",
    "text": "Choosing the threshold\n\\(X_i\\)의 marginal density는\n\\((1-w)\\phi(x) +w(\\gamma \\star \\phi)(x)\\)\n\\(l(w) = \\sum_{i=1}^{n}\\log \\big\\{(1-w)\\phi(X_i)+wg(X_i) \\big\\}\\)\n와 같이 정의가능하다. 단, 여기에서 \\(g:= \\gamma\\star \\phi\\) 이다.\n이제 우리는 아래의 식을 풀면된다.\n\\[\\underset{w}{\\operatorname{argmax}} l(w)\\quad\\quad \\text{subject to}\\quad t(w) \\leq \\sqrt{2\\log n}\\]\n여기에서 \\(\\sqrt{2\\log n}\\)은 흔히 말하는 universal threshold 이다.\n만약에 \\(w\\)이외에 \\(a\\)도 추정해야 한다면 아래와 같이 추정할 수 있다.\n\\[\\underset{w}{\\operatorname{argmax}} l(w)\\quad\\quad \\text{subject to}\\quad t(w) \\leq \\sqrt{2\\log n}\\]"
  },
  {
    "objectID": "posts/CGSP/2022-12-26-CGSP-Chap-12-2-Weakly Stationary Graph Processes.html",
    "href": "posts/CGSP/2022-12-26-CGSP-Chap-12-2-Weakly Stationary Graph Processes.html",
    "title": "[CGSP] Chap 12.2: Weakly Stationary Graph Processes",
    "section": "",
    "text": "using LinearAlgebra, DSP"
  },
  {
    "objectID": "posts/CGSP/2022-12-26-CGSP-Chap-12-2-Weakly Stationary Graph Processes.html#simultaneously-diagonalizable",
    "href": "posts/CGSP/2022-12-26-CGSP-Chap-12-2-Weakly Stationary Graph Processes.html#simultaneously-diagonalizable",
    "title": "[CGSP] Chap 12.2: Weakly Stationary Graph Processes",
    "section": "Simultaneously Diagonalizable",
    "text": "Simultaneously Diagonalizable\n매트릭스 \\({\\bf A}\\)와 \\({\\bf B}\\)가 대각화 가능하다는 것은 아래의 표현을 만족하는 적당한 invertible matrix \\({\\bf \\Psi}_A\\), \\({\\bf \\Psi}_B\\)와 대각행렬 \\({\\bf \\Lambda}_A\\), \\({\\bf \\Lambda}_B\\)가 존재한다는 의미가 된다.\n\\[{\\bf A} = {\\bf V}_{A} {\\bf \\Lambda}_A {\\bf V}_{A}^{-1}\\]\n\\[{\\bf B} = {\\bf V}_{B} {\\bf \\Lambda}_B {\\bf V}_{B}^{-1}\\]\n그리고 만약에 \\({\\bf V}_{A}={\\bf V}_{B}\\)이라면 즉\n\\[{\\bf A} = {\\bf V} {\\bf \\Lambda}_A {\\bf V}^{-1}\\]\n\\[{\\bf B} = {\\bf V} {\\bf \\Lambda}_B {\\bf V}^{-1}\\]\n이라면 \\(\\{{\\bf A},{\\bf B}\\}\\)가 simultaneously diagonalzable 하다고 표현한다."
  },
  {
    "objectID": "posts/CGSP/2022-12-26-CGSP-Chap-12-2-Weakly Stationary Graph Processes.html#commute",
    "href": "posts/CGSP/2022-12-26-CGSP-Chap-12-2-Weakly Stationary Graph Processes.html#commute",
    "title": "[CGSP] Chap 12.2: Weakly Stationary Graph Processes",
    "section": "Commute",
    "text": "Commute\n두 matrix \\({\\bf A}\\)와 \\({\\bf B}\\)에 대하여\n\\[{\\bf A}{\\bf B}= {\\bf B}{\\bf A}\\]\n인 관계가 성립하면 두 매트릭스가 commute 한다고 표현한다. 그런데 \\({\\bf A}{\\bf B}={\\bf A}{\\bf B}\\)의 조건은 \\({\\bf A}, {\\bf B}\\)가 동시대각화가능할 (simultaneously diagonalzable) 조건과 같다. 1 따라서 simultaneously diagonalzable 는 commute와 같은 말이라 생각해도 무방하다.\n\n참고: 위키피디아.."
  },
  {
    "objectID": "posts/CGSP/2022-12-26-CGSP-Chap-12-2-Weakly Stationary Graph Processes.html#shift-invariant-filter",
    "href": "posts/CGSP/2022-12-26-CGSP-Chap-12-2-Weakly Stationary Graph Processes.html#shift-invariant-filter",
    "title": "[CGSP] Chap 12.2: Weakly Stationary Graph Processes",
    "section": "Shift Invariant Filter",
    "text": "Shift Invariant Filter\n\nref: Djuric and Richard (2018) Chap 8.3 의 내용 중 일부\n\nDefine the matrix \\({\\bf B}\\) as periodic shift matrix such that\n\\[\n{\\bf B} = \\begin{bmatrix}\n0 & 0 & 0 & \\dots  & 0 & 1 \\\\\n1 & 0 & 0 & \\dots & 0 & 0 \\\\\n0 & 1 & 0 & \\dots & 0 & 0 \\\\\n\\dots & \\dots & \\dots & \\dots & \\dots & \\dots\\\\\n0 & 0 & \\dots & 1 & 0 & 0 \\\\\n0 & 0 & \\dots & 0 & 1 & 0 \\\\\n\\end{bmatrix}.\\]\nA generic filter \\({\\boldsymbol h}\\) is given by its \\(z\\)-transform\n\\[h(z)=h_0z^0+h_1z^{-1}+\\cdots +h_{N-1}z^{-(N-1)}\\]\nwhere \\(s_{n-1}=z^{-1}s_n\\). In vector notation, and with respect to the standard basis \\({\\bf I}\\), the filter is represented by the matrix \\({\\bf H}\\), a polynomial in the cyclic shift\n\\[{\\bf H}=h({\\bf B})=h_0{\\bf B}^0+h_1{\\bf B}^1+\\cdots+h_{N-1}{\\bf B}^{N-1}.\\]\nFilters are shift invariant iff\n\\[z\\cdot h(z) = h(z)\\cdot z\\]\nor from the matrix representation\n\\[{\\bf B}h({\\bf B})=h({\\bf B}){\\bf B}.\\]\nExample\nLet \\({\\bf B}\\) as\n\nB= [0 1 0 0 0 0 0\n    0 0 1 0 0 0 0 \n    0 0 0 1 0 0 0 \n    0 0 0 0 1 0 0 \n    0 0 0 0 0 1 0 \n    0 0 0 0 0 0 1 \n    1 0 0 0 0 0 0]\n\n7×7 Matrix{Int64}:\n 0  1  0  0  0  0  0\n 0  0  1  0  0  0  0\n 0  0  0  1  0  0  0\n 0  0  0  0  1  0  0\n 0  0  0  0  0  1  0\n 0  0  0  0  0  0  1\n 1  0  0  0  0  0  0\n\n\nDefine \\({\\boldsymbol h}\\) as\n\nh = [1/3,1/3,1/3]\n\n3-element Vector{Float64}:\n 0.3333333333333333\n 0.3333333333333333\n 0.3333333333333333\n\n\nFurthermore define \\({\\bf H}=h({\\bf B})=h_0{\\bf B}^0+h_1{\\bf B}^1+h_2{\\bf B}^2\\)\n\nH = (1/3)*B^0 + (1/3)*B^1 + (1/3)*B^2 \n\n7×7 Matrix{Float64}:\n 0.333333  0.333333  0.333333  0.0       0.0       0.0       0.0\n 0.0       0.333333  0.333333  0.333333  0.0       0.0       0.0\n 0.0       0.0       0.333333  0.333333  0.333333  0.0       0.0\n 0.0       0.0       0.0       0.333333  0.333333  0.333333  0.0\n 0.0       0.0       0.0       0.0       0.333333  0.333333  0.333333\n 0.333333  0.0       0.0       0.0       0.0       0.333333  0.333333\n 0.333333  0.333333  0.0       0.0       0.0       0.0       0.333333\n\n\nObserve following:\n\nB*H == H*B \n\ntrue\n\n\nThus, filter \\({\\boldsymbol h}\\) is shift invariant filter and matrix \\({\\bf H}\\) is shift invariant operator.\nnote: \\({\\boldsymbol h}\\) is moving average filter.\nnote: for any \\({\\bf x}\\), \\({\\bf H}{\\bf x}\\) is definded by\n\\[\\left[\\frac{x_{n-1}+x_n+x_1}{3},\\frac{x_n+x_1+x_2}{3},\\dots,\\frac{x_{n-3}+x_{n-2}+x_n}{3}\\right].\\]\n\nx = [1,1,1,1,2,2,2]\nH*x\n\n7-element Vector{Float64}:\n 1.0\n 1.0\n 1.3333333333333333\n 1.6666666666666665\n 2.0\n 1.6666666666666665\n 1.3333333333333333\n\n\nnote: In some sense, the matrix \\({\\bf H}{\\bf x}\\) can be thought as generalized version of \\({\\boldsymbol h}\\star {\\bf x}\\) where \\(\\star\\) is convolution up to shift\n\nconv(h,x)\n\n9-element Vector{Float64}:\n 0.3333333333333334\n 0.6666666666666667\n 1.0\n 1.0\n 1.3333333333333333\n 1.6666666666666667\n 2.0\n 1.3333333333333333\n 0.6666666666666667\n\n\nFinally, we observe that, from the Cayley-Hamilton Theorem, \\({\\bf B}\\) satisfies its characteristic polynomial \\(\\Delta({\\bf B})\\), where \\(\\Delta(\\lambda)\\) is the determinant of \\(\\lambda{\\bf I}-{\\bf B}\\). The characteristic polynomial \\(\\Delta({\\bf B})\\) has degree \\(N\\), so, in DSP, as described so far, linear filters are (matrix) polynomial with degree at most \\(N-1\\)."
  },
  {
    "objectID": "posts/CGSP/2022-12-26-CGSP-Chap-12-2-Weakly Stationary Graph Processes.html#coexisting-approaches",
    "href": "posts/CGSP/2022-12-26-CGSP-Chap-12-2-Weakly Stationary Graph Processes.html#coexisting-approaches",
    "title": "[CGSP] Chap 12.2: Weakly Stationary Graph Processes",
    "section": "Coexisting Approaches",
    "text": "Coexisting Approaches\nStationary graph processes were first defined and analyzed in (Girault 2015). The fundamental problem identified there is that GSOs do not preserve energy in general and therefore cannot be isometric (Gavili and Zhang 2017). This problem is addressed in (Girault, Gonçalves, and Fleury 2015) with the definition of an isometric graph shift that preserves the eigenvector space of the Laplacian GSO but modifies its eigenvalues.\nA stationary graph process is then defined as one whose probability distributions are invariant with respect to multiplications with the isometric shift. One drawback of this approach is that the isometric shift is a complex-valued operator and has a sparsity structure (if any) different from \\({\\bf S}\\). By contrast, the vertex-based definition in\n\\[\\mathbb{E} \\bigg[ \\big({\\bf S}^a{\\bf x}\\big)\\Big(\\big({\\bf S}^H)^b {\\bf x}\\Big)^H  \\bigg]=\\mathbb{E}\\bigg[\\big({\\bf S}^{a+c}{\\bf x}\\big)\\Big(\\big({\\bf S}^H\\big)^{b-c}{\\bf x} \\Big)^H \\bigg]\\]\nis based on the original GSO \\({\\bf S}\\), which is local and real-valued. As a result, above Eq. provides intuition on the relations between stationarity and locality, which can be leveraged to develop stationarity tests or estimation schemes that work with local information. Graph stationarity was also studied in (Perraudin and Vandergheynst 2017) where the requirement of having a covariance matrix diagonalizable by the eigenvectors of the Laplacian GSO is adopted as a definition. This condition is shown to be equivalent to statistical invariance with respect to the translation operator introduced in (Shuman, Ricaud, and Vandergheynst 2016). When the shift \\({\\bf S}\\) coincides with the Laplacian of the graph and the eigenvalues of \\({\\bf S}\\) are all distinct, Definitions 12.1 and 12.2 are equivalent to those in Perraudin and Vandergheynst (2017). Hence, the definitions presented here differ from (Perraudin and Vandergheynst 2017) in that we consider general normal shifts instead of Laplacians and that we see Definition 12.1 as a definition, not a property. These are mathematically minor differences that are important in practice though; see Segarra et al. (2017) for more details."
  },
  {
    "objectID": "posts/CGSP/2022-12-24-CGSP-Chap-8-3-DFT.html",
    "href": "posts/CGSP/2022-12-24-CGSP-Chap-8-3-DFT.html",
    "title": "[CGSP] Chap 8.3: Discrete Fourier Transform",
    "section": "",
    "text": "using LinearAlgebra"
  },
  {
    "objectID": "posts/CGSP/2022-12-24-CGSP-Chap-8-3-DFT.html#cyclic-shfit-operator-bf-b",
    "href": "posts/CGSP/2022-12-24-CGSP-Chap-8-3-DFT.html#cyclic-shfit-operator-bf-b",
    "title": "[CGSP] Chap 8.3: Discrete Fourier Transform",
    "section": "Cyclic shfit operator \\({\\bf B}\\)",
    "text": "Cyclic shfit operator \\({\\bf B}\\)\nThe matrix \\({\\bf B}\\) representing the periodic shift is\n\nB= [0 0 0 0 1\n    1 0 0 0 0 \n    0 1 0 0 0\n    0 0 1 0 0\n    0 0 0 1 0]\n\n5×5 Matrix{Int64}:\n 0  0  0  0  1\n 1  0  0  0  0\n 0  1  0  0  0\n 0  0  1  0  0\n 0  0  0  1  0\n\n\nThis matrix is the cyclic shift.\nnote: \\({\\bf B}\\) is orthogonal matrix.\n\nB'B\n\n5×5 Matrix{Int64}:\n 1  0  0  0  0\n 0  1  0  0  0\n 0  0  1  0  0\n 0  0  0  1  0\n 0  0  0  0  1\n\n\n(ex1) Define \\({\\bf s}\\) as\n\ns = [1,2,3,4,5]\ns\n\n5-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n\n\nObserve that\n\nB*s\n\n5-element Vector{Int64}:\n 5\n 1\n 2\n 3\n 4\n\n\n\nB^2*s\n\n5-element Vector{Int64}:\n 4\n 5\n 1\n 2\n 3\n\n\n\nB^3*s\n\n5-element Vector{Int64}:\n 3\n 4\n 5\n 1\n 2\n\n\nThus we can interprete the matrix \\({\\bf B}\\) as cyclic shift operator such that\n\\[\n{\\bf B}s_n =s_{n-1}\n\\]\nfor \\(n=1,\\dots, N-1\\) and \\({\\bf B}s_0 =s_N\\).\nnote: \\({\\bf B}\\)는 시계열에서 다루는 backshift operator 와 비슷함."
  },
  {
    "objectID": "posts/CGSP/2022-12-24-CGSP-Chap-8-3-DFT.html#dft",
    "href": "posts/CGSP/2022-12-24-CGSP-Chap-8-3-DFT.html#dft",
    "title": "[CGSP] Chap 8.3: Discrete Fourier Transform",
    "section": "DFT",
    "text": "DFT\nThe matrix \\({\\bf B}\\) can be expressed as\n\\({\\bf B}={\\bf DFT}^\\ast \\cdot {\\bf \\Lambda} \\cdot {\\bf DFT}\\)\nwhere \\({\\bf DFT}\\) is unitary and symmetric matrix and \\(\\bf \\Lambda\\) is diagonal matrix.\n\nλ, Ψ = eigen(B)\n\nEigen{ComplexF64, ComplexF64, Matrix{ComplexF64}, Vector{ComplexF64}}\nvalues:\n5-element Vector{ComplexF64}:\n -0.8090169943749472 - 0.5877852522924725im\n -0.8090169943749472 + 0.5877852522924725im\n 0.30901699437494734 - 0.9510565162951536im\n 0.30901699437494734 + 0.9510565162951536im\n  0.9999999999999998 + 0.0im\nvectors:\n5×5 Matrix{ComplexF64}:\n  0.138197+0.425325im   0.138197-0.425325im  …  0.447214+0.0im\n -0.361803-0.262866im  -0.361803+0.262866im     0.447214+0.0im\n  0.447214-0.0im        0.447214+0.0im          0.447214+0.0im\n -0.361803+0.262866im  -0.361803-0.262866im     0.447214+0.0im\n  0.138197-0.425325im   0.138197+0.425325im     0.447214+0.0im\n\n\n\nB ≈ Ψ * Diagonal(λ) * Ψ'\n\ntrue\n\n\nDefine \\({\\boldsymbol \\Psi}^\\ast={\\bf DFT}\\).\n\nDFT = Ψ'\n\n5×5 adjoint(::Matrix{ComplexF64}) with eltype ComplexF64:\n  0.138197-0.425325im  -0.361803+0.262866im  …  0.138197+0.425325im\n  0.138197+0.425325im  -0.361803-0.262866im     0.138197-0.425325im\n -0.361803-0.262866im  -0.361803+0.262866im     0.138197-0.425325im\n -0.361803+0.262866im  -0.361803-0.262866im     0.138197+0.425325im\n  0.447214-0.0im        0.447214-0.0im          0.447214-0.0im\n\n\nNote that the eigenvalues are not ordered in julia.\n\nλ[5], exp(-im* 2π/5 * 0)\n\n(0.9999999999999998 + 0.0im, 1.0 - 0.0im)\n\n\n\nλ[3], exp(-im* 2π/5 * 1)\n\n(0.30901699437494734 - 0.9510565162951536im, 0.30901699437494745 - 0.9510565162951535im)\n\n\n\nλ[1], exp(-im* 2π/5 * 2)\n\n(-0.8090169943749472 - 0.5877852522924725im, -0.8090169943749473 - 0.5877852522924732im)\n\n\n\nλ[2], exp(-im* 2π/5 * 3)\n\n(-0.8090169943749472 + 0.5877852522924725im, -0.8090169943749475 + 0.587785252292473im)"
  },
  {
    "objectID": "posts/CGSP/2022-12-24-CGSP-Chap-8-3-DFT.html#spectral-components-and-frequencies",
    "href": "posts/CGSP/2022-12-24-CGSP-Chap-8-3-DFT.html#spectral-components-and-frequencies",
    "title": "[CGSP] Chap 8.3: Discrete Fourier Transform",
    "section": "Spectral components and Frequencies",
    "text": "Spectral components and Frequencies\nWe remark:\n(1) Spectral components: For \\(k = 0,1,2,\\dots, N-1\\), the \\(k\\)-th column of \\({\\bf DFT}^\\ast\\) is defined by\n\\[\\Psi_k:=\\frac{1}{\\sqrt{N}}\\begin{bmatrix} 1 \\\\ e^{j\\frac{2\\pi}{N}k} \\\\ e^{j\\frac{2\\pi}{N}2k} \\\\ e^{j\\frac{2\\pi}{N}3k} \\\\  \\dots \\\\ e^{j\\frac{2\\pi}{N}(N-1)k} \\end{bmatrix}.\\]\nNote that \\(\\Psi_k\\) can be also interpreted as \\(\\ell\\)-th eigenvector of \\({\\bf A}\\) correspoding \\(\\lambda_\\ell = e^{-j\\frac{2\\pi}{N}k}\\). Those eigenvectors\n\\[\\big\\{{\\bf 1},\\Psi_1,\\Psi_2, \\dots, \\Psi_{N-1}\\big\\}\\]\nform a complete orthonomal basis of \\(\\mathbb{C}^N\\). These vectors are called spectral components.\n(2) Frequencies: The diagonal entries of \\({\\bf \\Lambda}\\) are the eigenvalues of the time shift \\({\\bf B}\\). In Physics and in operator theory, these eigenvalues are the frequencies of the signal. In DSP it is more common to call frequencies\n\\[\\Omega_k=\\frac{-1}{2\\pi j}\\ln\\lambda_k=\\frac{-1}{2\\pi j}\\ln e^{-j \\frac{2\\pi}{N}k}=\\frac{k}{N}, \\quad k=0,1,2,\\dots,N-1.\\]\n\nThe \\(N\\) (time) frequencies \\(\\Omega_k\\) are all distinct, positive, equally spaced, and increasing from \\(0\\) to \\(\\frac{N-1}{N}\\). The spectral components are the complex exponential sinusiodal functions. For example, corresponding to the zero frequency is the DC spectral component (a vector whose entries are constant and all equal to \\(\\frac{1}{\\sqrt{N}}\\))."
  },
  {
    "objectID": "posts/CGSP/2022-12-24-CGSP-Chap-8-3-DFT.html#dft-1",
    "href": "posts/CGSP/2022-12-24-CGSP-Chap-8-3-DFT.html#dft-1",
    "title": "[CGSP] Chap 8.3: Discrete Fourier Transform",
    "section": "DFT",
    "text": "DFT\n일반적으로 우리가 알고있는 DFT1는 아래와 같다. (이 그림은 위키피디아에서 캡쳐한 것이다)\n\n\n\n그림1: 위키에서 긁어온 DFT의 정의\n\n\n즉 DFT는 임의의 신호 \\(\\{{\\bf x}_n\\}:=x_0,x_1,\\dots,x_{N-1}\\)를 적당한 규칙2에 따라서 \\(\\{{\\bf X}_k\\}:=X_0,X_1,\\dots,X_{N-1}\\)로 바꾸는 변환을 이라고 이해할 수 있다. 이때 사용되는 적당한 규칙은 구체적으로 아래의 수식을 의미한다.\n\\[X_k = \\sum_{n=0}^{N-1}x_n\\cdot e^{-i\\frac{2\\pi}{N}kn}\\]\n그런데 매트릭스를 활용하면 위의 수식을 아래와 같이 표현할 수 있다.\n\\[\\begin{bmatrix} X_1 \\\\ X_2 \\\\ X_3 \\\\ \\dots \\\\ X_{N-1} \\end{bmatrix}\n=\\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 1} & e^{-i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 2} & e^{-i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n\\end{bmatrix}\n\\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ \\dots \\\\ x_{N-1} \\end{bmatrix}\\]\n편의상 \\({\\bf X}\\)와 \\({\\bf x}\\)를 \\(N \\times 1\\) col-vec이라고 생각하고 DFT를 아래와 같은 matrix로 정의하자.\n\\[{\\bf DFT} = \\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 1} & e^{-i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 2} & e^{-i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n    \\end{bmatrix}\\]\n그러면\n\\[{\\bf X} = {\\bf DFT} \\cdot {\\bf x}\\]\n와 같이 표현할 수 있고 \\({\\bf x}\\)에서 \\({\\bf X}\\)로 바꾸는 과정을 단순히 \\({\\bf DFT}\\)행렬을 \\({\\bf x}\\)의 왼쪽에 곱하는 과정으로 이해할 수 있다.\n(참고) 사실 아래와 같이 \\({\\bf DFT}\\)를 정의하는 버전도 있다. (둘이 혼용해서 쓰인다)\n\\[{\\bf DFT} = \\frac{1}{\\sqrt{N}}\\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 1} & e^{-i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 2} & e^{-i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n    \\end{bmatrix}\\]\n\n예제1 아래는 위키에서 긁어온 예제이다. 이 예제를 따라가보자.\n\n\n\n그림2: 위키에서 긁어온 예제이미지\n\n\n예제를 풀기위해서 우선 아래와 같은 벡터를 선언하다.\n\nx = [1, 2-im, -im, -1+2im]\n\n4-element Vector{Complex{Int64}}:\n  1 + 0im\n  2 - 1im\n  0 - 1im\n -1 + 2im\n\n\n이제 \\(4\\times 4\\)의 크기를 가지는 DFT행렬을 선언해야 한다.\n(step1) 아래의 매트릭스 생성\n\n_DFT = reshape([i*j for i in 0:3 for j in 0:3], (4,4))\n_DFT\n\n4×4 Matrix{Int64}:\n 0  0  0  0\n 0  1  2  3\n 0  2  4  6\n 0  3  6  9\n\n\n(step2) _DFT의 각 원소에 함수 \\(f: x \\to \\exp(-i\\frac{2\\pi}{4}x)\\)를 취함\n\nf = x -> exp(-im * (2π/4) * x)\nDFT = _DFT .|> f\n\n4×4 Matrix{ComplexF64}:\n 1.0-0.0im           1.0-0.0im          …           1.0-0.0im\n 1.0-0.0im   6.12323e-17-1.0im             -1.83697e-16+1.0im\n 1.0-0.0im          -1.0-1.22465e-16im             -1.0-3.67394e-16im\n 1.0-0.0im  -1.83697e-16+1.0im              5.51091e-16-1.0im\n\n\n이제 \\({\\bf X}\\)를 구하면 아래와 같다.\n\nDFT * x\n\n4-element Vector{ComplexF64}:\n                   2.0 + 0.0im\n   -1.9999999999999998 - 2.0000000000000004im\n 8.881784197001252e-16 - 1.9999999999999998im\n    3.9999999999999987 + 4.000000000000001im\n\n\n위키의 답이 잘 나옴"
  },
  {
    "objectID": "posts/CGSP/2022-12-24-CGSP-Chap-8-3-DFT.html#inverse-dft",
    "href": "posts/CGSP/2022-12-24-CGSP-Chap-8-3-DFT.html#inverse-dft",
    "title": "[CGSP] Chap 8.3: Discrete Fourier Transform",
    "section": "Inverse DFT",
    "text": "Inverse DFT\n앞으로는 \\({\\bf DFT}\\)를 아래와 같이 정의하자.\n\\[{\\bf DFT} = \\frac{1}{\\sqrt{N}}\\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 1} & e^{-i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 2} & e^{-i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n    \\end{bmatrix}\\]\n\\({\\bf DFT}\\)행렬에는 몇 가지 특징이 있다.\n특징1: 유니터리행렬이다. 즉 \\({\\bf DFT}^\\ast \\cdot {\\bf DFT} = {\\bf DFT}^\\ast \\cdot{\\bf DFT} = {\\bf I}\\) 이다.\n\n_DFT = reshape([i*j for i in 0:3 for j in 0:3], (4,4))\nf = x -> exp(-im * (2π/4) * x)\nDFT = _DFT .|> f\nDFT # 아까의 예제의 DFT!\n\n4×4 Matrix{ComplexF64}:\n 1.0-0.0im           1.0-0.0im          …           1.0-0.0im\n 1.0-0.0im   6.12323e-17-1.0im             -1.83697e-16+1.0im\n 1.0-0.0im          -1.0-1.22465e-16im             -1.0-3.67394e-16im\n 1.0-0.0im  -1.83697e-16+1.0im              5.51091e-16-1.0im\n\n\n\nDFT = (1/√4)*DFT # 새로운 DFT의 정의 \nDFT'DFT .|> round # 유니터리행렬임을 확인!\n\n4×4 Matrix{ComplexF64}:\n  1.0+0.0im  -0.0-0.0im   0.0-0.0im   0.0-0.0im\n -0.0+0.0im   1.0+0.0im  -0.0-0.0im   0.0-0.0im\n  0.0+0.0im  -0.0+0.0im   1.0+0.0im  -0.0-0.0im\n  0.0+0.0im   0.0+0.0im  -0.0+0.0im   1.0+0.0im\n\n\n특징2: \\({\\bf DFT}\\)는 대칭행렬이다. 따라서 이 행렬의 켤레전치는 DFT의 각 원소에서 단순히 \\(i=\\sqrt{-1}\\) 대신에 \\(-i\\) 를 넣은 것과 같다.\n특징1-2를 조합하면 아래와 같이 \\({\\bf DFT}\\)에서 \\(i\\) 대신에 \\(-i\\)를 넣은 행렬이 변환 DFT를 취소시킬 수 있음을 이해할 수 있다. 3\n\\[\\frac{1}{\\sqrt{N}}\\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{i \\frac{2\\pi}{N}\\cdot 1} & e^{i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{i \\frac{2\\pi}{N}\\cdot 2} & e^{i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n    \\end{bmatrix}\\]\n행렬 \\({\\bf DFT}\\)를 discrete Fourier transform으로 생각했듯이 위의 행렬을 inverse discrete Fourier transform으로 해석할 수 있다."
  },
  {
    "objectID": "posts/CGSP/2022-12-24-CGSP-Chap-8-3-DFT.html#dft의-또-다른-정의",
    "href": "posts/CGSP/2022-12-24-CGSP-Chap-8-3-DFT.html#dft의-또-다른-정의",
    "title": "[CGSP] Chap 8.3: Discrete Fourier Transform",
    "section": "DFT의 또 다른 정의",
    "text": "DFT의 또 다른 정의\n이번에는 \\({\\bf DFT}\\)에 대한 다른 정의를 생각해보자. 우선 아래와 같은 행렬 \\({\\bf B}\\)를 고려하자.\n\nB= [0 0 0 1 \n    1 0 0 0 \n    0 1 0 0\n    0 0 1 0]\n\n4×4 Matrix{Int64}:\n 0  0  0  1\n 1  0  0  0\n 0  1  0  0\n 0  0  1  0\n\n\n이것은 길이가 4인 임의의 column vector를 아래로 한칸씩 이동시키는 매트릭스이다.\n\nx = [1, 2-im, -im, -1+2im]\n\n4-element Vector{Complex{Int64}}:\n  1 + 0im\n  2 - 1im\n  0 - 1im\n -1 + 2im\n\n\n\nB*x # 아래로 한칸이동 \n\n4-element Vector{Complex{Int64}}:\n -1 + 2im\n  1 + 0im\n  2 - 1im\n  0 - 1im\n\n\n\nB^2*x # 아래로 두칸이동, B^2*x = B*(Bx) 이므로 \n\n4-element Vector{Complex{Int64}}:\n  0 - 1im\n -1 + 2im\n  1 + 0im\n  2 - 1im\n\n\n한편 이 매트릭스 \\({\\bf B}\\)는 아래와 같이 고유분해가 가능하다.\n\\[ {\\bf B} = {\\bf \\Psi} {\\bf \\Lambda} {\\bf \\Psi}^\\ast\\]\n\n\\({\\bf \\Psi}\\): make \\(\\frac{1}{\\sqrt{N}}[e^{\\sqrt{-1} \\frac{2\\pi}{N} ij}~\\text{ for }~ i=0,1,2,\\dots,N-1~\\text{ for }~j=0,1,2,\\dots,N-1]\\) and apply reshape function with \\((N,N)\\).\n\\({\\bf \\Lambda}\\): make \\([e^{-\\sqrt{-1}\\frac{2\\pi}{N}i}~\\text{ for }~ i=0,1,2\\dots,N-1]\\) and apply Diagonal function.\n\n\nN = 4 \nλ = [exp(-im * (2π/N) *i) for i in 0:(N-1)]\nΛ = Diagonal(λ)\n_Ψ = 1/√N *[exp(im * (2π/N) * i*j) for i in 0:(N-1) for j in 0:(N-1)]\nΨ = reshape(_Ψ, (N,N))\nB ≈ Ψ * Λ * Ψ'\n\ntrue\n\n\n그런데 위에서 정의된 \\({\\bf \\Psi}^\\ast\\)는 우리가 그전에 정의하였던 \\({\\bf DFT}\\)의 행렬과 같다.\n\n_DFT = reshape([i*j for i in 0:3 for j in 0:3], (4,4))\nDFT = _DFT .|> (x -> exp(-im * (2π/4) * x)) \nDFT = DFT * 1/√N\n\n4×4 Matrix{ComplexF64}:\n 0.5-0.0im           0.5-0.0im          …           0.5-0.0im\n 0.5-0.0im   3.06162e-17-0.5im             -9.18485e-17+0.5im\n 0.5-0.0im          -0.5-6.12323e-17im             -0.5-1.83697e-16im\n 0.5-0.0im  -9.18485e-17+0.5im              2.75546e-16-0.5im\n\n\n\nΨ' == DFT \n\ntrue\n\n\n결국 요약하면 길이가 \\(N\\)인 신호의 \\({\\bf DFT}\\)행렬은 아래의 과정으로 구할 수 있음을 알 수 있다.\n\nForward operator \\({\\bf A}\\)를 정의한다.\n\\({\\bf A}\\)의 고유벡터행렬 \\({\\bf \\Psi}\\)을 구한다. 4\n\\({\\bf \\Psi}\\)의 conjugate transpose matrix \\({\\bf \\Psi}^\\ast\\) 를 구한다. 이것이 \\({\\bf DFT}\\) matrix 이다. 5"
  },
  {
    "objectID": "posts/CGSP/2022-12-24-CGSP-Chap-8-3-DFT.html#spectral-component-and-frequencies",
    "href": "posts/CGSP/2022-12-24-CGSP-Chap-8-3-DFT.html#spectral-component-and-frequencies",
    "title": "[CGSP] Chap 8.3: Discrete Fourier Transform",
    "section": "Spectral component and Frequencies",
    "text": "Spectral component and Frequencies\n\\({\\bf A}\\)의 고유벡터 \\({\\bf \\Psi}\\)의 각 column을 spectral component라고 부른다.\n\nψ₁ = Ψ[:,1] # ψ₁ is first spectral component \nψ₂ = Ψ[:,2] # ψ₂ is seconde spectral component \nψ₃ = Ψ[:,3] # ψ₃ is third spectral component \nψ₄ = Ψ[:,4] # ψ₄ is last spectral component\n\n그리고 아래와 같은 수열을 \\(\\Omega_{k}=\\frac{k}{N}\\)을 frequency 라고 부른다.\n\nN=4 \nΩ = [k/N for k in 0:(N-1)]\nΩ\n\n4-element Vector{Float64}:\n 0.0\n 0.25\n 0.5\n 0.75"
  },
  {
    "objectID": "posts/CGSP/2022-12-27-CGSP-Chap-12-2-1-PSD.html",
    "href": "posts/CGSP/2022-12-27-CGSP-Chap-12-2-1-PSD.html",
    "title": "[CGSP] Chap 12.2.1: Power Spectral Density",
    "section": "",
    "text": "크로네커곱의 정의는 아래와 같다.\n\\[{\\bf A} \\otimes {\\bf B}\n=\\begin{bmatrix}\na_{11}{\\bf B} & a_{12}{\\bf B} & \\dots & a_{1m}{\\bf B} \\\\\na_{21}{\\bf B} & a_{22}{\\bf B} & \\dots & a_{2m}{\\bf B} \\\\\n\\dots & \\dots & \\dots & \\dots \\\\\na_{n1}{\\bf B} & a_{n2}{\\bf B} & \\dots & a_{nm}{\\bf B} \\\\\n\\end{bmatrix}\\]\n두 행렬 \\({\\bf A}_{m\\times n}\\), \\({\\bf B}_{p\\times q}\\)의 크로네커곱 \\({\\bf A}\\otimes {\\bf B}\\)의 차원은 \\(mp \\times nq\\) 가 된다. 계산예시는 아래와 같다.\n\n\n\n위키에서 긁은 예제, 글씨가 좀 작음\n\n\n크로네커곱에 대한 성질들이 위키에 많이 있으니 참고하면 좋다.\n\n\n\n카트리라오곱은 매트릭스 \\({\\bf A}\\)와 \\({\\bf B}\\)가 같은 차원의 블락매트릭스로 정의될때 각 서브매트릭스의 크로네커 곱으로 정의된다. 정의와 계산예시는 아래와 같다.\n\n\n\n예시1: 위키에서 긁은 그림\n\n\n또 다른 계산예시는 아래와 같다.\n\n\n\n예시2: 위키에서 긁은 그림"
  },
  {
    "objectID": "posts/CGSP/2022-12-27-CGSP-Chap-12-2-1-PSD.html#nonparametric-psd-estimators",
    "href": "posts/CGSP/2022-12-27-CGSP-Chap-12-2-1-PSD.html#nonparametric-psd-estimators",
    "title": "[CGSP] Chap 12.2.1: Power Spectral Density",
    "section": "Nonparametric PSD estimators",
    "text": "Nonparametric PSD estimators\nNonparametric estimators—as opposed to their parametric counterparts—do not assume any specific generating model on the process \\({\\bf x}\\). This more agnostic view of \\({\\bf x}\\) comes with the price of needing, in general, to observe more graph signals to achieve satisfactory performance. In this section, we extend to the graph setting the periodogram, the correlogram, and the least-squares (LS) estimator, which are classical unbiased nonparametric estimators. Moreover, for the special case where the observations are Gaussian, we derive the Cramér-Rao lower bound. We also discuss the windowed average periodogram, which attains a better performance when a few observations are available by introducing bias in a controlled manner while drastically reducing the variance.\n\nPeriodogram, correlogram, and LS estimator\nFrom \\({\\bf C}_{\\tilde{\\bf x}}:= \\mathbb{E}\\left[\\tilde{\\bf x}\\tilde{\\bf x}^H \\right]=\\mathbb{E}\\left[({\\bf V}^H{\\bf x})({\\bf V}^H{\\bf x})^H \\right]=\\text{diag}({\\bf p})\\) it follows that one may express the PSD as \\({\\bf p}=\\mathbb{E}\\left[|{\\bf V}^H{\\bf x}|^2\\right]\\). That is, the PSD is given by the expected value of the squared frequency components of the random process. This leads to a natural approach for the estimation of \\({\\bf p}\\) from a finite set of \\(R\\) realizations of the process \\({\\bf x}\\). Indeed, we compute the \\({\\bf GFT} \\tilde{\\bf x}_r = {\\bf V}^H{\\bf x}_r\\) of each observed signal \\({\\bf x}_r\\) and estimate \\({\\bf p}\\) as\n\\[\n\\hat{\\bf p}_{pg}:= \\frac{1}{R}\\sum_{r=1}^R|\\tilde{\\bf x}_r|^2=\\frac{1}{R}\\sum_{r=1}^{R}|{\\bf V}^H{\\bf x}_{r}|^2.\n\\]\nThe estimator \\(\\hat{\\bf p}_{pg}\\) is termed periodogram due to its evident similarity with its homonym2 in classical estimation. It is simple to show that \\({\\bf p}_{pg}\\) is an unbiased estimator, that is, \\(\\mathbb{E}[\\hat{\\bf p}_{pg}]= {\\bf p}\\). A more detailed analysis of the performance of \\(\\hat{\\bf p}_{pg}\\), for the case where the observations are Gaussian, is given in Proposition 12.1.3\nAn alternative nonparametric estimation scheme, denominated correlogram, can be devised by starting from the definition of \\({\\bf p}\\) in\n\\[{\\bf p}:=\\text{diag}\\big({\\bf V}^H {\\bf C}_{\\bf x}{\\bf V} \\big).\\]\nNamely, one may substitute \\({\\bf C}_{\\bf x}\\) in above equation by the sample covariance \\(\\hat{\\bf C}_{\\bf x} = \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_r{\\bf x}_r^H\\) computed based on the available observations to obtain\n\\[\\hat{\\bf p}_{cg}:= \\text{diag}\\left({\\bf V}^H \\hat{\\bf C}_{\\bf x}{\\bf V} \\right):=\\text{diag}\\left[{\\bf V}^H\\big[ \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_r{\\bf x}_r^H\\big]{\\bf V} \\right].\\]\nNotice that the matrix \\({\\bf V}^H\\hat{\\bf C}_{\\bf x}{\\bf V}\\) is in general, not diagonal because the eigenbasis of \\(\\hat{\\bf C}_{\\bf x}\\) differs from \\({\\bf V}\\), the eigenbasis of \\({\\bf C}_{\\bf x}\\). Nonetheless, we keep only the diagonal elements \\({\\bf v}_i^H \\hat{\\bf C}_{\\bf x}{\\bf v}_i\\) for \\(i = 1, \\dots , N\\) as our PSD estimator. It can be shown that the correlogram \\({\\bf p}_{cg}\\) and the periodogram \\({\\bf p}_{pg}\\) lead to identical estimators, as is the case in classical signal processing.\nThe correlogram can also be interpreted as an LS estimator. The decomposition in \\({\\bf C}_{\\bf x}={\\bf V}\\text{diag}({\\bf p}){\\bf V}^H\\) allows a linear parameterization of the covariance matrix \\({\\bf C}_{\\bf x}\\) as\n\\[\n{\\bf C}_{\\bf x}({\\bf p})=\\sum_{i=1}^N p_i{\\bf v}_i{\\bf v}_i^H.\n\\]\nThis linear parametrization will also be useful for the sampling schemes developed in Section 12.4. Vectorizing \\({\\bf C}_{\\bf x}\\) in \\({\\bf C}_{\\bf x}({\\bf p})=\\sum_{i=1}^N p_i{\\bf v}_i{\\bf v}_i^H\\) results in a set of \\(N^2\\) equations in \\({\\bf p}\\)\n\\[\n{\\bf c}_{\\bf x} = \\text{vec}({\\bf C}_{\\bf x})=\\sum_{i=1}^{N}p_i \\text{vec}({\\bf v}_i{\\bf v}_i^H)={\\bf G}_{np}{\\bf p},\n\\]\nwhere \\(\\text{vec}({\\bf v}_i{\\bf v}_i^H)={\\bf v}_i^\\ast \\otimes {\\bf v}_i\\). Relying on the Khatri-Rao product, we then form the \\(N^2 \\times N\\) matrix \\({\\bf G}_{np}\\) as\n\\[\n{\\bf G}_{np}:= \\left[{\\bf v}_1^\\ast \\otimes {\\bf v}_1, \\dots, {\\bf v}_N^\\ast \\otimes {\\bf v}_N \\right] = {\\bf V}^\\ast \\odot {\\bf V}.\n\\]\n\nHere \\(\\otimes\\) denote the Kronecker matrix product and \\(\\odot\\) denote the Khatri-Rao matrix product.\n\nUsing the sample covariance matrix \\(\\hat{\\bf C}_{\\bf x}\\) as an estimate of \\({\\bf C}_{\\bf x}\\), we can match the estimated covariance vector \\(\\hat{\\bf c}_{\\bf x}=\\text{vec}(\\hat{\\bf C}_{\\bf x})\\) to the true covariance vector \\({\\bf c}_{\\bf x}\\) in the LS sense as\n\\[\n\\hat{\\bf p}_{ls} = \\underset{\\bf p}{\\operatorname{argmin}} \\|\\hat{\\bf c}_{\\bf x}-{\\bf G}_{np}{\\bf p}\\|_2^2=({\\bf G}_{np}^H{\\bf G}_{np})^{-1}{\\bf G}_{np}^H\\hat{\\bf c}_{\\bf x}.\n\\]\nIn other words, the LS estimator minimizes the squared error \\(\\text{tr}\\left[\\big(\\hat{\\bf C}_{\\bf x} − \\hat{\\bf C}_{\\bf x}({\\bf p})\\big)^T \\big(\\hat{\\bf C}_{\\bf x} − \\hat{\\bf C}_{\\bf x}({\\bf p})\\big)\\right]\\). From expression \\(\\hat{\\bf p}_{ls} = \\underset{\\bf p}{\\operatorname{argmin}} \\|\\hat{\\bf c}_{\\bf x}-{\\bf G}_{np}{\\bf p}\\|_2^2=({\\bf G}_{np}^H{\\bf G}_{np})^{-1}{\\bf G}_{np}^H\\hat{\\bf c}_{\\bf x}\\) it can be shown that the \\(i\\)th element of \\(\\hat{\\bf p}_{ls}\\) is \\({\\bf v}_i^H \\hat{\\bf C}_{\\bf x} {\\bf v}_i\\). Combining this with Eq.\n\\[\\hat{\\bf p}_{cg}:= \\text{diag}\\left({\\bf V}^H \\hat{\\bf C}_{\\bf x}{\\bf V} \\right):=\\text{diag}\\left[{\\bf V}^H\\big[ \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_r{\\bf x}_r^H\\big]{\\bf V} \\right]\\]\nwe get that the LS estimator \\(\\hat{\\bf p}_{ls}\\) and the correlogram \\(\\hat{\\bf p}_{cg}\\) —and hence the periodogram as well— are all identical estimators. The estimators derived in this subsection do not assume any data distribution and are well suited for cases where the data probability density function is not available. In what follows, we provide performance bounds for these estimators under the condition that the observed signals are Gaussian."
  },
  {
    "objectID": "posts/2022-12-30-STGCN-Toy Example.html",
    "href": "posts/2022-12-30-STGCN-Toy Example.html",
    "title": "[STGCN] Toy Example",
    "section": "",
    "text": "import networkx as nx\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport torch"
  },
  {
    "objectID": "posts/2022-12-30-STGCN-Toy Example.html#data",
    "href": "posts/2022-12-30-STGCN-Toy Example.html#data",
    "title": "[STGCN] Toy Example",
    "section": "data",
    "text": "data\n\nfrom torch_geometric_temporal.dataset import WikiMathsDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = WikiMathsDatasetLoader()\n\ndataset = loader.get_dataset(lags=14)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)"
  },
  {
    "objectID": "posts/2022-12-30-STGCN-Toy Example.html#recurrentgcn",
    "href": "posts/2022-12-30-STGCN-Toy Example.html#recurrentgcn",
    "title": "[STGCN] Toy Example",
    "section": "RecurrentGCN",
    "text": "RecurrentGCN\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h"
  },
  {
    "objectID": "posts/2022-12-30-STGCN-Toy Example.html#learn",
    "href": "posts/2022-12-30-STGCN-Toy Example.html#learn",
    "title": "[STGCN] Toy Example",
    "section": "Learn",
    "text": "Learn\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features=14, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [03:48<00:00,  4.57s/it]"
  },
  {
    "objectID": "posts/2022-12-30-STGCN-Toy Example.html#예제의-차원-조사",
    "href": "posts/2022-12-30-STGCN-Toy Example.html#예제의-차원-조사",
    "title": "[STGCN] Toy Example",
    "section": "예제의 차원 조사",
    "text": "예제의 차원 조사\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([1068, 14])\n\n\n\n1068: number of nodes // 1068개의 노드가 있음\n14: number of features // 하나의 노드에 맵핑된 차원의수\n\n\n_edge_index.shape\n\ntorch.Size([2, 27079])\n\n\n\n_edge_attr.shape\n\ntorch.Size([27079])\n\n\n\n_y.shape\n\ntorch.Size([1068])\n\n\n\n1068: number of nodes\n\n\n_x.shape\n\ntorch.Size([1068, 14])"
  },
  {
    "objectID": "posts/PytorchLightning/2022-11-29-Simple Linear Regression.html",
    "href": "posts/PytorchLightning/2022-11-29-Simple Linear Regression.html",
    "title": "[PytorchLightning] 단순선형회귀",
    "section": "",
    "text": "import torch\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport pytorch_lightning as pl \n\n\nref\nref: https://guebin.github.io/DL2022/posts/II.%20DNN/2022-09-20-3wk-2.html\n\n\nRegression 1: CPU\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2022/main/posts/II.%20DNN/2022-09-22-regression.csv\")\n\n\nx= torch.tensor(df.x).reshape(-1,1).float()\ny= torch.tensor(df.y).reshape(-1,1).float()\n\n\nds = torch.utils.data.TensorDataset(x,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=100)\n\n\nclass NetLO(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.linr = torch.nn.Linear(1,1)\n        self.loss_fn = torch.nn.MSELoss()\n    def forward(self,x):\n        yhat = self.linr(x)\n        return yhat\n    def configure_optimizers(self):\n        optimizr = torch.optim.SGD(self.parameters(), lr=0.1)\n        return optimizr \n    def training_step(self,batch,batch_idx):\n        x,y = batch\n        yhat = self(x)\n        loss = self.loss_fn(yhat,y) \n        return loss \n\n\nnet = NetLO()\n\n\ntrnr = pl.Trainer(max_epochs=1)\n\nGPU available: True (cuda), used: False\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1767: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n  category=PossibleUserWarning,\n\n\n\nnet.linr.bias.data = torch.tensor([-5.0])\nnet.linr.weight.data = torch.tensor([[10.0]])\n\n\ntrnr.fit(net, train_dataloaders=dl) \n\n\n  | Name    | Type    | Params\n------------------------------------\n0 | linr    | Linear  | 2     \n1 | loss_fn | MSELoss | 0     \n------------------------------------\n2         Trainable params\n0         Non-trainable params\n2         Total params\n0.000     Total estimated model params size (MB)\n\n\n\n\n\n`Trainer.fit` stopped: `max_epochs=1` reached.\n\n\n\nnet.linr.weight, net.linr.bias\n\n(Parameter containing:\n tensor([[8.8111]], requires_grad=True),\n Parameter containing:\n tensor([-3.6577], requires_grad=True))\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\nRegression 2: GPU\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2022/main/posts/II.%20DNN/2022-09-22-regression.csv\")\n\n\nx= torch.tensor(df.x).reshape(-1,1).float()\ny= torch.tensor(df.y).reshape(-1,1).float()\n\n\nds = torch.utils.data.TensorDataset(x,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=100)\n\n\nclass NetLO(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.linr = torch.nn.Linear(1,1)\n        self.loss_fn = torch.nn.MSELoss()\n    def forward(self,x):\n        yhat = self.linr(x)\n        return yhat\n    def configure_optimizers(self):\n        optimizr = torch.optim.SGD(self.parameters(), lr=0.1)\n        return optimizr \n    def training_step(self,batch,batch_idx):\n        x,y = batch\n        yhat = self(x)\n        loss = self.loss_fn(yhat,y) \n        return loss \n\n\nnet = NetLO()\n\n\ntrnr = pl.Trainer(max_epochs=1, accelerator='gpu', devices=1)\n\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\n\n\n\nnet.linr.bias.data = torch.tensor([-5.0])\nnet.linr.weight.data = torch.tensor([[10.0]])\n\n\ntrnr.fit(net, train_dataloaders=dl) \n\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n  | Name    | Type    | Params\n------------------------------------\n0 | linr    | Linear  | 2     \n1 | loss_fn | MSELoss | 0     \n------------------------------------\n2         Trainable params\n0         Non-trainable params\n2         Total params\n0.000     Total estimated model params size (MB)\n\n\n\n\n\n`Trainer.fit` stopped: `max_epochs=1` reached.\n\n\n\nnet.linr.weight, net.linr.bias\n\n(Parameter containing:\n tensor([[8.8111]], requires_grad=True),\n Parameter containing:\n tensor([-3.6577], requires_grad=True))\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "신록예찬’s blog",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJan 12, 2023\n\n\n토폴로지\n\n\n신록예찬\n\n\n\n\nJan 11, 2023\n\n\n부등식\n\n\n신록예찬\n\n\n\n\nJan 7, 2023\n\n\n해석학\n\n\n신록예찬\n\n\n\n\nDec 30, 2022\n\n\n[STGCN] Toy Example\n\n\n신록예찬\n\n\n\n\nDec 27, 2022\n\n\n[CGSP] Chap 12.2.1: Power Spectral Density\n\n\n신록예찬\n\n\n\n\nDec 26, 2022\n\n\n[CGSP] Chap 12.2: Weakly Stationary Graph Processes\n\n\n신록예찬\n\n\n\n\nDec 24, 2022\n\n\n[CGSP] Chap 8.3: Discrete Fourier Transform\n\n\n신록예찬\n\n\n\n\nDec 23, 2022\n\n\n[논문리뷰] EbayesThresh: R Programs for Empirical Bayes Thresholding\n\n\n신록예찬\n\n\n\n\nSep 21, 2022\n\n\n[PytorchLightning] 단순선형회귀\n\n\n신록예찬\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "신록예찬3\ngbchoi0814@gmail.com"
  },
  {
    "objectID": "posts/2022-01-07-RealAnalysis.html",
    "href": "posts/2022-01-07-RealAnalysis.html",
    "title": "해석학",
    "section": "",
    "text": "이걸 증명하려면 자연수를 정의하는 페아노공리를 알아야함.\n그리고 그 공리로부터 유도되는 여러가지 자연수 성질중 하나인 자연수 집합은 위로 유계가 아니라는 사실을 알아야함.\n아르키메데스성질: For all \\(x \\in \\mathbb{R}\\) there exists \\(N \\in \\mathbb{N}\\) such that \\(x<N\\).\n\n아무 실수나 잡으면 그 숫자보다 큰 자연수가 존재한다는 의미\n아르키메데스 성질은 완비성공리로부터 증명가능함.\n\n아르키메데스 성질을 이용하면 임의의 \\(\\epsilon\\)보다 작은 \\(\\frac{1}{N}\\)을 항상 잡을수 있다. 즉 모든 \\(\\epsilon>0\\) 에 대하여 \\(0\\leq \\frac{1}{N} < \\epsilon\\) 을 만족하는 \\(N\\)이 항상 존재함을 알 수 있다.\n(예제) 아래를 증명하라.\n\\[\\lim_{n\\to \\infty}\\frac{4n}{2n+1}=2\\]\n(풀이) 모든 \\(\\epsilon>0\\)에 대하여 아래가 항상 성립함을 보이면 된다.\n\\[\\exists N \\in \\mathbb{N} \\quad \\text{such that} \\quad n \\geq N \\Rightarrow 0\\leq \\left |\\frac{4n}{2n+1}-2 \\right|<\\epsilon\\]\n그런데 \\(|\\frac{4n}{2n+1}-2|\\leq \\frac{1}{n}\\) 이므로 우리는 모든 \\(\\epsilon >0\\)에 대하여 아래가 성립함을 보이면 된다.\n\\[\\exists N \\in \\mathbb{N} \\quad \\text{such that} \\quad n \\geq N \\Rightarrow 0\\leq \\frac{1}{n} <\\epsilon\\]\n그런데 \\(n\\geq N\\)이라는 조건하에서는 \\(\\frac{1}{n} \\leq \\frac{1}{N}\\) 이므로 우리는 다시 모든 \\(\\epsilon>0\\)에 대하여 아래가 성립함을 보이면 된다.\n\\[\\exists N \\in \\mathbb{N} \\quad \\text{such that} \\quad 0 \\leq \\frac{1}{N} <\\epsilon\\]\n이러한 \\(N\\)은 아르키메데스의 성질에 의하여 항상 존재한다."
  },
  {
    "objectID": "posts/2022-01-07-RealAnalysis.html#연속의-정의",
    "href": "posts/2022-01-07-RealAnalysis.html#연속의-정의",
    "title": "해석학",
    "section": "연속의 정의",
    "text": "연속의 정의"
  },
  {
    "objectID": "posts/2022-01-07-RealAnalysis.html#thomae-함수",
    "href": "posts/2022-01-07-RealAnalysis.html#thomae-함수",
    "title": "해석학",
    "section": "Thomae 함수",
    "text": "Thomae 함수\n유리수에서는 불연속, 무리수에서는 연속"
  },
  {
    "objectID": "posts/2022-01-07-RealAnalysis.html#디리클레함수",
    "href": "posts/2022-01-07-RealAnalysis.html#디리클레함수",
    "title": "해석학",
    "section": "디리클레함수",
    "text": "디리클레함수\n모든 점에서 불연속인 함수임"
  },
  {
    "objectID": "posts/2022-01-07-RealAnalysis.html#합성함수의-연속",
    "href": "posts/2022-01-07-RealAnalysis.html#합성함수의-연속",
    "title": "해석학",
    "section": "합성함수의 연속",
    "text": "합성함수의 연속\n함수 \\(f(x)\\)와 \\(g(x)\\)가 모두 \\(x=c\\)에서 연속이면 함수 \\((f\\circ g)(x)\\) 혹은 \\((g \\circ f)(x)\\)도 \\(x=c\\)에서 연속이다."
  },
  {
    "objectID": "posts/2022-01-07-RealAnalysis.html#중간값정리-leftrightarrow-완비성공리",
    "href": "posts/2022-01-07-RealAnalysis.html#중간값정리-leftrightarrow-완비성공리",
    "title": "해석학",
    "section": "중간값정리 \\(\\Leftrightarrow\\) 완비성공리",
    "text": "중간값정리 \\(\\Leftrightarrow\\) 완비성공리"
  },
  {
    "objectID": "posts/2022-01-07-RealAnalysis.html#균등연속임을-판단하는-방법",
    "href": "posts/2022-01-07-RealAnalysis.html#균등연속임을-판단하는-방법",
    "title": "해석학",
    "section": "균등연속임을 판단하는 방법",
    "text": "균등연속임을 판단하는 방법\n\n립쉬츠조건: 어떠한 함수 \\(f\\)가 \\(|f(x)-f(u)|\\leq K|x-u|\\)를 만족하면 이러한 함수는 균등연속이다. \\(\\delta=\\frac{\\epsilon}{K}\\) 로만 선택하면 되므로\n\\(f(x)\\)가 연속이라고하자. \\(f(x)\\)의 정의역이 유계폐구간이면 함수 \\(f\\)는 균등연속이라 주장할 수 있다. 만약에 \\(f(x)\\)의 정의역이 개구간이면 구간의 양 끝점에서의 극한이 존재할때 \\(f\\)를 균등연속이라고 주장할 수 있다.\n\\(f(x)\\)가 개구간에서 정의된 경우"
  },
  {
    "objectID": "posts/2022-01-07-RealAnalysis.html#균등연속이-아님을-판단하는-방법",
    "href": "posts/2022-01-07-RealAnalysis.html#균등연속이-아님을-판단하는-방법",
    "title": "해석학",
    "section": "균등연속이 아님을 판단하는 방법",
    "text": "균등연속이 아님을 판단하는 방법\n\n어떠한 \\(\\epsilon_0>0\\)가 존재하여, 내가 \\(\\delta\\)를 어떻게 잡든 \\(|x-u|<\\delta\\) and \\(|f(x)-f(u)|\\geq\\epsilon_0\\) 를 만족하는 \\(x\\)와 \\(u\\)가 존재하면 균등연속이 아니다.\n\\(\\lim_{n\\to\\infty}(x_n-u_n)=0\\) 이지만 \\(|f(x_n)-f(u_n)| \\geq \\epsilon_0\\) 임을 확인하면 균등연속이 아니다. 즉 \\(x\\)축에서는 수렴하는 두개의 수열이 함수를 태우면 수렴하지 않는 경우"
  },
  {
    "objectID": "posts/2022-01-07-RealAnalysis.html#균등연속의-특징",
    "href": "posts/2022-01-07-RealAnalysis.html#균등연속의-특징",
    "title": "해석학",
    "section": "균등연속의 특징",
    "text": "균등연속의 특징\n코시수열을 보존한다. 즉 \\(x_n\\)이 코시수열이고 함수 \\(f\\)가 균등연속이면 \\(f(x_n)\\)역시 코시수열이다.\n연속확장정리: 개구간에서의 균등연속을 사용하고 싶음. \\(f(x)\\)가 개구간 \\((a,b)\\)에서 연속이고 양 끝점, 즉 \\(a\\), \\(b\\)에서의 극한이 존재하면 \\(f(x)\\)는 균등연속이다.\n균등연속의 아이디어: x축에서 수렴하던 어떤애가 y축에서도 수렴했으면 좋겠음. (이게 원래 안되는 건데요, 균등연속일때는 가능합니다)"
  },
  {
    "objectID": "posts/2022-01-07-RealAnalysis.html#모티브",
    "href": "posts/2022-01-07-RealAnalysis.html#모티브",
    "title": "해석학",
    "section": "모티브",
    "text": "모티브\n아래와 같은 합성함수의 미분을 생각하여 보자.4\n\\[(f\\circ g)'(c) = \\lim_{x\\to c}\\frac{f(g(x))-f(g(c))}{x-c}\\]\n(풀이1)\n고등학교 수준에서는 이것을 아래와 같이 쓸 수 있다.\n\\[\\lim_{x\\to c}\\frac{f(g(x))-f(g(c))}{x-c}=\\lim_{x\\to c}\\left(\\frac{f(g(x))-f(g(c))}{g(x)-g(c)}\\frac{g(x)-g(c)}{x-c}\\right)=f'\\big(g(c)\\big)\\cdot g'(c)\\]\n(아쉬움)\n이 증명의 단점은 \\(g(x)-g(c)\\neq 0\\)이라는 조건이 필요하다는 것이다. 이 조건을 제외할 수는 없을까? 그리스 수학자인 카라테오도리(Caratheodory)는 아래와 같은 명제를 발견하였다.\n(명제) \\(f(x)\\) 가 \\(x=c\\) 에서 미분가능하다 \\(\\Longleftrightarrow\\) 적당한 연속함수 \\(\\varphi(x)\\) 가 존재하여 (i) \\(\\varphi(x)\\) 는 \\(x=c\\) 에서 미분가능하고 (ii) \\(f(x)-f(c)=\\varphi(c)(x-c)\\) 이다.\n이것을 이용하면 합성함수의 미분을 다시 풀어보자.\n(풀이2)\n먼저 \\(g(x)\\) 는 \\(x=c\\) 에서 미분가능하다라는 조건은 아래와 같이 표현할 수 있다.\n\n\\(g(x)\\) 가 \\(x=c\\) 에서 미분가능하다 \\(\\Leftrightarrow\\) \\(g(x)-g(c)=\\varphi(c)(x-c)\\)\n\n또한 \\((f\\circ g)(x)=f(g(x))\\) 는 \\(x=g(c)\\) 에서 미분가능하다라는 조건은 아래와 같이 표현할 수 있다.\n\n\\((f\\circ g)(x)\\) 가 \\(x=g(c)\\) 에서 미분가능하다 \\(\\Leftrightarrow\\) \\(f(g(x))-f(g(c))=\\psi(g(c))(g(x)-g(c))\\)\n\n\n#"
  },
  {
    "objectID": "posts/2022-01-07-RealAnalysis.html#체-공리",
    "href": "posts/2022-01-07-RealAnalysis.html#체-공리",
    "title": "해석학",
    "section": "체 공리",
    "text": "체 공리\n- 실수는 더하기와 곱셈이라는 연산이 합리적으로 정리되는 집합이라는 의미"
  },
  {
    "objectID": "posts/2022-01-07-RealAnalysis.html#순서-공리",
    "href": "posts/2022-01-07-RealAnalysis.html#순서-공리",
    "title": "해석학",
    "section": "순서 공리",
    "text": "순서 공리\n- 순서공리에 의하여 부등식이 정의됨\n- 3분성질"
  },
  {
    "objectID": "posts/2023-01-11-Inequality.html",
    "href": "posts/2023-01-11-Inequality.html",
    "title": "부등식",
    "section": "",
    "text": "부등식\n\n(베르누이 부등식) \\(\\forall n \\in N, h>-1 \\Rightarrow (1+h)^n \\geq 1+nh\\)"
  },
  {
    "objectID": "posts/2023-01-07-RealAnalysis.html",
    "href": "posts/2023-01-07-RealAnalysis.html",
    "title": "해석학",
    "section": "",
    "text": "이걸 증명하려면 자연수를 정의하는 페아노공리를 알아야함.\n그리고 그 공리로부터 유도되는 여러가지 자연수 성질중 하나인 자연수 집합은 위로 유계가 아니라는 사실을 알아야함.\n아르키메데스성질: For all \\(x \\in \\mathbb{R}\\) there exists \\(N \\in \\mathbb{N}\\) such that \\(x<N\\).\n\n아무 실수나 잡으면 그 숫자보다 큰 자연수가 존재한다는 의미\n아르키메데스 성질은 완비성공리로부터 증명가능함.\n\n아르키메데스 성질을 이용하면 임의의 \\(\\epsilon\\)보다 작은 \\(\\frac{1}{N}\\)을 항상 잡을수 있다. 즉 모든 \\(\\epsilon>0\\) 에 대하여 \\(0\\leq \\frac{1}{N} < \\epsilon\\) 을 만족하는 \\(N\\)이 항상 존재함을 알 수 있다.\n(예제) 아래를 증명하라.\n\\[\\lim_{n\\to \\infty}\\frac{4n}{2n+1}=2\\]\n(풀이) 모든 \\(\\epsilon>0\\)에 대하여 아래가 항상 성립함을 보이면 된다.\n\\[\\exists N \\in \\mathbb{N} \\quad \\text{such that} \\quad n \\geq N \\Rightarrow 0\\leq \\left |\\frac{4n}{2n+1}-2 \\right|<\\epsilon\\]\n그런데 \\(|\\frac{4n}{2n+1}-2|\\leq \\frac{1}{n}\\) 이므로 우리는 모든 \\(\\epsilon >0\\)에 대하여 아래가 성립함을 보이면 된다.\n\\[\\exists N \\in \\mathbb{N} \\quad \\text{such that} \\quad n \\geq N \\Rightarrow 0\\leq \\frac{1}{n} <\\epsilon\\]\n그런데 \\(n\\geq N\\)이라는 조건하에서는 \\(\\frac{1}{n} \\leq \\frac{1}{N}\\) 이므로 우리는 다시 모든 \\(\\epsilon>0\\)에 대하여 아래가 성립함을 보이면 된다.\n\\[\\exists N \\in \\mathbb{N} \\quad \\text{such that} \\quad 0 \\leq \\frac{1}{N} <\\epsilon\\]\n이러한 \\(N\\)은 아르키메데스의 성질에 의하여 항상 존재한다."
  },
  {
    "objectID": "posts/2023-01-07-RealAnalysis.html#체-공리",
    "href": "posts/2023-01-07-RealAnalysis.html#체-공리",
    "title": "해석학",
    "section": "체 공리",
    "text": "체 공리\n- 실수는 더하기와 곱셈이라는 연산이 합리적으로 정리되는 집합이라는 의미"
  },
  {
    "objectID": "posts/2023-01-07-RealAnalysis.html#순서-공리",
    "href": "posts/2023-01-07-RealAnalysis.html#순서-공리",
    "title": "해석학",
    "section": "순서 공리",
    "text": "순서 공리\n- 순서공리에 의하여 부등식이 정의됨\n- 3분성질"
  },
  {
    "objectID": "posts/2023-01-07-RealAnalysis.html#디리클레함수",
    "href": "posts/2023-01-07-RealAnalysis.html#디리클레함수",
    "title": "해석학",
    "section": "디리클레함수",
    "text": "디리클레함수\n모든 점에서 불연속인 함수임"
  },
  {
    "objectID": "posts/2023-01-07-RealAnalysis.html#thomae-함수",
    "href": "posts/2023-01-07-RealAnalysis.html#thomae-함수",
    "title": "해석학",
    "section": "Thomae 함수",
    "text": "Thomae 함수\n유리수에서는 불연속, 무리수에서는 연속"
  },
  {
    "objectID": "posts/2023-01-07-RealAnalysis.html#합성함수의-연속",
    "href": "posts/2023-01-07-RealAnalysis.html#합성함수의-연속",
    "title": "해석학",
    "section": "합성함수의 연속",
    "text": "합성함수의 연속\n함수 \\(f(x)\\)와 \\(g(x)\\)가 모두 \\(x=c\\)에서 연속이면 함수 \\((f\\circ g)(x)\\) 혹은 \\((g \\circ f)(x)\\)도 \\(x=c\\)에서 연속이다."
  },
  {
    "objectID": "posts/2023-01-07-RealAnalysis.html#중간값정리-leftrightarrow-완비성공리",
    "href": "posts/2023-01-07-RealAnalysis.html#중간값정리-leftrightarrow-완비성공리",
    "title": "해석학",
    "section": "중간값정리 \\(\\Leftrightarrow\\) 완비성공리",
    "text": "중간값정리 \\(\\Leftrightarrow\\) 완비성공리"
  },
  {
    "objectID": "posts/2023-01-07-RealAnalysis.html#균등연속임을-판단하는-방법",
    "href": "posts/2023-01-07-RealAnalysis.html#균등연속임을-판단하는-방법",
    "title": "해석학",
    "section": "균등연속임을 판단하는 방법",
    "text": "균등연속임을 판단하는 방법\n\n립쉬츠조건: 어떠한 함수 \\(f\\)가 \\(|f(x)-f(u)|\\leq K|x-u|\\)를 만족하면 이러한 함수는 균등연속이다. \\(\\delta=\\frac{\\epsilon}{K}\\) 로만 선택하면 되므로\n\\(f(x)\\)가 연속이라고하자. \\(f(x)\\)의 정의역이 유계폐구간이면 함수 \\(f\\)는 균등연속이라 주장할 수 있다. 만약에 \\(f(x)\\)의 정의역이 개구간이면 구간의 양 끝점에서의 극한이 존재할때 \\(f\\)를 균등연속이라고 주장할 수 있다.\n\\(f(x)\\)가 개구간에서 정의된 경우"
  },
  {
    "objectID": "posts/2023-01-07-RealAnalysis.html#균등연속이-아님을-판단하는-방법",
    "href": "posts/2023-01-07-RealAnalysis.html#균등연속이-아님을-판단하는-방법",
    "title": "해석학",
    "section": "균등연속이 아님을 판단하는 방법",
    "text": "균등연속이 아님을 판단하는 방법\n\n어떠한 \\(\\epsilon_0>0\\)가 존재하여, 내가 \\(\\delta\\)를 어떻게 잡든 \\(|x-u|<\\delta\\) and \\(|f(x)-f(u)|\\geq\\epsilon_0\\) 를 만족하는 \\(x\\)와 \\(u\\)가 존재하면 균등연속이 아니다.\n\\(\\lim_{n\\to\\infty}(x_n-u_n)=0\\) 이지만 \\(|f(x_n)-f(u_n)| \\geq \\epsilon_0\\) 임을 확인하면 균등연속이 아니다. 즉 \\(x\\)축에서는 수렴하는 두개의 수열이 함수를 태우면 수렴하지 않는 경우"
  },
  {
    "objectID": "posts/2023-01-07-RealAnalysis.html#균등연속의-특징",
    "href": "posts/2023-01-07-RealAnalysis.html#균등연속의-특징",
    "title": "해석학",
    "section": "균등연속의 특징",
    "text": "균등연속의 특징\n코시수열을 보존한다. 즉 \\(x_n\\)이 코시수열이고 함수 \\(f\\)가 균등연속이면 \\(f(x_n)\\)역시 코시수열이다.\n연속확장정리: 개구간에서의 균등연속을 사용하고 싶음. \\(f(x)\\)가 개구간 \\((a,b)\\)에서 연속이고 양 끝점, 즉 \\(a\\), \\(b\\)에서의 극한이 존재하면 \\(f(x)\\)는 균등연속이다.\n균등연속의 아이디어: x축에서 수렴하던 어떤애가 y축에서도 수렴했으면 좋겠음. (이게 원래 안되는 건데요, 균등연속일때는 가능합니다)"
  },
  {
    "objectID": "posts/2023-01-07-RealAnalysis.html#모티브",
    "href": "posts/2023-01-07-RealAnalysis.html#모티브",
    "title": "해석학",
    "section": "모티브",
    "text": "모티브\n아래와 같은 합성함수의 미분을 생각하여 보자.4\n\\[(f\\circ g)'(c) = \\lim_{x\\to c}\\frac{f(g(x))-f(g(c))}{x-c}\\]\n(풀이1)\n고등학교 수준에서는 이것을 아래와 같이 쓸 수 있다.\n\\[\\lim_{x\\to c}\\frac{f(g(x))-f(g(c))}{x-c}=\\lim_{x\\to c}\\left(\\frac{f(g(x))-f(g(c))}{g(x)-g(c)}\\frac{g(x)-g(c)}{x-c}\\right)=f'\\big(g(c)\\big)\\cdot g'(c)\\]\n(아쉬움)\n이 증명의 단점은 \\(g(x)-g(c)\\neq 0\\)이라는 조건이 필요하다는 것이다. 이 조건을 제외할 수는 없을까? 그리스 수학자인 카라테오도리(Caratheodory)는 아래와 같은 명제를 발견하였다.\n(명제) \\(f(x)\\) 가 \\(x=c\\) 에서 미분가능하다 \\(\\Longleftrightarrow\\) 적당한 연속함수 \\(\\varphi(x)\\) 가 존재하여 (i) \\(\\varphi(x)\\) 는 \\(x=c\\) 에서 미분가능하고 (ii) \\(f(x)-f(c)=\\varphi(c)(x-c)\\) 이다.\n이것을 이용하면 합성함수의 미분을 다시 풀어보자.\n(풀이2)\n먼저 \\(g(x)\\) 는 \\(x=c\\) 에서 미분가능하다라는 조건은 아래와 같이 표현할 수 있다.\n\n\\(g(x)\\) 가 \\(x=c\\) 에서 미분가능하다 \\(\\Leftrightarrow\\) \\(g(x)-g(c)=\\varphi(c)(x-c)\\)\n\n또한 \\((f\\circ g)(x)=f(g(x))\\) 는 \\(x=g(c)\\) 에서 미분가능하다라는 조건은 아래와 같이 표현할 수 있다.\n\n\\((f\\circ g)(x)\\) 가 \\(x=g(c)\\) 에서 미분가능하다 \\(\\Leftrightarrow\\) \\(f(g(x))-f(g(c))=\\psi(g(c))(g(x)-g(c))\\)\n\n\n#"
  },
  {
    "objectID": "posts/2022-01-12-Topology.html",
    "href": "posts/2022-01-12-Topology.html",
    "title": "토폴로지",
    "section": "",
    "text": "About this doc\n- 수학공부\n- 학부수준\n- 이 문서는 논문을 읽을때 등장하는 topology 용어들을 좀더 명확하게 이해하고 싶어서 작성하였다. 가볍게 정의만 훑어보는 것이라 깊게 들어가지는 않을 예정이다. 교재는 Schaum’s General Topology 를 참고하였다. - Lipschutz, S. (1965). Schaum’s outline of theory and problems of general topology. Schaum’s Outline Series.\n- 여기에서는 토폴로지의 정의와 메트릭스페이스의 정의 그리고 컴플리션의 정의에 대하여 다룬다.\n\n\n토폴로지\n- \\({\\cal T}\\) 가 \\(X\\) 의 subset 으로 이루어진 collection 이라고 하자. \\({\\cal T}\\) 가 \\(X\\) 를 포함하며 uncountable union 에 닫혀있고 finite intersection 에 닫혀있다면 \\({\\cal T}\\) 를 \\(X\\) 의 topology 라고 한다. 그리고 \\((X,{\\cal T})\\) 를 topological space 라고 한다.\n- \\({\\cal T}\\) 가 \\(X\\)의 토플로지일때 \\({\\cal T}\\) 의 원소를 \\({\\cal T}\\)-open set 이라고 한다. 따라서 원래 오픈셋은 마치 확률변수처럼 단독으로 정의할 수 없고 어떠한 토폴로지 \\({\\cal T}\\)와 같이 정의된다.\n- 아래와 같은 collection 을 생각하자.\n\\[{\\cal O}:=\\{O: O=\\cup_i(a_i,b_i), a_i,b_i \\in \\mathbb{R} \\} \\]\n컬렉션 \\({\\cal O}\\) 는 \\(\\mathbb{R}\\) 의 토폴로지가 된다. (증명은 알아서..) 이러한 토폴로지(=오픈인터벌의 카운터블-유니온으로 표현가능한 집합들의 모임)을 특별히 usual topology 라고 한다. 그리고 이 토폴로지의 원소를 \\({\\cal O}\\)-오픈셋이라고 부른다. 따라서 어떤 집합 \\(O\\) 가 \\({\\cal O}\\)-오픈셋 이라는 말은 그 집합이 오픈인터벌의 카운터블-유니온으로 표현가능한 집합임을 의미한다.\n- 참고로 \\({\\cal O}\\) 가 우리가 일반적으로 생각하는 ‘오픈셋들의 모임’ 이고 \\({\\cal O}\\)-오픈셋이 보통 우리가 일반적으로 유클리드 공간에서 상상하는 오픈셋이다. 그래서 앞으로 특별한 언급없이 그냥 ‘오픈셋’ 이라고 부르면 토폴로지 \\((\\mathbb{R},{\\cal O})\\) 에서 정의가능한 ‘\\({\\cal O}\\)-오픈셋’ 을 의미하는 것이라고 생각하면 된다.\n- 즉 우리가 일반적으로 생각하는 오픈셋1은 오픈인터벌 \\((a,b)\\) 의 countable-many union 으로 표현가능한 집합이라고 이해해도 된다.\n- 오픈셋 \\(O\\)의 원소를 interior point of \\(O\\) 라고 한다. \\({\\cal O}\\)의 정의에 의해서 인테리어포인트는 모두 아래의 성질을 만족한다.\n\\[\\forall o \\in O ~ \\exists a,b \\in \\mathbb{R}~ st.~  o \\in (a,b)\\]\n증명은 귀류법을 쓰면 쉽게 된다.\n- 저 정리가 생각보다 중요하다. 그리고 이 정리를 나이테정리 라고 기억하자. 이 정리는 \\({\\cal O}\\)-오픈셋이 아닌 일반적인 \\({\\cal T}\\)-오픈셋에 대하여서도 성립한다. 즉 \\((X,{\\cal T})\\)가 위상공간이고 \\(T\\)가 \\({\\cal T}\\)의 임의의 집합이라 하자. \\(T\\)의 임의의 원소 \\(p\\)에 대하여 (1) \\(p\\) 를 포함하지만 (2) \\(T\\) 보다 작은 다른 \\({\\cal T}\\)-오픈셋이 항상 존재한다.\n- 그리고 교재에 따라서는 위와 같은 성질을 만족하는 것을 오픈셋이라고 정의하기도 한다. 이와 같은 논리흐름으로는 오픈인터벌 \\((a,b)\\)를 정의하고 그로부터 인테리어포인트 \\(o\\)와 오픈셋 \\(O\\)를 정의하고 그로부터 토폴로지 \\({\\cal O}\\)를 정의할 수 있다. 하지만 이러한 방식의 contruction 으로는 \\((\\mathbb{R},{\\cal O})\\) 만 만들수있다. 일반적으로는 적당한 \\({\\cal T}\\)가 \\(X\\)의 토폴로지임을 밝히고 그로부터 오픈셋을 정의하고 그 다음 인테리어포인트를 정의하는 식으로 각 요소들을 contruction 한다.\n- 오픈셋의 여집합을 클로즈드셋이라고 한다. 여기서 사람들이 “모든 집합은 오픈셋이거나 클로즈드셋 이어야 한다” 라고 착각하기 쉬운데 사실 그런것은 아니다.\n- 어떠한 construction을 사용하든지 아래의 사실들이 성립한다. 따로 설명을 쓰지 않은 것은 아주 약간의 머리를 쓰면 쉽게 증명할 수 있는 것들이다. (하지만 그냥 받아들이거나 외우는 것이 편하다.) 참고로 아래의 모든 사실들은 보통위상공간 즉 \\((\\mathbb{R},{\\cal O})\\) 를 전제하고 서술한 것이다.\n(1) \\((a,b)\\) 는 오픈셋이다.\n(2) \\(\\mathbb{R}\\) 은 오픈셋이다. 동시에 클로즈드셋이다2.\n(3) \\(\\emptyset\\) 은 오픈셋이다. 동시에 클로즈드셋이다3.\n(4) 오픈셋은 uncountable union 에 닫혀있다. 즉 \\(O_t\\)가 각각 오픈셋일때 \\(\\cup_t O_t\\) 역시 오픈셋이다.\n(5) 오픈셋은 finite intersection 에 닫혀있다. 즉 \\(O_i\\)가 각각 오픈셋이면 \\(\\cap_{i=1}^{n} O_i\\) 역시 오픈셋이다\n(6) 한점 \\(p\\)로 이루어진 집합 \\(\\{p\\}\\)는 오픈셋이 아니다. 이것이 오픈셋이 되려면 \\(\\{p\\}\\)의 모든원소(라고 해봤자 \\(p\\) 밖에 없음)가 내점이어야 하고 \\(p\\)가 \\(\\{p\\}\\)의 내점이려면 \\(p\\)를 포함하는 오픈인터벌 \\((a,b)\\)가 \\(\\{p\\}\\)의 부분집합으로 존재해야하는데 이것이 불가능하기 때문이다. 4\n(7) 오픈셋의 countable-many intersection 은 오픈셋이 아니다. 왜냐하면 \\(\\cap_{n=1}^{\\infty}(-1/n,1/n)=\\{0\\}\\) 인데 \\(\\{0\\}\\)은 오픈셋이 아니기 때문이다.\n\n\n기저\n- 오픈인터벌 \\((a,b)\\)를 적당히 countable-many union 하면 \\(\\mathbb{R}\\) 에 존재하는 어떠한 오픈셋 \\(O\\)도 표현할 수 있다. 이럴때 \\((a,b)\\) 모아놓은 collection \\({\\cal B}:=\\{(a,b): a<b \\in \\mathbb{R}\\}\\) 를 토폴로지 \\({\\cal O}\\)의 base 라고 한다. 이처럼 어떠한 위상공간 \\((X,{\\cal T})\\) 가 있을때 토폴로지 \\({\\cal T}\\) 의 임의의 집합을 \\({\\cal B}\\)의 원소들의 uncountable union 으로 표현가능때 \\({\\cal B}\\)를 \\({\\cal T}\\)의 base 라고 한다. 그리고 추가적으로 base의 모든 원소는 \\({\\cal T}\\)-오픈셋이어야 한다는 조건도 포함된다.\n- 토폴로지 \\({\\cal T}\\)의 base는 유일하지 않다.\n- 아래와 같은 collection을 상상하여 보자.\n\\[\\tilde{\\cal B}:=\\{all~ ray~ in~\\mathbb{R} \\} := \\{(-\\infty,b): b\\in \\mathbb{R} \\} \\cup \\{(a,\\infty): a \\in \\mathbb{R}\\}\\]\n보는 것처럼 \\(\\tilde{\\cal B}\\)는 위상의 정의를 만족한다. 그리고 \\(\\tilde{\\cal B}\\)는 \\({\\cal O}\\)의 base가 아니다. 하지만 \\(\\pi(\\tilde{\\cal B})\\) 는 \\((a,b)\\)를 포함하고 있기에 \\({\\cal O}\\) 의 base가 된다. 여기에서 \\(\\pi(\\tilde{\\cal B})\\) 는 \\(\\tilde{\\cal B}\\) 에 의해서 생성된 가장 작은 \\(\\pi\\)-system 이다.\n- 참고로 \\(\\pi\\)-시스템은 모든 원소가 finite intersection 에 닫혀있는 collection 을 의미한다. 전체집합은 empty intersection 으로 해석할 수 있으므로 모든 파이시스템은 전체집합을 포함한다. 따라서 파이시스템을 정의하면 전체집합을 같이 정의하는것과 마찬가지이다. 따라서 파이시스템 역시 시그마필드와 토폴로지처럼 전체집합과 동시에 정의된다. 그리고 정의에 따라서 임의의 집합에 대한 토폴로지와 시그마필드 모두 파이시스템이 된다.\n- 위에서 예를 든 \\(\\tilde{\\cal B}\\) 와 같이 그것 자체가 어떤 위상 \\({\\cal T}\\) 의 base는 아니지만 \\(\\pi(\\tilde{\\cal B})\\) 는 \\({\\cal T}\\) 의 base가 될때 \\(\\tilde{\\cal B}\\)를 \\({\\cal T}\\)의 subbase 라고 한다.\n- \\(\\tilde{\\cal B}\\) 가 토폴로지 \\({\\cal T}\\)의 subbase이면 \\(\\tilde{\\cal B}\\)로 \\({\\cal T}\\)를 generate 할 수 있다.\n\n\nmetric space\n- \\(d:X \\times X \\to \\mathbb{R}\\) 가 (1) 음이 아니고 (2) 대칭이며 (3) 삼각부등식을 만족하면 집합 \\(X\\) 에서의 metric 이라고 한다. 이때 음이 아닐 조건은\n\\[\\begin{cases}\nd(a,b) > 0 & a \\neq b \\\\\nd(a,b) = 0 & a=b\n\\end{cases}\\]\n이다. 만약에 메트릭의 모든 조건을 만족하는데 \\(d(a,b)=0\\) 인 서로 다른 \\(a,b \\in X\\) 가 존재하는 경우 \\(d\\) 를 pseudometric 이라고 한다.\n- \\(d\\) 을 집합 \\(X\\) 에서의 메트릭이라고 하자. 메트릭이 존재한다는 것은 집합 \\(X\\)의 어떠한 두 원소라도 그 사이의 거리를 잴 수 있다는 말이고 그것은 집합 \\(X\\)의 임의의 점 \\(p\\)에서 아래와 같은 ball 을 정의할 수 있는 말이다.\n\\[S(p,\\delta) := \\{x:d(p,x)<\\delta,x \\in X \\}\\]\n참고로 위와 같은 ball 들을 모은 collection 을 \\({\\cal B}\\)라고 하자. 그리고 \\({\\cal B}\\)의 임의의 원소를 언카운터블-유니온하여 얻을 수 있는 집합들의 모임을 \\({\\cal T}\\)라고 하자. 그러면 (1) \\({\\cal T}\\) 가 \\(X\\) 의 토폴로지임을 보이고 (2) \\({\\cal B}\\)의 모든 원소가 \\({\\cal T}\\)-오픈셋임을 보인다면 \\({\\cal B}\\)는 \\({\\cal T}\\)의 base가 된다고 주장할 수 있다(Thm 8.4). 그런데 (2)는 (1)이 성립하면 자동으로 성립하므로 (1)만 보이면 된다. 그러기 위해서는 아래의 (i)-(iii)을 보이면 된다.\n(i) 우선 \\({\\cal T}\\)가 언카운터블-유니온에 닫혀있음은 associative laws 에 의해서 쉽게 증명된다.\n(ii) 이제 \\({\\cal T}\\)가 파이나이트-인터섹션에 닫혀있음을 보이자. \\({\\cal T}\\)의 임의의 두 원소는 각각 \\({\\cal B}\\)의 언카운터블-유니온으로 표현가능하다. 가령 예를들어 임의의 \\(T,S \\in {\\cal T}\\) 가 아래와 같이 표현되었다고 치자.\n\\[T=\\bigcup_{t\\in [0,1]}B_{t}, \\quad S=\\bigcup_{s\\in [2,3]}B_{s}\\]\n따라서 \\(T\\cap S\\) 는 distributive laws 에 의해서 아래와 같이 표현가능하다.\n\\[T \\cap S = \\bigcup_{(t,s) \\in [0,1]\\times[2,3]} B_t \\cap B_s \\]\n(i)에 의해서 \\(B_t \\cap B_s\\)가 \\({\\cal T}\\)의 원소이기만 하면 \\(T \\cap S\\) 역시 \\({\\cal T}\\)의 원소가 되는 구조라 (ii)가 증명된다. 따라서 이제 우리가 할일은 \\(B_t\\cap B_s\\)가 \\({\\cal T}\\)의 원소임을 보이는 것이고 이것은 \\(B_t \\cap B_s\\)가 \\({\\cal B}\\)의 언카운터블-유니온으로 표현가능하다는 조건과 동치이다. 우선 \\(B_t \\cap B_s\\)에 속하는 임의의 원소를 $b^* $ 라고 하자. 이 점에 대하여 나이테정리를 만족시키는 ball이 존재한다. 즉\n\\[\\exists S(b^* ,\\delta)~ st. ~ S(b^* ,\\delta) \\subset B_t \\cap B_s\\]\n이다(Lemma 8.3). 그런데 \\(B_t \\cap B_s\\)의 모든점에서 이런식으로 나이테정리를 만족하는 ball을 잡을 수 있다. 이러한 ball들의 합집합을\n\\[\\bigcup_{b^* \\in (B_t \\cap B_s)} S(b^* , \\delta)\\]\n이라고 하자. 자명하게 이 집합은 \\(B_t\\cap B_s\\) 보다 작다(부분집합들의 합이므로). 하지만 \\(B_t\\cap B_s\\)의 모든 원소는 이 집합에 포함되므로 이 집합은 \\(B_t\\cap B_s\\)보다 크다. 따라서\n\\[\\bigcup_{b^* \\in (B_t \\cap B_s)} S(b^* , \\delta)=B_t \\cap B_s\\]\n이 성립한다.\n(iii) \\({\\cal T}\\)가 \\(X\\)를 포함한다는 것을 보이는것은 볼의 반지름을 크게 만들면 쉽게 증명할 수 있다.\n- 참고로 위의 (i)-(iii)을 요약하면 (1) \\(X\\)가 \\({\\cal B}\\)의 언카운터블 유니온으로 표현가능하고 (2) \\({\\cal B}\\)의 임의의 두 원소가 \\({\\cal B}\\)의 언카운터블 유니온으로 표현가능하기만 하면 볼들이 집합이 아니라 어떠한 \\({\\cal B}\\)라도 특정 토폴로지의 base라고 주장할 수 있다. 이것이 교재의 Thm 6.1 이다.\n- 아무튼 위의 과정을 거치면 \\(X\\)위에서 거리를 정의할 수 있을때 그 거리에 의해서 ball을 정의할 수 있고 ball들의 콜렉션을 base \\({\\cal B}\\)로 정의하고 \\({\\cal B}\\) 원소들의 언카운터블-유니온으로 표현가능한 집합모임을 토폴로지 \\({\\cal T}\\)로 정의해도 논리적모순점이 없다. 즉 \\(X\\)에서 메트릭이 정의되기만 하면 그것에 의해서 순차적으로 토폴로지 \\({\\cal T}\\)를 자연스럽게 유도할 수 있는데 이러한 토폴로지를 특별히 \\(X\\)와 \\(d\\)에 의해서 유도된 metric topology 라고 한다. 그리고 \\((X,d)\\)를 metric-space 라고 한다.\n- \\(\\mathbb{R}\\)에서 \\({\\cal O}\\)를 유도하는 메트릭은 우리가 보통 생각하는 유클리드거리이다. 이러한 메트릭을 usual metric 이라고 한다.\n- \\(\\mathbb{R}\\)에서 아래와 같은 거리를 정의할 수 있다.\n\\[d(a,b)=\\begin{cases}\n0 & a=b \\\\\n1 & a\\neq b\n\\end{cases}\\]\n이러한 거리를 trivial metric 이라고 한다. 그리고 이 거리가 유도하는 토폴로지는 \\(2^{\\mathbb{R}}\\) 이다. (아 몰라.. 따지기 싫어.. 그냥 외워..)\n- 만약에 집합 \\(X\\)에서 정의된 2개의 메트릭 \\(d_1\\), \\(d_2\\)가 같은 토폴로지를 유도한다면 두 메트릭 \\(d_1\\)과 \\(d_2\\)는 equivalent 하다고 말한다.\n- 토폴로지컬-스페이스 \\((X,{\\cal T})\\) 가 있다고 하자. 그런데 \\(X\\) 에서 어떠한 메트릭 \\(d\\)가 존재해 그것이 \\({\\cal T}\\)를 유도하였다고 하자. 그럼 \\({\\cal T}\\)는 메트릭-토폴로지가 된다. 이와 같이 (1) \\(X\\)에서 정의되고 (2) 메트릭-토폴로지 \\({\\cal T}\\)를 유도하는 적당한 메트릭 \\(d\\)가 명시된것은 아니지만 그런 메트릭의 존재를 하나 이상 우리가 알고 있을때 위상공간 \\((X,{\\cal T})\\)를 metrizable 하다고 한다.\n- 두 메트릭스페이스 \\((X,d_1)\\) 와 \\((Y,d_2)\\) 가 isometric 하다는 것은 아래가 만족하는 one-one, onto 인 \\(f:X \\to Y\\) 가 존재한다는 것이다.\n\\[d_1(p,q) = d_2(f(p),f(q))\\]\n- 이때 isometric 이라는 relation 은 보는것 처럼 모든 메트릭공간들의 집합 \\({\\cal M}\\)에서 equivalence relation 이다. 즉 아래가 성립한다.\n(i) \\((X,d_1) \\overset{ism}{\\sim} (X,d_1)\\),\n(ii) \\((X,d_1) \\overset{ism}{\\sim} (Y,d_2)\\) implies \\((Y,d_2) \\overset{ism}{\\sim} (X,d_1)\\),\n(iii) \\((X,d_1) \\overset{ism}{\\sim} (Y,d_2)\\) and \\((Y,d_2) \\overset{ism}{\\sim} (Z,d_3)\\) imply \\((X,d_1) \\overset{ism}{\\sim} (Z,d_3)\\).\n\n\ncomplete metric space\n- convergent sequence 은 단독으로 정의될 수 없으며 위상공간 \\((X,{\\cal T})\\) 와 묶어서 정의된다. 그리고 Cauchy sequence 역시 단독으로 정의될 수 없으며 메트릭스페이스 \\((X,d)\\) 와 묶어서 정의된다.\n- convergent sequence 와 Cauchy sequence 는 비슷해보이지만 미묘하게 다른점이 있다.\n(1) 컨버전트-시컨트는 위상공간 \\((X,{\\cal T})\\) 만 있으면 정의할 수 있지만 코시수열은 그 위상공간이 메트릭스페이스 이어야 한다는 제약이 있다. 왜냐하면 컨버전트-시컨스의 정의에는 오픈셋만 필요하지만 코시수열은 볼이 필요하고 볼은 메트릭에 의해서만 정의되기 때문이다.\n(2) 컨버전트-시컨스와 코시수열 모두 열의 각 항이 \\(X\\)의 원소이어야 한다는 조건이 있다. 하지만 컨버전트-시컨스는 그 limit 까지 \\(X\\)의 원소이어야 하는데 코시수열은 그렇지 않다는 차이점이 있다.\n- \\(X=(0,1)\\) 위의 usual metric 에 의해서 유도되는 메트릭스페이스 \\((X,d)\\) 를 생각하자. 수열\n\\[\\big\\{\\frac{1}{2},\\frac{1}{3},\\frac{1}{4},\\dots,\\big\\}\\]\n\\(X\\)에서 정의된 코시수열이지만 \\(X\\)에서 정의되는 컨버전트-시컨스는 아니다.\n- 내가 이해한 바는 아래와 같다.\n(1) 토폴로지 \\((X,{\\cal T})\\) 는 항상 컨버전트-시컨스를 준비가 되어있는 공간이다.\n(2) 위에서 정의가능한 컨버전트-시컨스는 코시수열과 아무런 관련이 없다. 그리고 우리가 통상적으로 고등학교때부터 다루어왔던 수열의 수렴의 개념과도 거리가 멀다.\n(3) 토폴로지 \\((X,{\\cal T})\\) 가 메트릭스페이스라면 컨버전트-시컨스는 코시수열과 어떤관계가 있으며 고등학교때부터 내가 다루어 왔던 상식적인 수렴하는 수열의 개념과도 관련이 있다.\n(4) \\((X,{\\cal T})\\) 가 메트릭스페이스 라고 가정하자. 그럼 아래가 만족한다고 생각할 수 있다.\n\n\\(\\{a_n\\}\\) converges on \\(X\\) \\(\\Longleftrightarrow\\) \\(\\{a_b\\}\\) is Cauchy sequence on \\(X\\) and \\(\\lim_{n\\to\\infty} a_n \\in X\\)\n\n즉 러프하게 말해서 \\(X\\)에서의 컨버전트-시컨스는 (i) \\(X\\)에서의 코시수열이면서 (ii) limit 이 \\(X\\)에 포함되는 수열이라고 말할 수 있다. 이런 정의로 치면 우리가 고등학교때부터 생각해왔던 소박한 정의의 수렴하는 수열은 사실 코시수열에 가깝고 컨버전트-시컨스는 고등학교때부터 배운 소박한 수렴을 하며 동시에 수렴값이 \\(X\\)이 잘 정의되는 수열을 의미한다고 볼 수 있다. 앞으로는 소박한 수렴과 컨버전트-시컨스를 엄밀하게 구분하여 말하도록 하자. 즉 \\(\\{a_n\\}\\)이 코시수열이라는 말은 \\(\\{a_n\\}\\)이 소박한 수렴을 한다는 의미이고 \\(\\{a_n\\}\\)이 컨버전트-시컨스라는 의미는 \\(\\{a_n\\}\\)이 소박한수렴을 하며 동시에 그 극한값이 well-define 된다는 의미(=\\(\\{a_n\\}\\)의 수렴값이 \\(X\\)의 원소라는 의미)이다.\n- (proposition 14.1) 메트릭스페이스 한정으로, 컨버전트-시컨스는 모두 코시수열이다. (당연한 소리를.. 이런걸 proposition 이라고..)\n- 당연히 위 정리의 역은 성립하지 않는다. 즉 메트릭스페이스 \\((X,{\\cal T})\\) 에서 정의된 코시수열이 반드시 컨버전트-시컨스라는 보장은 없다. (이것도 당연한 소리.. 왜냐하면 수렴값이 \\(X\\)에 포함된다는 보장이 없기 때문) 하지만 그 메트릭스페이스가 complete 하다면 위 정리의 역도 성립한다.\n- 컴플리트하지 않은 메트릭스페이스 \\((X,d)\\)를 컴플리트한 메트릭스페이스 \\((X^* , d)\\) 로 바꿀 수 없을까? 유주얼메트릭(usual metric) \\(d\\) 와 \\(X=(0,1)\\) 로 만들어지는 메트릭스페이스는 컴플리트하지 않지만 \\(d\\) 와 \\(X^* =[0,1]\\) 로 만들어지는 메트릭스페이스는 컴플리트하다. 이런 경우 $(X^* ,d) $ 는 \\((X,d)\\) 의 completion 이라고 한다.\n- 즉 아래의 조건들을 만족하면 $(X^* ,d) $ 는 \\((X,d)\\) 의 completion 이라고 부른다.\n(1) \\(X\\subset X^*\\)\n(2) \\((X^* ,d)\\) is complete metric space\n(3) \\((X,d) \\overset{ism}{\\sim} (X^* ,d)\\).\n- 메트릭스페이스 \\((X,d)\\)에서 아래의 식을 만족하는 두 코시수열 \\(\\{a_n\\}\\), \\(\\{\\tilde a_n\\}\\) 을 생각하여보자.\n\\[\\lim_{n\\to\\infty} d(a_n,\\tilde a_n)=0 \\]\n이러한 코시수열들을\n\\[\\{a_n\\} \\overset{slim}{\\sim} \\{\\tilde a_n\\}\\]\n이라고 표현하자. 이때 관계 \\(\\overset{slim}{\\sim}\\) 은 \\(X\\)에서 정의가능한 모든 코시수열들의 집합 \\({\\cal C}_ X\\) 에서 equivalence relation 이 된다고 한다. (증명은 알아서) 따라서 이걸 이용하면 거리공간에서 \\(slim\\) 의 관계를 가지는 임의의 두 수열은 같은 극한을 가진다는 결론이 나온다. (이것도 잘 따져보자.)\n- 잠시 (1) 바이너리-릴레이션(binary relation), (2) 이퀴배런스-릴레이션(equivalence relation), (3) 이퀴배런스-클래스(equivalence class) 그리고 (4) 코션트셋(quotient set)에 대하여 설명하고 넘어가겠다.\n(1) 집합 \\({\\cal C}_ X\\) 의 두 원소 \\(\\{a_n\\}\\), \\(\\{b_n\\}\\) 간 바이너리-릴레이션 \\(R\\)이 존재한다는 문장은 집합론적인 언어로 표현가능하다. 구체적으로는 \\(R\\)을 곱집합 \\({\\cal C}_ X \\times {\\cal C}_ X\\) 의 적당한 부분집합으로 설정하고 순서쌍 \\(\\big(\\{a_n\\},\\{b_n\\}\\big)\\) 이 \\(R\\) 의 원소라는 식으로 표현한다. 예를 들면 아래와 같은 식으로 말이다.\n$ {a_n} and {b_n} has arelation with~ R \\ ({a_n},{b_n}) R _ X _ X \\ {a_n} {b_n}$\n(2) 그리고 \\({\\cal C}_ X\\) 위에서의 바이너리-릴레이션 \\(R\\)이 (i) reflexivity (ii) symmetricity (iii) transitivity 를 만족하면 이 릴레이션을 특별히 이퀴배런스-릴레이션 이라고 말한다.\n(3) 그리고 아래와 같이 \\({\\cal C}_ X\\) 에서 \\(\\{a_n\\}\\) 과 이퀴배런스-릴레이션을 가지는 원소들을 모아놓은 집합을 생각할 수 있다. \\[\\big[\\{a_n\\}\\big]_ R:=\\big\\{ \\{x_n\\} : \\{x_n\\} \\overset{R}{\\sim} \\{a_n\\} ~and~ \\{x_n\\} \\in {\\cal C}_ X \\big\\}\\]\n이 집합을 \\(\\{a_n\\}\\)의 equivalence class on \\({\\cal C}_ X\\) by \\(R\\) 이라고 부른다. 보통은 \\(R\\)을 생략하여 \\(\\big[\\{a_n\\}\\big]\\)와 같이만 표현하지만 나는 기호의 명확성을 위해서 관계까지 명시하였다.\n(4) 이퀴배런스-클래스는 본질적으로 파티션과 밀접한 연관이 있다. 여기에서 클래스 \\({\\cal P}_ A\\) 가 집합 \\(A\\)의 파티션이란 의미는 클래스 \\({\\cal P}_ A\\) 에 속한 모든 원소의 합이 \\(A\\) 이며 클래스 \\({\\cal P}_ A\\) 의 각 원소는 서로 배타적이라는 의미이다. 이퀴배런스-클래스가 그럼 왜 파티션과 관련이 있을까? 그것은 어떠한 집합에서 이퀴배런스-릴레이션이 존재하면 그 집합을 배타적인 이퀴배런스-클래스의 합집합으로 표현가능하기 때문이다. 즉 이퀴배런스-릴레이션 혹은 이퀴배런-클래스의 존재는 파티션의 존재를 임플라이 한다. 그리고 이러한 파티션을 이퀴배런스-릴레이션 \\(R\\)에 의해 생성된 quotient set 혹은 quotient space 라고 한다. 관계 \\(R\\)에 의한 \\(A\\)의 코션트 셋은 기호로 \\(A ~\\overset{R}{\\sim}\\) 와 같이 쓴다. 예를들어 \\[\\begin{align}\n{\\cal C}_ X ~ /\\overset{slim}{\\sim}\n\\end{align}\\] 은 집합 \\(X\\) 상에서 존재하는 코시수열들의 집합 \\({\\cal C}_ X\\) 에서 이퀴배런스-릴레이션 \\(slim\\) 에 의해서 생성된 코션트셋을 의미한다.\n\n\n\n\n\nFootnotes\n\n\n정확하게는 \\(\\cal O\\)-오픈셋↩︎\n공집합이 오픈셋이므로↩︎\n\\(\\mathbb{R}\\)이 오픈셋이므로↩︎\n다만 이것은 위상공간을 \\((\\mathbb{R},{\\cal O})\\)로 생각하였을때 이야기이고 위상공간을 \\((\\mathbb{R},2^{\\mathbb{R}})\\)로 생각한다면 \\(\\{p\\}\\) 도 오픈셋이 된다.↩︎"
  }
]