[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "신록예찬's Blog",
    "section": "",
    "text": "About this blog\nThis blog was created for my personal research, study and lecture preparation. Therefore, the contents of the blog can be thought of as my practice notes. As a result, sometimes the content of a post may be left unstructured or unfinished. The blog is named after my favorite essay ‘신록예찬’, which is also a nickname I use informally. You can check the written article in the sidebar on the left. It is a great honor for me if these posts can help others to learn and research.\n\nSome links that help me\n\nfirst batchsecond batchthird batchlectures notes\n\n\n\npaperswithcode: https://paperswithcode.com/\n\n\n\n\nmatplotlib: https://matplotlib.org/stable/gallery/index.html\njupyterlab: https://jupyterlab.readthedocs.io/en/stable/index.html\npandas: https://pandas.pydata.org/docs/user_guide/index.html#user-guide\njulia: https://docs.julialang.org/en/v1/\nkeras: https://keras.io/examples/\njulia plots: https://docs.juliaplots.org/stable/\npytorch lightning: https://www.pytorchlightning.ai/\nplotly: https://plotly.com/graphing-libraries/\nquarto: https://quarto.org/\nAutoGluon: https://auto.gluon.ai/stable/index.html\n\n\n\n\nlatex: https://editor.codecogs.com/\ntable: https://www.tablesgenerator.com/\npytorch lightning (codes in book): https://github.com/PacktPublishing/Deep-Learning-with-PyTorch-Lightning\nPyG: https://github.com/rusty1s/pytorch_geometric\nrayshader: https://www.rayshader.com/reference/plot_gg.html\nSouth Korea (map): https://github.com/southkorea\nregexp: https://zvon.org/comp/m/regexp.html\nrpy2: https://rpy2.github.io/doc/v3.1.x/html/index.html\npywave: https://pywavelets.readthedocs.io/en/latest/ref/wavelets.html\nPyGSP: https://pygsp.readthedocs.io/en/stable/#\nlatex (neural networks): https://tikz.net/neural_networks/\nplotly overview: https://plotly.com/python/plotly-express/\nfastai (official): https://docs.fast.ai/\nfastai (lecture): https://course.fast.ai/#\nfastai (github codes): https://github.com/fastai/fastai/tree/master/dev_nbs/course\nGML (codes in book): https://github.com/PacktPublishing/Graph-Machine-Learning\nGMLKOR (codes in book): https://github.com/AcornPublishing/graph-ml\nmathNET https://gtribello.github.io/mathNET/index.html\n\n\n\n\nhttp://personal.psu.edu/drh20/asymp/fall2006/lectures/\nhttps://web.ma.utexas.edu/users/gordanz/lecture_notes_page.html\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nNov 9, 2023\n\n\n(자료) 데이터생성 – 성별,몸무게 –&gt; 키\n\n\n신록예찬 \n\n\n\n\nOct 26, 2023\n\n\n(공부) Julia – Vector\n\n\n신록예찬 \n\n\n\n\nOct 25, 2023\n\n\n(공부) Julia – 문자와 문자열\n\n\n신록예찬 \n\n\n\n\nOct 21, 2023\n\n\n(공부&지윤) – Imputer와 Scaler의 적용\n\n\n신록예찬 \n\n\n\n\nOct 12, 2023\n\n\n(연구&재인) MBTI – MBTI\n\n\n신록예찬 \n\n\n\n\nOct 11, 2023\n\n\n(연구&재인) MBTI – 감성분석\n\n\n신록예찬 \n\n\n\n\nSep 24, 2023\n\n\n(공부) – ggraph\n\n\n신록예찬 \n\n\n\n\nSep 14, 2023\n\n\n(연구&서연) IT-STGCN – 논문리비전\n\n\n최서연 \n\n\n\n\nAug 25, 2023\n\n\n[FRAUD] 데이터정리 시도(8.25 df02 커널죽음)\n\n\n김보람 \n\n\n\n\nAug 18, 2023\n\n\n(연구) EPT-DISSIM – PRCP_KOR2 데이터정리\n\n\n신록예찬 \n\n\n\n\nAug 14, 2023\n\n\n(연구&지윤) 태양광자료분석 – GConvLSTM +++++++ 이거!!! ++++++++++++\n\n\nJiyunLim \n\n\n\n\nAug 8, 2023\n\n\n(연구) EPT-DISSIM – 진행사항\n\n\n신록예찬 \n\n\n\n\nAug 7, 2023\n\n\n(연구) EPT-DISSIM – PRCP_KOR 데이터정리\n\n\n신록예찬 \n\n\n\n\nJul 30, 2023\n\n\n[FRAUD] 신용카드 거래 사기탐지 CTGAN 이용 (하다가 말았음)\n\n\n신록예찬 \n\n\n\n\nJul 20, 2023\n\n\n(연구&지윤) 태양광자료분석 – EPT + RGCN (시뮬레이션)\n\n\n신록예찬 \n\n\n\n\nJul 19, 2023\n\n\n(공부) PyG – lesson6: GCN\n\n\n신록예찬 \n\n\n\n\nJul 19, 2023\n\n\n(연구) 보람 – (사기탐지 + 그래프) 관련연구 리뷰\n\n\n신록예찬 \n\n\n\n\nJul 19, 2023\n\n\n[FRAUD] 그래프자료로 데이터정리\n\n\n신록예찬 \n\n\n\n\nJul 17, 2023\n\n\n(연구&지윤) 태양광자료분석 – EPT + RGCN\n\n\n신록예찬 \n\n\n\n\nJul 14, 2023\n\n\n(공부) PyG – lesson5: Learning Methods on Graphs\n\n\n신록예찬 \n\n\n\n\nJul 12, 2023\n\n\n(공부) PyG – lesson3: 미니배치\n\n\n신록예찬 \n\n\n\n\nJul 12, 2023\n\n\n(공부) PyG – lesson4: Data Transform???\n\n\n신록예찬 \n\n\n\n\nJul 7, 2023\n\n\n(공부) PyG – lesson2: 벤치마크 데이터셋 (train/test분리)\n\n\n신록예찬 \n\n\n\n\nJul 7, 2023\n\n\n(연구) 다중척도방법\n\n\n신록예찬 \n\n\n\n\nJul 4, 2023\n\n\n(공부) – 토폴로지\n\n\n신록예찬 \n\n\n\n\nJul 2, 2023\n\n\n(공부) PyG – lesson1: 자료형\n\n\n신록예찬 \n\n\n\n\nJul 1, 2023\n\n\n[CTGAN] CTGAN\n\n\n신록예찬 \n\n\n\n\nJul 1, 2023\n\n\n[CTGAN] CTGAN ToyEX\n\n\n신록예찬 \n\n\n\n\nJun 23, 2023\n\n\n(공부&지윤) – 커널리그레션\n\n\n신록예찬 \n\n\n\n\nJun 23, 2023\n\n\n(공부&지윤) – 퓨리에변환(detailed)\n\n\n신록예찬 \n\n\n\n\nJun 23, 2023\n\n\n(공부&지윤) – 퓨리에변환4jy\n\n\n신록예찬 \n\n\n\n\nJun 14, 2023\n\n\n(공부&지윤) – 추정\n\n\n신록예찬 \n\n\n\n\nMay 19, 2023\n\n\n(연구) 보람 – 신용카드거래 사기탐지, Try2\n\n\n신록예찬 \n\n\n\n\nMay 19, 2023\n\n\n[FRAUD] 신용카드 거래 사기탐지 Try2 변형\n\n\n신록예찬 \n\n\n\n\nMay 12, 2023\n\n\n(연구) 보람 – 신용카드거래 사기탐지, Try1\n\n\n신록예찬 \n\n\n\n\nMay 12, 2023\n\n\n[FRAUD] 신용카드 거래 사기탐지 Try1 변형\n\n\n신록예찬 \n\n\n\n\nMay 6, 2023\n\n\n(연구) 보람 – 신용카드거래 사기탐지, Start\n\n\n신록예찬 \n\n\n\n\nApr 27, 2023\n\n\n(연구&서연) IT-STGCN – Toy Example Figure(Intro)\n\n\n최서연 \n\n\n\n\nApr 4, 2023\n\n\n(연구&지윤) 태양광자료분석\n\n\n신록예찬 \n\n\n\n\nApr 3, 2023\n\n\n(연구&지윤) 태양광자료분석 – 일사량자료정리\n\n\n임지윤, 신록예찬\n\n\n\n\nMar 18, 2023\n\n\n(연구&서연) IT-STGCN – SimualtionPlanner-Tutorial\n\n\nSEOYEON CHOI\n\n\n\n\nMar 17, 2023\n\n\n(연구&서연) IT-STGCN – ITSTGCN-Tutorial\n\n\nSEOYEON CHOI\n\n\n\n\nMar 1, 2023\n\n\n(공부&서연) – 지수분포 가설검정\n\n\n신록예찬 \n\n\n\n\nJan 20, 2023\n\n\n(공부) – 추정\n\n\n신록예찬 \n\n\n\n\nJan 15, 2023\n\n\n(공부) CGSP – Chap 12.4: Node Subsampling for PSD Estimation\n\n\n신록예찬 \n\n\n\n\nJan 12, 2023\n\n\n(공부&서연) – 지수분포 평균검정\n\n\n신록예찬 \n\n\n\n\nJan 1, 2023\n\n\n(연구) 지윤 – 0717 면담\n\n\n신록예찬 \n\n\n\n\nDec 30, 2022\n\n\n(연구&서연) IT-STGCN – Toy Example\n\n\n신록예찬 \n\n\n\n\nDec 29, 2022\n\n\n(연구&서연) IT-STGCN – Tables\n\n\n신록예찬 \n\n\n\n\nDec 29, 2022\n\n\n(연구&서연) IT-STGCN – Tutorial\n\n\n신록예찬, 최서연\n\n\n\n\nDec 27, 2022\n\n\n(공부) CGSP – Chap 12.2 ~ 3: Power Spectral Density and its Estimators\n\n\n신록예찬 \n\n\n\n\nDec 26, 2022\n\n\n(공부) CGSP – Chap 12.2: Weakly Stationary Graph Processes\n\n\n신록예찬 \n\n\n\n\nDec 24, 2022\n\n\n(공부) CGSP – Chap 8.3: Discrete Fourier Transform\n\n\n신록예찬 \n\n\n\n\nDec 23, 2022\n\n\n(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes Thresholding\n\n\n신록예찬 \n\n\n\n\nApr 26, 2019\n\n\n(공부) – 퓨리에변환\n\n\n신록예찬 \n\n\n\n\nJan 10, 2000\n\n\n(메모) – DGX station 설정\n\n\n신록예찬 \n\n\n\n\nJan 9, 2000\n\n\n(메모) – docker\n\n\n신록예찬 \n\n\n\n\nJan 8, 2000\n\n\n(메모) – 주피터랩, 설정 및 몇가지 팁\n\n\n신록예찬 \n\n\n\n\nJan 7, 2000\n\n\n(메모) – 줄리아 설치 및 실행\n\n\n신록예찬 \n\n\n\n\nJan 6, 2000\n\n\n(메모) – 깃 익히기\n\n\n신록예찬 \n\n\n\n\nJan 5, 2000\n\n\n(메모) – vi 익히기\n\n\n신록예찬 \n\n\n\n\nJan 4, 2000\n\n\n(메모) – 우분투 익히기\n\n\n신록예찬 \n\n\n\n\nJan 2, 2000\n\n\n(메모) – 우분투 포맷 및 개발용 서버 셋팅2\n\n\n신록예찬 \n\n\n\n\nJan 1, 2000\n\n\n(메모) – 우분투 포맷 및 개발용 서버 셋팅 (old)\n\n\n신록예찬 \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "서연.html",
    "href": "서연.html",
    "title": "서연",
    "section": "",
    "text": "https://github.com/seoyeonc\nhttps://seoyeonc.github.io/sy_hub/\n\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nSep 14, 2023\n\n\n(연구&서연) IT-STGCN – 논문리비전\n\n\n최서연 \n\n\n\n\nApr 27, 2023\n\n\n(연구&서연) IT-STGCN – Toy Example Figure(Intro)\n\n\n최서연 \n\n\n\n\nMar 18, 2023\n\n\n(연구&서연) IT-STGCN – SimualtionPlanner-Tutorial\n\n\nSEOYEON CHOI\n\n\n\n\nMar 17, 2023\n\n\n(연구&서연) IT-STGCN – ITSTGCN-Tutorial\n\n\nSEOYEON CHOI\n\n\n\n\nDec 30, 2022\n\n\n(연구&서연) IT-STGCN – Toy Example\n\n\n신록예찬 \n\n\n\n\nDec 29, 2022\n\n\n(연구&서연) IT-STGCN – Tables\n\n\n신록예찬 \n\n\n\n\nDec 29, 2022\n\n\n(연구&서연) IT-STGCN – Tutorial\n\n\n신록예찬, 최서연\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "DL2022",
      "연구",
      "서연"
    ]
  },
  {
    "objectID": "보람.html",
    "href": "보람.html",
    "title": "보람",
    "section": "",
    "text": "https://github.com/boram-coco\nhttps://boram-coco.github.io/coco/\nhttps://boram-coco.github.io/Scribbling/\n\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nAug 25, 2023\n\n\n[FRAUD] 데이터정리 시도(8.25 df02 커널죽음)\n\n\n김보람 \n\n\n\n\nJul 30, 2023\n\n\n[FRAUD] 신용카드 거래 사기탐지 CTGAN 이용 (하다가 말았음)\n\n\n신록예찬 \n\n\n\n\nJul 19, 2023\n\n\n(연구) 보람 – (사기탐지 + 그래프) 관련연구 리뷰\n\n\n신록예찬 \n\n\n\n\nJul 19, 2023\n\n\n[FRAUD] 그래프자료로 데이터정리\n\n\n신록예찬 \n\n\n\n\nJul 1, 2023\n\n\n[CTGAN] CTGAN\n\n\n신록예찬 \n\n\n\n\nJul 1, 2023\n\n\n[CTGAN] CTGAN ToyEX\n\n\n신록예찬 \n\n\n\n\nMay 19, 2023\n\n\n(연구) 보람 – 신용카드거래 사기탐지, Try2\n\n\n신록예찬 \n\n\n\n\nMay 19, 2023\n\n\n[FRAUD] 신용카드 거래 사기탐지 Try2 변형\n\n\n신록예찬 \n\n\n\n\nMay 12, 2023\n\n\n(연구) 보람 – 신용카드거래 사기탐지, Try1\n\n\n신록예찬 \n\n\n\n\nMay 12, 2023\n\n\n[FRAUD] 신용카드 거래 사기탐지 Try1 변형\n\n\n신록예찬 \n\n\n\n\nMay 6, 2023\n\n\n(연구) 보람 – 신용카드거래 사기탐지, Start\n\n\n신록예찬 \n\n\n\n\n\nNo matching items",
    "crumbs": [
      "DL2022",
      "연구",
      "보람"
    ]
  },
  {
    "objectID": "지윤.html",
    "href": "지윤.html",
    "title": "지윤",
    "section": "",
    "text": "https://github.com/pinkocto\nhttps://pinkocto.github.io/noteda/\nhttps://pinkocto.github.io/Quarto-Blog/\n\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nAug 14, 2023\n\n\n(연구&지윤) 태양광자료분석 – GConvLSTM +++++++ 이거!!! ++++++++++++\n\n\nJiyunLim \n\n\n\n\nJul 20, 2023\n\n\n(연구&지윤) 태양광자료분석 – EPT + RGCN (시뮬레이션)\n\n\n신록예찬 \n\n\n\n\nJul 17, 2023\n\n\n(연구&지윤) 태양광자료분석 – EPT + RGCN\n\n\n신록예찬 \n\n\n\n\nApr 4, 2023\n\n\n(연구&지윤) 태양광자료분석\n\n\n신록예찬 \n\n\n\n\nApr 3, 2023\n\n\n(연구&지윤) 태양광자료분석 – 일사량자료정리\n\n\n임지윤, 신록예찬\n\n\n\n\nJan 1, 2023\n\n\n(연구) 지윤 – 0717 면담\n\n\n신록예찬 \n\n\n\n\n\nNo matching items",
    "crumbs": [
      "DL2022",
      "연구",
      "지윤"
    ]
  },
  {
    "objectID": "자료.html",
    "href": "자료.html",
    "title": "자료",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nNov 9, 2023\n\n\n(자료) 데이터생성 – 성별,몸무게 –&gt; 키\n\n\n신록예찬 \n\n\n\n\n\nNo matching items",
    "crumbs": [
      "DL2022",
      "자료"
    ]
  },
  {
    "objectID": "공부.html",
    "href": "공부.html",
    "title": "공부",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nOct 26, 2023\n\n\n(공부) Julia – Vector\n\n\n신록예찬 \n\n\n\n\nOct 25, 2023\n\n\n(공부) Julia – 문자와 문자열\n\n\n신록예찬 \n\n\n\n\nOct 21, 2023\n\n\n(공부&지윤) – Imputer와 Scaler의 적용\n\n\n신록예찬 \n\n\n\n\nSep 24, 2023\n\n\n(공부) – ggraph\n\n\n신록예찬 \n\n\n\n\nJul 19, 2023\n\n\n(공부) PyG – lesson6: GCN\n\n\n신록예찬 \n\n\n\n\nJul 14, 2023\n\n\n(공부) PyG – lesson5: Learning Methods on Graphs\n\n\n신록예찬 \n\n\n\n\nJul 12, 2023\n\n\n(공부) PyG – lesson4: Data Transform???\n\n\n신록예찬 \n\n\n\n\nJul 12, 2023\n\n\n(공부) PyG – lesson3: 미니배치\n\n\n신록예찬 \n\n\n\n\nJul 7, 2023\n\n\n(공부) PyG – lesson2: 벤치마크 데이터셋 (train/test분리)\n\n\n신록예찬 \n\n\n\n\nJul 4, 2023\n\n\n(공부) – 토폴로지\n\n\n신록예찬 \n\n\n\n\nJul 2, 2023\n\n\n(공부) PyG – lesson1: 자료형\n\n\n신록예찬 \n\n\n\n\nJun 23, 2023\n\n\n(공부&지윤) – 퓨리에변환(detailed)\n\n\n신록예찬 \n\n\n\n\nJun 23, 2023\n\n\n(공부&지윤) – 커널리그레션\n\n\n신록예찬 \n\n\n\n\nJun 23, 2023\n\n\n(공부&지윤) – 퓨리에변환4jy\n\n\n신록예찬 \n\n\n\n\nJun 14, 2023\n\n\n(공부&지윤) – 추정\n\n\n신록예찬 \n\n\n\n\nMar 1, 2023\n\n\n(공부&서연) – 지수분포 가설검정\n\n\n신록예찬 \n\n\n\n\nJan 20, 2023\n\n\n(공부) – 추정\n\n\n신록예찬 \n\n\n\n\nJan 15, 2023\n\n\n(공부) CGSP – Chap 12.4: Node Subsampling for PSD Estimation\n\n\n신록예찬 \n\n\n\n\nJan 12, 2023\n\n\n(공부&서연) – 지수분포 평균검정\n\n\n신록예찬 \n\n\n\n\nDec 27, 2022\n\n\n(공부) CGSP – Chap 12.2 ~ 3: Power Spectral Density and its Estimators\n\n\n신록예찬 \n\n\n\n\nDec 26, 2022\n\n\n(공부) CGSP – Chap 12.2: Weakly Stationary Graph Processes\n\n\n신록예찬 \n\n\n\n\nDec 24, 2022\n\n\n(공부) CGSP – Chap 8.3: Discrete Fourier Transform\n\n\n신록예찬 \n\n\n\n\nDec 23, 2022\n\n\n(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes Thresholding\n\n\n신록예찬 \n\n\n\n\nApr 26, 2019\n\n\n(공부) – 퓨리에변환\n\n\n신록예찬 \n\n\n\n\n\nNo matching items",
    "crumbs": [
      "DL2022",
      "공부"
    ]
  },
  {
    "objectID": "메모.html",
    "href": "메모.html",
    "title": "메모",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJan 10, 2000\n\n\n(메모) – DGX station 설정\n\n\n신록예찬 \n\n\n\n\nJan 9, 2000\n\n\n(메모) – docker\n\n\n신록예찬 \n\n\n\n\nJan 8, 2000\n\n\n(메모) – 주피터랩, 설정 및 몇가지 팁\n\n\n신록예찬 \n\n\n\n\nJan 7, 2000\n\n\n(메모) – 줄리아 설치 및 실행\n\n\n신록예찬 \n\n\n\n\nJan 6, 2000\n\n\n(메모) – 깃 익히기\n\n\n신록예찬 \n\n\n\n\nJan 5, 2000\n\n\n(메모) – vi 익히기\n\n\n신록예찬 \n\n\n\n\nJan 4, 2000\n\n\n(메모) – 우분투 익히기\n\n\n신록예찬 \n\n\n\n\nJan 2, 2000\n\n\n(메모) – 우분투 포맷 및 개발용 서버 셋팅2\n\n\n신록예찬 \n\n\n\n\nJan 1, 2000\n\n\n(메모) – 우분투 포맷 및 개발용 서버 셋팅 (old)\n\n\n신록예찬 \n\n\n\n\n\nNo matching items",
    "crumbs": [
      "DL2022",
      "메모"
    ]
  },
  {
    "objectID": "공부/2023-10-26-Julia -- Vector.html",
    "href": "공부/2023-10-26-Julia -- Vector.html",
    "title": "(공부) Julia – Vector",
    "section": "",
    "text": "- Python의 리스트와 비슷하기도 하고, numpy array와 비슷하기도 함"
  },
  {
    "objectID": "공부/2023-10-26-Julia -- Vector.html#a.-더하기",
    "href": "공부/2023-10-26-Julia -- Vector.html#a.-더하기",
    "title": "(공부) Julia – Vector",
    "section": "A. 더하기",
    "text": "A. 더하기\n- 예시1 – 길이가 같은 벡터의 합\n\na = [1,2] \nb = [-1,-2]\na + b\n\n2-element Vector{Int64}:\n 0\n 0\n\n\n\n# 사실아래도 가능\na .+ b\n\n2-element Vector{Int64}:\n 0\n 0\n\n\n- 예시2 – 벡터+스칼라 (실패)\n\na = [1,2]\na + 1 # 브로드캐스팅 실패\n\nLoadError: MethodError: no method matching +(::Vector{Int64}, ::Int64)\nFor element-wise addition, use broadcasting with dot syntax: array .+ scalar\n\n\u001b[0mClosest candidates are:\n\u001b[0m  +(::Any, ::Any, \u001b[91m::Any\u001b[39m, \u001b[91m::Any...\u001b[39m)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4moperators.jl:578\u001b[24m\u001b[39m\n\u001b[0m  +(\u001b[91m::T\u001b[39m, ::T) where T&lt;:Union{Int128, Int16, Int32, Int64, Int8, UInt128, UInt16, UInt32, UInt64, UInt8}\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4mint.jl:87\u001b[24m\u001b[39m\n\u001b[0m  +(\u001b[91m::Base.TwicePrecision\u001b[39m, ::Number)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4mtwiceprecision.jl:290\u001b[24m\u001b[39m\n\u001b[0m  ...\n\n\n- 예시3 – 벡터+스칼라 (성공)\n\na = [1,2]\na .+ 1 \n\n2-element Vector{Int64}:\n 2\n 3"
  },
  {
    "objectID": "공부/2023-10-26-Julia -- Vector.html#b.-곱셉",
    "href": "공부/2023-10-26-Julia -- Vector.html#b.-곱셉",
    "title": "(공부) Julia – Vector",
    "section": "B. 곱셉",
    "text": "B. 곱셉\n- 예시1 – 벡터*스칼라 (성공)\n\na = [1,2]\na*2\n\n2-element Vector{Int64}:\n 2\n 4\n\n\n\n# 사실 아래도 가능\na .* 2\n\n2-element Vector{Int64}:\n 2\n 4\n\n\n\n# 사실 아래도 가능\n2a\n\n2-element Vector{Int64}:\n 2\n 4\n\n\n- 예시2 – 하다마르곱\n\na = [1,2]\nb = [2,3] \na .* b \n\n2-element Vector{Int64}:\n 2\n 6\n\n\n- 예시3 – 예시2를 응용\n\na = [1,'a']\nb = [3,'b']\na .* b\n\n2-element Vector{Any}:\n 3\n  \"ab\""
  },
  {
    "objectID": "공부/2023-10-26-Julia -- Vector.html#c.-제곱연산",
    "href": "공부/2023-10-26-Julia -- Vector.html#c.-제곱연산",
    "title": "(공부) Julia – Vector",
    "section": "C. 제곱연산",
    "text": "C. 제곱연산\n- 예시1\n\na = [1,2]\na .^ 2\n\n2-element Vector{Int64}:\n 1\n 4\n\n\n- 예시2\n\na = [\"a\", \"bb\"] \na .^ 2 \n\n2-element Vector{String}:\n \"aa\"\n \"bbbb\""
  },
  {
    "objectID": "공부/2023-10-26-Julia -- Vector.html#d.-내적",
    "href": "공부/2023-10-26-Julia -- Vector.html#d.-내적",
    "title": "(공부) Julia – Vector",
    "section": "D. 내적",
    "text": "D. 내적\n- 예시\n\nusing LinearAlgebra\n\n\n[1,2,3] ⋅ [1,2,3]\n\n14\n\n\n\ndot([1,2,3],[1,2,3])\n\n14\n\n\n\n[1,2,3]' * [1,2,3]\n\n14"
  },
  {
    "objectID": "공부/2023-10-26-Julia -- Vector.html#a.-append",
    "href": "공부/2023-10-26-Julia -- Vector.html#a.-append",
    "title": "(공부) Julia – Vector",
    "section": "A. append!",
    "text": "A. append!\n- 예시\n\na = [1,2,3]\nb = [4] \nappend!(a,b)\n\n4-element Vector{Int64}:\n 1\n 2\n 3\n 4\n\n\n\na,b\n\n([1, 2, 3, 4], [4])\n\n\n\nappend!는 numpy에서 concat 느낌"
  },
  {
    "objectID": "공부/2023-10-26-Julia -- Vector.html#b.-push",
    "href": "공부/2023-10-26-Julia -- Vector.html#b.-push",
    "title": "(공부) Julia – Vector",
    "section": "B. push!",
    "text": "B. push!\n- 예시\n\na = [1,2,3]\npush!(a,4)\n\n4-element Vector{Int64}:\n 1\n 2\n 3\n 4\n\n\n\npush!는 list에서 append 느낌"
  },
  {
    "objectID": "공부/2023-10-26-Julia -- Vector.html#a.-cat",
    "href": "공부/2023-10-26-Julia -- Vector.html#a.-cat",
    "title": "(공부) Julia – Vector",
    "section": "A. cat",
    "text": "A. cat\n\nnp.concat, np.stack 등이 합쳐진 형태\n\n- 예시1\n\na = [1,2,3]\nb = [4] \n\n1-element Vector{Int64}:\n 4\n\n\n\ncat(a,b,dims=1) # np.concat 과 비슷\n\n4-element Vector{Int64}:\n 1\n 2\n 3\n 4\n\n\n- 예시2\n\na = [1,2,3]\nb = -a\n\n3-element Vector{Int64}:\n -1\n -2\n -3\n\n\n\ncat(a,b,dims=2) \n\n3×2 Matrix{Int64}:\n 1  -1\n 2  -2\n 3  -3\n\n\n\ncat(a,b,dims=1)\n\n6-element Vector{Int64}:\n  1\n  2\n  3\n -1\n -2\n -3\n\n\n- 예시3\n\na = [1 2 3\n     3 4 5]\nb = -a\n\n2×3 Matrix{Int64}:\n -1  -2  -3\n -3  -4  -5\n\n\n\ncat(a,b,dims=1)\n\n4×3 Matrix{Int64}:\n  1   2   3\n  3   4   5\n -1  -2  -3\n -3  -4  -5\n\n\n\ncat(a,b,dims=2)\n\n2×6 Matrix{Int64}:\n 1  2  3  -1  -2  -3\n 3  4  5  -3  -4  -5\n\n\n\ncat(a,b,dims=3)\n\n2×3×2 Array{Int64, 3}:\n[:, :, 1] =\n 1  2  3\n 3  4  5\n\n[:, :, 2] =\n -1  -2  -3\n -3  -4  -5\n\n\n- 예시4 – 아래도 가능\n\na = [1,2,3]\nb = 2 \ncat(a,b,dims=1)\n\n4-element Vector{Int64}:\n 1\n 2\n 3\n 2\n\n\n- 예시5 – 아래도 가능\n\na = reshape(1:4, (2,2))\nb = [3,4]\na,b\n\n([1 3; 2 4], [3, 4])\n\n\n\ncat(a,b,dims=2)\n\n2×3 Matrix{Int64}:\n 1  3  3\n 2  4  4"
  },
  {
    "objectID": "공부/2023-10-26-Julia -- Vector.html#b.-를-이용한-결합",
    "href": "공부/2023-10-26-Julia -- Vector.html#b.-를-이용한-결합",
    "title": "(공부) Julia – Vector",
    "section": "B. []를 이용한 결합",
    "text": "B. []를 이용한 결합\n- 예시1\n\na = [1,2,3]\nb = -a\na,b\n\n([1, 2, 3], [-1, -2, -3])\n\n\n\n[a b]\n\n3×2 Matrix{Int64}:\n 1  -1\n 2  -2\n 3  -3\n\n\n\n[a\n b]\n\n6-element Vector{Int64}:\n  1\n  2\n  3\n -1\n -2\n -3\n\n\n- 예시2\n\na = [1,2,3] \nb = 4\n\n4\n\n\n\n[a \n b]\n\n4-element Vector{Int64}:\n 1\n 2\n 3\n 4\n\n\n- 예시3\n\na = [1 2; 3 4]\nb = [0,0] \n\n2-element Vector{Int64}:\n 0\n 0\n\n\n\n[a b]\n\n2×3 Matrix{Int64}:\n 1  2  0\n 3  4  0"
  },
  {
    "objectID": "자료/2023-11-14-구조가 있는 결측치 자료.html",
    "href": "자료/2023-11-14-구조가 있는 결측치 자료.html",
    "title": "(자료) 데이터생성 – 성별,몸무게 –> 키",
    "section": "",
    "text": "- imports\n\nimport numpy as np\nimport pandas as pd\nimport sklearn.model_selection\nimport seaborn as sns\n\n- 결측이 있는 자료\n\nnp.random.seed(42)\ndata = np.array(['male'] * 500 + ['female'] * 500)\ndef sample_data(data, male_prob, female_prob, size):\n    male_sample = np.random.choice(data[data=='male'], size=int(size * male_prob))\n    female_sample = np.random.choice(data[data=='female'], size=int(size * female_prob))\n    return np.concatenate([male_sample, female_sample])\ntrain = sample_data(data, 0.8, 0.2, 280)\ntest = sample_data(data, 0.2, 0.8, 120)\nnp.random.shuffle(train)\nnp.random.shuffle(test)\nsex = np.concatenate([train,test])\nweight = np.random.randn(400)*7\nheight = np.random.randn(400)*3\nfor i,s in enumerate(sex):\n    if s =='male':\n        weight[i] = 75+weight[i]\n        height[i] = height[i]+0.8*weight[i]+120\n    else:\n        weight[i] = 50+weight[i]*0.6\n        height[i] = height[i]+1.3*weight[i]+100\ndf = pd.DataFrame({'weight':weight,'sex':sex,'height':height})\nmissing_ratio = 0.2\nnum_missing = int(len(df) * missing_ratio)\nmissing_indices = np.random.choice(df.index, size=num_missing, replace=False)\ndf.loc[missing_indices, 'weight'] = np.nan\ndf_train, df_test = sklearn.model_selection.train_test_split(df,test_size=120)\n\n\nsns.scatterplot(df, x='weight', y='height', hue='sex')\n\n\n\n\n\n\n\n\n자료특징\n\n결측값이 있다.\ntr에는 남자가, test에는 여자가 많다.\n남녀의 (몸무게,키)의 분포는 서로 다르다."
  },
  {
    "objectID": "공부/2023-10-25-Julia -- 문자와 문자열.html",
    "href": "공부/2023-10-25-Julia -- 문자와 문자열.html",
    "title": "(공부) Julia – 문자와 문자열",
    "section": "",
    "text": "- 선언 및 자료형\n\n'B' # 선언 \n\n'B': ASCII/Unicode U+0042 (category Lu: Letter, uppercase)\n\n\n\ntypeof('b') # 자료형\n\nChar\n\n\n\n\n\n- 선언 및 자료형\n\n\"A\" # 선언\n\n\"A\"\n\n\n\ntypeof(\"A\") # 자료형\n\nString\n\n\n\n\n\n- \"a\"와 'a'의 차이\n\n'a' # 단일문자\n\n'a': ASCII/Unicode U+0061 (category Ll: Letter, lowercase)\n\n\n\n\"a\" # 문자열\n\n\"a\"\n\n\n\n\"a\"[1] # 'a'와 같음\n\n'a': ASCII/Unicode U+0061 (category Ll: Letter, lowercase)"
  },
  {
    "objectID": "공부/2023-10-25-Julia -- 문자와 문자열.html#a.-문자-0차원-자료형",
    "href": "공부/2023-10-25-Julia -- 문자와 문자열.html#a.-문자-0차원-자료형",
    "title": "(공부) Julia – 문자와 문자열",
    "section": "",
    "text": "- 선언 및 자료형\n\n'B' # 선언 \n\n'B': ASCII/Unicode U+0042 (category Lu: Letter, uppercase)\n\n\n\ntypeof('b') # 자료형\n\nChar"
  },
  {
    "objectID": "공부/2023-10-25-Julia -- 문자와 문자열.html#b.-문자열-1차원-자료형",
    "href": "공부/2023-10-25-Julia -- 문자와 문자열.html#b.-문자열-1차원-자료형",
    "title": "(공부) Julia – 문자와 문자열",
    "section": "",
    "text": "- 선언 및 자료형\n\n\"A\" # 선언\n\n\"A\"\n\n\n\ntypeof(\"A\") # 자료형\n\nString"
  },
  {
    "objectID": "공부/2023-10-25-Julia -- 문자와 문자열.html#c.-차이점",
    "href": "공부/2023-10-25-Julia -- 문자와 문자열.html#c.-차이점",
    "title": "(공부) Julia – 문자와 문자열",
    "section": "",
    "text": "- \"a\"와 'a'의 차이\n\n'a' # 단일문자\n\n'a': ASCII/Unicode U+0061 (category Ll: Letter, lowercase)\n\n\n\n\"a\" # 문자열\n\n\"a\"\n\n\n\n\"a\"[1] # 'a'와 같음\n\n'a': ASCII/Unicode U+0061 (category Ll: Letter, lowercase)"
  },
  {
    "objectID": "공부/2023-10-25-Julia -- 문자와 문자열.html#a.-문자-관련-기능",
    "href": "공부/2023-10-25-Julia -- 문자와 문자열.html#a.-문자-관련-기능",
    "title": "(공부) Julia – 문자와 문자열",
    "section": "A. 문자 관련 기능",
    "text": "A. 문자 관련 기능\n- isuppercase: 대소문자 판단\n\nisuppercase('a'), islowercase('a')\n\n(false, true)\n\n\n\nisuppercase('A'), islowercase('A')\n\n(true, false)"
  },
  {
    "objectID": "공부/2023-10-25-Julia -- 문자와 문자열.html#b.-문자열-관련-기능",
    "href": "공부/2023-10-25-Julia -- 문자와 문자열.html#b.-문자열-관련-기능",
    "title": "(공부) Julia – 문자와 문자열",
    "section": "B. 문자열 관련 기능",
    "text": "B. 문자열 관련 기능\n- 문자열 슬라이싱\n\nstr = \"Jeonbuk National University\"\nstr[end-1:end]\n\n\"ty\"\n\n\n- 문자열의 결합\n\n\"a\"*\"b\"\n\n\"ab\"\n\n\n- 문자열의 반복\n\n\"a\"^5\n\n\"aaaaa\"\n\n\n\nrepeat(\"a\",5)\n\n\"aaaaa\"\n\n\n- 문자열 끼워넣기\n\nname = \"최규빈\"\n\"제 이름은 $name 입니다\"\n\n\"제 이름은 최규빈 입니다\"\n\n\n- 문자열 바꾸기\n\nstr = \"abcdefg\"\nreplace(str, \"g\" =&gt; \"u\")\n\n\"abcdefu\"\n\n\n- 문자열 나누기\n\nstr = \"2023-08\"\nsplit(str,\"-\")\n\n2-element Vector{SubString{String}}:\n \"2023\"\n \"08\"\n\n\n- 문자열 합치기\n\njoin([\"2023\",\"08\"],\"-\")\n\n\"2023-08\"\n\n\n\njoin([\"2023\",\"08\"])\n\n\"202308\"\n\n\n- lowercase: 대문자를 소문자로 바꾸는 방법\n\nstr = \"HELLO, JULIA!\"\nlowercase(str)\n\n\"hello, julia!\""
  },
  {
    "objectID": "연구/보람/2023-05-24-(try1변형.html",
    "href": "연구/보람/2023-05-24-(try1변형.html",
    "title": "[FRAUD] 신용카드 거래 사기탐지 Try1 변형",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport networkx as nx\nimport sklearn\n\n# sklearn\nfrom sklearn import model_selection # split함수이용\nfrom sklearn import ensemble # RF \nfrom sklearn import metrics \n\n# embedding \nfrom node2vec import Node2Vec\nfrom node2vec.edges import HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder\n\n/home/cgb2/anaconda3/envs/py38/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\n\ndef build_graph_bipartite(df_input, graph_type=nx.Graph()):\n    df=df_input.copy()\n    mapping={x:node_id for node_id, x in enumerate(set(df[\"cc_num\"].values.tolist()+\\\n                                                      df[\"merchant\"].values.tolist()))}\n    \n    df[\"from\"]=df[\"cc_num\"].apply(lambda x:mapping[x])  #엣지의 출발점\n    df[\"to\"]=df[\"merchant\"].apply(lambda x:mapping[x])  #엣지의 도착점\n    \n    df = df[['from', 'to', \"amt\", \"is_fraud\"]].groupby(['from','to']).agg({\"is_fraud\":\"sum\",\"amt\":\"sum\"}).reset_index()\n    df[\"is_fraud\"]=df[\"is_fraud\"].apply(lambda x:1 if x&gt;0 else 0)\n    \n    G=nx.from_edgelist(df[[\"from\",\"to\"]].values, create_using=graph_type)\n    \n    nx.set_edge_attributes(G,{(int(x[\"from\"]),int(x[\"to\"])):x[\"is_fraud\"] for idx, x in df[[\"from\",\"to\",\"is_fraud\"]].iterrows()}, \"label\")  #엣지 속성 설정,각 속성의 사기 여부부     \n    nx.set_edge_attributes(G,{(int(x[\"from\"]),int(x[\"to\"])):x[\"amt\"] for idx,x in df[[\"from\",\"to\",\"amt\"]].iterrows()}, \"weight\") # 엣지 속성 설정, 각 엣지의 거래 금액\n\n    return G\n\n\ndef build_graph_tripartite(df_input, graph_type=nx.Graph()):\n    df=df_input.copy()\n    mapping={x:node_id for node_id, x in enumerate(set(df.index.values.tolist() + \n                                                       df[\"cc_num\"].values.tolist() +\n                                                       df[\"merchant\"].values.tolist()))}\n    df[\"in_node\"]= df[\"cc_num\"].apply(lambda x: mapping[x])\n    df[\"out_node\"]=df[\"merchant\"].apply(lambda x:mapping[x])\n    \n        \n    G=nx.from_edgelist([(x[\"in_node\"], mapping[idx]) for idx, x in df.iterrows()] +\\\n                        [(x[\"out_node\"], mapping[idx]) for idx, x in df.iterrows()], create_using=graph_type)\n    \n    nx.set_edge_attributes(G,{(x[\"in_node\"], mapping[idx]):x[\"is_fraud\"] for idx, x in df.iterrows()}, \"label\")     \n    nx.set_edge_attributes(G,{(x[\"out_node\"], mapping[idx]):x[\"is_fraud\"] for idx, x in df.iterrows()}, \"label\")   \n    nx.set_edge_attributes(G,{(x[\"in_node\"], mapping[idx]):x[\"amt\"] for idx, x in df.iterrows()}, \"weight\")  \n    nx.set_edge_attributes(G,{(x[\"out_node\"], mapping[idx]):x[\"amt\"] for idx, x in df.iterrows()}, \"weight\")\n\n    return G\n    \n    \ndef down_sample_textbook(df):\n    df_majority = df[df.is_fraud==0].copy()\n    df_minority = df[df.is_fraud==1].copy()\n    df_maj_dowsampled = sklearn.utils.resample(df_majority, n_samples=len(df_minority), replace=False, random_state=42)\n    df_downsampled = pd.concat([df_minority, df_maj_dowsampled])\n    return df_downsampled\n\ndef embedding(Graph):\n    # Graph -&gt; X (feature)\n    _edgs = list(Graph.edges)\n    subGraph = Graph.edge_subgraph([_edgs[x] for x in range(len(Graph.edges))]).copy()\n    subGraph.add_nodes_from(list(set(Graph.nodes) - set(subGraph.nodes)))    \n    embedded = AverageEmbedder(Node2Vec(subGraph, weight_key='weight').fit(window=10).wv)\n    X = [embedded[str(_edgs[x][0]), str(_edgs[x][1])] for x in range(len(Graph.edges))]\n    # Graph -&gt; y (label)\n    y = np.array(list(nx.get_edge_attributes(Graph, \"label\").values()))\n    return X,y \n\ndef anal(df):\n    Graph = build_graph_bipartite(df)\n    X,XX,y,yy = embedding(Graph)\n    lrnr = RandomForestClassifier(n_estimators=100, random_state=42) \n    lrnr.fit(X,y)\n    yyhat = lrnr.predict(XX)\n    df = pd.DataFrame({\n        'acc':[sklearn.metrics.accuracy_score(yy,yyhat)], \n        'pre':[sklearn.metrics.precision_score(yy,yyhat)], \n        'rec':[sklearn.metrics.recall_score(yy,yyhat)],\n        'f1':[sklearn.metrics.f1_score(yy,yyhat)]}\n    )    \n    return df\n\ndef our_sampling1(df):\n    cus_list = set(df.query('is_fraud==1').cc_num.tolist())\n    return df.query(\"cc_num in @ cus_list\")"
  },
  {
    "objectID": "연구/보람/2023-05-24-(try1변형.html#데이터-종류",
    "href": "연구/보람/2023-05-24-(try1변형.html#데이터-종류",
    "title": "[FRAUD] 신용카드 거래 사기탐지 Try1 변형",
    "section": "데이터 종류",
    "text": "데이터 종류\n\nfraudTrain.csv: (1048575, 23), 기본데이터\ndf02: (214520, 23), is_fraud==0 에서는 20퍼의 샘플만, is_fraud==1 에서는 모든 샘플을 뽑아서 정리한 새로운 자료\ndf50 = (12012, 23), df20에서 is_fraud==0 와 is_fraud==1 의 비율을 맞추어서 샘플을 뽑은 것\n\n\n\n\n\n\n\n\n\n\n데이터\nshape\n사기거래빈도\n설명\n\n\n\n\nfraudTrain\n(1048575, 22)\n0.00573\n원래자료\n\n\ndf02\n(214520, 22)\n0.028\nis_fraud==0 에서는 20퍼의 샘플만, is_fraud==1 에서는 모든 샘플을 뽑아서 정리한 새로운 자료\n\n\ndf50\n(12012, 22)\n0.5\ndf02에서 사기비율을 50퍼로 맞추어 샘플링한 자료\n\n\ndf50_tr\n(9009, 22)\n0.49828\ndf50에서 랜덤으로 train/test를 분리하여 얻은 train dataset\n\n\ndf50_test\n(3003, 22)\n0.50516\ndf50에서 랜덤으로 train/test를 분리하여 얻은 test dataset\n\n\ndf02_tr\n(211517, 22)\n0.02122\ndf02에서 df50_test에 해당하는 인덱스를 제외\n\n\nfraudTrain_tr\n(1045572, 22)\n0.00429\nfraudTrain에서 df50_test에 해당하는 인덱스를 제외\n\n\n\n- fraudTrain\n\nfraudTrain = pd.read_csv(\"fraudTrain.csv\").iloc[:,1:]\nfraudTrain.shape\n\n(1048575, 22)\n\n\n\nfraudTrain.is_fraud.mean().round(5)\n\n0.00573\n\n\n- df20\n\n_df1 = fraudTrain[fraudTrain[\"is_fraud\"] == 0].sample(frac=0.20, random_state=42)\n_df2 = fraudTrain[fraudTrain[\"is_fraud\"] == 1]\ndf02 = pd.concat([_df1,_df2])\ndf02.shape\n\n(214520, 22)\n\n\n\ndf02.is_fraud.mean().round(5)\n\n0.028\n\n\n- df50\n\ndf50 = down_sample_textbook(df02)\ndf50.shape\n\n(12012, 22)\n\n\n\ndf50\n\n\n\n\n\n\n\n\ntrans_date_trans_time\ncc_num\nmerchant\ncategory\namt\nfirst\nlast\ngender\nstreet\ncity\n...\nlat\nlong\ncity_pop\njob\ndob\ntrans_num\nunix_time\nmerch_lat\nmerch_long\nis_fraud\n\n\n\n\n2449\n2019-01-02 1:06\n4.613310e+12\nfraud_Rutherford-Mertz\ngrocery_pos\n281.06\nJason\nMurphy\nM\n542 Steve Curve Suite 011\nCollettsville\n...\n35.9946\n-81.7266\n885\nSoil scientist\n1988-09-15\ne8a81877ae9a0a7f883e15cb39dc4022\n1325466397\n36.430124\n-81.179483\n1\n\n\n2472\n2019-01-02 1:47\n3.401870e+14\nfraud_Jenkins, Hauck and Friesen\ngas_transport\n11.52\nMisty\nHart\nF\n27954 Hall Mill Suite 575\nSan Antonio\n...\n29.4400\n-98.4590\n1595797\nHorticultural consultant\n1960-10-28\nbc7d41c41103877b03232f03f1f8d3f5\n1325468849\n29.819364\n-99.142791\n1\n\n\n2523\n2019-01-02 3:05\n3.401870e+14\nfraud_Goodwin-Nitzsche\ngrocery_pos\n276.31\nMisty\nHart\nF\n27954 Hall Mill Suite 575\nSan Antonio\n...\n29.4400\n-98.4590\n1595797\nHorticultural consultant\n1960-10-28\nb98f12f4168391b2203238813df5aa8c\n1325473523\n29.273085\n-98.836360\n1\n\n\n2546\n2019-01-02 3:38\n4.613310e+12\nfraud_Erdman-Kertzmann\ngas_transport\n7.03\nJason\nMurphy\nM\n542 Steve Curve Suite 011\nCollettsville\n...\n35.9946\n-81.7266\n885\nSoil scientist\n1988-09-15\n397894a5c4c02e3c61c784001f0f14e4\n1325475483\n35.909292\n-82.091010\n1\n\n\n2553\n2019-01-02 3:55\n3.401870e+14\nfraud_Koepp-Parker\ngrocery_pos\n275.73\nMisty\nHart\nF\n27954 Hall Mill Suite 575\nSan Antonio\n...\n29.4400\n-98.4590\n1595797\nHorticultural consultant\n1960-10-28\n7863235a750d73a244c07f1fb7f0185a\n1325476547\n29.786426\n-98.683410\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n363827\n2019-06-17 19:30\n2.475090e+15\nfraud_Frami Group\nentertainment\n81.13\nJohn\nMiller\nM\n153 Mccullough Springs Apt. 857\nLamberton\n...\n44.2378\n-95.2739\n1507\nLand/geomatics surveyor\n1993-10-12\nc66cb411019c7dfd4d89f42a1ba4765f\n1339961448\n44.212695\n-95.661879\n0\n\n\n140154\n2019-03-17 14:33\n2.131550e+14\nfraud_Bahringer-Streich\nfood_dining\n55.00\nChristopher\nSheppard\nM\n39218 Baker Shoals\nBristow\n...\n38.1981\n-86.6821\n965\nHorticultural therapist\n1982-02-10\n316b9d25b9fa7d08a6831b7dab6634cd\n1331994839\n38.394240\n-86.413557\n0\n\n\n860597\n2019-12-17 12:31\n2.280870e+15\nfraud_Lubowitz-Walter\nkids_pets\n8.12\nKatherine\nCooper\nF\n3854 Lauren Springs Suite 648\nOakford\n...\n40.0994\n-89.9601\n530\nTransport planner\n1967-09-23\nd92e9e63d9b24c3ccb92d05cba4cac54\n1355747517\n39.695248\n-89.853063\n0\n\n\n29341\n2019-01-18 9:20\n4.878360e+15\nfraud_Denesik and Sons\nshopping_pos\n3.52\nTina\nAlvarez\nF\n1976 Tyler Underpass\nEarly\n...\n42.4483\n-95.1726\n885\nPilot, airline\n1949-08-14\n8390ce51cfb8482b618ebc4ac370bcf7\n1326878457\n42.633204\n-95.598143\n0\n\n\n529797\n2019-08-16 13:17\n4.450830e+15\nfraud_Beier and Sons\nhome\n84.15\nDonna\nDavis\nF\n6760 Donovan Lakes\nClayton\n...\n34.5906\n-95.3800\n1760\nOccupational psychologist\n1972-01-20\n04e1be9bcb18ea8b96048659bd02177b\n1345123058\n33.885236\n-95.885110\n0\n\n\n\n\n12012 rows × 22 columns\n\n\n\n\ndf50.is_fraud.mean().round(5)\n\n0.5\n\n\n- df50_tr, df50_test\n\ndf50_tr,df50_test = sklearn.model_selection.train_test_split(df50, random_state=42)\n\n\ndf50_tr.is_fraud.mean().round(5), df50_test.is_fraud.mean().round(5)\n\n(0.49828, 0.50516)\n\n\n- df02_tr, fraudTrain_tr\n\ndf02_tr = df02.loc[[i not in df50_test.index for i in df02.index],:].copy()\nfraudTrain_tr = fraudTrain.loc[[i not in df50_test.index for i in fraudTrain.index],:].copy()\n\n\ndf02_tr.shape, fraudTrain_tr.shape\n\n((211517, 22), (1045572, 22))\n\n\n\ndf02_tr.is_fraud.mean().round(5), fraudTrain_tr.is_fraud.mean().round(5)\n\n(0.02122, 0.00429)"
  },
  {
    "objectID": "연구/지윤/SOLAR/2023-07-17-EPT-RGCN.html",
    "href": "연구/지윤/SOLAR/2023-07-17-EPT-RGCN.html",
    "title": "(연구) 지윤 – 태양광자료분석, EPT + RGCN",
    "section": "",
    "text": "Import\n- source\n\nhttps://github.com/miruetoto/yechan3/blob/main/posts/3_Researches/PINKOCTO/SOLAR/0720.py\n\n- download source\n\n# https://github.com/miruetoto/yechan3/blob/main/posts/3_Researches/PINKOCTO/SOLAR/0720.py\n\n- run\n\n%run 0720.py\n\n\n\nLoad data\n\n# read dataframe \ndf = pd.read_csv('https://media.githubusercontent.com/media/miruetoto/yechan3/main/posts/3_Researches/PINKOCTO/SOLAR/data_eng_230710.csv')\n\n# make y, y_upper, y_period, time, regions \ny = df.loc[:,'Bukchoncheon':'Gyeongju-si'].to_numpy()\nyU = df.loc[:,'Bukchoncheon_Upper':'Gyeongju-si_Upper'].to_numpy()\nyP = np.divide(y, yU+1e-10)\nt = df.loc[:,'date']\nregions = list(df.loc[:,'Bukchoncheon':'Gyeongju-si'].columns)\n\n# plot rawdata \nstart = 50 \nend = 50+24*3\ncity = 19 # 광주 \nwith plt.style.context('cyberpunk'):\n    plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n    plt.plot(t[start:end],y[start:end,city],'o',label='y')\n    plt.plot(t[start:end],yU[start:end,city],'--',label='yU')\n    plt.plot(t[start:end],yP[start:end,city],'o',label='y/yU')\n    tick_interval = 4\n    plt.xticks(range(1, len(t) + 1, tick_interval),rotation=25)        \n    plt.legend()\n    plt.title(\"The solar radiation data in {} from {} to {} \".format(regions[city],t.to_list()[0][:10],t.to_list()[-1][:10]))\n    mplcyberpunk.add_glow_effects()    \n\n\n\n\n\n\n\n\n\n\nLearn\n- y \\(\\to\\) yhat\n\n# hyper params\nLAGS = 4\nFILTERS = 8\nEPOCH = 5\n\n# global params\nTRAIN_RATIO = 0.8\nT,N = len(t),len(regions) \nLEN_TEST = int(np.floor(T*(1-TRAIN_RATIO)))\nLEN_TR = T - LEN_TEST\n\n# 방법1\nmodel = RecurrentGCN(node_features=LAGS, filters=FILTERS)\nyhat = rgcn(y, model = model, train_ratio = TRAIN_RATIO, lags=LAGS, epoch=EPOCH)\nyhat[yhat &lt; 0]= 0 \n\n# 방법2 \nmodel = RecurrentGCN(node_features=LAGS, filters=FILTERS)\nyUhat = rgcn(yU, model = model, train_ratio = TRAIN_RATIO, lags=LAGS, epoch=EPOCH)\n\nmodel = RecurrentGCN(node_features=LAGS, filters=FILTERS)\nyPhat = rgcn(yP, model = model, train_ratio = TRAIN_RATIO, lags=LAGS, epoch=EPOCH)\nyPhat[yPhat &lt; 0] =0 \n\n\nclassic = ((y - yhat)[LEN_TR:, :] ** 2)\nproposed = ((y - yUhat*yPhat)[LEN_TR:, :] ** 2)\n\n# print mse\nprint(\"\"\"\ntotal_mse(classic): {:.4f}\ntotal_mse(proposed): {:.4f}\n\"\"\".format(classic.mean(), proposed.mean()))\n\n5/5\ntotal_mse(classic): 0.0573\ntotal_mse(proposed): 0.0476\n\n\n\n\n# plot \nstart = LEN_TR \nend = LEN_TR + LEN_TEST \ncity = 20\ntick_interval = 24 \n\nclassic = (y - yhat)[start:end, :] ** 2\nproposed = (y - yUhat*yPhat)[start:end, :] ** 2\n\nprint(\"\"\"\ntotal_mse(classic): {:.4f}\ntotal_mse(proposed): {:.4f}\n\"\"\".format(classic.mean(), proposed.mean()))\n\nwith plt.style.context('cyberpunk'): \n    plt.rcParams['figure.figsize'] = [20, 4]  # [가로 크기, 세로 크기]\n    plt.plot(t[start:end],y[start:end,city],'-',label='real')\n    plt.plot(t[start:end],yhat[start:end,city],'--',label='predited(classic)')\n    plt.plot(t[start:end],(yUhat*yPhat)[start:end,city],'--',label='predited(proposed)')\n    plt.xticks(range(1, len(t[start:end]) + 1, tick_interval),rotation=25,ha='right')\n    plt.title(\"The predicted results in {} from {} to {} \".format(regions[city],t[start:end].to_list()[0][:10],t[start:end].to_list()[-1][:10]))    \n    plt.legend()\n    mplcyberpunk.add_glow_effects()\n\n\ntotal_mse(classic): 0.0573\ntotal_mse(proposed): 0.0476\n\n\n\n\n\n\n\n\n\n\n\n\nAnalyze\n- y vs yhat\n\nwith plt.style.context('seaborn-bright'): \n    plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n    plt.plot(y[50:150,0],'o-',label='real')\n    plt.plot(yhat[50:150,0],'o--',label='predited')\n    plt.legend()\n    mplcyberpunk.add_glow_effects()    \n\n\n\n\n\n\n\n\n- yU vs yUhat\n\nwith plt.style.context('seaborn-bright'): \n    plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n    plt.plot(yU[:,25],label='real')\n    plt.plot(yUhat[:,25],label='predited')\n    plt.legend()\n    mplcyberpunk.add_glow_effects()    \n\n\n\n\n\n\n\n\n- yP vs yPhat\n\nwith plt.style.context('seaborn-bright'): \n    plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n    plt.plot(yP[50:150,city],'o-',label='real')\n    plt.plot(yPhat[50:150,city],'o--',label='predited')\n    plt.legend()\n    mplcyberpunk.add_glow_effects()    \n\n\n\n\n\n\n\n\n- y vs (yUhat*yPhat)\n\nwith plt.style.context('seaborn-bright'): \n    plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n    plt.plot(y[50:150,0],'o-',label='real')\n    plt.plot((yUhat*yPhat)[50:150,0],'o--',label='predited')\n    plt.legend()\n    mplcyberpunk.add_glow_effects()    \n\n\n\n\n\n\n\n\n- 지역별분석\n\nwith plt.style.context('cyberpunk'):\n    plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n    plt.plot(regions,classic.mean(axis=0)-proposed.mean(axis=0),'--o');\n    plt.xticks(regions, rotation=55, ha='right');    \n    mplcyberpunk.add_glow_effects()"
  },
  {
    "objectID": "규빈.html",
    "href": "규빈.html",
    "title": "규빈",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nAug 18, 2023\n\n\n(연구) EPT-DISSIM – PRCP_KOR2 데이터정리\n\n\n신록예찬 \n\n\n\n\nAug 8, 2023\n\n\n(연구) EPT-DISSIM – 진행사항\n\n\n신록예찬 \n\n\n\n\nAug 7, 2023\n\n\n(연구) EPT-DISSIM – PRCP_KOR 데이터정리\n\n\n신록예찬 \n\n\n\n\nJul 7, 2023\n\n\n(연구) 다중척도방법\n\n\n신록예찬 \n\n\n\n\n\nNo matching items",
    "crumbs": [
      "DL2022",
      "연구",
      "규빈"
    ]
  },
  {
    "objectID": "연구/지윤/notes.html",
    "href": "연구/지윤/notes.html",
    "title": "(연구) 지윤 – 0717 면담",
    "section": "",
    "text": "23-07-17\n- 실험해볼것 (모형, 필터/lag, 에폭 변화하여서) 50번정도..\n\n에폭이 적을수록 우리가 잘맞았음.\n필터나 lag도 단순할수록 괜찮았음\nlag은 24를 넘길 필요는 없음.\n필터는 64이상은 필요없는듯\n\n- quarto 팁\nquarto preview --host 210.117.173.182 --no-browser\n- 파라메트릭 vs 넌파 vs 세미\n- 비트시그널\n- 발표자료 + 페이퍼작업\n- 레퍼런스정리\n\nGNN -&gt; GCN / RGNN -&gt; STGCN, ST-GCN\n\n23-07-20\n- 라마: https://www.youtube.com/watch?v=OZbarkziC14\n- 저널 vs 학회:\n\n원래개념: SCIE (~10) &gt;&gt;&gt;&gt;&gt;&gt; SCIE (10~50) &gt;&gt; SCIE(50~) &gt;&gt;&gt;&gt;&gt;&gt; KCI &gt;&gt; 컨퍼런스\nAI분야 한정: SCIE (~10), 일부top컨퍼런스 (NIPS, AAAI, ICML, ICLR) &gt;&gt;&gt;&gt;&gt;&gt; SCIE (10~50) &gt;&gt; SCIE(50~) &gt;&gt;&gt;&gt;&gt;&gt; KCI &gt;&gt; 컨퍼런스\n\n- 오타발견시알려주세요\n\nhttps://guebin.github.io/PP2023SUM/\n\n23-08-14\n논문쓰는 방법\n1. introduction = motivating ex (원래 반반)\n\nmotivating ex 로 시작할수도 있고 –&gt; 방법론에 강점이 있을때\nsolar enery에 대한 개론으로 시작 –&gt; 데이터가 자신있을 경우\n담백하게 (1) goal (2) method (3) contribution –&gt; 이론적인 측면에 자신이 있을때 꼭 들어가야 하는 것\n구성 // Graphical abstract\n기존방법과 차이점 (*)\n\n\n\n\nGraphical abstract 예시 @li2022multi\n\n\n2. review existing methods (원래 지윤학생, 수틀리면 내가)\n\nRGCN 까지 이어지는 연구흐름을 간략하게 소개\n\n3. proposed method (원래 지윤학생이 해야하는데, 안되면 내가)\n\n우리가 제안하는 방법이 기존과 무엇이 다르냐?\n수식, 알고리즘, 이론적 백그라운드\n\n4. simulation study (연구의 꽃) - beat signal - priodic signal * low-freq amplitude signal 꼴의 신호의 분해 - 시뮬레이션 데이터를 고안 + 결과를 입증\n5. real-data analysis (지윤학생이 거의다 해야함) - 일사량자료 분석 결과 - 우리가 제인한방법 + 기존의 방법들 -&gt; 퍼포먼스 비교 - 데이터설명 - 데이터는 어디에서 얻었는지, 언제부터 언제까지인지, 데이터의 특징 (주기성을 가진다. 0인 값이 많다) - 그림을 보여줘야함\n6. conclusion & future works & limitations & 어디에 활용\n\n결론: 좋은 분석이었다..\n한계: 어떠한 점에 한계가 있다. -&gt; 향후연구: 향후에는 어떤연구로 발전할 것이다.. (다른변수를 고려해서 할 예정이다)\n활용: 주기성을 가진 어떠한 자료도 우리의 방법을 사용하면 잘 예측할수있어요.."
  },
  {
    "objectID": "연구/지윤/2023-10-21-Imputer와 Scaler의 적용.html",
    "href": "연구/지윤/2023-10-21-Imputer와 Scaler의 적용.html",
    "title": "(연구) 지윤 – Imputer와 Scaler의 적용 (질문내용)",
    "section": "",
    "text": "import numpy as np \nimport pandas as pd\nimport sklearn.preprocessing\nimport sklearn.impute \n\n\nX = pd.DataFrame({'X':[7.424885,4.201394,np.nan,np.nan,5.190914,np.nan,6.433033]})\nX\n\n\n\n\n\n\n\n\nX\n\n\n\n\n0\n7.424885\n\n\n1\n4.201394\n\n\n2\nNaN\n\n\n3\nNaN\n\n\n4\n5.190914\n\n\n5\nNaN\n\n\n6\n6.433033\n\n\n\n\n\n\n\n\nsclr = sklearn.preprocessing.StandardScaler()\nimputr = sklearn.impute.SimpleImputer()\n\n\nsclr.fit(X.dropna())\n\nStandardScaler()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.StandardScalerStandardScaler()\n\n\n\nsclr.transform(imputr.fit_transform(X))\n\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n\n\narray([[ 1.32010944],\n       [-1.31915477],\n       [ 0.        ],\n       [ 0.        ],\n       [-0.50897577],\n       [ 0.        ],\n       [ 0.50802109]])"
  },
  {
    "objectID": "공부/2023-01-20-추정.html",
    "href": "공부/2023-01-20-추정.html",
    "title": "(공부) – 추정",
    "section": "",
    "text": "using Distributions, Plots"
  },
  {
    "objectID": "공부/2023-01-20-추정.html#mle의-일치성에-대한-구체적인-논의",
    "href": "공부/2023-01-20-추정.html#mle의-일치성에-대한-구체적인-논의",
    "title": "(공부) – 추정",
    "section": "MLE의 일치성에 대한 구체적인 논의",
    "text": "MLE의 일치성에 대한 구체적인 논의\n\\(X_1,\\dots,X_{10} \\overset{i.i.d.}{\\sim} Ber(\\theta)\\) 이라고 하자.\n\nx = rand(Bernoulli(0.3),10)\nx\n\n10-element Vector{Bool}:\n 0\n 0\n 1\n 1\n 1\n 1\n 0\n 0\n 0\n 0\n\n\n여기에서 \\(\\theta\\)는 추정해야할 미지의 모수이지만 우리는 시뮬레이션의 편의상 \\(\\theta\\)의 참값을 \\(\\theta_0=\\frac{1}{3}\\)로 알고 있다고 하자. MLE를 논의함에 있어 핵심적인 역할을 하는 것은 \\(Y_1=\\log f(X_1;\\theta)\\)이다. 아래는 \\(Y_1\\)에 대한 몇가지 코멘트이다.\n(1) \\(Y_1\\)은 \\(X_1\\)와 \\(\\theta\\)의 함수이다.\n\n우선 \\(X_1\\)의 함수이므로 \\(Y_1\\)역시 확률변수이다. 따라서 \\(Y_1\\)에 대하여 평균등을 취할 수 있으며 LLN을 쓸 수 있다.\n\\(Y_1\\)은 \\(\\theta\\)에 대한 함수이므로 \\(\\theta\\)에 대하여 미분할 수 있다.\n\n(베르누이 예제)\n우리의 베르누이 예제에서 \\(Y_1\\)은 아래와 같이 계산된다.\n\\[Y_1 = \\log f(X_1;\\theta)= X_1 \\log \\theta + (1-X_1)\\log(1-\\theta)\\]\n보는 것 처럼 \\(Y_1\\)은 \\(X_1\\)와 \\(\\theta\\)의 함수임\n(2) \\(\\mathbb{E}_{\\theta_0}(Y_1)\\)은 \\(\\theta\\) 만의 함수이다. 적당한 조건4이 만족된다면 \\(\\mathbb{E}_{\\theta_0}(Y_1)\\)은 \\(\\theta_0\\) 에서 최대화 된다.\n(베르누이 예제)\n\\(\\mathbb{E}_{\\theta_0}(Y_1) = \\mathbb{E}_{\\theta_0}(X_1)\\log\\theta + (1-\\mathbb{E}_{\\theta_0}(X_1))\\log(1-\\theta) = \\frac{1}{3} \\log\\theta + (1-\\frac{1}{3})\\log(1-\\theta)\\)\n\n일반적인 상황에서는 참모수를 모르지만 우리는 시뮬레이션을 \\(\\theta=1/3\\)에서 하였으므로 참모수 \\(\\theta_0=\\mathbb{E}_{\\theta_0}(X_1)=\\frac{1}{3}\\)을 알고 있다고 가정한다.\n\n\nplot(θ -&gt; (1/3)*log(θ) + (1-1/3)*log(1-θ)) \n\n\n\n\n\n\n\n\n보는것처럼 이 함수 \\(\\mathbb{E}_{\\theta_0}(Y_1)\\)은 \\(\\theta=\\theta_0=\\frac{1}{3}\\) 에서 최대값을 가진다.\n(3) \\(\\frac{\\partial}{\\partial \\theta}Y_1\\) 역시 \\(X_1\\)와 \\(\\theta\\)의 함수이다.\n\n따라서 \\(\\frac{\\partial}{\\partial \\theta}Y_1\\) 역시 확률변수이고 \\(\\frac{\\partial}{\\partial \\theta}Y_1\\)에 대하여 평균등을 취할 수 있으며 LLN을 쓸 수 있다.\n\n(베르누이 예제)\n\\(\\frac{\\partial}{\\partial\\theta}Y_1 = X_1\\frac{1}{\\theta} + (1-X_1)\\frac{-1}{1-\\theta}\\)\n(4) \\(\\mathbb{E}_{\\theta}[\\frac{\\partial}{\\partial \\theta}Y_1]=0\\) 이다.\n(베르누이 예제)\n\\(\\mathbb{E}_{\\theta}[\\frac{\\partial}{\\partial\\theta}Y_1] = \\theta\\frac{1}{\\theta} + (1-\\theta)\\frac{-1}{1-\\theta}=0\\)\n(5) \\(\\mathbb{V}_{\\theta}[\\frac{\\partial}{\\partial\\theta}Y_1]=\\mathbb{E}_{\\theta}[-\\frac{\\partial^2}{\\partial \\theta^2}Y_1]=I(\\theta)\\)\n(베르누이 예제)\n\\(\\mathbb{V}_{\\theta}\\big[\\frac{\\partial}{\\partial\\theta}Y_1\\big]=\\mathbb{E}_{\\theta}\\big[(\\frac{\\partial}{\\partial\\theta}Y_1)^2\\big]=\\mathbb{E}_{\\theta}\\big[-\\frac{\\partial^2}{\\partial\\theta^2}Y_1\\big]=\\frac{1}{\\theta(1-\\theta)}\\)\n\n두번째 등호는 \\(\\mathbb{E}_{\\theta}[\\frac{\\partial}{\\partial\\theta}Y_1]=0\\)을 이용하여 증명가능하다.\n언뜻 보면 \\(\\mathbb{V}_{\\theta}\\big[\\frac{\\partial}{\\partial\\theta}Y_1\\big]\\)를 계산하는 것이 \\(\\mathbb{E}_{\\theta}\\big[-\\frac{\\partial^2}{\\partial\\theta^2}Y_1\\big]\\)를 계산하는것보다 훨씬 쉬워보인다. 그런데 \\(X_1\\)와 \\(1-X_1\\)이 독립이 아니라서 \\(\\mathbb{V}(X+Y)=\\mathbb{V}(X)+\\mathbb{V}(V)+2\\text{Cov}(X,Y)\\)와 같이 공분산 term을 계산해야 하므로 계산이 까다롭다.\n\n\n베르누이에 대한 피셔정보량은 https://en.wikipedia.org/wiki/Fisher_information 에서 확인할 수 있음"
  },
  {
    "objectID": "공부/2023-01-20-추정.html#footnotes",
    "href": "공부/2023-01-20-추정.html#footnotes",
    "title": "(공부) – 추정",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n거의 암산가능↩︎\n균등확률수렴성은 로그가능도함수가 strictly convex일 경우 성립한다는 것이 알려져 있음↩︎\nhttps://en.wikipedia.org/wiki/Identifiability↩︎\nidentifiable & common support↩︎"
  },
  {
    "objectID": "공부/2023-06-23-(공부) 지윤 -- 퓨리에변환4jy -- 논문지도.html",
    "href": "공부/2023-06-23-(공부) 지윤 -- 퓨리에변환4jy -- 논문지도.html",
    "title": "(공부&지윤) – 퓨리에변환4jy",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\n\n회귀모형 (1)\n\nx = np.linspace(-10,10,1000)\nx0 = x*0+1\nx1 = x \nbeta0 = 3 \nbeta1 = 2\ny = x0*beta0+x1*beta1+np.random.randn(1000)\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n\n\n회귀모형 (2)\n- 관측한자료\n\nN=1000\nx=np.linspace(0,1,N)\neps = np.random.randn(N)\nX0 = np.sin(x*0*np.pi)\nX1 = np.sin(x*2*np.pi)\nX2 = np.sin(x*4*np.pi)\nX3 = np.sin(x*6*np.pi)\n\ny=2*X1+1*X2+3*X3+eps\n\n\nplt.plot(x,y,'o',alpha=0.1)\n\n\n\n\n\n\n\n\n\nobserved signal\n\n- 위의 자료를 해석하는 방법\n\ndef spec(y):\n    N= len(y)\n    return abs(np.fft.fft(y)/N)*2 \n\n\ny=2*X1+1*X2+3*X3+eps\nyfft =spec(y) \ny1=2*X1\ny2=1*X2\ny3=3*X3\nyfft1=spec(y1)\nyfft2=spec(y2)\nyfft3=spec(y3)\nepsfft=spec(eps)\n\n\nplt.plot(yfft[:20],'o',alpha=0.5)\nplt.plot(yfft1[:20],'x',alpha=1,)\nplt.plot(yfft2[:20],'x',alpha=1)\nplt.plot(yfft3[:20],'x',alpha=1)\nplt.plot(epsfft[:20],'x',alpha=1)\n\n\n\n\n\n\n\n\n- 퓨리에변환 -&gt; threshold -&gt; 역퓨리에변환을 이용한 스킬\n\nyfft=np.fft.fft(y)\n\n\nplt.plot(abs(yfft[1:50]),'o')\n\n\n\n\n\n\n\n\n\nyfft[abs(yfft)&lt;100] = 0\n\n\nplt.plot(y,'o',alpha=0.1)\nyhat=np.fft.ifft(yfft)\nplt.plot(yhat,'--')\nplt.plot(y-eps,'-')\n\n\n\n\n\n\n\n\n\nplt.plot(spec2(y)[:50],'o')\nplt.plot(spec2(yhat)[:50],'x')\n\n\n\n\n\n\n\n\n\n\n삼성전자 주가자료를 스무딩해보기\n- 삼성전자 자료\n\nimport yfinance as yf\n\n\nstart_date = \"2023-01-01\"\nend_date = \"2023-05-02\"\ny = yf.download(\"005930.KS\", start=start_date, end=end_date)['Adj Close'].to_numpy()\n\n[*********************100%***********************]  1 of 1 completed\n\n\n\nplt.plot(y)\n\n\n\n\n\n\n\n\n- 스펙트럼\n\nyfft = np.fft.fft(y)\n\n\nplt.plot(abs(yfft))\n\n\n\n\n\n\n\n\n- 처음 50개정도만 관찰\n\nplt.plot(abs(yfft[:50]),'o')\n\n\n\n\n\n\n\n\n\n첫값이 너무커서 나머지는 잘안보임\n\n- 2번째부터 50번째까지만 관찰\n\nplt.plot(abs(yfft)[2:50],'o')\nplt.axhline(y=22500, color='r', linestyle='--')\n\n\n\n\n\n\n\n\n\n대충 이정도 짜르면 될것같음\n\n- thresholded value\n\ntresh_value = 22500\n\n\nyfft[abs(yfft)&lt;tresh_value] =0 \n\n- 퓨리에역변환\n\nyhat = np.fft.ifft(yfft)\nyhat[:5]\n\narray([59664.72193044+8.87311904e-14j, 58572.98839934+8.87311904e-14j,\n       58066.07369126+3.39894326e-14j, 58169.18671667-6.87747670e-14j,\n       58706.41986821-1.14383435e-13j])\n\n\n실수화\n\nyhat = np.real(yhat)\nyhat[:5]\n\narray([59664.72193044, 58572.98839934, 58066.07369126, 58169.18671667,\n       58706.41986821])\n\n\n- 적합결과 시각화\n\nplt.plot(y)\nplt.plot(yhat,'--')\n\n\n\n\n\n\n\n\n- 숙제: treshold value를 관찰하며 시각화해볼것\n\n\nminor topics\n- y의 FFT 결과는 항상 y와 같은길이임\n\nlen(y)\n\n82\n\n\n\nlen(np.fft.fft(y))\n\n82\n\n\n- 에일리어싱: number of observation은 얼마나 세밀한 주파수까지 측정가능하냐를 결정함\n예시1: 에일리어싱\n\nx = np.linspace(-3.14,3.14,10)\n\n\nx1 = np.sin(8*x)\nx2 = np.sin(10*x)\n\n\nnp.corrcoef([x1,x2])\n\narray([[ 1.        , -0.99975131],\n       [-0.99975131,  1.        ]])\n\n\n\nplt.plot(x1,label='x1')\nplt.plot(x2,label='x2')\nplt.legend()\n\n\n\n\n\n\n\n\n\n실제로는 x2가 더 고주파인데, 같은 주파수처럼 보임\n\n예시2: 에일리어싱이 없는 경우\n\nx = np.linspace(-3.14,3.14,100000)\n\n\nx1 = np.sin(8*x)\nx2 = np.sin(10*x)\n\n\nnp.corrcoef([x1,x2])\n\narray([[ 1.00000000e+00, -6.45767105e-08],\n       [-6.45767105e-08,  1.00000000e+00]])\n\n\n\nplt.plot(x1)\nplt.plot(x2)\n\n\n\n\n\n\n\n\n\n주파수 왜곡떄문에 실제로는 corr ceof = 0 일지라도 관측되는건 corr coef &gt;0 일 수 있음"
  },
  {
    "objectID": "공부/2023-05-13-(공부) 추정 -- 지윤 질문 답변.html",
    "href": "공부/2023-05-13-(공부) 추정 -- 지윤 질문 답변.html",
    "title": "[PINKOCTO] 추정 for JY",
    "section": "",
    "text": "- 비편향추정량(UB)란 \\(\\theta\\)의 추정량 중\n\\[\\forall \\theta\\in \\Theta:~ E(\\hat{\\theta})=\\theta\\]\n를 만족하는 추정량 \\(\\hat{\\theta}\\)을 의미한다.\n- (예시) 아래와 같은 상황을 가정하자.\n\\[X_n \\overset{iid}{\\sim} N(\\theta,1)\\]\n여기에서\n\n\\(\\hat{\\theta}_1=0\\) 은 \\(\\theta=0\\) 일 경우에는 \\(E(\\hat{\\theta})=\\theta\\) 를 만족하지만 그 외의 경우에는 \\(E(\\hat{\\theta})\\neq\\theta\\) 이므로 UB가 아니다.\n\\(\\hat{\\theta}_2=X_1\\) 은 UB이다.\n\\(\\hat{\\theta}_3=\\frac{X_1+X_2}{2}\\) 역시 UB이다.\n\\(\\hat{\\theta}_4=X_1+X_2-X_3\\) 역시 UB이다.\n\\(\\hat{\\theta}_5=-99X_1+100X_2\\) 역시 UB이다.\n\\(\\hat{\\theta}_6=\\frac{X_1+0}{2}\\) 은 1과 동일한 이유로 UB가 아니다.\n\\(\\hat{\\theta}_7=\\bar{X}\\)는 UB이다.\n\\(\\hat{\\theta}_8=w_1X_1+\\dots+w_nX_n\\) ,where \\(\\sum_{i=1}^{n}w_i=1\\) 형태의 estimator는 모두 UB이다.\n\n- 최소분산비편향추정량(MVUE)란 \\(\\theta\\)에 대한 비편향추정량을 모아놓은 집합 \\(\\hat{\\Theta}_{UB}\\) 에서 최소분산을 가지는 추정량을 의미한다. MVUE를 구하는 방법은 아래와 같다.\n\n\\(\\theta\\)에 대한 모든 비편향추정량을 구한다. 즉 집합 \\(\\hat{\\Theta}_{UB}\\)를 구한다. 그리고 \\(\\forall \\hat{\\theta} \\in \\hat{\\Theta}_{UB}\\) 에 대하여 \\(V(\\hat{\\theta})\\) 를 구한 뒤 \\(V(\\hat{\\theta})\\)가 가장 작은 \\(\\hat{\\theta}\\)를 선택한다.\n\n예를들어 위의 예제에서 \\(V(\\hat{\\theta}_2)=1\\) 이고 \\(V(\\hat{\\theta}_3)=\\frac{1}{4}+\\frac{1}{4}=\\frac{1}{2}\\) 이므로 \\(\\hat{\\theta}_3\\) 이 더 좋은 추정량이라 볼 수 있다.\n- (의문) 왜 비편향추정량만 모아서 그중에서 최소분산을 구할까?\n\n\\(\\hat{\\theta}_1\\)와 같은 추정량은 \\(V(\\hat{\\theta}_1)=0\\) 이므로 그냥 최소분산을 만족한다. 따라서 이러한 추정량은 제외해야지 게임이 성립함.\n\n- 불만: 아래의 방법으로 구하는건 거의 불가능하지 않나?\n\n\\(\\theta\\)에 대한 모든 비편향추정량을 구한다. 즉 집합 \\(\\hat{\\Theta}_{UB}\\)를 구한다. 그리고 \\(\\forall \\hat{\\theta} \\in \\hat{\\Theta}_{UB}\\) 에 대하여 \\(V(\\hat{\\theta})\\) 를 구한 뒤 \\(V(\\hat{\\theta})\\)가 가장 작은 \\(\\hat{\\theta}\\)를 선택한다.\n\n- 이론: 크래머라오 하한값(편의상 \\(L^\\star\\)이라고 하자)이라고 있는데, 이는 \\({\\Theta}_{UB}\\)에 존재하는 모든 추정량에 대한 분산의 하한값을 제공한다.1 즉 아래가 성립한다.\n\n\\(L^\\star\\) is Cramer-Rao lower bound \\(\\Rightarrow\\) \\(\\forall \\hat{\\theta} \\in {\\Theta}_{UB}:~ V(\\hat{\\theta}) \\geq L^\\star\\)\n\n역은 성립하지 않음을 주의하자. 즉 아래를 만족하는 \\(L\\)이 존재할 수 있다.\n\n\\(V(\\hat{\\theta}) \\geq L &gt; L^\\star\\) for some \\(\\hat{\\theta} \\in \\Theta_{UB}\\)\n\n- 위의 이론을 이용하면 아래의 논리전개를 펼 수 있다.\n\n\\(L^\\star\\)를 구한다.\n왠지 MVUE가 될 것 같은 \\(\\hat{\\theta}\\)을 하나 찍고 그것의 분산 \\(V(\\hat{\\theta})\\)를 구한다.\n만약에 \\(V(\\hat{\\theta})=L^\\star\\)를 만족하면 그 \\(\\hat{\\theta}\\)이 MVUE라고 주장할 수 있다.\n\n- 위의 논리전개에 대한 불만 [p.212]\n\n\\(V(\\hat{\\theta})=L^\\star\\) 이길 기도해야함.\n\\(\\forall \\hat{\\theta} \\in {\\Theta}_{UB}:~ V(\\hat{\\theta}) \\geq L &gt; L^\\star\\) 와 같은 \\(L\\)이 존재하는 경우는 쓸 수 없음.\n\n- 또 다른 방법: 완비충분통계량을 이용함\n\n\n아래와 같은 상황을 가정하자.\n\\[ X_1,\\dots,X_n \\overset{iid}{\\sim} P_{\\theta}\\]\n- 충분통계량(SS)의 느낌: “이 값만 기억하면 \\(\\theta\\)를 추정하는데 무난할듯”\n- 예시1: \\(X_1 \\sim N(\\theta,1)\\)\n\n\\(X_1\\)은 \\(\\theta_1\\) 의 SS. (하나밖에 없으니 그거라도 기억해야지)\n즉 \\(\\hat{\\theta}=X_1\\)은 \\(\\theta\\)의 SS\n\n- 예시2: \\(X_1,X_2 \\sim N(\\theta,1)\\)\n\n당연히 \\(\\hat{\\boldsymbol \\theta}=(X_1,X_2)\\)는 \\(\\theta\\)의 SS (둘다 기억하면 당연히 \\(\\theta\\)를 추정함에 있어서 충분함)\n그렇지만 좀 더 생각해보면 굳이 값 두개를 기억하기보다 \\(\\frac{1}{2}(X_1+X_2)\\)의 값만 기억해도 왠지 충분할것 같음. 따라서 \\(\\hat{\\theta} = \\frac{1}{2}(X_1+X_2)\\) 역시 \\(\\theta\\)의 SS 일듯\n그런데 좀 더 생각해보니까 \\(X_1+X_2\\)의 값만 기억해도 \\(\\frac{1}{2}(X_1+X_2)\\)를 나중에 만들 수 있음 (1/2만 곱하면 되니까) 따라서 \\(X_1+X_2\\)만 기억해도 왠지 충분할 것 같음. 따라서 \\(\\hat{\\theta}=X_1+X_2\\) 역시 \\(\\theta\\)의 SS 일듯\n\n- 예시3: \\(X_1,\\dots,X_n \\sim N(\\theta,1)\\)\n\n당연히 \\(\\hat{\\boldsymbol \\theta}=(X_1,X_2,\\dots,X_n)\\)은 \\(\\theta\\)의 SS.\n하지만 \\(n\\)개의 숫자를 기억할 필요 없이 \\(\\sum_{i=1}^{n} X_i\\) 하나의 숫자만 기억해도 왠지 충분할듯. 그래서 \\(\\hat{\\theta} = \\sum_{i=1}^{n} X_i\\) 역시 \\(\\theta\\)의 SS 일듯\n\n- SS에 대한 직관1\n\n기억할 숫자가 적을수록 유리 -&gt; MSS의 개념\n충분통계량의 1:1은 충분통계량 (\\(\\frac{1}{2}(X_1+X_2)\\)을 기억하면 충분한 상황이라면, \\(X_1+X_2\\)를 기억해도 충분하니까..)\n\n- 예시4: \\(X_1,X_2 \\sim {\\cal B}er(\\theta)\\)\n\n당연히 \\(\\hat{\\boldsymbol \\theta}=(X_1,X_2)\\)은 \\(\\theta\\)의 SS.\n그리고 \\(\\hat{\\theta}=X_1+X_2\\) 역시 \\(\\theta\\) SS 일듯.\n두개보다 한개가 유리하니까 둘다 SS이면 \\((X_1,X_2)\\)보다 \\(X_1+X_2\\)가 더 좋은 SS.\n\\(X_1\\)은 SS가 아닐듯. \\(p\\)를 추정함에 있어서 \\(X_1\\)만 가지고서는 충분하지 않아보임\n\\(X_2\\)도 SS가 아닐듯.\n\n왠지 충분할 것 같은 느낌의 정의\n아래와 같은 상황을 가정하자.\n\\[X_1,X_2 \\sim {\\cal B}er(\\theta)\\]\n- 일반적으로\n\n\\(P((X_1,X_2)=(0,0))=P(X_1=0,X_2=0)=(1-\\theta)^2\\)\n\\(P((X_1,X_2)=(0,1))=P(X_1=0,X_2=1)=\\theta(1-\\theta)\\)\n\\(P((X_1,X_2)=(1,0))=P(X_1=1,X_2=0)=(1-\\theta)^2\\)\n\\(P((X_1,X_2)=(1,1))=P(X_1=1,X_2=1)=\\theta^2\\)\n\n와 같은 확률들은 \\(\\theta\\)가 unknown일 때 하나의 숫자로 정할 수 없다. 예를들어 \\(\\theta=0\\) 이라면 아래와 같을 것이고\n\n\\(P((X_1,X_2)=(0,0))=P(X_1=0,X_2=0)=1\\)\n\\(P((X_1,X_2)=(0,1))=P(X_1=0,X_2=1)=0\\)\n\\(P((X_1,X_2)=(1,0))=P(X_1=1,X_2=0)=0\\)\n\\(P((X_1,X_2)=(1,1))=P(X_1=1,X_2=1)=0\\)\n\n\\(\\theta=1/2\\) 이라면 아래와 같을 것이다.\n\n\\(P((X_1,X_2)=(0,0))=P(X_1=0,X_2=0)=1/4\\)\n\\(P((X_1,X_2)=(0,1))=P(X_1=0,X_2=1)=1/4\\)\n\\(P((X_1,X_2)=(1,0))=P(X_1=1,X_2=0)=1/4\\)\n\\(P((X_1,X_2)=(1,1))=P(X_1=1,X_2=1)=1/4\\)\n\n즉 \\(X_1,X_2\\)의 결합확률분포는 \\(\\theta\\)가 변함에 따라 같이 변화한다. 이를 이용해 우리는 \\(X_1,X_2\\)의 결합확률분포에서 관찰한 샘플들을 이용하여 \\(\\theta\\)의 값을 역으로 추론한다.\n- 만약에 어떠한 “특수한 정보를 알고 있을 경우” \\(X_1,X_2\\)의 결합확률분포를 완벽하게 기술할 수 있을 때를 가정해보자.\n- 경우1: \\(\\theta\\)를 알고 있을 경우. \\((X_1,X_2)\\)의 조인트를 완벽하게 기술할 수 있다. 예를들어 \\(\\theta=1/2\\)일 경우는 아래와 같다.\n\n\\(P(X_1=0,X_2=0 | \\theta=1/2)=1/4\\)\n\\(P(X_1=0,X_2=1 | \\theta=1/2)=1/4\\)\n\\(P(X_1=1,X_2=0 | \\theta=1/2)=1/4\\)\n\\(P(X_1=1,X_2=1 | \\theta=1/2)=1/4\\)\n\n- 경우2: \\(X_1,X_2\\)의 realization을 알고 있을 경우. \\((X_1,X_2)\\)의 조인트를 완벽하게 기술할 수 있다. 예를들어 \\(X_1=0,X_2=1\\)일 경우는 아래와 같다.\n\n\\(P(X_1=0,X_2=0 | X_1=0,X_2=0)=0\\)\n\\(P(X_1=0,X_2=1| X_1=0,X_2=1)=0\\)\n\\(P(X_1=1,X_2=0| X_1=1,X_2=0)=1\\)\n\\(P(X_1=1,X_2=1| X_1=1,X_2=1)=0\\)\n\n- 경우3: \\((X_1+X_2)(\\omega)\\)의 realization을 알고 있을 경우. 이때도 매우 특이하게 \\((X_1,X_2)\\) 의 조인트를 완벽하게 기술할 수 있다.\ncase1: \\(X_1+X_2=0\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1+X_2=0)=1\\)\n\\(P(X_1=0,X_2=1| X_1+X_2=0)=0\\)\n\\(P(X_1=1,X_2=0| X_1+X_2=0)=0\\)\n\\(P(X_1=1,X_2=1| X_1+X_2=0)=0\\)\n\ncase2: \\(X_1+X_2=1\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1+X_2=1)=0\\)\n\\(P(X_1=0,X_2=1| X_1+X_2=1)=1/2\\)\n\\(P(X_1=1,X_2=0| X_1+X_2=1)=1/2\\)\n\\(P(X_1=1,X_2=1| X_1+X_2=1)=0\\)\n\ncase3: \\(X_1+X_2=2\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1+X_2=2)=0\\)\n\\(P(X_1=0,X_2=1| X_1+X_2=2)=0\\)\n\\(P(X_1=1,X_2=0| X_1+X_2=2)=0\\)\n\\(P(X_1=1,X_2=1| X_1+X_2=2)=1\\)\n\n- 경우4: \\(X_1\\)의 realization만 알고 있을 경우. 이때는 \\((X_1,X_2)\\) 의 조인트를 완벽하게 기술할 수 없다.\ncase1: \\(X_1=0\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1=0)=1-\\theta\\)\n\\(P(X_1=0,X_2=1| X_1=0)=\\theta\\)\n\\(P(X_1=1,X_2=0| X_1=0)=0\\)\n\\(P(X_1=1,X_2=1| X_1=0)=0\\)\n\ncase2: \\(X_1=1\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1=1)=0\\)\n\\(P(X_1=0,X_2=1| X_1=1)=0\\)\n\\(P(X_1=1,X_2=0| X_1=1)=1-\\theta\\)\n\\(P(X_1=1,X_2=1| X_1=1)=\\theta\\)\n\n- 종합해보면 경우1,경우2,경우3은 경우4와 구분되는 어떠한 공통점을 가지고 있다 볼 수 있다. 특징은 결합확률분포가 \\(\\theta\\)에 대한 함수로 표현되지 않는다는 것이다. 하나씩 살펴보면\n\n경우1: 당연히 \\(\\theta\\)를 줬으니까 \\((X_1,X_2)\\)의 조인트는 \\(\\theta\\)에 의존하지 않음.\n경우2: \\(X_1,X_2\\)를 줬음. \\((X_1,X_2)\\)의 조인트는 \\(\\theta\\)에 의존하지 않음.\n경우3: \\(X_1+X_2\\)를 줬음. \\((X_1,X_2)\\)의 조인트는 \\(\\theta\\)에 의존하지 않음.\n\n이렇게보면 경우1과 경우2,3은 또 다시 구분된다. 경우1은 \\(\\theta\\)에 대한 완전한 정보를 준 상황이므로 당연히 조인트는 \\(\\theta\\)에 의존하지 않는다. 경우2-3은 \\(\\theta\\)를 주지 않았음에도 조인트가 \\(\\theta\\)에 의존하지 않는 매우 특별해보이는 상황이다. 따라서 이를 통해서 유추하면\n\n경우2에서는 \\((X_1,X_2)\\) 가 경우3에서는 \\(X_1+X_2\\)가 \\(\\theta\\)에 대한 완전한 정보를 대신하고 있는것 아닐까?\n\n라는 생각이 든다. 정리하면\n\n경우2: \\((X_1,X_2)\\)을 주는 것은 \\(\\theta\\)의 값을 그냥 알려주는 것과 대등한 효과\n경우3: \\(X_1+X_2\\)를 주는 것은 \\(\\theta\\)의 값을 그냥 알려주는 것과 대등한 효과\n\n라고 해석할 수 있는데 이를 수식화 하면 아래와 같다.\n- 대충정의: 어떠한 통계량 \\(S\\)의 값을 줬을때, \\((X_1,X_2\\dots,X_n)\\)의 조인트가 \\(\\theta\\)에 의존하지 않으면 그 통계량 \\(S\\)를 \\(\\theta\\)의 충분통계량이라고 한다.\n- 충분통계량 구하는 방법\n\n지수족일때 구하는 방식이 있음! &lt;– 외우세여\n분해정리를 쓰는 경우. &lt;– 거의 안쓰는거같은데..\n1-2로도 잘 모르겠으면 충분통계량일듯한 애를 잡아와서 정의에 넣고 노가다로 때려맞춤. (문제가 디스크릿할때만 쓸것)\n\n\n\n\n- 충분통계량에 대한 realization을 알려주면 \\(\\theta\\)의 값을 그냥 알려주는 효과임. 그래서 충분통계량은 좋은 것임\n- 그런데 충분통계량에도 급이 있음. 아래와 같은 상황을 가정하자.\n\\[X_1,X_2 \\sim {\\cal B}er(\\theta)\\]\n이 경우\n\n\\((X_1,X_2)\\)는 SS\n\\(X_1+X_2\\)는 SS\n\n이지만 1은 두개의 숫자를 기억해야하고 2는 하나의 숫자만 기억하면 되니까 2가 더 좋음\n- 예비개념: 상태1과 상태2가 있다고 하자. 상태1에서 상태2로 가는 변화는 쉽지만, 상태2에서 상태1로 가는 변화는 어렵다고 할때, 상태1이 더 좋은 상태이다.\n\n두가지 상태 “500원을 가지고 있음”, “1000원을 가지고 있음” 을 고려하자. 1000원을 500원을 만드는 것은 쉽지만 500원을 1000원으로 만들기는 어렵다. 따라서 1000원이 더 좋은 상태이다.\n\n- 충분통계량의 급을 어떻게 구분할까? 아래의 상황에서\n\n\\((X_1,X_2)\\)는 SS\n\\(X_1+X_2\\)는 SS\n\n1을 이용하면 2를 만들 수 있지만, 2를 이용해서 1을 만들 수는 없음. 즉 \\(1\\to 2\\) 인 변환(=함수)는 가능하지만 \\(2\\to 1\\)로 만드는 변환(=함수)는 가능하지 않음. 예비개념을 잘 이해했다면 2가 더 좋은 상태라고 볼 수 있다.\n- 이를 확장하자. 어떠한 충분 통계량 \\(S^\\star\\)가 있다고 가정하자. 다른 모든 충분통계량 \\(S_1,S_2,S_3 \\dots\\)에서 \\(S^\\star\\)로 만드는 변환은 존재하는데 (함수는 존재하는데) 그 반대는 \\(S^\\star\\)의 전단사인 충분통계량만 가능하다고 하자. 그렇다면 \\(S^\\star\\)는 가장 좋은 충분통계량이라고 하며, 가장 적은 숫자만 기억하면 되는 충분통계량이라 볼 수 있다. 이러한 충분통계량을 MSS 라고 하자.\n\n\n\n- 충분통계량 \\(S\\)을 알려주면 (기븐하면) \\(\\theta\\)에 대한 완벽한 정보를 알려주는 셈이다. 따라서 \\(\\theta\\)를 추정하는 어떠한 추정량 \\(\\hat{\\theta}\\)도 충분통계량의 정보 \\(S\\)가 있다면 \\(\\hat{\\theta}\\)를 업그레이드할 수 있다고 볼 수 있다. (뭐 수틀리면 정보야 안쓰면 그만이니까 나빠질것은 없다)\n- 충분통계량을 줬을때 \\(\\hat{\\theta}\\)의 업그레이드 방법은\n\\[\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\]\n와 같이 할 수 있는데 이는 충분통계량 \\(S\\)의 정보를 받아서 어떠한 방식으로 업데이트된 \\(\\hat{\\theta}\\) 이므로 \\(S\\)의 함수라 해석할 수 있다.\n- 이론 (라오블랙웰, Thm, 4.5): \\(\\hat{\\theta}\\)가 UB일때 충분통계량의 값을 알려주면 \\(\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\)와 같이 \\(\\hat{\\theta}\\)를 업그레이드 할 수 있다.\n\n\n\n- 충분통계량 \\(S\\)을 알려주면 (기븐하면) \\(\\theta\\)에 대한 완벽한 정보를 알려주는 셈이다. 따라서 \\(\\theta\\)를 추정하는 어떠한 추정량 \\(\\hat{\\theta}\\)도 충분통계량의 정보 \\(S\\)가 있다면 \\(\\hat{\\theta}\\)를 업그레이드할 수 있다고 볼 수 있다. (뭐 수틀리면 정보야 안쓰면 그만이니까 나빠질것은 없다)\n- 충분통계량을 줬을때 \\(\\hat{\\theta}\\)의 업그레이드 방법은\n\\[\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\]\n와 같이 할 수 있는데 이는 충분통계량 \\(S\\)의 정보를 받아서 어떠한 방식으로 업데이트된 \\(\\hat{\\theta}\\) 이므로 \\(S\\)의 함수라 해석할 수 있다.\n- 이론 (라오블랙웰, Thm, 4.5): \\(\\hat{\\theta}\\)가 UB일때 충분통계량의 값을 알려주면 \\(\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\)와 같이 \\(\\hat{\\theta}\\)를 업그레이드 할 수 있다."
  },
  {
    "objectID": "공부/2023-05-13-(공부) 추정 -- 지윤 질문 답변.html#충분통계량",
    "href": "공부/2023-05-13-(공부) 추정 -- 지윤 질문 답변.html#충분통계량",
    "title": "[PINKOCTO] 추정 for JY",
    "section": "",
    "text": "아래와 같은 상황을 가정하자.\n\\[ X_1,\\dots,X_n \\overset{iid}{\\sim} P_{\\theta}\\]\n- 충분통계량(SS)의 느낌: “이 값만 기억하면 \\(\\theta\\)를 추정하는데 무난할듯”\n- 예시1: \\(X_1 \\sim N(\\theta,1)\\)\n\n\\(X_1\\)은 \\(\\theta_1\\) 의 SS. (하나밖에 없으니 그거라도 기억해야지)\n즉 \\(\\hat{\\theta}=X_1\\)은 \\(\\theta\\)의 SS\n\n- 예시2: \\(X_1,X_2 \\sim N(\\theta,1)\\)\n\n당연히 \\(\\hat{\\boldsymbol \\theta}=(X_1,X_2)\\)는 \\(\\theta\\)의 SS (둘다 기억하면 당연히 \\(\\theta\\)를 추정함에 있어서 충분함)\n그렇지만 좀 더 생각해보면 굳이 값 두개를 기억하기보다 \\(\\frac{1}{2}(X_1+X_2)\\)의 값만 기억해도 왠지 충분할것 같음. 따라서 \\(\\hat{\\theta} = \\frac{1}{2}(X_1+X_2)\\) 역시 \\(\\theta\\)의 SS 일듯\n그런데 좀 더 생각해보니까 \\(X_1+X_2\\)의 값만 기억해도 \\(\\frac{1}{2}(X_1+X_2)\\)를 나중에 만들 수 있음 (1/2만 곱하면 되니까) 따라서 \\(X_1+X_2\\)만 기억해도 왠지 충분할 것 같음. 따라서 \\(\\hat{\\theta}=X_1+X_2\\) 역시 \\(\\theta\\)의 SS 일듯\n\n- 예시3: \\(X_1,\\dots,X_n \\sim N(\\theta,1)\\)\n\n당연히 \\(\\hat{\\boldsymbol \\theta}=(X_1,X_2,\\dots,X_n)\\)은 \\(\\theta\\)의 SS.\n하지만 \\(n\\)개의 숫자를 기억할 필요 없이 \\(\\sum_{i=1}^{n} X_i\\) 하나의 숫자만 기억해도 왠지 충분할듯. 그래서 \\(\\hat{\\theta} = \\sum_{i=1}^{n} X_i\\) 역시 \\(\\theta\\)의 SS 일듯\n\n- SS에 대한 직관1\n\n기억할 숫자가 적을수록 유리 -&gt; MSS의 개념\n충분통계량의 1:1은 충분통계량 (\\(\\frac{1}{2}(X_1+X_2)\\)을 기억하면 충분한 상황이라면, \\(X_1+X_2\\)를 기억해도 충분하니까..)\n\n- 예시4: \\(X_1,X_2 \\sim {\\cal B}er(\\theta)\\)\n\n당연히 \\(\\hat{\\boldsymbol \\theta}=(X_1,X_2)\\)은 \\(\\theta\\)의 SS.\n그리고 \\(\\hat{\\theta}=X_1+X_2\\) 역시 \\(\\theta\\) SS 일듯.\n두개보다 한개가 유리하니까 둘다 SS이면 \\((X_1,X_2)\\)보다 \\(X_1+X_2\\)가 더 좋은 SS.\n\\(X_1\\)은 SS가 아닐듯. \\(p\\)를 추정함에 있어서 \\(X_1\\)만 가지고서는 충분하지 않아보임\n\\(X_2\\)도 SS가 아닐듯.\n\n왠지 충분할 것 같은 느낌의 정의\n아래와 같은 상황을 가정하자.\n\\[X_1,X_2 \\sim {\\cal B}er(\\theta)\\]\n- 일반적으로\n\n\\(P((X_1,X_2)=(0,0))=P(X_1=0,X_2=0)=(1-\\theta)^2\\)\n\\(P((X_1,X_2)=(0,1))=P(X_1=0,X_2=1)=\\theta(1-\\theta)\\)\n\\(P((X_1,X_2)=(1,0))=P(X_1=1,X_2=0)=(1-\\theta)^2\\)\n\\(P((X_1,X_2)=(1,1))=P(X_1=1,X_2=1)=\\theta^2\\)\n\n와 같은 확률들은 \\(\\theta\\)가 unknown일 때 하나의 숫자로 정할 수 없다. 예를들어 \\(\\theta=0\\) 이라면 아래와 같을 것이고\n\n\\(P((X_1,X_2)=(0,0))=P(X_1=0,X_2=0)=1\\)\n\\(P((X_1,X_2)=(0,1))=P(X_1=0,X_2=1)=0\\)\n\\(P((X_1,X_2)=(1,0))=P(X_1=1,X_2=0)=0\\)\n\\(P((X_1,X_2)=(1,1))=P(X_1=1,X_2=1)=0\\)\n\n\\(\\theta=1/2\\) 이라면 아래와 같을 것이다.\n\n\\(P((X_1,X_2)=(0,0))=P(X_1=0,X_2=0)=1/4\\)\n\\(P((X_1,X_2)=(0,1))=P(X_1=0,X_2=1)=1/4\\)\n\\(P((X_1,X_2)=(1,0))=P(X_1=1,X_2=0)=1/4\\)\n\\(P((X_1,X_2)=(1,1))=P(X_1=1,X_2=1)=1/4\\)\n\n즉 \\(X_1,X_2\\)의 결합확률분포는 \\(\\theta\\)가 변함에 따라 같이 변화한다. 이를 이용해 우리는 \\(X_1,X_2\\)의 결합확률분포에서 관찰한 샘플들을 이용하여 \\(\\theta\\)의 값을 역으로 추론한다.\n- 만약에 어떠한 “특수한 정보를 알고 있을 경우” \\(X_1,X_2\\)의 결합확률분포를 완벽하게 기술할 수 있을 때를 가정해보자.\n- 경우1: \\(\\theta\\)를 알고 있을 경우. \\((X_1,X_2)\\)의 조인트를 완벽하게 기술할 수 있다. 예를들어 \\(\\theta=1/2\\)일 경우는 아래와 같다.\n\n\\(P(X_1=0,X_2=0 | \\theta=1/2)=1/4\\)\n\\(P(X_1=0,X_2=1 | \\theta=1/2)=1/4\\)\n\\(P(X_1=1,X_2=0 | \\theta=1/2)=1/4\\)\n\\(P(X_1=1,X_2=1 | \\theta=1/2)=1/4\\)\n\n- 경우2: \\(X_1,X_2\\)의 realization을 알고 있을 경우. \\((X_1,X_2)\\)의 조인트를 완벽하게 기술할 수 있다. 예를들어 \\(X_1=0,X_2=1\\)일 경우는 아래와 같다.\n\n\\(P(X_1=0,X_2=0 | X_1=0,X_2=0)=0\\)\n\\(P(X_1=0,X_2=1| X_1=0,X_2=1)=0\\)\n\\(P(X_1=1,X_2=0| X_1=1,X_2=0)=1\\)\n\\(P(X_1=1,X_2=1| X_1=1,X_2=1)=0\\)\n\n- 경우3: \\((X_1+X_2)(\\omega)\\)의 realization을 알고 있을 경우. 이때도 매우 특이하게 \\((X_1,X_2)\\) 의 조인트를 완벽하게 기술할 수 있다.\ncase1: \\(X_1+X_2=0\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1+X_2=0)=1\\)\n\\(P(X_1=0,X_2=1| X_1+X_2=0)=0\\)\n\\(P(X_1=1,X_2=0| X_1+X_2=0)=0\\)\n\\(P(X_1=1,X_2=1| X_1+X_2=0)=0\\)\n\ncase2: \\(X_1+X_2=1\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1+X_2=1)=0\\)\n\\(P(X_1=0,X_2=1| X_1+X_2=1)=1/2\\)\n\\(P(X_1=1,X_2=0| X_1+X_2=1)=1/2\\)\n\\(P(X_1=1,X_2=1| X_1+X_2=1)=0\\)\n\ncase3: \\(X_1+X_2=2\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1+X_2=2)=0\\)\n\\(P(X_1=0,X_2=1| X_1+X_2=2)=0\\)\n\\(P(X_1=1,X_2=0| X_1+X_2=2)=0\\)\n\\(P(X_1=1,X_2=1| X_1+X_2=2)=1\\)\n\n- 경우4: \\(X_1\\)의 realization만 알고 있을 경우. 이때는 \\((X_1,X_2)\\) 의 조인트를 완벽하게 기술할 수 없다.\ncase1: \\(X_1=0\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1=0)=1-\\theta\\)\n\\(P(X_1=0,X_2=1| X_1=0)=\\theta\\)\n\\(P(X_1=1,X_2=0| X_1=0)=0\\)\n\\(P(X_1=1,X_2=1| X_1=0)=0\\)\n\ncase2: \\(X_1=1\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1=1)=0\\)\n\\(P(X_1=0,X_2=1| X_1=1)=0\\)\n\\(P(X_1=1,X_2=0| X_1=1)=1-\\theta\\)\n\\(P(X_1=1,X_2=1| X_1=1)=\\theta\\)\n\n- 종합해보면 경우1,경우2,경우3은 경우4와 구분되는 어떠한 공통점을 가지고 있다 볼 수 있다. 특징은 결합확률분포가 \\(\\theta\\)에 대한 함수로 표현되지 않는다는 것이다. 하나씩 살펴보면\n\n경우1: 당연히 \\(\\theta\\)를 줬으니까 \\((X_1,X_2)\\)의 조인트는 \\(\\theta\\)에 의존하지 않음.\n경우2: \\(X_1,X_2\\)를 줬음. \\((X_1,X_2)\\)의 조인트는 \\(\\theta\\)에 의존하지 않음.\n경우3: \\(X_1+X_2\\)를 줬음. \\((X_1,X_2)\\)의 조인트는 \\(\\theta\\)에 의존하지 않음.\n\n이렇게보면 경우1과 경우2,3은 또 다시 구분된다. 경우1은 \\(\\theta\\)에 대한 완전한 정보를 준 상황이므로 당연히 조인트는 \\(\\theta\\)에 의존하지 않는다. 경우2-3은 \\(\\theta\\)를 주지 않았음에도 조인트가 \\(\\theta\\)에 의존하지 않는 매우 특별해보이는 상황이다. 따라서 이를 통해서 유추하면\n\n경우2에서는 \\((X_1,X_2)\\) 가 경우3에서는 \\(X_1+X_2\\)가 \\(\\theta\\)에 대한 완전한 정보를 대신하고 있는것 아닐까?\n\n라는 생각이 든다. 정리하면\n\n경우2: \\((X_1,X_2)\\)을 주는 것은 \\(\\theta\\)의 값을 그냥 알려주는 것과 대등한 효과\n경우3: \\(X_1+X_2\\)를 주는 것은 \\(\\theta\\)의 값을 그냥 알려주는 것과 대등한 효과\n\n라고 해석할 수 있는데 이를 수식화 하면 아래와 같다.\n- 대충정의: 어떠한 통계량 \\(S\\)의 값을 줬을때, \\((X_1,X_2\\dots,X_n)\\)의 조인트가 \\(\\theta\\)에 의존하지 않으면 그 통계량 \\(S\\)를 \\(\\theta\\)의 충분통계량이라고 한다.\n- 충분통계량 구하는 방법\n\n지수족일때 구하는 방식이 있음! &lt;– 외우세여\n분해정리를 쓰는 경우. &lt;– 거의 안쓰는거같은데..\n1-2로도 잘 모르겠으면 충분통계량일듯한 애를 잡아와서 정의에 넣고 노가다로 때려맞춤. (문제가 디스크릿할때만 쓸것)"
  },
  {
    "objectID": "공부/2023-05-13-(공부) 추정 -- 지윤 질문 답변.html#최소충분통계량",
    "href": "공부/2023-05-13-(공부) 추정 -- 지윤 질문 답변.html#최소충분통계량",
    "title": "[PINKOCTO] 추정 for JY",
    "section": "",
    "text": "- 충분통계량에 대한 realization을 알려주면 \\(\\theta\\)의 값을 그냥 알려주는 효과임. 그래서 충분통계량은 좋은 것임\n- 그런데 충분통계량에도 급이 있음. 아래와 같은 상황을 가정하자.\n\\[X_1,X_2 \\sim {\\cal B}er(\\theta)\\]\n이 경우\n\n\\((X_1,X_2)\\)는 SS\n\\(X_1+X_2\\)는 SS\n\n이지만 1은 두개의 숫자를 기억해야하고 2는 하나의 숫자만 기억하면 되니까 2가 더 좋음\n- 예비개념: 상태1과 상태2가 있다고 하자. 상태1에서 상태2로 가는 변화는 쉽지만, 상태2에서 상태1로 가는 변화는 어렵다고 할때, 상태1이 더 좋은 상태이다.\n\n두가지 상태 “500원을 가지고 있음”, “1000원을 가지고 있음” 을 고려하자. 1000원을 500원을 만드는 것은 쉽지만 500원을 1000원으로 만들기는 어렵다. 따라서 1000원이 더 좋은 상태이다.\n\n- 충분통계량의 급을 어떻게 구분할까? 아래의 상황에서\n\n\\((X_1,X_2)\\)는 SS\n\\(X_1+X_2\\)는 SS\n\n1을 이용하면 2를 만들 수 있지만, 2를 이용해서 1을 만들 수는 없음. 즉 \\(1\\to 2\\) 인 변환(=함수)는 가능하지만 \\(2\\to 1\\)로 만드는 변환(=함수)는 가능하지 않음. 예비개념을 잘 이해했다면 2가 더 좋은 상태라고 볼 수 있다.\n- 이를 확장하자. 어떠한 충분 통계량 \\(S^\\star\\)가 있다고 가정하자. 다른 모든 충분통계량 \\(S_1,S_2,S_3 \\dots\\)에서 \\(S^\\star\\)로 만드는 변환은 존재하는데 (함수는 존재하는데) 그 반대는 \\(S^\\star\\)의 전단사인 충분통계량만 가능하다고 하자. 그렇다면 \\(S^\\star\\)는 가장 좋은 충분통계량이라고 하며, 가장 적은 숫자만 기억하면 되는 충분통계량이라 볼 수 있다. 이러한 충분통계량을 MSS 라고 하자."
  },
  {
    "objectID": "공부/2023-05-13-(공부) 추정 -- 지윤 질문 답변.html#라오블랙웰",
    "href": "공부/2023-05-13-(공부) 추정 -- 지윤 질문 답변.html#라오블랙웰",
    "title": "[PINKOCTO] 추정 for JY",
    "section": "",
    "text": "- 충분통계량 \\(S\\)을 알려주면 (기븐하면) \\(\\theta\\)에 대한 완벽한 정보를 알려주는 셈이다. 따라서 \\(\\theta\\)를 추정하는 어떠한 추정량 \\(\\hat{\\theta}\\)도 충분통계량의 정보 \\(S\\)가 있다면 \\(\\hat{\\theta}\\)를 업그레이드할 수 있다고 볼 수 있다. (뭐 수틀리면 정보야 안쓰면 그만이니까 나빠질것은 없다)\n- 충분통계량을 줬을때 \\(\\hat{\\theta}\\)의 업그레이드 방법은\n\\[\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\]\n와 같이 할 수 있는데 이는 충분통계량 \\(S\\)의 정보를 받아서 어떠한 방식으로 업데이트된 \\(\\hat{\\theta}\\) 이므로 \\(S\\)의 함수라 해석할 수 있다.\n- 이론 (라오블랙웰, Thm, 4.5): \\(\\hat{\\theta}\\)가 UB일때 충분통계량의 값을 알려주면 \\(\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\)와 같이 \\(\\hat{\\theta}\\)를 업그레이드 할 수 있다."
  },
  {
    "objectID": "공부/2023-05-13-(공부) 추정 -- 지윤 질문 답변.html#레만쉐페정리",
    "href": "공부/2023-05-13-(공부) 추정 -- 지윤 질문 답변.html#레만쉐페정리",
    "title": "[PINKOCTO] 추정 for JY",
    "section": "",
    "text": "- 충분통계량 \\(S\\)을 알려주면 (기븐하면) \\(\\theta\\)에 대한 완벽한 정보를 알려주는 셈이다. 따라서 \\(\\theta\\)를 추정하는 어떠한 추정량 \\(\\hat{\\theta}\\)도 충분통계량의 정보 \\(S\\)가 있다면 \\(\\hat{\\theta}\\)를 업그레이드할 수 있다고 볼 수 있다. (뭐 수틀리면 정보야 안쓰면 그만이니까 나빠질것은 없다)\n- 충분통계량을 줬을때 \\(\\hat{\\theta}\\)의 업그레이드 방법은\n\\[\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\]\n와 같이 할 수 있는데 이는 충분통계량 \\(S\\)의 정보를 받아서 어떠한 방식으로 업데이트된 \\(\\hat{\\theta}\\) 이므로 \\(S\\)의 함수라 해석할 수 있다.\n- 이론 (라오블랙웰, Thm, 4.5): \\(\\hat{\\theta}\\)가 UB일때 충분통계량의 값을 알려주면 \\(\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\)와 같이 \\(\\hat{\\theta}\\)를 업그레이드 할 수 있다."
  },
  {
    "objectID": "공부/2023-05-13-(공부) 추정 -- 지윤 질문 답변.html#footnotes",
    "href": "공부/2023-05-13-(공부) 추정 -- 지윤 질문 답변.html#footnotes",
    "title": "[PINKOCTO] 추정 for JY",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n(사실 \\({\\Theta}_{UB}\\)가 아닌 집합에 대해서도 하한값을 제공함, 그런데 교재에서는 \\({\\Theta}_{UB}\\)에 대한 하한값만 다루는듯↩︎"
  },
  {
    "objectID": "재인.html",
    "href": "재인.html",
    "title": "재인",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nOct 12, 2023\n\n\n(연구&재인) MBTI – MBTI\n\n\n신록예찬 \n\n\n\n\nOct 11, 2023\n\n\n(연구&재인) MBTI – 감성분석\n\n\n신록예찬 \n\n\n\n\n\nNo matching items",
    "crumbs": [
      "DL2022",
      "연구",
      "재인"
    ]
  },
  {
    "objectID": "자료/2023-11-09-(자료) 데이터생성 -- 성별,몸무게 --> 키.html",
    "href": "자료/2023-11-09-(자료) 데이터생성 -- 성별,몸무게 --> 키.html",
    "title": "(자료) 데이터생성 – 성별,몸무게 –> 키",
    "section": "",
    "text": "- imports\n\nimport numpy as np\nimport pandas as pd\nimport sklearn.model_selection\nimport seaborn as sns\n\n- 결측이 있는 자료\n\nnp.random.seed(42)\ndata = np.array(['male'] * 500 + ['female'] * 500)\ndef sample_data(data, male_prob, female_prob, size):\n    male_sample = np.random.choice(data[data=='male'], size=int(size * male_prob))\n    female_sample = np.random.choice(data[data=='female'], size=int(size * female_prob))\n    return np.concatenate([male_sample, female_sample])\ntrain = sample_data(data, 0.8, 0.2, 280)\ntest = sample_data(data, 0.2, 0.8, 120)\nnp.random.shuffle(train)\nnp.random.shuffle(test)\nsex = np.concatenate([train,test])\nweight = np.random.randn(400)*7\nheight = np.random.randn(400)*3\nfor i,s in enumerate(sex):\n    if s =='male':\n        weight[i] = 75+weight[i]\n        height[i] = height[i]+0.8*weight[i]+120\n    else:\n        weight[i] = 50+weight[i]*0.6\n        height[i] = height[i]+1.3*weight[i]+100\ndf = pd.DataFrame({'weight':weight,'sex':sex,'height':height})\nmissing_ratio = 0.2\nnum_missing = int(len(df) * missing_ratio)\nmissing_indices = np.random.choice(df.index, size=num_missing, replace=False)\ndf.loc[missing_indices, 'weight'] = np.nan\ndf_train, df_test = sklearn.model_selection.train_test_split(df,test_size=120)\n\n\nsns.scatterplot(df, x='weight', y='height', hue='sex')\n\n\n\n\n\n\n\n\n자료특징\n\n결측값이 있다.\ntr에는 남자가, test에는 여자가 많다.\n남녀의 (몸무게,키)의 분포는 서로 다르다."
  },
  {
    "objectID": "연구/지윤/2023-07-17-(연구) 지윤 -- 0717 면담.html",
    "href": "연구/지윤/2023-07-17-(연구) 지윤 -- 0717 면담.html",
    "title": "(연구&지윤) – 0717 면담",
    "section": "",
    "text": "23-07-17\n- 실험해볼것 (모형, 필터/lag, 에폭 변화하여서) 50번정도..\n\n에폭이 적을수록 우리가 잘맞았음.\n필터나 lag도 단순할수록 괜찮았음\nlag은 24를 넘길 필요는 없음.\n필터는 64이상은 필요없는듯\n\n- quarto 팁\nquarto preview --host 210.117.173.182 --no-browser\n- 파라메트릭 vs 넌파 vs 세미\n- 비트시그널\n- 발표자료 + 페이퍼작업\n- 레퍼런스정리\n\nGNN -&gt; GCN / RGNN -&gt; STGCN, ST-GCN\n\n23-07-20\n- 라마: https://www.youtube.com/watch?v=OZbarkziC14\n- 저널 vs 학회:\n\n원래개념: SCIE (~10) &gt;&gt;&gt;&gt;&gt;&gt; SCIE (10~50) &gt;&gt; SCIE(50~) &gt;&gt;&gt;&gt;&gt;&gt; KCI &gt;&gt; 컨퍼런스\nAI분야 한정: SCIE (~10), 일부top컨퍼런스 (NIPS, AAAI, ICML, ICLR) &gt;&gt;&gt;&gt;&gt;&gt; SCIE (10~50) &gt;&gt; SCIE(50~) &gt;&gt;&gt;&gt;&gt;&gt; KCI &gt;&gt; 컨퍼런스\n\n- 오타발견시알려주세요\n\nhttps://guebin.github.io/PP2023SUM/\n\n23-08-14\n논문쓰는 방법\n1. introduction = motivating ex (원래 반반)\n\nmotivating ex 로 시작할수도 있고 –&gt; 방법론에 강점이 있을때\nsolar enery에 대한 개론으로 시작 –&gt; 데이터가 자신있을 경우\n담백하게 (1) goal (2) method (3) contribution –&gt; 이론적인 측면에 자신이 있을때 꼭 들어가야 하는 것\n구성 // Graphical abstract\n기존방법과 차이점 (*)\n\n\n\n\nGraphical abstract 예시 @li2022multi\n\n\n2. review existing methods (원래 지윤학생, 수틀리면 내가)\n\nRGCN 까지 이어지는 연구흐름을 간략하게 소개\n\n3. proposed method (원래 지윤학생이 해야하는데, 안되면 내가)\n\n우리가 제안하는 방법이 기존과 무엇이 다르냐?\n수식, 알고리즘, 이론적 백그라운드\n\n4. simulation study (연구의 꽃) - beat signal - priodic signal * low-freq amplitude signal 꼴의 신호의 분해 - 시뮬레이션 데이터를 고안 + 결과를 입증\n5. real-data analysis (지윤학생이 거의다 해야함) - 일사량자료 분석 결과 - 우리가 제인한방법 + 기존의 방법들 -&gt; 퍼포먼스 비교 - 데이터설명 - 데이터는 어디에서 얻었는지, 언제부터 언제까지인지, 데이터의 특징 (주기성을 가진다. 0인 값이 많다) - 그림을 보여줘야함\n6. conclusion & future works & limitations & 어디에 활용\n\n결론: 좋은 분석이었다..\n한계: 어떠한 점에 한계가 있다. -&gt; 향후연구: 향후에는 어떤연구로 발전할 것이다.. (다른변수를 고려해서 할 예정이다)\n활용: 주기성을 가진 어떠한 자료도 우리의 방법을 사용하면 잘 예측할수있어요.."
  },
  {
    "objectID": "공부/2023-10-21-(공부) 지윤 -- Imputer와 Scaler의 적용 -- 질문답변.html",
    "href": "공부/2023-10-21-(공부) 지윤 -- Imputer와 Scaler의 적용 -- 질문답변.html",
    "title": "(연구) 지윤 – Imputer와 Scaler의 적용 (질문내용)",
    "section": "",
    "text": "import numpy as np \nimport pandas as pd\nimport sklearn.preprocessing\nimport sklearn.impute \n\n\nX = pd.DataFrame({'X':[7.424885,4.201394,np.nan,np.nan,5.190914,np.nan,6.433033]})\nX\n\n\n\n\n\n\n\n\nX\n\n\n\n\n0\n7.424885\n\n\n1\n4.201394\n\n\n2\nNaN\n\n\n3\nNaN\n\n\n4\n5.190914\n\n\n5\nNaN\n\n\n6\n6.433033\n\n\n\n\n\n\n\n\nsclr = sklearn.preprocessing.StandardScaler()\nimputr = sklearn.impute.SimpleImputer()\n\n\nsclr.fit(X.dropna())\n\nStandardScaler()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.StandardScalerStandardScaler()\n\n\n\nsclr.transform(imputr.fit_transform(X))\n\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n\n\narray([[ 1.32010944],\n       [-1.31915477],\n       [ 0.        ],\n       [ 0.        ],\n       [-0.50897577],\n       [ 0.        ],\n       [ 0.50802109]])"
  },
  {
    "objectID": "공부/2023-06-28-(공부&지윤) -- 퓨리에변환(detailed) -- 논문지도.html",
    "href": "공부/2023-06-28-(공부&지윤) -- 퓨리에변환(detailed) -- 논문지도.html",
    "title": "(공부&지윤) – 퓨리에변환(detailed)",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "공부/2023-06-28-(공부&지윤) -- 퓨리에변환(detailed) -- 논문지도.html#이론-및-예시",
    "href": "공부/2023-06-28-(공부&지윤) -- 퓨리에변환(detailed) -- 논문지도.html#이론-및-예시",
    "title": "(공부&지윤) – 퓨리에변환(detailed)",
    "section": "이론 및 예시",
    "text": "이론 및 예시\n- 이론: real-valued signal은 무조건 \\(|X[k]|^2\\)의 그래프가 대칭으로 나옴 (단, \\(X[0]\\)은 제외)\n- 예시1:\n\nx = np.array([1,2,3,4,5])\nX = np.fft.fft(x) \n\n\nplt.plot(abs(X)**2,'o')\n\n\n\n\n\n\n\n\n\n첫항을 제외하고 대칭임\n\n- 예시2:\n\nx = np.array([1,2,3,-3,-2,-1])\nX = np.fft.fft(x) \n\n\nplt.plot(abs(X)**2,'o')\n\n\n\n\n\n\n\n\n\n첫항을 제외하고 대칭임\n\n- 예시3: \\({\\bf x}\\)가 복소수일 경우는 첫항을 제외하고 대칭이 되지 않음\n\nx = np.array([1+1j,2+2j,3+3j,-3-3j,-2-2j,1-1j]) \nX = np.fft.fft(x) \n\n\nplt.plot(abs(X)**2,'o')"
  },
  {
    "objectID": "공부/2023-06-28-(공부&지윤) -- 퓨리에변환(detailed) -- 논문지도.html#왜-xn이-실수일-경우만-xk2이-대칭으로-나올까",
    "href": "공부/2023-06-28-(공부&지윤) -- 퓨리에변환(detailed) -- 논문지도.html#왜-xn이-실수일-경우만-xk2이-대칭으로-나올까",
    "title": "(공부&지윤) – 퓨리에변환(detailed)",
    "section": "왜 \\(x[n]\\)이 실수일 경우만 \\(|X[k]|^2\\)이 대칭으로 나올까?",
    "text": "왜 \\(x[n]\\)이 실수일 경우만 \\(|X[k]|^2\\)이 대칭으로 나올까?\n- 예비학습1\n임의의 \\(0 \\leq \\alpha \\leq 1\\)에 대하여 \\(\\cos(2\\pi \\alpha) =\\cos(2\\pi (1-\\alpha))\\) 가 성립함\n\nalpha = 0.2\nnp.cos(2*np.pi*alpha),np.cos(2*np.pi*(1-alpha))\n\n(0.30901699437494745, 0.30901699437494723)\n\n\n\n그래프를 잘 그려보세여\n\n- 예비학습2\n임의의 \\(0 \\leq \\alpha \\leq 1\\)에 대하여 \\(\\sin(2\\pi \\alpha) = -\\sin(2\\pi (1-\\alpha))\\) 가 성립함\n\nalpha = 0.2\nnp.sin(2*np.pi*alpha),np.sin(2*np.pi*(1-alpha))\n\n(0.9510565162951535, -0.9510565162951536)\n\n\n\n그래프를 잘 그려보세여\n\n- 왜 실수일경우만 대칭인지? (어디 정리된걸 아무리 찾아도 못찾겠어서 그냥 직접 수식을 썼는데요, 이걸 기억할 필요는 없어요.. 아마 제가 쓴것보다 쉽게 설명하는 방법이 있을겁니다)\n(해설) \\(k=0,1,2,\\dots,N-1\\)에 대하여 \\(X[k]\\)는 아래와 같이 표현가능하다.\n\\[X[k] = \\sum_{n=0}^{N-1}x[n]e^{-\\frac{j2\\pi kn}{N}}\\]\n오일러공식을 사용하면 아래와 같이 정리할 수 있다.\n\\[X[k] = \\sum_{n=0}^{N-1}x[n]\\cos\\left(-\\frac{2\\pi kn}{N}\\right) + i \\sum_{n=0}^{N-1}x[n]\\sin\\left(-\\frac{2\\pi kn}{N}\\right)\\]\ncos은 짝함수, sin은 홀함수임을 이용하여 다시정리하면\n\\[X[k] = \\sum_{n=0}^{N-1}x[n]\\cos\\left(\\frac{2\\pi kn}{N}\\right) - i \\sum_{n=0}^{N-1}x[n]\\sin\\left(\\frac{2\\pi kn}{N}\\right)\\]\ncase1 \\(k=1\\) 인 경우와 \\(k=N-1\\)인 경우는 서로 \\(|X[k]|^2\\)이 같음을 보이자.\n\\[X[1] = \\sum_{n=0}^{N-1}x[n]\\cos\\left(\\frac{2\\pi n}{N}\\right) - i \\sum_{n=0}^{N-1}x[n]\\sin\\left(\\frac{2\\pi n}{N}\\right)\\]\n\\[X[N-1] = \\sum_{n=0}^{N-1}x[n]\\cos\\left(\\frac{2\\pi (N-1)n}{N}\\right) - i \\sum_{n=0}^{N-1}x[n]\\sin\\left(\\frac{2\\pi(N-1) n}{N}\\right)\\]\n여기에서 예비학습1,2를 떠올리면 \\(\\cos\\left(\\frac{2\\pi n}{N}\\right)=\\cos\\left(\\frac{2\\pi (N-1)n}{N}\\right)\\) 이고 \\(\\sin\\left(\\frac{2\\pi n}{N}\\right)=-\\sin\\left(\\frac{2\\pi(N-1) n}{N}\\right)\\) 임을 알 수 있다. 따라서 \\(X[1]\\)와 \\(X[N-1]\\)은 켤레복소수이다. 즉\n\\[X[1] = X[N-1]^\\ast, \\quad X[1]^\\ast = X[N-1]\\]\n이다. 그런데 임의의 복소수 \\(x=a+bi\\)에 대하여 \\(|x|^2 = a^2+b^2 = (a+bi)(a-bi)= x x^\\ast\\) 가 성립하므로\n\\[|X[1]|^2 = |X[N-1]|^2\\]\n이 성립한다.\n\n만약에 \\(x[n]\\)이 실수가 아닌경우는 \\(\\cos\\left(\\frac{2\\pi n}{N}\\right)=\\cos\\left(\\frac{2\\pi (N-1)n}{N}\\right)\\) 이고 \\(\\sin\\left(\\frac{2\\pi n}{N}\\right)=-\\sin\\left(\\frac{2\\pi(N-1) n}{N}\\right)\\) 이라고 하여도 \\(X[1]\\)와 \\(X[N-1]\\)은 켤레복소수라고 주장할수 없다.\n\ncase2 \\(k=2\\) 인 경우와 \\(k=N-2\\)인 경우는 서로 \\(|X[k]|^2\\)이 같음도 비슷한 논리로 보일 수 있다."
  },
  {
    "objectID": "공부/2023-06-28-(공부&지윤) -- 퓨리에변환(detailed) -- 논문지도.html#허수파트-해석",
    "href": "공부/2023-06-28-(공부&지윤) -- 퓨리에변환(detailed) -- 논문지도.html#허수파트-해석",
    "title": "(공부&지윤) – 퓨리에변환(detailed)",
    "section": "허수파트 해석",
    "text": "허수파트 해석\n관찰1: 모든 \\(k\\)에 대하여 \\(X[k]\\)의 허수파트는 항상 0이다.\nk=0\n\nk=0\nsin_part_0 = np.array([np.sin(2*np.pi*k*n/N) for n in range(N)])\n\n\nx*sin_part_0\n\narray([ 0.,  0.,  0.,  0., -0., -0., -0., -0., -0., -0., -0., -0.,  0.,\n        0.,  0.])\n\n\n\nsum(x*sin_part_0)\n\n0.0\n\n\nk=1\n\nk=1\nsin_part_1 = np.array([np.sin(2*np.pi*k*n/N) for n in range(N)])\n\n\nx*sin_part_1\n\narray([ 0.        ,  0.37157241,  0.49726095,  0.29389263, -0.10395585,\n       -0.4330127 , -0.47552826, -0.20336832,  0.20336832,  0.47552826,\n        0.4330127 ,  0.10395585, -0.29389263, -0.49726095, -0.37157241])\n\n\n\nsum(x*sin_part_1)\n\n1.0547118733938987e-15\n\n\n약간을 직관을 위해서 그림을 그려보자.\n\nplt.plot(x,'--o')\nplt.plot(sin_part_1,'--o')\n\n\n\n\n\n\n\n\n\\(x\\)가 \\(\\mathbb{R}\\)에서 정의된 연속함수라고 상상하면 \\(\\sum_{n=0}^{N-1}\\cos\\left(\\frac{2\\pi n}{N} \\right)\\sin\\left(\\frac{2\\pi kn}{N}\\right)\\)에 대응하는 식은 \\(\\int_0^{2\\pi}\\cos(t)\\sin(t)dt\\)라고 볼 수 있어서 sum(x*sin_part_1)=0임을 더 쉽게 이해할 수 있다.\nk=2\n\nk=2\nsin_part_2 = np.array([np.sin(2*np.pi*k*n/N) for n in range(N)])\n\n\nplt.plot(x,'--o')\nplt.plot(sin_part_2,'--o')\n\n\n\n\n\n\n\n\n\\(x\\)가 \\(\\mathbb{R}\\)에서 정의된 연속함수라고 상상하면 파란선에 대응하는것은 \\(\\cos(t)\\) 주황선에 대응하는 것은 \\(\\sin(2t)\\)로 볼 수 있는데 둘은 직교하므로 둘을 곱한뒤 적분하면 (더하면) 0이 된다.\n\nsum(x*sin_part_2)\n\n-1.2212453270876722e-15\n\n\n\\(\\cos(t)\\)는 임의의 \\(\\sin(kt)\\)와 항상 직교하므로, 임의의 \\(k\\)에 대하여 허수파트는 항상 0이다.\n따라서 이 경우 \\(X[k]\\)는 아래와 같이 써도 무방하다.\n\\[X[k] = \\sum_{n=0}^{N-1}x[n]\\cos\\left(\\frac{2\\pi kn}{N}\\right)\\]"
  },
  {
    "objectID": "공부/2023-06-28-(공부&지윤) -- 퓨리에변환(detailed) -- 논문지도.html#실수파트-해석",
    "href": "공부/2023-06-28-(공부&지윤) -- 퓨리에변환(detailed) -- 논문지도.html#실수파트-해석",
    "title": "(공부&지윤) – 퓨리에변환(detailed)",
    "section": "실수파트 해석",
    "text": "실수파트 해석\n관찰2: \\(X[k]\\)의 실수파트는 \\(k=1\\)혹은 \\(k=N-1\\)일때 아래와 같이 정리된다.\n\\[\\sum_{n=0}^{N-1}\\cos\\left(\\frac{2\\pi n}{N} \\right)^2\\]\n그외의 경우에는 아래와 같이 된다.\nk=0\n\nk=0\ncos_part_0 = np.array([np.cos(2*np.pi*k*n/N) for n in range(N)])\n\n\nplt.plot(x,'--o')\nplt.plot(cos_part_0,'--o')\n\n\n\n\n\n\n\n\n\n파란선에 대응하는것은 \\(\\cos(t)\\) 주황선에 대응하는 것은 \\(1\\)로 볼 수 있는데 둘은 직교하므로 둘을 곱한뒤 적분하면 (더하면) 0이 된다.\n\nk=2\n\nk=2\ncos_part_2 = np.array([np.cos(2*np.pi*k*n/N) for n in range(N)])\n\n\nplt.plot(x,'--o')\nplt.plot(cos_part_2,'--o')\n\n\n\n\n\n\n\n\n\n파란선에 대응하는것은 \\(\\cos(t)\\) 주황선에 대응하는 것은 \\(\\cos(2t)\\)로 볼 수 있는데 둘은 직교하므로 둘을 곱한뒤 적분하면 (더하면) 0이 된다.\n\n임의의 \\(k\\)에 대하여 \\(\\cos(t)\\)와 \\(\\cos(kt)\\)는 항상 직교하므로 둘을 곱한뒤 적분하면 (더하면) 0이 된다.\n- 요약: 만약에 \\(x[n]\\)이 아래와 같은 꼴이라고 하자.\n\\[x[n] = \\cos\\left(\\frac{2\\pi n}{N} \\right)\\]\n이때 퓨리에변환 \\(X[k]\\)는 아래와 같이 정리된다.\n\\[X[k] = \\sum_{n=0}^{N-1}x[n]\\cos\\left(\\frac{2\\pi kn}{N}\\right) - i \\sum_{n=0}^{N-1}x[n]\\sin\\left(\\frac{2\\pi kn}{N}\\right)\\]\n\\(X[k]\\)의 허수파트는 항상 0이 되고, 실수 파트는 \\(k=1,N-1\\)일 경우에만 값을 가지고 나머지는 0의 값을 가진다.\n\nX = np.fft.fft(x)\nfig, ax = plt.subplots(1,3)\nax[0].plot(x,'o--'); ax[0].set_title('x[n]')\nax[1].plot(np.real(X),'x'); ax[1].set_title('real(X[k])')\nax[2].plot(np.imag(X),'x'); ax[2].set_title('imag(X[k])')\nfig.set_figwidth(15)\n\n\n\n\n\n\n\n\n- 응용: \\(x[n]\\)이 아래와 같은 꼴이라고 하자.\n\\[x[n] = \\cos\\left(\\frac{6\\pi n}{N} \\right)\\]\n퓨리에변환 \\(X[k]\\)는 아래와 같이 정리된다.\n\\[X[k] = \\sum_{n=0}^{N-1}x[n]\\cos\\left(\\frac{2\\pi kn}{N}\\right) - i \\sum_{n=0}^{N-1}x[n]\\sin\\left(\\frac{2\\pi kn}{N}\\right)\\]\n\\(X[k]\\)의 허수파트는 항상 0이 되고, 실수 파트는 \\(k=3,N-3\\)일 경우에만 값을 가지고 나머지는 0의 값을 가진다.\n\nN = 15 \nx = np.array([np.cos(6*np.pi*n/N) for n in range(N)]) \nX = np.fft.fft(x)\nfig, ax = plt.subplots(1,3)\nax[0].plot(x,'o--'); ax[0].set_title('x[n]')\nax[1].plot(np.real(X),'x'); ax[1].set_title('real(X[k])')\nax[2].plot(np.imag(X),'x'); ax[2].set_title('imag(X[k])')\nfig.set_figwidth(15)"
  },
  {
    "objectID": "공부/2019-04-26-퓨리에변환.html",
    "href": "공부/2019-04-26-퓨리에변환.html",
    "title": "(공부) – 퓨리에 변환",
    "section": "",
    "text": "- 이번에는 퓨리에 표현들을 정리하도록 하겠다. 내생각엔 퓨리에 표현들도 벡터의 미분만큼 복잡한 것 같다. 정의가 너무 많고 그게 그거 같아서 그렇다. 이번기회에 깔끔하게 정리하도록 하자. 참고한 문헌은 아래와 같다.\n\nHaykin, S., & Van Veen, B. (2007). Signals and systems. John Wiley & Sons."
  },
  {
    "objectID": "공부/2019-04-26-퓨리에변환.html#footnotes",
    "href": "공부/2019-04-26-퓨리에변환.html#footnotes",
    "title": "(공부) – 퓨리에 변환",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n나도 그렇다.↩︎\n사실 나도 잘 모름 (뭐 quotient group이런거 알아야 하는데 공부하려면 꽤 걸릴듯)↩︎"
  },
  {
    "objectID": "공부/2023-07-04-(공부) -- 토폴로지.html",
    "href": "공부/2023-07-04-(공부) -- 토폴로지.html",
    "title": "(공부) – 토폴로지",
    "section": "",
    "text": "- 수학공부\n- 학부수준\n- 이 문서는 논문을 읽을때 등장하는 topology 용어들을 좀더 명확하게 이해하고 싶어서 작성하였다. 가볍게 정의만 훑어보는 것이라 깊게 들어가지는 않을 예정이다. 교재는 Schaum’s General Topology 를 참고하였다. - Lipschutz, S. (1965). Schaum’s outline of theory and problems of general topology. Schaum’s Outline Series.\n- 여기에서는 토폴로지의 정의와 메트릭스페이스의 정의 그리고 컴플리션의 정의에 대하여 다룬다."
  },
  {
    "objectID": "공부/2023-07-04-(공부) -- 토폴로지.html#footnotes",
    "href": "공부/2023-07-04-(공부) -- 토폴로지.html#footnotes",
    "title": "(공부) – 토폴로지",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n정확하게는 \\(\\cal O\\)-오픈셋↩︎\n공집합이 오픈셋이므로↩︎\n\\(\\mathbb{R}\\)이 오픈셋이므로↩︎\n다만 이것은 위상공간을 \\((\\mathbb{R},{\\cal O})\\)로 생각하였을때 이야기이고 위상공간을 \\((\\mathbb{R},2^{\\mathbb{R}})\\)로 생각한다면 \\(\\{p\\}\\) 도 오픈셋이 된다.↩︎\n\\({\\cal T}=\\{\\emptyset, X\\}\\)로 설정한다면 이 조건은 당연히 성립하지 않겠지?↩︎\n즉 \\((X,{\\cal T}_4)\\)가 countable한 base를 가진다면↩︎"
  },
  {
    "objectID": "공부/2023-10-25-(공부) Julia -- 문자와 문자열.html",
    "href": "공부/2023-10-25-(공부) Julia -- 문자와 문자열.html",
    "title": "(공부) Julia – 문자와 문자열",
    "section": "",
    "text": "- 선언 및 자료형\n\n'B' # 선언 \n\n'B': ASCII/Unicode U+0042 (category Lu: Letter, uppercase)\n\n\n\ntypeof('b') # 자료형\n\nChar\n\n\n\n\n\n- 선언 및 자료형\n\n\"A\" # 선언\n\n\"A\"\n\n\n\ntypeof(\"A\") # 자료형\n\nString\n\n\n\n\n\n- \"a\"와 'a'의 차이\n\n'a' # 단일문자\n\n'a': ASCII/Unicode U+0061 (category Ll: Letter, lowercase)\n\n\n\n\"a\" # 문자열\n\n\"a\"\n\n\n\n\"a\"[1] # 'a'와 같음\n\n'a': ASCII/Unicode U+0061 (category Ll: Letter, lowercase)"
  },
  {
    "objectID": "공부/2023-10-25-(공부) Julia -- 문자와 문자열.html#a.-문자-0차원-자료형",
    "href": "공부/2023-10-25-(공부) Julia -- 문자와 문자열.html#a.-문자-0차원-자료형",
    "title": "(공부) Julia – 문자와 문자열",
    "section": "",
    "text": "- 선언 및 자료형\n\n'B' # 선언 \n\n'B': ASCII/Unicode U+0042 (category Lu: Letter, uppercase)\n\n\n\ntypeof('b') # 자료형\n\nChar"
  },
  {
    "objectID": "공부/2023-10-25-(공부) Julia -- 문자와 문자열.html#b.-문자열-1차원-자료형",
    "href": "공부/2023-10-25-(공부) Julia -- 문자와 문자열.html#b.-문자열-1차원-자료형",
    "title": "(공부) Julia – 문자와 문자열",
    "section": "",
    "text": "- 선언 및 자료형\n\n\"A\" # 선언\n\n\"A\"\n\n\n\ntypeof(\"A\") # 자료형\n\nString"
  },
  {
    "objectID": "공부/2023-10-25-(공부) Julia -- 문자와 문자열.html#c.-차이점",
    "href": "공부/2023-10-25-(공부) Julia -- 문자와 문자열.html#c.-차이점",
    "title": "(공부) Julia – 문자와 문자열",
    "section": "",
    "text": "- \"a\"와 'a'의 차이\n\n'a' # 단일문자\n\n'a': ASCII/Unicode U+0061 (category Ll: Letter, lowercase)\n\n\n\n\"a\" # 문자열\n\n\"a\"\n\n\n\n\"a\"[1] # 'a'와 같음\n\n'a': ASCII/Unicode U+0061 (category Ll: Letter, lowercase)"
  },
  {
    "objectID": "공부/2023-10-25-(공부) Julia -- 문자와 문자열.html#a.-문자-관련-기능",
    "href": "공부/2023-10-25-(공부) Julia -- 문자와 문자열.html#a.-문자-관련-기능",
    "title": "(공부) Julia – 문자와 문자열",
    "section": "A. 문자 관련 기능",
    "text": "A. 문자 관련 기능\n- isuppercase: 대소문자 판단\n\nisuppercase('a'), islowercase('a')\n\n(false, true)\n\n\n\nisuppercase('A'), islowercase('A')\n\n(true, false)"
  },
  {
    "objectID": "공부/2023-10-25-(공부) Julia -- 문자와 문자열.html#b.-문자열-관련-기능",
    "href": "공부/2023-10-25-(공부) Julia -- 문자와 문자열.html#b.-문자열-관련-기능",
    "title": "(공부) Julia – 문자와 문자열",
    "section": "B. 문자열 관련 기능",
    "text": "B. 문자열 관련 기능\n- 문자열 슬라이싱\n\nstr = \"Jeonbuk National University\"\nstr[end-1:end]\n\n\"ty\"\n\n\n- 문자열의 결합\n\n\"a\"*\"b\"\n\n\"ab\"\n\n\n- 문자열의 반복\n\n\"a\"^5\n\n\"aaaaa\"\n\n\n\nrepeat(\"a\",5)\n\n\"aaaaa\"\n\n\n- 문자열 끼워넣기\n\nname = \"최규빈\"\n\"제 이름은 $name 입니다\"\n\n\"제 이름은 최규빈 입니다\"\n\n\n- 문자열 바꾸기\n\nstr = \"abcdefg\"\nreplace(str, \"g\" =&gt; \"u\")\n\n\"abcdefu\"\n\n\n- 문자열 나누기\n\nstr = \"2023-08\"\nsplit(str,\"-\")\n\n2-element Vector{SubString{String}}:\n \"2023\"\n \"08\"\n\n\n- 문자열 합치기\n\njoin([\"2023\",\"08\"],\"-\")\n\n\"2023-08\"\n\n\n\njoin([\"2023\",\"08\"])\n\n\"202308\"\n\n\n- lowercase: 대문자를 소문자로 바꾸는 방법\n\nstr = \"HELLO, JULIA!\"\nlowercase(str)\n\n\"hello, julia!\""
  },
  {
    "objectID": "공부/2023-09-24-(공부) -- ggraph.html",
    "href": "공부/2023-09-24-(공부) -- ggraph.html",
    "title": "(공부) – ggraph",
    "section": "",
    "text": "Imports\n\nsource(\"ggplot3.R\")\nlibrary(ggraph)\nlibrary(tidygraph)\n\n\nfigsize()\n\n\nas_tbl_graph(highschool)\n\n\n# A tbl_graph: 70 nodes and 506 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 70 × 1\n  name \n  &lt;chr&gt;\n1 1    \n2 2    \n3 3    \n4 4    \n5 5    \n6 6    \n# ℹ 64 more rows\n#\n# A tibble: 506 × 3\n   from    to  year\n  &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n1     1    13  1957\n2     1    14  1957\n3     1    20  1957\n# ℹ 503 more rows\n\n\n\n\n\n\n# Create graph of highschool friendships\ngraph &lt;- as_tbl_graph(highschool) %&gt;% \n    mutate(Popularity = centrality_degree(mode = 'in'))\n\n# plot using ggraph\nggraph(graph, layout = 'kk') + \n    geom_edge_fan(aes(alpha = after_stat(index)), show.legend = FALSE) + \n    geom_node_point(aes(size = Popularity)) + \n    facet_edges(~year) + \n    theme_graph(foreground = 'steelblue', fg_text_colour = 'white')"
  },
  {
    "objectID": "공부/2023-10-21-(공부&지윤) -- Imputer와 Scaler의 적용.html",
    "href": "공부/2023-10-21-(공부&지윤) -- Imputer와 Scaler의 적용.html",
    "title": "(공부&지윤) – Imputer와 Scaler의 적용",
    "section": "",
    "text": "import numpy as np \nimport pandas as pd\nimport sklearn.preprocessing\nimport sklearn.impute \n\n\nX = pd.DataFrame({'X':[7.424885,4.201394,np.nan,np.nan,5.190914,np.nan,6.433033]})\nX\n\n\n\n\n\n\n\n\nX\n\n\n\n\n0\n7.424885\n\n\n1\n4.201394\n\n\n2\nNaN\n\n\n3\nNaN\n\n\n4\n5.190914\n\n\n5\nNaN\n\n\n6\n6.433033\n\n\n\n\n\n\n\n\nsclr = sklearn.preprocessing.StandardScaler()\nimputr = sklearn.impute.SimpleImputer()\n\n\nsclr.fit(X.dropna())\n\nStandardScaler()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.StandardScalerStandardScaler()\n\n\n\nsclr.transform(imputr.fit_transform(X))\n\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n\n\narray([[ 1.32010944],\n       [-1.31915477],\n       [ 0.        ],\n       [ 0.        ],\n       [-0.50897577],\n       [ 0.        ],\n       [ 0.50802109]])"
  },
  {
    "objectID": "공부/2023-10-26-(공부) Julia -- Vector.html",
    "href": "공부/2023-10-26-(공부) Julia -- Vector.html",
    "title": "(공부) Julia – Vector",
    "section": "",
    "text": "- Python의 리스트와 비슷하기도 하고, numpy array와 비슷하기도 함"
  },
  {
    "objectID": "공부/2023-10-26-(공부) Julia -- Vector.html#a.-더하기",
    "href": "공부/2023-10-26-(공부) Julia -- Vector.html#a.-더하기",
    "title": "(공부) Julia – Vector",
    "section": "A. 더하기",
    "text": "A. 더하기\n- 예시1 – 길이가 같은 벡터의 합\n\na = [1,2] \nb = [-1,-2]\na + b\n\n2-element Vector{Int64}:\n 0\n 0\n\n\n\n# 사실아래도 가능\na .+ b\n\n2-element Vector{Int64}:\n 0\n 0\n\n\n- 예시2 – 벡터+스칼라 (실패)\n\na = [1,2]\na + 1 # 브로드캐스팅 실패\n\nLoadError: MethodError: no method matching +(::Vector{Int64}, ::Int64)\nFor element-wise addition, use broadcasting with dot syntax: array .+ scalar\n\n\u001b[0mClosest candidates are:\n\u001b[0m  +(::Any, ::Any, \u001b[91m::Any\u001b[39m, \u001b[91m::Any...\u001b[39m)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4moperators.jl:578\u001b[24m\u001b[39m\n\u001b[0m  +(\u001b[91m::T\u001b[39m, ::T) where T&lt;:Union{Int128, Int16, Int32, Int64, Int8, UInt128, UInt16, UInt32, UInt64, UInt8}\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4mint.jl:87\u001b[24m\u001b[39m\n\u001b[0m  +(\u001b[91m::Base.TwicePrecision\u001b[39m, ::Number)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4mtwiceprecision.jl:290\u001b[24m\u001b[39m\n\u001b[0m  ...\n\n\n- 예시3 – 벡터+스칼라 (성공)\n\na = [1,2]\na .+ 1 \n\n2-element Vector{Int64}:\n 2\n 3"
  },
  {
    "objectID": "공부/2023-10-26-(공부) Julia -- Vector.html#b.-곱셉",
    "href": "공부/2023-10-26-(공부) Julia -- Vector.html#b.-곱셉",
    "title": "(공부) Julia – Vector",
    "section": "B. 곱셉",
    "text": "B. 곱셉\n- 예시1 – 벡터*스칼라 (성공)\n\na = [1,2]\na*2\n\n2-element Vector{Int64}:\n 2\n 4\n\n\n\n# 사실 아래도 가능\na .* 2\n\n2-element Vector{Int64}:\n 2\n 4\n\n\n\n# 사실 아래도 가능\n2a\n\n2-element Vector{Int64}:\n 2\n 4\n\n\n- 예시2 – 하다마르곱\n\na = [1,2]\nb = [2,3] \na .* b \n\n2-element Vector{Int64}:\n 2\n 6\n\n\n- 예시3 – 예시2를 응용\n\na = [1,'a']\nb = [3,'b']\na .* b\n\n2-element Vector{Any}:\n 3\n  \"ab\""
  },
  {
    "objectID": "공부/2023-10-26-(공부) Julia -- Vector.html#c.-제곱연산",
    "href": "공부/2023-10-26-(공부) Julia -- Vector.html#c.-제곱연산",
    "title": "(공부) Julia – Vector",
    "section": "C. 제곱연산",
    "text": "C. 제곱연산\n- 예시1\n\na = [1,2]\na .^ 2\n\n2-element Vector{Int64}:\n 1\n 4\n\n\n- 예시2\n\na = [\"a\", \"bb\"] \na .^ 2 \n\n2-element Vector{String}:\n \"aa\"\n \"bbbb\""
  },
  {
    "objectID": "공부/2023-10-26-(공부) Julia -- Vector.html#d.-내적",
    "href": "공부/2023-10-26-(공부) Julia -- Vector.html#d.-내적",
    "title": "(공부) Julia – Vector",
    "section": "D. 내적",
    "text": "D. 내적\n- 예시\n\nusing LinearAlgebra\n\n\n[1,2,3] ⋅ [1,2,3]\n\n14\n\n\n\ndot([1,2,3],[1,2,3])\n\n14\n\n\n\n[1,2,3]' * [1,2,3]\n\n14"
  },
  {
    "objectID": "공부/2023-10-26-(공부) Julia -- Vector.html#a.-append",
    "href": "공부/2023-10-26-(공부) Julia -- Vector.html#a.-append",
    "title": "(공부) Julia – Vector",
    "section": "A. append!",
    "text": "A. append!\n- 예시\n\na = [1,2,3]\nb = [4] \nappend!(a,b)\n\n4-element Vector{Int64}:\n 1\n 2\n 3\n 4\n\n\n\na,b\n\n([1, 2, 3, 4], [4])\n\n\n\nappend!는 numpy에서 concat 느낌"
  },
  {
    "objectID": "공부/2023-10-26-(공부) Julia -- Vector.html#b.-push",
    "href": "공부/2023-10-26-(공부) Julia -- Vector.html#b.-push",
    "title": "(공부) Julia – Vector",
    "section": "B. push!",
    "text": "B. push!\n- 예시\n\na = [1,2,3]\npush!(a,4)\n\n4-element Vector{Int64}:\n 1\n 2\n 3\n 4\n\n\n\npush!는 list에서 append 느낌"
  },
  {
    "objectID": "공부/2023-10-26-(공부) Julia -- Vector.html#a.-cat",
    "href": "공부/2023-10-26-(공부) Julia -- Vector.html#a.-cat",
    "title": "(공부) Julia – Vector",
    "section": "A. cat",
    "text": "A. cat\n\nnp.concat, np.stack 등이 합쳐진 형태\n\n- 예시1\n\na = [1,2,3]\nb = [4] \n\n1-element Vector{Int64}:\n 4\n\n\n\ncat(a,b,dims=1) # np.concat 과 비슷\n\n4-element Vector{Int64}:\n 1\n 2\n 3\n 4\n\n\n- 예시2\n\na = [1,2,3]\nb = -a\n\n3-element Vector{Int64}:\n -1\n -2\n -3\n\n\n\ncat(a,b,dims=2) \n\n3×2 Matrix{Int64}:\n 1  -1\n 2  -2\n 3  -3\n\n\n\ncat(a,b,dims=1)\n\n6-element Vector{Int64}:\n  1\n  2\n  3\n -1\n -2\n -3\n\n\n- 예시3\n\na = [1 2 3\n     3 4 5]\nb = -a\n\n2×3 Matrix{Int64}:\n -1  -2  -3\n -3  -4  -5\n\n\n\ncat(a,b,dims=1)\n\n4×3 Matrix{Int64}:\n  1   2   3\n  3   4   5\n -1  -2  -3\n -3  -4  -5\n\n\n\ncat(a,b,dims=2)\n\n2×6 Matrix{Int64}:\n 1  2  3  -1  -2  -3\n 3  4  5  -3  -4  -5\n\n\n\ncat(a,b,dims=3)\n\n2×3×2 Array{Int64, 3}:\n[:, :, 1] =\n 1  2  3\n 3  4  5\n\n[:, :, 2] =\n -1  -2  -3\n -3  -4  -5\n\n\n- 예시4 – 아래도 가능\n\na = [1,2,3]\nb = 2 \ncat(a,b,dims=1)\n\n4-element Vector{Int64}:\n 1\n 2\n 3\n 2\n\n\n- 예시5 – 아래도 가능\n\na = reshape(1:4, (2,2))\nb = [3,4]\na,b\n\n([1 3; 2 4], [3, 4])\n\n\n\ncat(a,b,dims=2)\n\n2×3 Matrix{Int64}:\n 1  3  3\n 2  4  4"
  },
  {
    "objectID": "공부/2023-10-26-(공부) Julia -- Vector.html#b.-를-이용한-결합",
    "href": "공부/2023-10-26-(공부) Julia -- Vector.html#b.-를-이용한-결합",
    "title": "(공부) Julia – Vector",
    "section": "B. []를 이용한 결합",
    "text": "B. []를 이용한 결합\n- 예시1\n\na = [1,2,3]\nb = -a\na,b\n\n([1, 2, 3], [-1, -2, -3])\n\n\n\n[a b]\n\n3×2 Matrix{Int64}:\n 1  -1\n 2  -2\n 3  -3\n\n\n\n[a\n b]\n\n6-element Vector{Int64}:\n  1\n  2\n  3\n -1\n -2\n -3\n\n\n- 예시2\n\na = [1,2,3] \nb = 4\n\n4\n\n\n\n[a \n b]\n\n4-element Vector{Int64}:\n 1\n 2\n 3\n 4\n\n\n- 예시3\n\na = [1 2; 3 4]\nb = [0,0] \n\n2-element Vector{Int64}:\n 0\n 0\n\n\n\n[a b]\n\n2×3 Matrix{Int64}:\n 1  2  0\n 3  4  0"
  },
  {
    "objectID": "메모/2000-01-10-DGX staion.html",
    "href": "메모/2000-01-10-DGX staion.html",
    "title": "(메모) – DGX station 설정",
    "section": "",
    "text": "- root 획득\nsudo -i \n- 모든 GPU enable\nnvidia-smi -mig 1 \nsudo systemctl stop nvidia-mig-manager.service\nsudo systemctl disable nvidia-mig-manager.service\nreboot\n- 모든 특정 GPU만 enable\n#nvidia-smi -i {GPUdev-ID} -mig 1\nnvidia-smi -i 0 -mig 1 \nsudo systemctl stop nvidia-mig-manager.service\nsudo systemctl disable nvidia-mig-manager.service\nreboot \n- GPU가 MIG 모드로 되면 아래와 같이 GPU-Util 에 N/A로 표시된다. 아래는 0,1,2,4 에 대응하는 GPU가 MIG모드로 설정된 상태임\n\n\n\n\n- 용어정리\n\nGPU: 말 그대로 GPU\nGI: GPU INSTANCE, 하나의 GPU에 여러개의 GPU INSTANCE가 존재할 수 있음.\nCI: COMPUTE INSTANCE, 하나의 GPU INSTANCE에 여러개의 COMPUTE INSTANCE를 만들 수 있음.\n\n- 상황확인\nnvidia-smi \n\n- GPU의 해석\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.141.03   Driver Version: 470.141.03   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA A100-SXM...  On   | 00000000:01:00.0 Off |                   On |\n| N/A   37C    P0    53W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n|   1  NVIDIA A100-SXM...  On   | 00000000:47:00.0 Off |                   On |\n| N/A   38C    P0    52W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n|   2  NVIDIA A100-SXM...  On   | 00000000:81:00.0 Off |                   On |\n| N/A   37C    P0    54W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n|   3  NVIDIA DGX Display  On   | 00000000:C1:00.0 Off |                  N/A |\n| 36%   39C    P8    N/A /  50W |      1MiB /  3911MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   4  NVIDIA A100-SXM...  On   | 00000000:C2:00.0 Off |                   On |\n| N/A   37C    P0    55W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n총 4개의 GPU가 있으며 아이디는 0,1,2,4 임을 알 수 있다.\n- GPUdev-ID, GI-ID, CI-ID, MIGdev-ID 확인\n+-----------------------------------------------------------------------------+\n| MIG devices:                                                                |\n+------------------+----------------------+-----------+-----------------------+\n| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |\n|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|\n|                  |                      |        ECC|                       |\n|==================+======================+===========+=======================|\n|  1    0   0   0  |      0MiB / 81251MiB | 98      0 |  7   0    5    1    1 |\n|                  |      1MiB / 13107... |           |                       |\n+------------------+----------------------+-----------+-----------------------+\n|  2    0   0   0  |      0MiB / 81251MiB | 98      0 |  7   0    5    1    1 |\n|                  |      1MiB / 13107... |           |                       |\n+------------------+----------------------+-----------+-----------------------+\n아래와 같은 상황을 유추할 수 있다.\n\n\n\nGPUdev ID\nGI ID\nCI ID\nMIGdev ID\n\n\n\n\n1\n0 (80G)\n0 (98SM)\n0\n\n\n2\n0 (80G)\n0 (98SM)\n0\n\n\n\n- 생성가능한 gi 확인\n\n- 생성가능한 ci 확인\n\n\n\nNote: GPU 1,2 에만 GI가 존재하므로, 목록에는 GPU 1,2 만 보임\n\n\n\n\n\n- GPUdev = 4 에서 생성가능한 GI 조회\n#nvidia-smi mig -i {GPUdev-ID} -lgip\nnvidia-smi mig -i 4 -lgip\n\n- 아래에 해당하는 GI를 2개 생성하고 싶다고 하자. (GPU-INSTANCE-PROFILE-ID=9 임을 유의)\n+-----------------------------------------------------------------------------+\n| GPU instance profiles:                                                      |\n| GPU   Name             ID    Instances   Memory     P2P    SM    DEC   ENC  |\n|                              Free/Total   GiB              CE    JPEG  OFA  |\n|=============================================================================|\n|   4  MIG 3g.40gb        9     0/2        39.50      No     42     2     0   |\n|                                                             3     0     0   |\n+-----------------------------------------------------------------------------+\n#nvidia-smi mig -i {GPUdev-ID} -cgi {GPU-INSTANCE-PROFILE-ID}\nnvidia-smi mig -i 4 -cgi 9 \nnvidia-smi mig -i 4 -cgi 9 \n\n\n\nNote: 2개까지는 잘 ㅁ나들어지고 그 이후에는 리소스 부족으로 에러가 발생한다.\n\n\n\n2개까지는 잘 만들어지고 그 이후에는 리소스부족으로 에러발생\n\n- 만들어진 GI 확인\n\n\n\nNote: 1,2번 GPU에 각각 GI가 1개씩 있고 4번 GPU에 GI가 2개 있다.\n\n\n- 생성가능한 CI 확인\nnvidia-smi mig -lcip\n\n\n\nNote: {GPU ID: GPU INSTANCE ID} 의 조합에서 {1:0}, {2:0}, {4:1}, {4:2} 에 해당하는 GI에서 생성가능한 CI들이 각각 출력된다. 4번 GPU의 GI들은 40기가가 한계이므로 생성가능 CI목록이 상대적으로 제한적임을 캐치하라\n\n\n\n\n\n- GPUdev=4 에서 생성가능한 CI 조회\n#nvidia-smi mig -i {GPU ID} -lcip\nnvidia-smi mig -i 4 -lcip\n\n\n\nNote: 각 GPU-인스턴스(GI)에서는 3개 계산-인스턴스(CI)를 만들수 있음. 만약에 Profile ID = 0 으로 만든다면 14의 계산능력을 가진 CI를 3개까지 만들수 있음, 만약 Profile ID = 2* 로 만든다면 42개의 계산능력을 가진 CI를 1개만 만들 수 있음\n\n\n- {GPUdev-ID:GI-ID} = {4:1} 에서 COMPUTE-INSTANCE-PROFILE-ID=0 에 해당하는 CI를 3개 생성\n#nvidia-smi mig -i {GPUdev-ID} -gi {GI-ID} -cci {COMPUTE-INSTANCE-PROFILE-ID}\nnvidia-smi mig -i 4 -gi 1 -cci 0\n\n\n\nNote: 자원부족으로 3개까지 밖에 못만든다..\n\n\n- {GPUdev-ID:GI-ID}={4:2} 에서 COMPUTE-INSTANCE-PROFILE-ID=2 에 해당하는 CI를 1개 생성\n#nvidia-smi mig -i {GPUdev-ID} -gi {GI-ID} -cci {COMPUTE-INSTANCE-PROFILE-ID}\nnvidia-smi mig -i 4 -gi 2 -cci 2 \n\n\n\nNote: 자원이 부족해서 1개밖에 못 만든다.\n\n\n- 현재 상황\n\n\n\n\nGPUdev ID\nGI ID\nCI ID\nMIGdev ID\n\n\n\n\n1\n0 (80G)\n0 (98SM)\n0\n\n\n2\n0 (80G)\n0 (98SM)\n0\n\n\n4\n1 (80G)\n0 (14SM)\n0\n\n\n4\n1 (80G)\n1 (14SM)\n1\n\n\n4\n1 (80G)\n2 (14SM)\n2\n\n\n4\n2 (80G)\n0 (42SM)\n3"
  },
  {
    "objectID": "메모/2000-01-10-DGX staion.html#a.-mig-모드-enable",
    "href": "메모/2000-01-10-DGX staion.html#a.-mig-모드-enable",
    "title": "(메모) – DGX station 설정",
    "section": "",
    "text": "- root 획득\nsudo -i \n- 모든 GPU enable\nnvidia-smi -mig 1 \nsudo systemctl stop nvidia-mig-manager.service\nsudo systemctl disable nvidia-mig-manager.service\nreboot\n- 모든 특정 GPU만 enable\n#nvidia-smi -i {GPUdev-ID} -mig 1\nnvidia-smi -i 0 -mig 1 \nsudo systemctl stop nvidia-mig-manager.service\nsudo systemctl disable nvidia-mig-manager.service\nreboot \n- GPU가 MIG 모드로 되면 아래와 같이 GPU-Util 에 N/A로 표시된다. 아래는 0,1,2,4 에 대응하는 GPU가 MIG모드로 설정된 상태임"
  },
  {
    "objectID": "메모/2000-01-10-DGX staion.html#b.-gpu-gi-ci-확인",
    "href": "메모/2000-01-10-DGX staion.html#b.-gpu-gi-ci-확인",
    "title": "(메모) – DGX station 설정",
    "section": "",
    "text": "- 용어정리\n\nGPU: 말 그대로 GPU\nGI: GPU INSTANCE, 하나의 GPU에 여러개의 GPU INSTANCE가 존재할 수 있음.\nCI: COMPUTE INSTANCE, 하나의 GPU INSTANCE에 여러개의 COMPUTE INSTANCE를 만들 수 있음.\n\n- 상황확인\nnvidia-smi \n\n- GPU의 해석\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.141.03   Driver Version: 470.141.03   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA A100-SXM...  On   | 00000000:01:00.0 Off |                   On |\n| N/A   37C    P0    53W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n|   1  NVIDIA A100-SXM...  On   | 00000000:47:00.0 Off |                   On |\n| N/A   38C    P0    52W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n|   2  NVIDIA A100-SXM...  On   | 00000000:81:00.0 Off |                   On |\n| N/A   37C    P0    54W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n|   3  NVIDIA DGX Display  On   | 00000000:C1:00.0 Off |                  N/A |\n| 36%   39C    P8    N/A /  50W |      1MiB /  3911MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   4  NVIDIA A100-SXM...  On   | 00000000:C2:00.0 Off |                   On |\n| N/A   37C    P0    55W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n총 4개의 GPU가 있으며 아이디는 0,1,2,4 임을 알 수 있다.\n- GPUdev-ID, GI-ID, CI-ID, MIGdev-ID 확인\n+-----------------------------------------------------------------------------+\n| MIG devices:                                                                |\n+------------------+----------------------+-----------+-----------------------+\n| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |\n|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|\n|                  |                      |        ECC|                       |\n|==================+======================+===========+=======================|\n|  1    0   0   0  |      0MiB / 81251MiB | 98      0 |  7   0    5    1    1 |\n|                  |      1MiB / 13107... |           |                       |\n+------------------+----------------------+-----------+-----------------------+\n|  2    0   0   0  |      0MiB / 81251MiB | 98      0 |  7   0    5    1    1 |\n|                  |      1MiB / 13107... |           |                       |\n+------------------+----------------------+-----------+-----------------------+\n아래와 같은 상황을 유추할 수 있다.\n\n\n\nGPUdev ID\nGI ID\nCI ID\nMIGdev ID\n\n\n\n\n1\n0 (80G)\n0 (98SM)\n0\n\n\n2\n0 (80G)\n0 (98SM)\n0\n\n\n\n- 생성가능한 gi 확인\n\n- 생성가능한 ci 확인\n\n\n\nNote: GPU 1,2 에만 GI가 존재하므로, 목록에는 GPU 1,2 만 보임"
  },
  {
    "objectID": "메모/2000-01-10-DGX staion.html#c.-gi-생성",
    "href": "메모/2000-01-10-DGX staion.html#c.-gi-생성",
    "title": "(메모) – DGX station 설정",
    "section": "",
    "text": "- GPUdev = 4 에서 생성가능한 GI 조회\n#nvidia-smi mig -i {GPUdev-ID} -lgip\nnvidia-smi mig -i 4 -lgip\n\n- 아래에 해당하는 GI를 2개 생성하고 싶다고 하자. (GPU-INSTANCE-PROFILE-ID=9 임을 유의)\n+-----------------------------------------------------------------------------+\n| GPU instance profiles:                                                      |\n| GPU   Name             ID    Instances   Memory     P2P    SM    DEC   ENC  |\n|                              Free/Total   GiB              CE    JPEG  OFA  |\n|=============================================================================|\n|   4  MIG 3g.40gb        9     0/2        39.50      No     42     2     0   |\n|                                                             3     0     0   |\n+-----------------------------------------------------------------------------+\n#nvidia-smi mig -i {GPUdev-ID} -cgi {GPU-INSTANCE-PROFILE-ID}\nnvidia-smi mig -i 4 -cgi 9 \nnvidia-smi mig -i 4 -cgi 9 \n\n\n\nNote: 2개까지는 잘 ㅁ나들어지고 그 이후에는 리소스 부족으로 에러가 발생한다.\n\n\n\n2개까지는 잘 만들어지고 그 이후에는 리소스부족으로 에러발생\n\n- 만들어진 GI 확인\n\n\n\nNote: 1,2번 GPU에 각각 GI가 1개씩 있고 4번 GPU에 GI가 2개 있다.\n\n\n- 생성가능한 CI 확인\nnvidia-smi mig -lcip\n\n\n\nNote: {GPU ID: GPU INSTANCE ID} 의 조합에서 {1:0}, {2:0}, {4:1}, {4:2} 에 해당하는 GI에서 생성가능한 CI들이 각각 출력된다. 4번 GPU의 GI들은 40기가가 한계이므로 생성가능 CI목록이 상대적으로 제한적임을 캐치하라"
  },
  {
    "objectID": "메모/2000-01-10-DGX staion.html#d.-ci-생성",
    "href": "메모/2000-01-10-DGX staion.html#d.-ci-생성",
    "title": "(메모) – DGX station 설정",
    "section": "",
    "text": "- GPUdev=4 에서 생성가능한 CI 조회\n#nvidia-smi mig -i {GPU ID} -lcip\nnvidia-smi mig -i 4 -lcip\n\n\n\nNote: 각 GPU-인스턴스(GI)에서는 3개 계산-인스턴스(CI)를 만들수 있음. 만약에 Profile ID = 0 으로 만든다면 14의 계산능력을 가진 CI를 3개까지 만들수 있음, 만약 Profile ID = 2* 로 만든다면 42개의 계산능력을 가진 CI를 1개만 만들 수 있음\n\n\n- {GPUdev-ID:GI-ID} = {4:1} 에서 COMPUTE-INSTANCE-PROFILE-ID=0 에 해당하는 CI를 3개 생성\n#nvidia-smi mig -i {GPUdev-ID} -gi {GI-ID} -cci {COMPUTE-INSTANCE-PROFILE-ID}\nnvidia-smi mig -i 4 -gi 1 -cci 0\n\n\n\nNote: 자원부족으로 3개까지 밖에 못만든다..\n\n\n- {GPUdev-ID:GI-ID}={4:2} 에서 COMPUTE-INSTANCE-PROFILE-ID=2 에 해당하는 CI를 1개 생성\n#nvidia-smi mig -i {GPUdev-ID} -gi {GI-ID} -cci {COMPUTE-INSTANCE-PROFILE-ID}\nnvidia-smi mig -i 4 -gi 2 -cci 2 \n\n\n\nNote: 자원이 부족해서 1개밖에 못 만든다.\n\n\n- 현재 상황\n\n\n\n\nGPUdev ID\nGI ID\nCI ID\nMIGdev ID\n\n\n\n\n1\n0 (80G)\n0 (98SM)\n0\n\n\n2\n0 (80G)\n0 (98SM)\n0\n\n\n4\n1 (80G)\n0 (14SM)\n0\n\n\n4\n1 (80G)\n1 (14SM)\n1\n\n\n4\n1 (80G)\n2 (14SM)\n2\n\n\n4\n2 (80G)\n0 (42SM)\n3"
  },
  {
    "objectID": "메모/2000-01-10-DGX staion.html#a.-컨테이너-생성",
    "href": "메모/2000-01-10-DGX staion.html#a.-컨테이너-생성",
    "title": "(메모) – DGX station 설정",
    "section": "A. 컨테이너 생성",
    "text": "A. 컨테이너 생성\n- 아래와 같은 방식으로 컨테이너 생성\n# nvidia-docker run --gpus '\"device={GPUdev-ID}:{MIGdev-ID}\"' -ti --rm -d -t -p {HOST-PORT}:{CONTAINER-PORT} {DOCKER-IMAGE-NAME} /bin/bash\nnvidia-docker run --gpus '\"device=1:0\"' -ti --rm -d -t -p 7749:7749  -p 1307:1307 ubuntu /bin/bash\nnvidia-docker run --gpus '\"device=2:0\"' -ti -d -t -p 4653:4653  -p 1212:1212 -p 1213:1213 -p 1214:1214 ubuntu /bin/bash\n\n-ti: 컨테이너를 대화형(interactive) 모드로 실행. 이 모드에서 컨테이너와 상호작용할 수 있음.\n--rm: 컨테이너가 종료되면 자동으로 컨테이너를 삭제. 이 옵션을 사용하면 컨테이너를 실행한 후 자동으로 정리.\n-d: 컨테이너를 백그라운드(background) 모드로 실행. 이 옵션을 사용하면 컨테이너가 백그라운드에서 실행되며 터미널이 차지되지 않음.\n-t: 컨테이너에 tty (터미널)를 할당. 이것은 대화형 모드와 함께 사용.\n/bin/bash: 컨테이너가 시작될 때 실행할 명령어. 이 경우, Bash 셸을 실행."
  },
  {
    "objectID": "메모/2000-01-10-DGX staion.html#b.-컨테이너-실행",
    "href": "메모/2000-01-10-DGX staion.html#b.-컨테이너-실행",
    "title": "(메모) – DGX station 설정",
    "section": "B. 컨테이너 실행",
    "text": "B. 컨테이너 실행\ndocker exec -ti {CONTAINER-ID} bash\n\n여기에서 {CONTAINER-ID}는 docker ps 혹은 docker ps -a로 확인한다."
  },
  {
    "objectID": "메모/2000-01-10-DGX staion.html#a.-passwd",
    "href": "메모/2000-01-10-DGX staion.html#a.-passwd",
    "title": "(메모) – DGX station 설정",
    "section": "A. passwd",
    "text": "A. passwd\n- 아래를 실행하여 비밀번호를 바꿀것\npasswd root"
  },
  {
    "objectID": "메모/2000-01-10-DGX staion.html#b.-update",
    "href": "메모/2000-01-10-DGX staion.html#b.-update",
    "title": "(메모) – DGX station 설정",
    "section": "B. update",
    "text": "B. update\n- 아래를 실행\napt update \napt install gcc\napt install build-essential"
  },
  {
    "objectID": "메모/2000-01-10-DGX staion.html#c.-쓸만한-패키지-설치",
    "href": "메모/2000-01-10-DGX staion.html#c.-쓸만한-패키지-설치",
    "title": "(메모) – DGX station 설정",
    "section": "C. 쓸만한 패키지 설치",
    "text": "C. 쓸만한 패키지 설치\n- 아래를 설치하면 좋음..\napt install vim \napt install openssh-server\napt install git"
  },
  {
    "objectID": "메모/2000-01-10-DGX staion.html#d.-ssh",
    "href": "메모/2000-01-10-DGX staion.html#d.-ssh",
    "title": "(메모) – DGX station 설정",
    "section": "D. ssh",
    "text": "D. ssh\n# apt install openssh-server\nvi /etc/ssh/sshd_config \nPort {My-SSH-Port}\nPermitRootLogin yes\nPasswordAuthentication yes\nservice ssh restart"
  },
  {
    "objectID": "메모/2000-01-10-DGX staion.html#e.-anaconda",
    "href": "메모/2000-01-10-DGX staion.html#e.-anaconda",
    "title": "(메모) – DGX station 설정",
    "section": "E. anaconda",
    "text": "E. anaconda\n- 생략"
  },
  {
    "objectID": "메모/2000-01-10-DGX staion.html#f.-vscode",
    "href": "메모/2000-01-10-DGX staion.html#f.-vscode",
    "title": "(메모) – DGX station 설정",
    "section": "F. vscode",
    "text": "F. vscode\n- 아래를 이용하여 설치\ncurl -Lk 'https://code.visualstudio.com/sha/download?build=stable&os=cli-alpine-x64' --output vscode_cli.tar.gz\ntar -xf vscode_cli.tar.gz\n- 아래를 이용하여 초기 설정 (깃헙아이디로 인증)\n./code tunnel \n- 초기설정 이후 아래를 이용하여 백그라운드에서 실행\nnohup ./code tunnel &gt; /dev/null 2&gt;&1 &\n- 패키지설치"
  },
  {
    "objectID": "메모/2000-01-10-DGX staion.html#g.-jupyter",
    "href": "메모/2000-01-10-DGX staion.html#g.-jupyter",
    "title": "(메모) – DGX station 설정",
    "section": "G. Jupyter",
    "text": "G. Jupyter\n- 암호설정: 여기로..\n- 주피터 실행할때 아래로 실행\nnohup jupyter lab --ip=\"0.0.0.0\" --port={MY-PORT} --no-browser --allow-root &gt; /dev/null 2&gt;&1 &"
  },
  {
    "objectID": "메모/2000-01-09-docker.html",
    "href": "메모/2000-01-09-docker.html",
    "title": "(메모) – docker",
    "section": "",
    "text": "- 우분투에서 설치\nref: https://docs.docker.com/engine/install/ubuntu/\n- 기본명령들\ndocker run penguin\ndocker stop penguin\ndocker image pull penguin \ndocker container start penguin\ndocker container run penguin\n- Docker에서 다운로드한 이미지와 실행 중인 컨테이너를 확인하기 위한 명령어를 소개하겠습니다:\n\n이미지 관련 명령어:\n\ndocker images: 현재 시스템에 다운로드된 모든 도커 이미지를 확인할 수 있습니다.\ndocker image ls: “docker images”와 동일한 결과를 출력합니다.\ndocker image ls &lt;이미지_이름&gt;: 특정 이미지의 버전을 명시하여 해당 이미지의 정보를 확인할 수 있습니다.\ndocker image history &lt;이미지_이름&gt;: 특정 이미지의 레이어별 변경 내역을 확인할 수 있습니다.\n\n컨테이너 관련 명령어:\n\ndocker ps: 현재 실행 중인 컨테이너의 목록을 확인합니다.\ndocker ps -a: 모든 컨테이너의 목록을 확인합니다 (실행 중인 것과 중지된 것 모두 포함).\ndocker container ls: “docker ps”와 동일한 결과를 출력합니다.\ndocker container ls -a: “docker ps -a”와 동일한 결과를 출력합니다.\ndocker container inspect &lt;컨테이너_ID 또는 이름&gt;: 특정 컨테이너의 자세한 정보를 확인할 수 있습니다.\ndocker logs &lt;컨테이너_ID 또는 이름&gt;: 컨테이너의 로그를 확인할 수 있습니다.\ndocker container stats: 실행 중인 컨테이너의 실시간 리소스 사용량을 모니터링할 수 있습니다.\n\n\n이 명령어들을 사용하여 이미지와 컨테이너에 대한 정보를 확인하고 관리할 수 있습니다.\n- docker run -ti --rm r-base 명령어에서 사용된 옵션들은 다음과 같은 의미를 갖습니다:\n\n-ti: 이 옵션은 두 개의 플래그인 -t와 -i를 결합한 것입니다.\n\n-t (또는 --tty): 이 플래그는 유사 터미널을 할당하고 터미널 상호작용을 가능하게 합니다. 컨테이너 내부에서 터미널 환경을 사용할 수 있게 해줍니다.\n-i (또는 --interactive): 이 플래그는 컨테이너와 상호작용할 수 있도록 표준 입력(STDIN)을 열어줍니다. 컨테이너 내부에서 입력을 주고 받을 수 있게 해줍니다.\n\n–rm: 이 옵션은 컨테이너가 실행을 마칠 때 자동으로 컨테이너를 삭제합니다. 컨테이너가 종료되면 그 내용과 상태는 모두 삭제됩니다. 주로 임시 작업을 수행하는데 사용됩니다.\n\n따라서 docker run -ti --rm r-base 명령어는 R 언어 기반의 컨테이너를 실행하는 명령어로, 터미널 환경을 제공하며 컨테이너가 종료될 때 컨테이너를 자동으로 삭제합니다. 이를 통해 R 언어를 실행하고 테스트하거나 실험할 수 있는 환경을 구성할 수 있습니다.\n- docker run -ti --rm -v \"$PWD\":/home/docker -w /home/docker -u docker r-base R CMD check 명령어에서 사용된 각 옵션에 대한 설명은 다음과 같습니다:\n\n-ti: 이 옵션은 터미널 상호작용을 위한 옵션입니다. -t는 유사 터미널 할당을 의미하고, -i는 터미널 입력 상호작용을 허용하는 것을 의미합니다.\n–rm: 컨테이너가 실행을 마칠 때 자동으로 컨테이너를 삭제합니다.\n-v “$PWD”:/home/docker: 이 옵션은 호스트 시스템의 현재 작업 디렉토리를 컨테이너 내의 /home/docker 디렉토리와 공유 마운트합니다. 이렇게 함으로써 호스트 시스템의 파일을 컨테이너 내부에서 사용할 수 있게 됩니다.\n-w /home/docker: 컨테이너가 실행될 작업 디렉토리를 /home/docker로 설정합니다. 즉, 컨테이너가 실행될 때 기본 디렉토리가 /home/docker가 됩니다.\n-u docker: 이 옵션은 컨테이너 안에서 사용자를 변경하여 실행하는 것을 의미합니다. docker라는 사용자로 컨테이너를 실행하게 됩니다.\nr-base: Docker 이미지 이름입니다. 여기서는 R 언어를 기반으로한 이미지를 사용합니다.\nR CMD check: 실제로 실행되는 컨테이너 내부의 명령어입니다. 이 경우 R 패키지를 체크하는 R 명령어 R CMD check가 실행됩니다.\n\n이 명령어는 호스트 시스템의 현재 작업 디렉토리에 있는 R 패키지를 컨테이너 내부에서 R CMD check 명령으로 체크하고자 할 때 사용될 수 있습니다.\n- “docker container start penguin”과 “docker container run penguin” 두 명령어의 차이점은 다음과 같습니다:\n\ndocker container start penguin:\n\n이 명령은 이미 생성된 (stopped 또는 exited 상태의) 컨테이너를 시작시킬 때 사용됩니다.\n컨테이너의 상태를 변경하지 않고, 중단된 상태에서 다시 실행합니다.\n이미지에서 컨테이너를 생성한 후, 실행 중인 컨테이너를 중단하고 다시 시작할 때 유용합니다.\n\ndocker container run penguin:\n\n이 명령은 도커 이미지를 기반으로 새로운 컨테이너를 생성하고 실행시킬 때 사용됩니다.\n이미지에서 새로운 컨테이너를 생성하고, 컨테이너를 시작합니다.\n이미 실행 중인 컨테이너가 아닌, 새로운 컨테이너를 생성하고 실행할 때 사용됩니다.\n\n\n요약하면, “docker container start penguin”은 이미 생성된 컨테이너를 다시 시작하고, “docker container run penguin”은 새로운 컨테이너를 생성하고 시작하는 데 사용됩니다."
  },
  {
    "objectID": "공부/2023-06-23-(공부&지윤) -- 퓨리에변환4jy.html",
    "href": "공부/2023-06-23-(공부&지윤) -- 퓨리에변환4jy.html",
    "title": "(공부&지윤) – 퓨리에변환4jy",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\n\n회귀모형 (1)\n\nx = np.linspace(-10,10,1000)\nx0 = x*0+1\nx1 = x \nbeta0 = 3 \nbeta1 = 2\ny = x0*beta0+x1*beta1+np.random.randn(1000)\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n\n\n회귀모형 (2)\n- 관측한자료\n\nN=1000\nx=np.linspace(0,1,N)\neps = np.random.randn(N)\nX0 = np.sin(x*0*np.pi)\nX1 = np.sin(x*2*np.pi)\nX2 = np.sin(x*4*np.pi)\nX3 = np.sin(x*6*np.pi)\n\ny=2*X1+1*X2+3*X3+eps\n\n\nplt.plot(x,y,'o',alpha=0.1)\n\n\n\n\n\n\n\n\n\nobserved signal\n\n- 위의 자료를 해석하는 방법\n\ndef spec(y):\n    N= len(y)\n    return abs(np.fft.fft(y)/N)*2 \n\n\ny=2*X1+1*X2+3*X3+eps\nyfft =spec(y) \ny1=2*X1\ny2=1*X2\ny3=3*X3\nyfft1=spec(y1)\nyfft2=spec(y2)\nyfft3=spec(y3)\nepsfft=spec(eps)\n\n\nplt.plot(yfft[:20],'o',alpha=0.5)\nplt.plot(yfft1[:20],'x',alpha=1,)\nplt.plot(yfft2[:20],'x',alpha=1)\nplt.plot(yfft3[:20],'x',alpha=1)\nplt.plot(epsfft[:20],'x',alpha=1)\n\n\n\n\n\n\n\n\n- 퓨리에변환 -&gt; threshold -&gt; 역퓨리에변환을 이용한 스킬\n\nyfft=np.fft.fft(y)\n\n\nplt.plot(abs(yfft[1:50]),'o')\n\n\n\n\n\n\n\n\n\nyfft[abs(yfft)&lt;100] = 0\n\n\nplt.plot(y,'o',alpha=0.1)\nyhat=np.fft.ifft(yfft)\nplt.plot(yhat,'--')\nplt.plot(y-eps,'-')\n\n\n\n\n\n\n\n\n\nplt.plot(spec2(y)[:50],'o')\nplt.plot(spec2(yhat)[:50],'x')\n\n\n\n\n\n\n\n\n\n\n삼성전자 주가자료를 스무딩해보기\n- 삼성전자 자료\n\nimport yfinance as yf\n\n\nstart_date = \"2023-01-01\"\nend_date = \"2023-05-02\"\ny = yf.download(\"005930.KS\", start=start_date, end=end_date)['Adj Close'].to_numpy()\n\n[*********************100%***********************]  1 of 1 completed\n\n\n\nplt.plot(y)\n\n\n\n\n\n\n\n\n- 스펙트럼\n\nyfft = np.fft.fft(y)\n\n\nplt.plot(abs(yfft))\n\n\n\n\n\n\n\n\n- 처음 50개정도만 관찰\n\nplt.plot(abs(yfft[:50]),'o')\n\n\n\n\n\n\n\n\n\n첫값이 너무커서 나머지는 잘안보임\n\n- 2번째부터 50번째까지만 관찰\n\nplt.plot(abs(yfft)[2:50],'o')\nplt.axhline(y=22500, color='r', linestyle='--')\n\n\n\n\n\n\n\n\n\n대충 이정도 짜르면 될것같음\n\n- thresholded value\n\ntresh_value = 22500\n\n\nyfft[abs(yfft)&lt;tresh_value] =0 \n\n- 퓨리에역변환\n\nyhat = np.fft.ifft(yfft)\nyhat[:5]\n\narray([59664.72193044+8.87311904e-14j, 58572.98839934+8.87311904e-14j,\n       58066.07369126+3.39894326e-14j, 58169.18671667-6.87747670e-14j,\n       58706.41986821-1.14383435e-13j])\n\n\n실수화\n\nyhat = np.real(yhat)\nyhat[:5]\n\narray([59664.72193044, 58572.98839934, 58066.07369126, 58169.18671667,\n       58706.41986821])\n\n\n- 적합결과 시각화\n\nplt.plot(y)\nplt.plot(yhat,'--')\n\n\n\n\n\n\n\n\n- 숙제: treshold value를 관찰하며 시각화해볼것\n\n\nminor topics\n- y의 FFT 결과는 항상 y와 같은길이임\n\nlen(y)\n\n82\n\n\n\nlen(np.fft.fft(y))\n\n82\n\n\n- 에일리어싱: number of observation은 얼마나 세밀한 주파수까지 측정가능하냐를 결정함\n예시1: 에일리어싱\n\nx = np.linspace(-3.14,3.14,10)\n\n\nx1 = np.sin(8*x)\nx2 = np.sin(10*x)\n\n\nnp.corrcoef([x1,x2])\n\narray([[ 1.        , -0.99975131],\n       [-0.99975131,  1.        ]])\n\n\n\nplt.plot(x1,label='x1')\nplt.plot(x2,label='x2')\nplt.legend()\n\n\n\n\n\n\n\n\n\n실제로는 x2가 더 고주파인데, 같은 주파수처럼 보임\n\n예시2: 에일리어싱이 없는 경우\n\nx = np.linspace(-3.14,3.14,100000)\n\n\nx1 = np.sin(8*x)\nx2 = np.sin(10*x)\n\n\nnp.corrcoef([x1,x2])\n\narray([[ 1.00000000e+00, -6.45767105e-08],\n       [-6.45767105e-08,  1.00000000e+00]])\n\n\n\nplt.plot(x1)\nplt.plot(x2)\n\n\n\n\n\n\n\n\n\n주파수 왜곡떄문에 실제로는 corr ceof = 0 일지라도 관측되는건 corr coef &gt;0 일 수 있음"
  },
  {
    "objectID": "공부/2019-04-26-(공부) -- 퓨리에변환.html",
    "href": "공부/2019-04-26-(공부) -- 퓨리에변환.html",
    "title": "(공부) – 퓨리에변환",
    "section": "",
    "text": "- 이번에는 퓨리에 표현들을 정리하도록 하겠다. 내생각엔 퓨리에 표현들도 벡터의 미분만큼 복잡한 것 같다. 정의가 너무 많고 그게 그거 같아서 그렇다. 이번기회에 깔끔하게 정리하도록 하자. 참고한 문헌은 아래와 같다.\n\nHaykin, S., & Van Veen, B. (2007). Signals and systems. John Wiley & Sons."
  },
  {
    "objectID": "공부/2019-04-26-(공부) -- 퓨리에변환.html#footnotes",
    "href": "공부/2019-04-26-(공부) -- 퓨리에변환.html#footnotes",
    "title": "(공부) – 퓨리에변환",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n나도 그렇다.↩︎\n사실 나도 잘 모름 (뭐 quotient group이런거 알아야 하는데 공부하려면 꽤 걸릴듯)↩︎"
  },
  {
    "objectID": "공부/2023-05-13-(공부&지윤) -- 추정.html",
    "href": "공부/2023-05-13-(공부&지윤) -- 추정.html",
    "title": "(공부&지윤) – 추정",
    "section": "",
    "text": "- 비편향추정량(UB)란 \\(\\theta\\)의 추정량 중\n\\[\\forall \\theta\\in \\Theta:~ E(\\hat{\\theta})=\\theta\\]\n를 만족하는 추정량 \\(\\hat{\\theta}\\)을 의미한다.\n- (예시) 아래와 같은 상황을 가정하자.\n\\[X_n \\overset{iid}{\\sim} N(\\theta,1)\\]\n여기에서\n\n\\(\\hat{\\theta}_1=0\\) 은 \\(\\theta=0\\) 일 경우에는 \\(E(\\hat{\\theta})=\\theta\\) 를 만족하지만 그 외의 경우에는 \\(E(\\hat{\\theta})\\neq\\theta\\) 이므로 UB가 아니다.\n\\(\\hat{\\theta}_2=X_1\\) 은 UB이다.\n\\(\\hat{\\theta}_3=\\frac{X_1+X_2}{2}\\) 역시 UB이다.\n\\(\\hat{\\theta}_4=X_1+X_2-X_3\\) 역시 UB이다.\n\\(\\hat{\\theta}_5=-99X_1+100X_2\\) 역시 UB이다.\n\\(\\hat{\\theta}_6=\\frac{X_1+0}{2}\\) 은 1과 동일한 이유로 UB가 아니다.\n\\(\\hat{\\theta}_7=\\bar{X}\\)는 UB이다.\n\\(\\hat{\\theta}_8=w_1X_1+\\dots+w_nX_n\\) ,where \\(\\sum_{i=1}^{n}w_i=1\\) 형태의 estimator는 모두 UB이다.\n\n- 최소분산비편향추정량(MVUE)란 \\(\\theta\\)에 대한 비편향추정량을 모아놓은 집합 \\(\\hat{\\Theta}_{UB}\\) 에서 최소분산을 가지는 추정량을 의미한다. MVUE를 구하는 방법은 아래와 같다.\n\n\\(\\theta\\)에 대한 모든 비편향추정량을 구한다. 즉 집합 \\(\\hat{\\Theta}_{UB}\\)를 구한다. 그리고 \\(\\forall \\hat{\\theta} \\in \\hat{\\Theta}_{UB}\\) 에 대하여 \\(V(\\hat{\\theta})\\) 를 구한 뒤 \\(V(\\hat{\\theta})\\)가 가장 작은 \\(\\hat{\\theta}\\)를 선택한다.\n\n예를들어 위의 예제에서 \\(V(\\hat{\\theta}_2)=1\\) 이고 \\(V(\\hat{\\theta}_3)=\\frac{1}{4}+\\frac{1}{4}=\\frac{1}{2}\\) 이므로 \\(\\hat{\\theta}_3\\) 이 더 좋은 추정량이라 볼 수 있다.\n- (의문) 왜 비편향추정량만 모아서 그중에서 최소분산을 구할까?\n\n\\(\\hat{\\theta}_1\\)와 같은 추정량은 \\(V(\\hat{\\theta}_1)=0\\) 이므로 그냥 최소분산을 만족한다. 따라서 이러한 추정량은 제외해야지 게임이 성립함.\n\n- 불만: 아래의 방법으로 구하는건 거의 불가능하지 않나?\n\n\\(\\theta\\)에 대한 모든 비편향추정량을 구한다. 즉 집합 \\(\\hat{\\Theta}_{UB}\\)를 구한다. 그리고 \\(\\forall \\hat{\\theta} \\in \\hat{\\Theta}_{UB}\\) 에 대하여 \\(V(\\hat{\\theta})\\) 를 구한 뒤 \\(V(\\hat{\\theta})\\)가 가장 작은 \\(\\hat{\\theta}\\)를 선택한다.\n\n- 이론: 크래머라오 하한값(편의상 \\(L^\\star\\)이라고 하자)이라고 있는데, 이는 \\({\\Theta}_{UB}\\)에 존재하는 모든 추정량에 대한 분산의 하한값을 제공한다.1 즉 아래가 성립한다.\n\n\\(L^\\star\\) is Cramer-Rao lower bound \\(\\Rightarrow\\) \\(\\forall \\hat{\\theta} \\in {\\Theta}_{UB}:~ V(\\hat{\\theta}) \\geq L^\\star\\)\n\n역은 성립하지 않음을 주의하자. 즉 아래를 만족하는 \\(L\\)이 존재할 수 있다.\n\n\\(V(\\hat{\\theta}) \\geq L &gt; L^\\star\\) for some \\(\\hat{\\theta} \\in \\Theta_{UB}\\)\n\n- 위의 이론을 이용하면 아래의 논리전개를 펼 수 있다.\n\n\\(L^\\star\\)를 구한다.\n왠지 MVUE가 될 것 같은 \\(\\hat{\\theta}\\)을 하나 찍고 그것의 분산 \\(V(\\hat{\\theta})\\)를 구한다.\n만약에 \\(V(\\hat{\\theta})=L^\\star\\)를 만족하면 그 \\(\\hat{\\theta}\\)이 MVUE라고 주장할 수 있다.\n\n- 위의 논리전개에 대한 불만 [p.212]\n\n\\(V(\\hat{\\theta})=L^\\star\\) 이길 기도해야함.\n\\(\\forall \\hat{\\theta} \\in {\\Theta}_{UB}:~ V(\\hat{\\theta}) \\geq L &gt; L^\\star\\) 와 같은 \\(L\\)이 존재하는 경우는 쓸 수 없음.\n\n- 또 다른 방법: 완비충분통계량을 이용함\n\n\n아래와 같은 상황을 가정하자.\n\\[ X_1,\\dots,X_n \\overset{iid}{\\sim} P_{\\theta}\\]\n- 충분통계량(SS)의 느낌: “이 값만 기억하면 \\(\\theta\\)를 추정하는데 무난할듯”\n- 예시1: \\(X_1 \\sim N(\\theta,1)\\)\n\n\\(X_1\\)은 \\(\\theta_1\\) 의 SS. (하나밖에 없으니 그거라도 기억해야지)\n즉 \\(\\hat{\\theta}=X_1\\)은 \\(\\theta\\)의 SS\n\n- 예시2: \\(X_1,X_2 \\sim N(\\theta,1)\\)\n\n당연히 \\(\\hat{\\boldsymbol \\theta}=(X_1,X_2)\\)는 \\(\\theta\\)의 SS (둘다 기억하면 당연히 \\(\\theta\\)를 추정함에 있어서 충분함)\n그렇지만 좀 더 생각해보면 굳이 값 두개를 기억하기보다 \\(\\frac{1}{2}(X_1+X_2)\\)의 값만 기억해도 왠지 충분할것 같음. 따라서 \\(\\hat{\\theta} = \\frac{1}{2}(X_1+X_2)\\) 역시 \\(\\theta\\)의 SS 일듯\n그런데 좀 더 생각해보니까 \\(X_1+X_2\\)의 값만 기억해도 \\(\\frac{1}{2}(X_1+X_2)\\)를 나중에 만들 수 있음 (1/2만 곱하면 되니까) 따라서 \\(X_1+X_2\\)만 기억해도 왠지 충분할 것 같음. 따라서 \\(\\hat{\\theta}=X_1+X_2\\) 역시 \\(\\theta\\)의 SS 일듯\n\n- 예시3: \\(X_1,\\dots,X_n \\sim N(\\theta,1)\\)\n\n당연히 \\(\\hat{\\boldsymbol \\theta}=(X_1,X_2,\\dots,X_n)\\)은 \\(\\theta\\)의 SS.\n하지만 \\(n\\)개의 숫자를 기억할 필요 없이 \\(\\sum_{i=1}^{n} X_i\\) 하나의 숫자만 기억해도 왠지 충분할듯. 그래서 \\(\\hat{\\theta} = \\sum_{i=1}^{n} X_i\\) 역시 \\(\\theta\\)의 SS 일듯\n\n- SS에 대한 직관1\n\n기억할 숫자가 적을수록 유리 -&gt; MSS의 개념\n충분통계량의 1:1은 충분통계량 (\\(\\frac{1}{2}(X_1+X_2)\\)을 기억하면 충분한 상황이라면, \\(X_1+X_2\\)를 기억해도 충분하니까..)\n\n- 예시4: \\(X_1,X_2 \\sim {\\cal B}er(\\theta)\\)\n\n당연히 \\(\\hat{\\boldsymbol \\theta}=(X_1,X_2)\\)은 \\(\\theta\\)의 SS.\n그리고 \\(\\hat{\\theta}=X_1+X_2\\) 역시 \\(\\theta\\) SS 일듯.\n두개보다 한개가 유리하니까 둘다 SS이면 \\((X_1,X_2)\\)보다 \\(X_1+X_2\\)가 더 좋은 SS.\n\\(X_1\\)은 SS가 아닐듯. \\(p\\)를 추정함에 있어서 \\(X_1\\)만 가지고서는 충분하지 않아보임\n\\(X_2\\)도 SS가 아닐듯.\n\n왠지 충분할 것 같은 느낌의 정의\n아래와 같은 상황을 가정하자.\n\\[X_1,X_2 \\sim {\\cal B}er(\\theta)\\]\n- 일반적으로\n\n\\(P((X_1,X_2)=(0,0))=P(X_1=0,X_2=0)=(1-\\theta)^2\\)\n\\(P((X_1,X_2)=(0,1))=P(X_1=0,X_2=1)=\\theta(1-\\theta)\\)\n\\(P((X_1,X_2)=(1,0))=P(X_1=1,X_2=0)=(1-\\theta)^2\\)\n\\(P((X_1,X_2)=(1,1))=P(X_1=1,X_2=1)=\\theta^2\\)\n\n와 같은 확률들은 \\(\\theta\\)가 unknown일 때 하나의 숫자로 정할 수 없다. 예를들어 \\(\\theta=0\\) 이라면 아래와 같을 것이고\n\n\\(P((X_1,X_2)=(0,0))=P(X_1=0,X_2=0)=1\\)\n\\(P((X_1,X_2)=(0,1))=P(X_1=0,X_2=1)=0\\)\n\\(P((X_1,X_2)=(1,0))=P(X_1=1,X_2=0)=0\\)\n\\(P((X_1,X_2)=(1,1))=P(X_1=1,X_2=1)=0\\)\n\n\\(\\theta=1/2\\) 이라면 아래와 같을 것이다.\n\n\\(P((X_1,X_2)=(0,0))=P(X_1=0,X_2=0)=1/4\\)\n\\(P((X_1,X_2)=(0,1))=P(X_1=0,X_2=1)=1/4\\)\n\\(P((X_1,X_2)=(1,0))=P(X_1=1,X_2=0)=1/4\\)\n\\(P((X_1,X_2)=(1,1))=P(X_1=1,X_2=1)=1/4\\)\n\n즉 \\(X_1,X_2\\)의 결합확률분포는 \\(\\theta\\)가 변함에 따라 같이 변화한다. 이를 이용해 우리는 \\(X_1,X_2\\)의 결합확률분포에서 관찰한 샘플들을 이용하여 \\(\\theta\\)의 값을 역으로 추론한다.\n- 만약에 어떠한 “특수한 정보를 알고 있을 경우” \\(X_1,X_2\\)의 결합확률분포를 완벽하게 기술할 수 있을 때를 가정해보자.\n- 경우1: \\(\\theta\\)를 알고 있을 경우. \\((X_1,X_2)\\)의 조인트를 완벽하게 기술할 수 있다. 예를들어 \\(\\theta=1/2\\)일 경우는 아래와 같다.\n\n\\(P(X_1=0,X_2=0 | \\theta=1/2)=1/4\\)\n\\(P(X_1=0,X_2=1 | \\theta=1/2)=1/4\\)\n\\(P(X_1=1,X_2=0 | \\theta=1/2)=1/4\\)\n\\(P(X_1=1,X_2=1 | \\theta=1/2)=1/4\\)\n\n- 경우2: \\(X_1,X_2\\)의 realization을 알고 있을 경우. \\((X_1,X_2)\\)의 조인트를 완벽하게 기술할 수 있다. 예를들어 \\(X_1=0,X_2=1\\)일 경우는 아래와 같다.\n\n\\(P(X_1=0,X_2=0 | X_1=0,X_2=0)=0\\)\n\\(P(X_1=0,X_2=1| X_1=0,X_2=1)=0\\)\n\\(P(X_1=1,X_2=0| X_1=1,X_2=0)=1\\)\n\\(P(X_1=1,X_2=1| X_1=1,X_2=1)=0\\)\n\n- 경우3: \\((X_1+X_2)(\\omega)\\)의 realization을 알고 있을 경우. 이때도 매우 특이하게 \\((X_1,X_2)\\) 의 조인트를 완벽하게 기술할 수 있다.\ncase1: \\(X_1+X_2=0\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1+X_2=0)=1\\)\n\\(P(X_1=0,X_2=1| X_1+X_2=0)=0\\)\n\\(P(X_1=1,X_2=0| X_1+X_2=0)=0\\)\n\\(P(X_1=1,X_2=1| X_1+X_2=0)=0\\)\n\ncase2: \\(X_1+X_2=1\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1+X_2=1)=0\\)\n\\(P(X_1=0,X_2=1| X_1+X_2=1)=1/2\\)\n\\(P(X_1=1,X_2=0| X_1+X_2=1)=1/2\\)\n\\(P(X_1=1,X_2=1| X_1+X_2=1)=0\\)\n\ncase3: \\(X_1+X_2=2\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1+X_2=2)=0\\)\n\\(P(X_1=0,X_2=1| X_1+X_2=2)=0\\)\n\\(P(X_1=1,X_2=0| X_1+X_2=2)=0\\)\n\\(P(X_1=1,X_2=1| X_1+X_2=2)=1\\)\n\n- 경우4: \\(X_1\\)의 realization만 알고 있을 경우. 이때는 \\((X_1,X_2)\\) 의 조인트를 완벽하게 기술할 수 없다.\ncase1: \\(X_1=0\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1=0)=1-\\theta\\)\n\\(P(X_1=0,X_2=1| X_1=0)=\\theta\\)\n\\(P(X_1=1,X_2=0| X_1=0)=0\\)\n\\(P(X_1=1,X_2=1| X_1=0)=0\\)\n\ncase2: \\(X_1=1\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1=1)=0\\)\n\\(P(X_1=0,X_2=1| X_1=1)=0\\)\n\\(P(X_1=1,X_2=0| X_1=1)=1-\\theta\\)\n\\(P(X_1=1,X_2=1| X_1=1)=\\theta\\)\n\n- 종합해보면 경우1,경우2,경우3은 경우4와 구분되는 어떠한 공통점을 가지고 있다 볼 수 있다. 특징은 결합확률분포가 \\(\\theta\\)에 대한 함수로 표현되지 않는다는 것이다. 하나씩 살펴보면\n\n경우1: 당연히 \\(\\theta\\)를 줬으니까 \\((X_1,X_2)\\)의 조인트는 \\(\\theta\\)에 의존하지 않음.\n경우2: \\(X_1,X_2\\)를 줬음. \\((X_1,X_2)\\)의 조인트는 \\(\\theta\\)에 의존하지 않음.\n경우3: \\(X_1+X_2\\)를 줬음. \\((X_1,X_2)\\)의 조인트는 \\(\\theta\\)에 의존하지 않음.\n\n이렇게보면 경우1과 경우2,3은 또 다시 구분된다. 경우1은 \\(\\theta\\)에 대한 완전한 정보를 준 상황이므로 당연히 조인트는 \\(\\theta\\)에 의존하지 않는다. 경우2-3은 \\(\\theta\\)를 주지 않았음에도 조인트가 \\(\\theta\\)에 의존하지 않는 매우 특별해보이는 상황이다. 따라서 이를 통해서 유추하면\n\n경우2에서는 \\((X_1,X_2)\\) 가 경우3에서는 \\(X_1+X_2\\)가 \\(\\theta\\)에 대한 완전한 정보를 대신하고 있는것 아닐까?\n\n라는 생각이 든다. 정리하면\n\n경우2: \\((X_1,X_2)\\)을 주는 것은 \\(\\theta\\)의 값을 그냥 알려주는 것과 대등한 효과\n경우3: \\(X_1+X_2\\)를 주는 것은 \\(\\theta\\)의 값을 그냥 알려주는 것과 대등한 효과\n\n라고 해석할 수 있는데 이를 수식화 하면 아래와 같다.\n- 대충정의: 어떠한 통계량 \\(S\\)의 값을 줬을때, \\((X_1,X_2\\dots,X_n)\\)의 조인트가 \\(\\theta\\)에 의존하지 않으면 그 통계량 \\(S\\)를 \\(\\theta\\)의 충분통계량이라고 한다.\n- 충분통계량 구하는 방법\n\n지수족일때 구하는 방식이 있음! &lt;– 외우세여\n분해정리를 쓰는 경우. &lt;– 거의 안쓰는거같은데..\n1-2로도 잘 모르겠으면 충분통계량일듯한 애를 잡아와서 정의에 넣고 노가다로 때려맞춤. (문제가 디스크릿할때만 쓸것)\n\n\n\n\n- 충분통계량에 대한 realization을 알려주면 \\(\\theta\\)의 값을 그냥 알려주는 효과임. 그래서 충분통계량은 좋은 것임\n- 그런데 충분통계량에도 급이 있음. 아래와 같은 상황을 가정하자.\n\\[X_1,X_2 \\sim {\\cal B}er(\\theta)\\]\n이 경우\n\n\\((X_1,X_2)\\)는 SS\n\\(X_1+X_2\\)는 SS\n\n이지만 1은 두개의 숫자를 기억해야하고 2는 하나의 숫자만 기억하면 되니까 2가 더 좋음\n- 예비개념: 상태1과 상태2가 있다고 하자. 상태1에서 상태2로 가는 변화는 쉽지만, 상태2에서 상태1로 가는 변화는 어렵다고 할때, 상태1이 더 좋은 상태이다.\n\n두가지 상태 “500원을 가지고 있음”, “1000원을 가지고 있음” 을 고려하자. 1000원을 500원을 만드는 것은 쉽지만 500원을 1000원으로 만들기는 어렵다. 따라서 1000원이 더 좋은 상태이다.\n\n- 충분통계량의 급을 어떻게 구분할까? 아래의 상황에서\n\n\\((X_1,X_2)\\)는 SS\n\\(X_1+X_2\\)는 SS\n\n1을 이용하면 2를 만들 수 있지만, 2를 이용해서 1을 만들 수는 없음. 즉 \\(1\\to 2\\) 인 변환(=함수)는 가능하지만 \\(2\\to 1\\)로 만드는 변환(=함수)는 가능하지 않음. 예비개념을 잘 이해했다면 2가 더 좋은 상태라고 볼 수 있다.\n- 이를 확장하자. 어떠한 충분 통계량 \\(S^\\star\\)가 있다고 가정하자. 다른 모든 충분통계량 \\(S_1,S_2,S_3 \\dots\\)에서 \\(S^\\star\\)로 만드는 변환은 존재하는데 (함수는 존재하는데) 그 반대는 \\(S^\\star\\)의 전단사인 충분통계량만 가능하다고 하자. 그렇다면 \\(S^\\star\\)는 가장 좋은 충분통계량이라고 하며, 가장 적은 숫자만 기억하면 되는 충분통계량이라 볼 수 있다. 이러한 충분통계량을 MSS 라고 하자.\n\n\n\n- 충분통계량 \\(S\\)을 알려주면 (기븐하면) \\(\\theta\\)에 대한 완벽한 정보를 알려주는 셈이다. 따라서 \\(\\theta\\)를 추정하는 어떠한 추정량 \\(\\hat{\\theta}\\)도 충분통계량의 정보 \\(S\\)가 있다면 \\(\\hat{\\theta}\\)를 업그레이드할 수 있다고 볼 수 있다. (뭐 수틀리면 정보야 안쓰면 그만이니까 나빠질것은 없다)\n- 충분통계량을 줬을때 \\(\\hat{\\theta}\\)의 업그레이드 방법은\n\\[\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\]\n와 같이 할 수 있는데 이는 충분통계량 \\(S\\)의 정보를 받아서 어떠한 방식으로 업데이트된 \\(\\hat{\\theta}\\) 이므로 \\(S\\)의 함수라 해석할 수 있다.\n- 이론 (라오블랙웰, Thm, 4.5): \\(\\hat{\\theta}\\)가 UB일때 충분통계량의 값을 알려주면 \\(\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\)와 같이 \\(\\hat{\\theta}\\)를 업그레이드 할 수 있다.\n\n\n\n- 충분통계량 \\(S\\)을 알려주면 (기븐하면) \\(\\theta\\)에 대한 완벽한 정보를 알려주는 셈이다. 따라서 \\(\\theta\\)를 추정하는 어떠한 추정량 \\(\\hat{\\theta}\\)도 충분통계량의 정보 \\(S\\)가 있다면 \\(\\hat{\\theta}\\)를 업그레이드할 수 있다고 볼 수 있다. (뭐 수틀리면 정보야 안쓰면 그만이니까 나빠질것은 없다)\n- 충분통계량을 줬을때 \\(\\hat{\\theta}\\)의 업그레이드 방법은\n\\[\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\]\n와 같이 할 수 있는데 이는 충분통계량 \\(S\\)의 정보를 받아서 어떠한 방식으로 업데이트된 \\(\\hat{\\theta}\\) 이므로 \\(S\\)의 함수라 해석할 수 있다.\n- 이론 (라오블랙웰, Thm, 4.5): \\(\\hat{\\theta}\\)가 UB일때 충분통계량의 값을 알려주면 \\(\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\)와 같이 \\(\\hat{\\theta}\\)를 업그레이드 할 수 있다."
  },
  {
    "objectID": "공부/2023-05-13-(공부&지윤) -- 추정.html#충분통계량",
    "href": "공부/2023-05-13-(공부&지윤) -- 추정.html#충분통계량",
    "title": "(공부&지윤) – 추정",
    "section": "",
    "text": "아래와 같은 상황을 가정하자.\n\\[ X_1,\\dots,X_n \\overset{iid}{\\sim} P_{\\theta}\\]\n- 충분통계량(SS)의 느낌: “이 값만 기억하면 \\(\\theta\\)를 추정하는데 무난할듯”\n- 예시1: \\(X_1 \\sim N(\\theta,1)\\)\n\n\\(X_1\\)은 \\(\\theta_1\\) 의 SS. (하나밖에 없으니 그거라도 기억해야지)\n즉 \\(\\hat{\\theta}=X_1\\)은 \\(\\theta\\)의 SS\n\n- 예시2: \\(X_1,X_2 \\sim N(\\theta,1)\\)\n\n당연히 \\(\\hat{\\boldsymbol \\theta}=(X_1,X_2)\\)는 \\(\\theta\\)의 SS (둘다 기억하면 당연히 \\(\\theta\\)를 추정함에 있어서 충분함)\n그렇지만 좀 더 생각해보면 굳이 값 두개를 기억하기보다 \\(\\frac{1}{2}(X_1+X_2)\\)의 값만 기억해도 왠지 충분할것 같음. 따라서 \\(\\hat{\\theta} = \\frac{1}{2}(X_1+X_2)\\) 역시 \\(\\theta\\)의 SS 일듯\n그런데 좀 더 생각해보니까 \\(X_1+X_2\\)의 값만 기억해도 \\(\\frac{1}{2}(X_1+X_2)\\)를 나중에 만들 수 있음 (1/2만 곱하면 되니까) 따라서 \\(X_1+X_2\\)만 기억해도 왠지 충분할 것 같음. 따라서 \\(\\hat{\\theta}=X_1+X_2\\) 역시 \\(\\theta\\)의 SS 일듯\n\n- 예시3: \\(X_1,\\dots,X_n \\sim N(\\theta,1)\\)\n\n당연히 \\(\\hat{\\boldsymbol \\theta}=(X_1,X_2,\\dots,X_n)\\)은 \\(\\theta\\)의 SS.\n하지만 \\(n\\)개의 숫자를 기억할 필요 없이 \\(\\sum_{i=1}^{n} X_i\\) 하나의 숫자만 기억해도 왠지 충분할듯. 그래서 \\(\\hat{\\theta} = \\sum_{i=1}^{n} X_i\\) 역시 \\(\\theta\\)의 SS 일듯\n\n- SS에 대한 직관1\n\n기억할 숫자가 적을수록 유리 -&gt; MSS의 개념\n충분통계량의 1:1은 충분통계량 (\\(\\frac{1}{2}(X_1+X_2)\\)을 기억하면 충분한 상황이라면, \\(X_1+X_2\\)를 기억해도 충분하니까..)\n\n- 예시4: \\(X_1,X_2 \\sim {\\cal B}er(\\theta)\\)\n\n당연히 \\(\\hat{\\boldsymbol \\theta}=(X_1,X_2)\\)은 \\(\\theta\\)의 SS.\n그리고 \\(\\hat{\\theta}=X_1+X_2\\) 역시 \\(\\theta\\) SS 일듯.\n두개보다 한개가 유리하니까 둘다 SS이면 \\((X_1,X_2)\\)보다 \\(X_1+X_2\\)가 더 좋은 SS.\n\\(X_1\\)은 SS가 아닐듯. \\(p\\)를 추정함에 있어서 \\(X_1\\)만 가지고서는 충분하지 않아보임\n\\(X_2\\)도 SS가 아닐듯.\n\n왠지 충분할 것 같은 느낌의 정의\n아래와 같은 상황을 가정하자.\n\\[X_1,X_2 \\sim {\\cal B}er(\\theta)\\]\n- 일반적으로\n\n\\(P((X_1,X_2)=(0,0))=P(X_1=0,X_2=0)=(1-\\theta)^2\\)\n\\(P((X_1,X_2)=(0,1))=P(X_1=0,X_2=1)=\\theta(1-\\theta)\\)\n\\(P((X_1,X_2)=(1,0))=P(X_1=1,X_2=0)=(1-\\theta)^2\\)\n\\(P((X_1,X_2)=(1,1))=P(X_1=1,X_2=1)=\\theta^2\\)\n\n와 같은 확률들은 \\(\\theta\\)가 unknown일 때 하나의 숫자로 정할 수 없다. 예를들어 \\(\\theta=0\\) 이라면 아래와 같을 것이고\n\n\\(P((X_1,X_2)=(0,0))=P(X_1=0,X_2=0)=1\\)\n\\(P((X_1,X_2)=(0,1))=P(X_1=0,X_2=1)=0\\)\n\\(P((X_1,X_2)=(1,0))=P(X_1=1,X_2=0)=0\\)\n\\(P((X_1,X_2)=(1,1))=P(X_1=1,X_2=1)=0\\)\n\n\\(\\theta=1/2\\) 이라면 아래와 같을 것이다.\n\n\\(P((X_1,X_2)=(0,0))=P(X_1=0,X_2=0)=1/4\\)\n\\(P((X_1,X_2)=(0,1))=P(X_1=0,X_2=1)=1/4\\)\n\\(P((X_1,X_2)=(1,0))=P(X_1=1,X_2=0)=1/4\\)\n\\(P((X_1,X_2)=(1,1))=P(X_1=1,X_2=1)=1/4\\)\n\n즉 \\(X_1,X_2\\)의 결합확률분포는 \\(\\theta\\)가 변함에 따라 같이 변화한다. 이를 이용해 우리는 \\(X_1,X_2\\)의 결합확률분포에서 관찰한 샘플들을 이용하여 \\(\\theta\\)의 값을 역으로 추론한다.\n- 만약에 어떠한 “특수한 정보를 알고 있을 경우” \\(X_1,X_2\\)의 결합확률분포를 완벽하게 기술할 수 있을 때를 가정해보자.\n- 경우1: \\(\\theta\\)를 알고 있을 경우. \\((X_1,X_2)\\)의 조인트를 완벽하게 기술할 수 있다. 예를들어 \\(\\theta=1/2\\)일 경우는 아래와 같다.\n\n\\(P(X_1=0,X_2=0 | \\theta=1/2)=1/4\\)\n\\(P(X_1=0,X_2=1 | \\theta=1/2)=1/4\\)\n\\(P(X_1=1,X_2=0 | \\theta=1/2)=1/4\\)\n\\(P(X_1=1,X_2=1 | \\theta=1/2)=1/4\\)\n\n- 경우2: \\(X_1,X_2\\)의 realization을 알고 있을 경우. \\((X_1,X_2)\\)의 조인트를 완벽하게 기술할 수 있다. 예를들어 \\(X_1=0,X_2=1\\)일 경우는 아래와 같다.\n\n\\(P(X_1=0,X_2=0 | X_1=0,X_2=0)=0\\)\n\\(P(X_1=0,X_2=1| X_1=0,X_2=1)=0\\)\n\\(P(X_1=1,X_2=0| X_1=1,X_2=0)=1\\)\n\\(P(X_1=1,X_2=1| X_1=1,X_2=1)=0\\)\n\n- 경우3: \\((X_1+X_2)(\\omega)\\)의 realization을 알고 있을 경우. 이때도 매우 특이하게 \\((X_1,X_2)\\) 의 조인트를 완벽하게 기술할 수 있다.\ncase1: \\(X_1+X_2=0\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1+X_2=0)=1\\)\n\\(P(X_1=0,X_2=1| X_1+X_2=0)=0\\)\n\\(P(X_1=1,X_2=0| X_1+X_2=0)=0\\)\n\\(P(X_1=1,X_2=1| X_1+X_2=0)=0\\)\n\ncase2: \\(X_1+X_2=1\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1+X_2=1)=0\\)\n\\(P(X_1=0,X_2=1| X_1+X_2=1)=1/2\\)\n\\(P(X_1=1,X_2=0| X_1+X_2=1)=1/2\\)\n\\(P(X_1=1,X_2=1| X_1+X_2=1)=0\\)\n\ncase3: \\(X_1+X_2=2\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1+X_2=2)=0\\)\n\\(P(X_1=0,X_2=1| X_1+X_2=2)=0\\)\n\\(P(X_1=1,X_2=0| X_1+X_2=2)=0\\)\n\\(P(X_1=1,X_2=1| X_1+X_2=2)=1\\)\n\n- 경우4: \\(X_1\\)의 realization만 알고 있을 경우. 이때는 \\((X_1,X_2)\\) 의 조인트를 완벽하게 기술할 수 없다.\ncase1: \\(X_1=0\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1=0)=1-\\theta\\)\n\\(P(X_1=0,X_2=1| X_1=0)=\\theta\\)\n\\(P(X_1=1,X_2=0| X_1=0)=0\\)\n\\(P(X_1=1,X_2=1| X_1=0)=0\\)\n\ncase2: \\(X_1=1\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1=1)=0\\)\n\\(P(X_1=0,X_2=1| X_1=1)=0\\)\n\\(P(X_1=1,X_2=0| X_1=1)=1-\\theta\\)\n\\(P(X_1=1,X_2=1| X_1=1)=\\theta\\)\n\n- 종합해보면 경우1,경우2,경우3은 경우4와 구분되는 어떠한 공통점을 가지고 있다 볼 수 있다. 특징은 결합확률분포가 \\(\\theta\\)에 대한 함수로 표현되지 않는다는 것이다. 하나씩 살펴보면\n\n경우1: 당연히 \\(\\theta\\)를 줬으니까 \\((X_1,X_2)\\)의 조인트는 \\(\\theta\\)에 의존하지 않음.\n경우2: \\(X_1,X_2\\)를 줬음. \\((X_1,X_2)\\)의 조인트는 \\(\\theta\\)에 의존하지 않음.\n경우3: \\(X_1+X_2\\)를 줬음. \\((X_1,X_2)\\)의 조인트는 \\(\\theta\\)에 의존하지 않음.\n\n이렇게보면 경우1과 경우2,3은 또 다시 구분된다. 경우1은 \\(\\theta\\)에 대한 완전한 정보를 준 상황이므로 당연히 조인트는 \\(\\theta\\)에 의존하지 않는다. 경우2-3은 \\(\\theta\\)를 주지 않았음에도 조인트가 \\(\\theta\\)에 의존하지 않는 매우 특별해보이는 상황이다. 따라서 이를 통해서 유추하면\n\n경우2에서는 \\((X_1,X_2)\\) 가 경우3에서는 \\(X_1+X_2\\)가 \\(\\theta\\)에 대한 완전한 정보를 대신하고 있는것 아닐까?\n\n라는 생각이 든다. 정리하면\n\n경우2: \\((X_1,X_2)\\)을 주는 것은 \\(\\theta\\)의 값을 그냥 알려주는 것과 대등한 효과\n경우3: \\(X_1+X_2\\)를 주는 것은 \\(\\theta\\)의 값을 그냥 알려주는 것과 대등한 효과\n\n라고 해석할 수 있는데 이를 수식화 하면 아래와 같다.\n- 대충정의: 어떠한 통계량 \\(S\\)의 값을 줬을때, \\((X_1,X_2\\dots,X_n)\\)의 조인트가 \\(\\theta\\)에 의존하지 않으면 그 통계량 \\(S\\)를 \\(\\theta\\)의 충분통계량이라고 한다.\n- 충분통계량 구하는 방법\n\n지수족일때 구하는 방식이 있음! &lt;– 외우세여\n분해정리를 쓰는 경우. &lt;– 거의 안쓰는거같은데..\n1-2로도 잘 모르겠으면 충분통계량일듯한 애를 잡아와서 정의에 넣고 노가다로 때려맞춤. (문제가 디스크릿할때만 쓸것)"
  },
  {
    "objectID": "공부/2023-05-13-(공부&지윤) -- 추정.html#최소충분통계량",
    "href": "공부/2023-05-13-(공부&지윤) -- 추정.html#최소충분통계량",
    "title": "(공부&지윤) – 추정",
    "section": "",
    "text": "- 충분통계량에 대한 realization을 알려주면 \\(\\theta\\)의 값을 그냥 알려주는 효과임. 그래서 충분통계량은 좋은 것임\n- 그런데 충분통계량에도 급이 있음. 아래와 같은 상황을 가정하자.\n\\[X_1,X_2 \\sim {\\cal B}er(\\theta)\\]\n이 경우\n\n\\((X_1,X_2)\\)는 SS\n\\(X_1+X_2\\)는 SS\n\n이지만 1은 두개의 숫자를 기억해야하고 2는 하나의 숫자만 기억하면 되니까 2가 더 좋음\n- 예비개념: 상태1과 상태2가 있다고 하자. 상태1에서 상태2로 가는 변화는 쉽지만, 상태2에서 상태1로 가는 변화는 어렵다고 할때, 상태1이 더 좋은 상태이다.\n\n두가지 상태 “500원을 가지고 있음”, “1000원을 가지고 있음” 을 고려하자. 1000원을 500원을 만드는 것은 쉽지만 500원을 1000원으로 만들기는 어렵다. 따라서 1000원이 더 좋은 상태이다.\n\n- 충분통계량의 급을 어떻게 구분할까? 아래의 상황에서\n\n\\((X_1,X_2)\\)는 SS\n\\(X_1+X_2\\)는 SS\n\n1을 이용하면 2를 만들 수 있지만, 2를 이용해서 1을 만들 수는 없음. 즉 \\(1\\to 2\\) 인 변환(=함수)는 가능하지만 \\(2\\to 1\\)로 만드는 변환(=함수)는 가능하지 않음. 예비개념을 잘 이해했다면 2가 더 좋은 상태라고 볼 수 있다.\n- 이를 확장하자. 어떠한 충분 통계량 \\(S^\\star\\)가 있다고 가정하자. 다른 모든 충분통계량 \\(S_1,S_2,S_3 \\dots\\)에서 \\(S^\\star\\)로 만드는 변환은 존재하는데 (함수는 존재하는데) 그 반대는 \\(S^\\star\\)의 전단사인 충분통계량만 가능하다고 하자. 그렇다면 \\(S^\\star\\)는 가장 좋은 충분통계량이라고 하며, 가장 적은 숫자만 기억하면 되는 충분통계량이라 볼 수 있다. 이러한 충분통계량을 MSS 라고 하자."
  },
  {
    "objectID": "공부/2023-05-13-(공부&지윤) -- 추정.html#라오블랙웰",
    "href": "공부/2023-05-13-(공부&지윤) -- 추정.html#라오블랙웰",
    "title": "(공부&지윤) – 추정",
    "section": "",
    "text": "- 충분통계량 \\(S\\)을 알려주면 (기븐하면) \\(\\theta\\)에 대한 완벽한 정보를 알려주는 셈이다. 따라서 \\(\\theta\\)를 추정하는 어떠한 추정량 \\(\\hat{\\theta}\\)도 충분통계량의 정보 \\(S\\)가 있다면 \\(\\hat{\\theta}\\)를 업그레이드할 수 있다고 볼 수 있다. (뭐 수틀리면 정보야 안쓰면 그만이니까 나빠질것은 없다)\n- 충분통계량을 줬을때 \\(\\hat{\\theta}\\)의 업그레이드 방법은\n\\[\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\]\n와 같이 할 수 있는데 이는 충분통계량 \\(S\\)의 정보를 받아서 어떠한 방식으로 업데이트된 \\(\\hat{\\theta}\\) 이므로 \\(S\\)의 함수라 해석할 수 있다.\n- 이론 (라오블랙웰, Thm, 4.5): \\(\\hat{\\theta}\\)가 UB일때 충분통계량의 값을 알려주면 \\(\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\)와 같이 \\(\\hat{\\theta}\\)를 업그레이드 할 수 있다."
  },
  {
    "objectID": "공부/2023-05-13-(공부&지윤) -- 추정.html#레만쉐페정리",
    "href": "공부/2023-05-13-(공부&지윤) -- 추정.html#레만쉐페정리",
    "title": "(공부&지윤) – 추정",
    "section": "",
    "text": "- 충분통계량 \\(S\\)을 알려주면 (기븐하면) \\(\\theta\\)에 대한 완벽한 정보를 알려주는 셈이다. 따라서 \\(\\theta\\)를 추정하는 어떠한 추정량 \\(\\hat{\\theta}\\)도 충분통계량의 정보 \\(S\\)가 있다면 \\(\\hat{\\theta}\\)를 업그레이드할 수 있다고 볼 수 있다. (뭐 수틀리면 정보야 안쓰면 그만이니까 나빠질것은 없다)\n- 충분통계량을 줬을때 \\(\\hat{\\theta}\\)의 업그레이드 방법은\n\\[\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\]\n와 같이 할 수 있는데 이는 충분통계량 \\(S\\)의 정보를 받아서 어떠한 방식으로 업데이트된 \\(\\hat{\\theta}\\) 이므로 \\(S\\)의 함수라 해석할 수 있다.\n- 이론 (라오블랙웰, Thm, 4.5): \\(\\hat{\\theta}\\)가 UB일때 충분통계량의 값을 알려주면 \\(\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\)와 같이 \\(\\hat{\\theta}\\)를 업그레이드 할 수 있다."
  },
  {
    "objectID": "공부/2023-05-13-(공부&지윤) -- 추정.html#footnotes",
    "href": "공부/2023-05-13-(공부&지윤) -- 추정.html#footnotes",
    "title": "(공부&지윤) – 추정",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n(사실 \\({\\Theta}_{UB}\\)가 아닌 집합에 대해서도 하한값을 제공함, 그런데 교재에서는 \\({\\Theta}_{UB}\\)에 대한 하한값만 다루는듯↩︎"
  },
  {
    "objectID": "공부/2023-06-28-(공부&지윤) -- 퓨리에변환(detailed).html",
    "href": "공부/2023-06-28-(공부&지윤) -- 퓨리에변환(detailed).html",
    "title": "(공부&지윤) – 퓨리에변환(detailed)",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "공부/2023-06-28-(공부&지윤) -- 퓨리에변환(detailed).html#이론-및-예시",
    "href": "공부/2023-06-28-(공부&지윤) -- 퓨리에변환(detailed).html#이론-및-예시",
    "title": "(공부&지윤) – 퓨리에변환(detailed)",
    "section": "이론 및 예시",
    "text": "이론 및 예시\n- 이론: real-valued signal은 무조건 \\(|X[k]|^2\\)의 그래프가 대칭으로 나옴 (단, \\(X[0]\\)은 제외)\n- 예시1:\n\nx = np.array([1,2,3,4,5])\nX = np.fft.fft(x) \n\n\nplt.plot(abs(X)**2,'o')\n\n\n\n\n\n\n\n\n\n첫항을 제외하고 대칭임\n\n- 예시2:\n\nx = np.array([1,2,3,-3,-2,-1])\nX = np.fft.fft(x) \n\n\nplt.plot(abs(X)**2,'o')\n\n\n\n\n\n\n\n\n\n첫항을 제외하고 대칭임\n\n- 예시3: \\({\\bf x}\\)가 복소수일 경우는 첫항을 제외하고 대칭이 되지 않음\n\nx = np.array([1+1j,2+2j,3+3j,-3-3j,-2-2j,1-1j]) \nX = np.fft.fft(x) \n\n\nplt.plot(abs(X)**2,'o')"
  },
  {
    "objectID": "공부/2023-06-28-(공부&지윤) -- 퓨리에변환(detailed).html#왜-xn이-실수일-경우만-xk2이-대칭으로-나올까",
    "href": "공부/2023-06-28-(공부&지윤) -- 퓨리에변환(detailed).html#왜-xn이-실수일-경우만-xk2이-대칭으로-나올까",
    "title": "(공부&지윤) – 퓨리에변환(detailed)",
    "section": "왜 \\(x[n]\\)이 실수일 경우만 \\(|X[k]|^2\\)이 대칭으로 나올까?",
    "text": "왜 \\(x[n]\\)이 실수일 경우만 \\(|X[k]|^2\\)이 대칭으로 나올까?\n- 예비학습1\n임의의 \\(0 \\leq \\alpha \\leq 1\\)에 대하여 \\(\\cos(2\\pi \\alpha) =\\cos(2\\pi (1-\\alpha))\\) 가 성립함\n\nalpha = 0.2\nnp.cos(2*np.pi*alpha),np.cos(2*np.pi*(1-alpha))\n\n(0.30901699437494745, 0.30901699437494723)\n\n\n\n그래프를 잘 그려보세여\n\n- 예비학습2\n임의의 \\(0 \\leq \\alpha \\leq 1\\)에 대하여 \\(\\sin(2\\pi \\alpha) = -\\sin(2\\pi (1-\\alpha))\\) 가 성립함\n\nalpha = 0.2\nnp.sin(2*np.pi*alpha),np.sin(2*np.pi*(1-alpha))\n\n(0.9510565162951535, -0.9510565162951536)\n\n\n\n그래프를 잘 그려보세여\n\n- 왜 실수일경우만 대칭인지? (어디 정리된걸 아무리 찾아도 못찾겠어서 그냥 직접 수식을 썼는데요, 이걸 기억할 필요는 없어요.. 아마 제가 쓴것보다 쉽게 설명하는 방법이 있을겁니다)\n(해설) \\(k=0,1,2,\\dots,N-1\\)에 대하여 \\(X[k]\\)는 아래와 같이 표현가능하다.\n\\[X[k] = \\sum_{n=0}^{N-1}x[n]e^{-\\frac{j2\\pi kn}{N}}\\]\n오일러공식을 사용하면 아래와 같이 정리할 수 있다.\n\\[X[k] = \\sum_{n=0}^{N-1}x[n]\\cos\\left(-\\frac{2\\pi kn}{N}\\right) + i \\sum_{n=0}^{N-1}x[n]\\sin\\left(-\\frac{2\\pi kn}{N}\\right)\\]\ncos은 짝함수, sin은 홀함수임을 이용하여 다시정리하면\n\\[X[k] = \\sum_{n=0}^{N-1}x[n]\\cos\\left(\\frac{2\\pi kn}{N}\\right) - i \\sum_{n=0}^{N-1}x[n]\\sin\\left(\\frac{2\\pi kn}{N}\\right)\\]\ncase1 \\(k=1\\) 인 경우와 \\(k=N-1\\)인 경우는 서로 \\(|X[k]|^2\\)이 같음을 보이자.\n\\[X[1] = \\sum_{n=0}^{N-1}x[n]\\cos\\left(\\frac{2\\pi n}{N}\\right) - i \\sum_{n=0}^{N-1}x[n]\\sin\\left(\\frac{2\\pi n}{N}\\right)\\]\n\\[X[N-1] = \\sum_{n=0}^{N-1}x[n]\\cos\\left(\\frac{2\\pi (N-1)n}{N}\\right) - i \\sum_{n=0}^{N-1}x[n]\\sin\\left(\\frac{2\\pi(N-1) n}{N}\\right)\\]\n여기에서 예비학습1,2를 떠올리면 \\(\\cos\\left(\\frac{2\\pi n}{N}\\right)=\\cos\\left(\\frac{2\\pi (N-1)n}{N}\\right)\\) 이고 \\(\\sin\\left(\\frac{2\\pi n}{N}\\right)=-\\sin\\left(\\frac{2\\pi(N-1) n}{N}\\right)\\) 임을 알 수 있다. 따라서 \\(X[1]\\)와 \\(X[N-1]\\)은 켤레복소수이다. 즉\n\\[X[1] = X[N-1]^\\ast, \\quad X[1]^\\ast = X[N-1]\\]\n이다. 그런데 임의의 복소수 \\(x=a+bi\\)에 대하여 \\(|x|^2 = a^2+b^2 = (a+bi)(a-bi)= x x^\\ast\\) 가 성립하므로\n\\[|X[1]|^2 = |X[N-1]|^2\\]\n이 성립한다.\n\n만약에 \\(x[n]\\)이 실수가 아닌경우는 \\(\\cos\\left(\\frac{2\\pi n}{N}\\right)=\\cos\\left(\\frac{2\\pi (N-1)n}{N}\\right)\\) 이고 \\(\\sin\\left(\\frac{2\\pi n}{N}\\right)=-\\sin\\left(\\frac{2\\pi(N-1) n}{N}\\right)\\) 이라고 하여도 \\(X[1]\\)와 \\(X[N-1]\\)은 켤레복소수라고 주장할수 없다.\n\ncase2 \\(k=2\\) 인 경우와 \\(k=N-2\\)인 경우는 서로 \\(|X[k]|^2\\)이 같음도 비슷한 논리로 보일 수 있다."
  },
  {
    "objectID": "공부/2023-06-28-(공부&지윤) -- 퓨리에변환(detailed).html#허수파트-해석",
    "href": "공부/2023-06-28-(공부&지윤) -- 퓨리에변환(detailed).html#허수파트-해석",
    "title": "(공부&지윤) – 퓨리에변환(detailed)",
    "section": "허수파트 해석",
    "text": "허수파트 해석\n관찰1: 모든 \\(k\\)에 대하여 \\(X[k]\\)의 허수파트는 항상 0이다.\nk=0\n\nk=0\nsin_part_0 = np.array([np.sin(2*np.pi*k*n/N) for n in range(N)])\n\n\nx*sin_part_0\n\narray([ 0.,  0.,  0.,  0., -0., -0., -0., -0., -0., -0., -0., -0.,  0.,\n        0.,  0.])\n\n\n\nsum(x*sin_part_0)\n\n0.0\n\n\nk=1\n\nk=1\nsin_part_1 = np.array([np.sin(2*np.pi*k*n/N) for n in range(N)])\n\n\nx*sin_part_1\n\narray([ 0.        ,  0.37157241,  0.49726095,  0.29389263, -0.10395585,\n       -0.4330127 , -0.47552826, -0.20336832,  0.20336832,  0.47552826,\n        0.4330127 ,  0.10395585, -0.29389263, -0.49726095, -0.37157241])\n\n\n\nsum(x*sin_part_1)\n\n1.0547118733938987e-15\n\n\n약간을 직관을 위해서 그림을 그려보자.\n\nplt.plot(x,'--o')\nplt.plot(sin_part_1,'--o')\n\n\n\n\n\n\n\n\n\\(x\\)가 \\(\\mathbb{R}\\)에서 정의된 연속함수라고 상상하면 \\(\\sum_{n=0}^{N-1}\\cos\\left(\\frac{2\\pi n}{N} \\right)\\sin\\left(\\frac{2\\pi kn}{N}\\right)\\)에 대응하는 식은 \\(\\int_0^{2\\pi}\\cos(t)\\sin(t)dt\\)라고 볼 수 있어서 sum(x*sin_part_1)=0임을 더 쉽게 이해할 수 있다.\nk=2\n\nk=2\nsin_part_2 = np.array([np.sin(2*np.pi*k*n/N) for n in range(N)])\n\n\nplt.plot(x,'--o')\nplt.plot(sin_part_2,'--o')\n\n\n\n\n\n\n\n\n\\(x\\)가 \\(\\mathbb{R}\\)에서 정의된 연속함수라고 상상하면 파란선에 대응하는것은 \\(\\cos(t)\\) 주황선에 대응하는 것은 \\(\\sin(2t)\\)로 볼 수 있는데 둘은 직교하므로 둘을 곱한뒤 적분하면 (더하면) 0이 된다.\n\nsum(x*sin_part_2)\n\n-1.2212453270876722e-15\n\n\n\\(\\cos(t)\\)는 임의의 \\(\\sin(kt)\\)와 항상 직교하므로, 임의의 \\(k\\)에 대하여 허수파트는 항상 0이다.\n따라서 이 경우 \\(X[k]\\)는 아래와 같이 써도 무방하다.\n\\[X[k] = \\sum_{n=0}^{N-1}x[n]\\cos\\left(\\frac{2\\pi kn}{N}\\right)\\]"
  },
  {
    "objectID": "공부/2023-06-28-(공부&지윤) -- 퓨리에변환(detailed).html#실수파트-해석",
    "href": "공부/2023-06-28-(공부&지윤) -- 퓨리에변환(detailed).html#실수파트-해석",
    "title": "(공부&지윤) – 퓨리에변환(detailed)",
    "section": "실수파트 해석",
    "text": "실수파트 해석\n관찰2: \\(X[k]\\)의 실수파트는 \\(k=1\\)혹은 \\(k=N-1\\)일때 아래와 같이 정리된다.\n\\[\\sum_{n=0}^{N-1}\\cos\\left(\\frac{2\\pi n}{N} \\right)^2\\]\n그외의 경우에는 아래와 같이 된다.\nk=0\n\nk=0\ncos_part_0 = np.array([np.cos(2*np.pi*k*n/N) for n in range(N)])\n\n\nplt.plot(x,'--o')\nplt.plot(cos_part_0,'--o')\n\n\n\n\n\n\n\n\n\n파란선에 대응하는것은 \\(\\cos(t)\\) 주황선에 대응하는 것은 \\(1\\)로 볼 수 있는데 둘은 직교하므로 둘을 곱한뒤 적분하면 (더하면) 0이 된다.\n\nk=2\n\nk=2\ncos_part_2 = np.array([np.cos(2*np.pi*k*n/N) for n in range(N)])\n\n\nplt.plot(x,'--o')\nplt.plot(cos_part_2,'--o')\n\n\n\n\n\n\n\n\n\n파란선에 대응하는것은 \\(\\cos(t)\\) 주황선에 대응하는 것은 \\(\\cos(2t)\\)로 볼 수 있는데 둘은 직교하므로 둘을 곱한뒤 적분하면 (더하면) 0이 된다.\n\n임의의 \\(k\\)에 대하여 \\(\\cos(t)\\)와 \\(\\cos(kt)\\)는 항상 직교하므로 둘을 곱한뒤 적분하면 (더하면) 0이 된다.\n- 요약: 만약에 \\(x[n]\\)이 아래와 같은 꼴이라고 하자.\n\\[x[n] = \\cos\\left(\\frac{2\\pi n}{N} \\right)\\]\n이때 퓨리에변환 \\(X[k]\\)는 아래와 같이 정리된다.\n\\[X[k] = \\sum_{n=0}^{N-1}x[n]\\cos\\left(\\frac{2\\pi kn}{N}\\right) - i \\sum_{n=0}^{N-1}x[n]\\sin\\left(\\frac{2\\pi kn}{N}\\right)\\]\n\\(X[k]\\)의 허수파트는 항상 0이 되고, 실수 파트는 \\(k=1,N-1\\)일 경우에만 값을 가지고 나머지는 0의 값을 가진다.\n\nX = np.fft.fft(x)\nfig, ax = plt.subplots(1,3)\nax[0].plot(x,'o--'); ax[0].set_title('x[n]')\nax[1].plot(np.real(X),'x'); ax[1].set_title('real(X[k])')\nax[2].plot(np.imag(X),'x'); ax[2].set_title('imag(X[k])')\nfig.set_figwidth(15)\n\n\n\n\n\n\n\n\n- 응용: \\(x[n]\\)이 아래와 같은 꼴이라고 하자.\n\\[x[n] = \\cos\\left(\\frac{6\\pi n}{N} \\right)\\]\n퓨리에변환 \\(X[k]\\)는 아래와 같이 정리된다.\n\\[X[k] = \\sum_{n=0}^{N-1}x[n]\\cos\\left(\\frac{2\\pi kn}{N}\\right) - i \\sum_{n=0}^{N-1}x[n]\\sin\\left(\\frac{2\\pi kn}{N}\\right)\\]\n\\(X[k]\\)의 허수파트는 항상 0이 되고, 실수 파트는 \\(k=3,N-3\\)일 경우에만 값을 가지고 나머지는 0의 값을 가진다.\n\nN = 15 \nx = np.array([np.cos(6*np.pi*n/N) for n in range(N)]) \nX = np.fft.fft(x)\nfig, ax = plt.subplots(1,3)\nax[0].plot(x,'o--'); ax[0].set_title('x[n]')\nax[1].plot(np.real(X),'x'); ax[1].set_title('real(X[k])')\nax[2].plot(np.imag(X),'x'); ax[2].set_title('imag(X[k])')\nfig.set_figwidth(15)"
  },
  {
    "objectID": "공부/2023-01-20-(공부) -- 추정.html",
    "href": "공부/2023-01-20-(공부) -- 추정.html",
    "title": "(공부) – 추정",
    "section": "",
    "text": "using Distributions, Plots"
  },
  {
    "objectID": "공부/2023-01-20-(공부) -- 추정.html#mle의-일치성에-대한-구체적인-논의",
    "href": "공부/2023-01-20-(공부) -- 추정.html#mle의-일치성에-대한-구체적인-논의",
    "title": "(공부) – 추정",
    "section": "MLE의 일치성에 대한 구체적인 논의",
    "text": "MLE의 일치성에 대한 구체적인 논의\n\\(X_1,\\dots,X_{10} \\overset{i.i.d.}{\\sim} Ber(\\theta)\\) 이라고 하자.\n\nx = rand(Bernoulli(0.3),10)\nx\n\n10-element Vector{Bool}:\n 0\n 0\n 1\n 1\n 1\n 1\n 0\n 0\n 0\n 0\n\n\n여기에서 \\(\\theta\\)는 추정해야할 미지의 모수이지만 우리는 시뮬레이션의 편의상 \\(\\theta\\)의 참값을 \\(\\theta_0=\\frac{1}{3}\\)로 알고 있다고 하자. MLE를 논의함에 있어 핵심적인 역할을 하는 것은 \\(Y_1=\\log f(X_1;\\theta)\\)이다. 아래는 \\(Y_1\\)에 대한 몇가지 코멘트이다.\n(1) \\(Y_1\\)은 \\(X_1\\)와 \\(\\theta\\)의 함수이다.\n\n우선 \\(X_1\\)의 함수이므로 \\(Y_1\\)역시 확률변수이다. 따라서 \\(Y_1\\)에 대하여 평균등을 취할 수 있으며 LLN을 쓸 수 있다.\n\\(Y_1\\)은 \\(\\theta\\)에 대한 함수이므로 \\(\\theta\\)에 대하여 미분할 수 있다.\n\n(베르누이 예제)\n우리의 베르누이 예제에서 \\(Y_1\\)은 아래와 같이 계산된다.\n\\[Y_1 = \\log f(X_1;\\theta)= X_1 \\log \\theta + (1-X_1)\\log(1-\\theta)\\]\n보는 것 처럼 \\(Y_1\\)은 \\(X_1\\)와 \\(\\theta\\)의 함수임\n(2) \\(\\mathbb{E}_{\\theta_0}(Y_1)\\)은 \\(\\theta\\) 만의 함수이다. 적당한 조건4이 만족된다면 \\(\\mathbb{E}_{\\theta_0}(Y_1)\\)은 \\(\\theta_0\\) 에서 최대화 된다.\n(베르누이 예제)\n\\(\\mathbb{E}_{\\theta_0}(Y_1) = \\mathbb{E}_{\\theta_0}(X_1)\\log\\theta + (1-\\mathbb{E}_{\\theta_0}(X_1))\\log(1-\\theta) = \\frac{1}{3} \\log\\theta + (1-\\frac{1}{3})\\log(1-\\theta)\\)\n\n일반적인 상황에서는 참모수를 모르지만 우리는 시뮬레이션을 \\(\\theta=1/3\\)에서 하였으므로 참모수 \\(\\theta_0=\\mathbb{E}_{\\theta_0}(X_1)=\\frac{1}{3}\\)을 알고 있다고 가정한다.\n\n\nplot(θ -&gt; (1/3)*log(θ) + (1-1/3)*log(1-θ)) \n\n\n\n\n\n\n\n\n보는것처럼 이 함수 \\(\\mathbb{E}_{\\theta_0}(Y_1)\\)은 \\(\\theta=\\theta_0=\\frac{1}{3}\\) 에서 최대값을 가진다.\n(3) \\(\\frac{\\partial}{\\partial \\theta}Y_1\\) 역시 \\(X_1\\)와 \\(\\theta\\)의 함수이다.\n\n따라서 \\(\\frac{\\partial}{\\partial \\theta}Y_1\\) 역시 확률변수이고 \\(\\frac{\\partial}{\\partial \\theta}Y_1\\)에 대하여 평균등을 취할 수 있으며 LLN을 쓸 수 있다.\n\n(베르누이 예제)\n\\(\\frac{\\partial}{\\partial\\theta}Y_1 = X_1\\frac{1}{\\theta} + (1-X_1)\\frac{-1}{1-\\theta}\\)\n(4) \\(\\mathbb{E}_{\\theta}[\\frac{\\partial}{\\partial \\theta}Y_1]=0\\) 이다.\n(베르누이 예제)\n\\(\\mathbb{E}_{\\theta}[\\frac{\\partial}{\\partial\\theta}Y_1] = \\theta\\frac{1}{\\theta} + (1-\\theta)\\frac{-1}{1-\\theta}=0\\)\n(5) \\(\\mathbb{V}_{\\theta}[\\frac{\\partial}{\\partial\\theta}Y_1]=\\mathbb{E}_{\\theta}[-\\frac{\\partial^2}{\\partial \\theta^2}Y_1]=I(\\theta)\\)\n(베르누이 예제)\n\\(\\mathbb{V}_{\\theta}\\big[\\frac{\\partial}{\\partial\\theta}Y_1\\big]=\\mathbb{E}_{\\theta}\\big[(\\frac{\\partial}{\\partial\\theta}Y_1)^2\\big]=\\mathbb{E}_{\\theta}\\big[-\\frac{\\partial^2}{\\partial\\theta^2}Y_1\\big]=\\frac{1}{\\theta(1-\\theta)}\\)\n\n두번째 등호는 \\(\\mathbb{E}_{\\theta}[\\frac{\\partial}{\\partial\\theta}Y_1]=0\\)을 이용하여 증명가능하다.\n언뜻 보면 \\(\\mathbb{V}_{\\theta}\\big[\\frac{\\partial}{\\partial\\theta}Y_1\\big]\\)를 계산하는 것이 \\(\\mathbb{E}_{\\theta}\\big[-\\frac{\\partial^2}{\\partial\\theta^2}Y_1\\big]\\)를 계산하는것보다 훨씬 쉬워보인다. 그런데 \\(X_1\\)와 \\(1-X_1\\)이 독립이 아니라서 \\(\\mathbb{V}(X+Y)=\\mathbb{V}(X)+\\mathbb{V}(V)+2\\text{Cov}(X,Y)\\)와 같이 공분산 term을 계산해야 하므로 계산이 까다롭다.\n\n\n베르누이에 대한 피셔정보량은 https://en.wikipedia.org/wiki/Fisher_information 에서 확인할 수 있음"
  },
  {
    "objectID": "공부/2023-01-20-(공부) -- 추정.html#footnotes",
    "href": "공부/2023-01-20-(공부) -- 추정.html#footnotes",
    "title": "(공부) – 추정",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n거의 암산가능↩︎\n균등확률수렴성은 로그가능도함수가 strictly convex일 경우 성립한다는 것이 알려져 있음↩︎\nhttps://en.wikipedia.org/wiki/Identifiability↩︎\nidentifiable & common support↩︎"
  },
  {
    "objectID": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html",
    "href": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html",
    "title": "(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "",
    "text": "ref: https://www.jstatsoft.org/article/view/v012i08"
  },
  {
    "objectID": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#ebayesthresh로-무엇을-할-수-있는가",
    "href": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#ebayesthresh로-무엇을-할-수-있는가",
    "title": "(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "Ebayesthresh로 무엇을 할 수 있는가?",
    "text": "Ebayesthresh로 무엇을 할 수 있는가?\n아래와 같은 상황을 가정하자.\n\\[X_i = \\mu_i +\\epsilon_i.\\]\n여기에서 아래를 가정한다.\n\n\\(\\epsilon_i \\overset{iid}{\\sim} N(0,1)\\)\neach \\(\\mu_i\\) is zero with probability \\((1−w)\\), while, with probability \\(w\\), \\(\\mu_i\\) is drawn from a symmetric heavy-tailed density \\(\\gamma\\).\n\n일반적으로 \\(w\\), 즉 \\(\\mu_i\\)가 0이 아닐 확률은 매우 작은값으로 설정된다. 따라서 위와 같은 구조로 \\(\\epsilon_i\\)와 \\(\\mu_i\\)를 생성하면 아래와 같이 된다.\n\n\\(\\epsilon_i\\): 절대값이 작은 신호들이 dense하게 있음.\n\\(\\mu_i\\): 절대값이 큰 신호들이 sparse하게 있음. (sparse한 이유는 \\(w\\)가 작으므로)\n\n따라서 \\(X_i\\)의 모양은 아래의 그림의 왼쪽과 같다.\n\n이 논문의 목표는 왼쪽의 그림 \\(X_i= \\mu_i +\\epsilon_i\\)로부터 오른쪽의 그림 \\(\\hat{\\mu}_i\\)을 구하는 것이다. 즉 작은 절대값의 노이즈 \\(\\epsilon_i\\)에서 큰 절대값의 신호 \\(\\mu_i\\)를 골라내는 일을 목표로 한다. 저자들은 이러한 작업을 “건초더미에서 바늘찾기”라는 말로 비유하였다. 이러한 “건초더미에서 바늘찾기”는 여러 분야에 응용될 수 있다. 구체적으로는 천문학, 이미지프로세싱, 데이터마이닝, 모형선택등에 사용될 수 있다고 한다. 언급한 분야에 대한 자세한 discussion은 Johnstone and Silverman (2004)에서 찾을 수 있다. 또한 “건초더미에서 바늘찾기”는 위에서 언급한 분야 이외에 퓨리에, 웨이블릿 혹은 다른 dictionaries에 의한 함수추정문제를 해결할 수 있다. 이는 퓨리에나 웨이블릿변환과 같은 multiscale trasnform이 원래 신호를 sparese한 구조로 바꾸기 때문이다. 즉 퓨리에변환 웨이블릿변환으로 underlying function을 추정할 수 있다는 의미이다. 우리는 이러한 접근법에 좀 더 초점을 맞추도록 하겠다."
  },
  {
    "objectID": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#간단한-사용법",
    "href": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#간단한-사용법",
    "title": "(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "간단한 사용법",
    "text": "간단한 사용법\nR을 이용하여 Ebayesthresh를 사용하는 간단한 방법을 살펴보도록 하자. 논문에 표현된 그림1을 재현하여 보자.\n\nlibrary(EbayesThresh)\n\n\nset.seed(1)\nx &lt;- rnorm(1000) + sample(c( runif(25,-7,7), rep(0,975)))\nplot(x,type='l',lwd=0.2)\n\n\n\n\n\n\n\n\n위와 같은 자료 \\(X_i\\)를 관측하였다고 가정하자. 이 신호에는 “건초(\\(\\epsilon_i\\))”더미에 25개의 “바늘(\\(\\mu_i\\))”이 섞여있다. 여기에서 “바늘”만 골라내는 코드는 아래와 같이 작성할 수 있다.\n\nmuhat &lt;- ebayesthresh(x, sdev=1)\n\n결과를 시각화하면 아래와 같다.\n\nplot(x,type='l',lwd=0.2)\nlines(muhat,col=2,lwd=2)"
  },
  {
    "objectID": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#arguments",
    "href": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#arguments",
    "title": "(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "arguments",
    "text": "arguments\n일반적으로 ebayesthresh 함수를 사용하는 방법은 아래와 같다.\n\nmuhat &lt;- ebayesthresh(\n    x,\n    prior = \"laplace\", \n    a = 0.5, \n    bayesfac = FALSE, \n    sdev = NA, \n    verbose = FALSE, \n    threshrule = \"median\"\n)\n\nprior, a: \\(\\mu_i\\)의 density. 보통 \\(\\frac{1}{2}a \\exp(-a|u|)\\)라고 가정한다. parameter \\(a\\)는 Section 2.1에서 자시해 나옴.\nbayesfac, threshrule: Section 2.2, 2.3에 자세히 나온다.\nsdev: \\(\\epsilon_i\\)의 sd를 의미한다. 이 값을 알고 있다면 설정하면 되지만 보통은 이 값을 모른다고 가정한다. \\(\\epsilon_i\\)의 sd를 모르는 경우는 observed data로 부터 추정하는데 보통 \\({\\tt median}(|X_i|)\\)로 추정한다.\n\\(\\epsilon_i\\)의 sd를 \\({\\tt median}(|X_i|)\\)로 추정하는 motivation을 이해하는 것이 중요하다. 이는 sparse assumption of \\(\\mu_i\\)에서 시작한다. 신호 \\(\\mu_i\\)가 합리적인 수준에서 sparse하다면 median absolute value of \\(X_i\\)는 \\(\\mu_i\\)의 값들과 상관이 없을 것이다. 하지만 당연히 신호가 sparse하지 않다면 이러한 방식으로 sdev를 추정하는 것은 매우 조심스럽게 수행되어야 할 것이다.\n\nn &lt;- 1000\nx &lt;- rnorm(n) + sample(c(runif(25,-7,7), rep(0,n-25)))\nprint(sd(x))\nprint(median(abs(x)))\n\n[1] 1.117016\n[1] 0.6787613\n\n\n\n실제로는 잘 추론하지 못하는 것 같다?"
  },
  {
    "objectID": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#원리",
    "href": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#원리",
    "title": "(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "원리",
    "text": "원리\n어떻게 \\(\\hat{\\mu}_i\\)를 추정할 수 있을까? 가장 간단한 방법은 thresholding이다.\n많은 실제예제에서 \\(\\mu_i\\)는 어떤 의미에서 (in some sense) sparse하다고 여길 수 있다. EbayesThresh 패키지는 이처럼 \\(\\mu_i\\)가 sparse하다는 구조 (혹은 가정)을 이용하여 \\(\\mu_i\\)를 적절하게 추정한다.\nSparsity를 이용하는 자연스러운 방법은 threshoding이다: 여기에서 threshold의 값 \\(t\\)를 너무 크게 잡으면 신호를 잡음으로 잘못 판단할 것이고 \\(t\\)의 값이 너무 작다면 잡음을 신호로 잘못 판단할 수 있다. 따라서 \\(t\\)의 선택은 이 양쪽 기준사이의 tradeoff가 있는데 EbayesThresh는 이러한 tradeoff를 자동으로 조정하는 효과가 있다.\n\n\\(\\mu_i\\)는 \\(w\\)의 확률로 0 이며 \\((1-w)\\)의 확률로 0이 아니다. \\(\\mu_i\\)가 0이 아닐경우에는 symmetric heavy-tailed density \\(\\gamma\\)에서 추출된다고 가정한다. 여기에서 prior에 대한 key parameter인 \\(w\\)는 데이터로부터 자동으로 추정된다. (marginal maximum likelihood 를 이용한다) 그리고 추정된 \\(w\\)는 Bayesian model로 다시 대입된다.\n\\(w\\)가 추정되면 Bayesian model은 thresholding procedure를 수행할 수 있다. 왜냐하면 \\(w\\)를 추정하면 \\(t(w)\\)를 선택한다는 말과 같은말이기 때문이다.\n\nargument"
  },
  {
    "objectID": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#the-bayesian-model",
    "href": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#the-bayesian-model",
    "title": "(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "The Bayesian model",
    "text": "The Bayesian model\n\\[X_i \\sim N(\\mu_i,1)\\]\n\\(f_{\\text{prior}}(\\mu)=(1-w)\\delta_0(\\mu)+w \\gamma_a(\\mu), \\quad \\gamma_a(\\mu)=\\frac{1}{2}a\\exp(-a|\\mu|)\\)\n여기에서 \\(\\gamma_a(\\mu)\\)는 하나의 예시일 뿐이다. Ebayesthresh에 디폴트로 설정된 prior=\"laplace\"를 셋팅하면 \\(\\gamma_a(\\mu)\\)가 사용된다. \\(\\gamma\\)의 선택은 tail이 polynomial rates로 줄어드는 어떠한 분포를 사용해도 무방하다. 저자들은 quasi-Cauchy분포를 제안하였는데 이는 Johnstone and Sliverman이 만든 theoretical assumption을 만족하는 분포중 가장 꼬리가 두꺼운 분포이다."
  },
  {
    "objectID": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#thresholding-rules",
    "href": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#thresholding-rules",
    "title": "(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "Thresholding rules",
    "text": "Thresholding rules\n모수 \\(\\mu\\)는 사전분포(prior distribution)를 가진다고 가정하고 \\(X \\sim N(\\mu,1)\\)이라고 가정하자. 이 경우 \\(X=x\\)가 given되었을 경우 \\(\\mu\\)의 사후분포(posterior distribution)를 구할 수 있다. (자세한 내용은 Section 6을 참고해야함) 사후분포의 중앙값을 \\(\\hat{\\mu}(x;w)\\)라고 하자. (사후분포의 중앙값이 \\(w\\)에 영향받는 이유는 사전분포가 \\(w\\)에 depend하기 때문이다. 여기에서 \\(w\\)는 marginal MLE로 적절히 추론한다고 가정한다)\n\\(X_i\\)는 독립이라고 가정한다. 여기에서 \\(X_i\\)가 독립이 아니라면 약간의 정보손실이 있을 수 있다. 하지만 \\(X_i\\) 사이에 너무 많은 dependency가 존재하는 경우가 아니라면 Ebayesthresh는 어느정도 합리적인 결과를 제공한다.\n만약에 bayesfac=TRUE를 사용하면 \\(\\mu\\)의 사후분포의 중앙값 대신에 Bayes factor threshold 를 쓸 수도 있다."
  },
  {
    "objectID": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#choosing-the-threshold",
    "href": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#choosing-the-threshold",
    "title": "(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "Choosing the threshold",
    "text": "Choosing the threshold\n\\(X_i\\)의 marginal density는\n\\((1-w)\\phi(x) +w(\\gamma \\star \\phi)(x)\\)\n\\(l(w) = \\sum_{i=1}^{n}\\log \\big\\{(1-w)\\phi(X_i)+wg(X_i) \\big\\}\\)\n와 같이 정의가능하다. 단, 여기에서 \\(g:= \\gamma\\star \\phi\\) 이다.\n이제 우리는 아래의 식을 풀면된다.\n\\[\\underset{w}{\\operatorname{argmax}} l(w)\\quad\\quad \\text{subject to}\\quad t(w) \\leq \\sqrt{2\\log n}\\]\n여기에서 \\(\\sqrt{2\\log n}\\)은 흔히 말하는 universal threshold 이다.\n만약에 \\(w\\)이외에 \\(a\\)도 추정해야 한다면 아래와 같이 추정할 수 있다.\n\\[\\underset{w}{\\operatorname{argmax}} l(w)\\quad\\quad \\text{subject to}\\quad t(w) \\leq \\sqrt{2\\log n}\\]"
  },
  {
    "objectID": "메모/2000-01-07-줄리아 설치 및 실행.html",
    "href": "메모/2000-01-07-줄리아 설치 및 실행.html",
    "title": "(메모) – 줄리아 설치 및 실행",
    "section": "",
    "text": "설치\n- 여기에 접속한다. 스크롤링하여 ’Generic Linux Binaries for x86 / 64-bit(GPG)’를 찾는다. 그리고 ’64-bit’를 클릭해서 다운받는다. (참고로 왼쪽에 ’help’를 누르면 설치페이지 설명서가 나온다.) 그러면 아래와 같은 파일이 나온다.\njulia-1.3.1-linux-x86_64.tar.gz\n이 파일을 더블클릭해서 압축을 풀어준다. 압축을 풀면 julia-1.3.1라는 폴더가 생긴다. 이 폴더를 원하는 위치로 (줄리아가 설치되기를 원하는 위치) 이동시킨다. 나는 home에 이동시켰다.\n- 아래를 실행하면 줄리아가 실행된다. (둘중 아무거나)\n/home/cgb/julia-1.3.1/bin/julia\n~/julia-1.3.1/bin/julia\n\n\n주피터와 연결\n- 아래중 하나를 실행하여 줄리아를 킨다.\n/home/cgb/julia-1.3.1/bin/julia\n~/julia-1.3.1/bin/julia\n- 줄리아를 실행한뒤에 아래를 입력하면 주피터노트북에 연결된다.\nusing Pkg\nPkg.add(\"IJulia\")\n- 한 가지 의문점이 있다. 나같은 경우는 ’(base)’에서 줄리아를 실행하고 연결하였다. 그런데 혹시 몰라서 (py38r40)에서도 줄리아를 실행해봤는데 잘 실행되었다. 줄리아를 실행시키고 위의 명령 Pkg.add(\"IJulia\")를 다시쳤는데, 이미 연결되어서 더이상 변화시킨게 없다는 메시지가 떴다. 이러면 (base)에 설치된 줄리아가 (py38r40)에서도 실행된 줄리아와 동일하다는 의미일까? \\(\\Longrightarrow\\) 그렇다. 왜냐하면 줄리아는 anaconda내의 폴더에 설치한 것이 아니기 때문에. home에 보통 설치하니깐.\n\n\n환경변수 조정\n- 참고로 어디서든 줄리아를 실행시키고 싶다면 환경변수를 조작하면 된다. 아래를 실행해서 나노에디터를 킨다.\nsudo nano /etc/environment\n맨끝에 다음과 같이 되어있을 것이다.\n~~ usr/local/games\"\n마지막에 /home/cgb/julia-1.3.1/bin/julia를 추가한다. 즉 아래와 같이 만든다.\n~~ usr/local/games:/home/cgb/julia-1.3.1/bin/julia\"\n세이브하고 나온다. (그런데 이 과정을 안거쳐도 되는것 같음.) 이제 커맨드에서 아래를 실행한다.\nexport PATH=$PATH:/home/cgb/julia-1.3.1/bin\n이렇게하면 이제 단순히 julia라고만 쳐도 julia가 실행된다.\n\n\n플루토에서 강의영상 넣는 방법\n- 아래를 삽입\nhtml\"\"\"\n&lt;div style=\"display: flex; justify-content: center;\"&gt;\n&lt;div  notthestyle=\"position: relative; right: 0; top: 0; z-index: 300;\"&gt;\n&lt;iframe src=\n\"\nhttps://www.youtube.com/embed/\n\"\nwidth=600 height=375  frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen&gt;&lt;/iframe&gt;\n\"\"\"\n\n\n플루토를 이용한 홈페이지 만드는 방법\n- 단계1: https://github.com/JuliaPluto/static-export-template 에 가서 Clone\n- 단계2: Setting -&gt; GitHub Pages -&gt; Source -&gt; gh-pages / root\n\n\n플루토 키는 방법\nimport Pluto\nPluto.run(host=\"0.0.0.0\",port=1234,launch_browser=false,require_secret_for_open_links=false,require_secret_for_access=false,threads=\"8\")"
  },
  {
    "objectID": "메모/2000-01-04-우분투 익히기.html",
    "href": "메모/2000-01-04-우분투 익히기.html",
    "title": "(메모) – 우분투 익히기",
    "section": "",
    "text": "/root\n\n루트사용자의 홈 디렉토리\nsudo로도 들어갈 수 없음\n\n/etc\n\n리눅스 시스템 전반적인 환경설정 파일들을 모은 디렉터리임.\n이 디렉터리의 모든 파일은 텍스트형식임.\n/etc/password 사용자 계정정보\n\n/home\n\n사용자의 홈 디렉터리\n\n/mnt\n\n다른 파일 시스템이 파일 시스템에 연결되거나 마운트 되는 위치\n\n/media\n\nCD, USB 장치가 파일 시스템에 연결되거나 마운트되는 위치임\n\n/bin\n\n시스템 부팅과 실행에 필요한 바이너리(=윈도도의 실행파일=macOS의 애플리케이션)들을 포함\n\n/lib\n\n시스템 프로그램에서 사용하는 공유 라이브러리가 저장. 윈도우즈의 DLL과 비슷한 것.\n\n/usr\n\n사용자가 사용하는 모든 프로그램과 지원파일들 (Program files + 프로그램들의 설정값)\n/usr/bin 리눅스 배포판이 설치한 실행 프로그램들이 있다. (여기에 R이 깔린다!!)\n\nhp-align, hp-check, hp-config_usb-printer …\nX11\nvi\ngcc\nsu, sudo\nsar\nssh, ssh-agent, ssh-keygen, ….\nnvidia-smi\n\n/usr/lib 여기에는 /usr/bin에 있는 프로그램들을 위한 공유라이브러리가 저장된다. 여기에 R folder가 있다. (R패키지는 여기말고 다른데 깔림)\n/usr/local/bin 소스코드로 컴파일된 파일, 보통 비어있음\n/usr/local/lib/R/site-library R패키지가 설치되어있음, 예를들면 tidyverse"
  },
  {
    "objectID": "메모/2000-01-04-우분투 익히기.html#pwd-whoami",
    "href": "메모/2000-01-04-우분투 익히기.html#pwd-whoami",
    "title": "(메모) – 우분투 익히기",
    "section": "pwd, whoami",
    "text": "pwd, whoami\n- 현재위치확인\n(base) cgb2@cgb2-desktop:~$ pwd\n/home/cgb2\n- 유저확인\n### 예시1: 유저확인 \n(base) cgb2@cgb2-desktop:~$ whoami \ncgb2 \n\n### 예시2: 루트권한 획득이후 유저확인 \n(base) cgb2@cgb2-desktop:~$ sudo -i # 루트권한 획득\nroot@cgb2-desktop:~# whoami \nroot \n\n### 예시3: 일반유저로 전환후 유저확인\nroot@cgb2-desktop:~# su - cgb2 \n(base) cgb2@cgb2-desktop:~$ whoami\ncgb2"
  },
  {
    "objectID": "메모/2000-01-04-우분투 익히기.html#cd-ls",
    "href": "메모/2000-01-04-우분투 익히기.html#cd-ls",
    "title": "(메모) – 우분투 익히기",
    "section": "cd, ls",
    "text": "cd, ls\n- 홈디렉토리로 이동 + 목록\n(base) cgb2@cgb2-desktop:~/Dropbox$ cd ~\n(base) cgb2@cgb2-desktop:~$ ls\nDesktop                 julia-1.8.5\nDocuments               julia-1.8.5-linux-x86_64.tar.gz\nDownloads               lm.txt\nDropbox                 nbdev_tst\nMusic                   quarto-1.0.37-linux-amd64.deb\nPictures                rstudio-server-2021.09.2-382-amd64.deb\nPublic                  scikit_learn_data\nR                       snap\nTemplates               test.txt\nVideos                  v3net\nanaconda3               v3net-linux-3.6.10.11.805.tar.Z\nblacklist-nouveau.conf  vscode_cli.tar.gz\ncode\n- 루트로 이동 + 목록\n(base) cgb2@cgb2-desktop:~/Dropbox$ cd /\n(base) cgb2@cgb2-desktop:/$ ls\nbin    dev   lib    libx32      media  proc  sbin  swapfile  usr\nboot   etc   lib32  log         mnt    root  snap  sys       var\ncdrom  home  lib64  lost+found  opt    run   srv   tmp\n- ls 자세하게\n(base) cgb2@cgb2-desktop:/$ ls -l\ntotal 2097256\nlrwxrwxrwx   1 root  root           7  2월 11  2022 bin -&gt; usr/bin\ndrwxr-xr-x   3 root  root        4096  7월 27 12:19 boot\ndrwxrwxr-x   2 root  root        4096  2월 11  2022 cdrom\ndrwxr-xr-x  19 root  root        4480  7월 28 12:19 dev\ndrwxr-xr-x 143 root  root       12288  7월 27 21:08 etc\ndrwxr-xr-x   6 root  root        4096  7월  7 11:14 home\nlrwxrwxrwx   1 root  root           7  2월 11  2022 lib -&gt; usr/lib\nlrwxrwxrwx   1 root  root           9  2월 11  2022 lib32 -&gt; usr/lib32\nlrwxrwxrwx   1 root  root           9  2월 11  2022 lib64 -&gt; usr/lib64\nlrwxrwxrwx   1 root  root          10  2월 11  2022 libx32 -&gt; usr/libx32\ndrwxr-x---   2 root  root        4096  2월 11  2022 log\ndrwx------   2 root  root       16384  2월 11  2022 lost+found\ndrwxr-xr-x   2 root  root        4096  8월 19  2021 media\ndrwxr-xr-x   2 root  root        4096  8월 19  2021 mnt\ndrwxr-xr-x   4 jaein saned       4096  7월 16 11:21 opt\ndr-xr-xr-x 418 root  root           0  7월 28 12:16 proc\ndrwx------   6 root  root        4096  7월 27 12:21 root\ndrwxr-xr-x  40 root  root        1220  8월  3 13:31 run\nlrwxrwxrwx   1 root  root           8  2월 11  2022 sbin -&gt; usr/sbin\ndrwxr-xr-x  14 root  root        4096  7월 16 11:10 snap\ndrwxr-xr-x   2 root  root        4096  8월 19  2021 srv\n-rw-------   1 root  root  2147483648  2월 11  2022 swapfile\ndr-xr-xr-x  13 root  root           0  7월 28 12:16 sys\ndrwxrwxrwt  19 root  root       20480  8월  3 13:29 tmp\ndrwxr-xr-x  14 root  root        4096  8월 19  2021 usr\ndrwxr-xr-x  15 root  root        4096  7월 30  2022 var"
  },
  {
    "objectID": "메모/2000-01-04-우분투 익히기.html#h-man",
    "href": "메모/2000-01-04-우분투 익히기.html#h-man",
    "title": "(메모) – 우분투 익히기",
    "section": "-h, man",
    "text": "-h, man\n- 도움말확인\n(base) cgb2@cgb2-desktop:~$ git --help\nusage: git [--version] [--help] [-C &lt;path&gt;] [-c &lt;name&gt;=&lt;value&gt;]\n           [--exec-path[=&lt;path&gt;]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=&lt;path&gt;] [--work-tree=&lt;path&gt;] [--namespace=&lt;name&gt;]\n           &lt;command&gt; [&lt;args&gt;]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help &lt;command&gt;' or 'git help &lt;concept&gt;'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n- 메뉴얼 확인\n(base) cgb2@cgb2-desktop:~$ man git"
  },
  {
    "objectID": "메모/2000-01-04-우분투 익히기.html#cp-mv-mkdir-rm",
    "href": "메모/2000-01-04-우분투 익히기.html#cp-mv-mkdir-rm",
    "title": "(메모) – 우분투 익히기",
    "section": "cp, mv, mkdir, rm",
    "text": "cp, mv, mkdir, rm\n- 카피\ncp file1 file2 # file1을 복사하여 file2를 새로 만듬. file2가 이미 있다면 file1의 내용을 덮어씀 \ncp -r dir1 dir2 # dir1의 모든파일을 복사하여 dir2로 이동한뒤 붙어넣음. dir2가 없다면 새로 만듬. 기존의 dir2에 있던 파일이 삭제되는건 아님 \n- 이동\nmv file1 file2 # file1을 이동하여 file2로 이름바꿈. file2가 이미 있다면 file1의 내용을 덮어씀 \nmv -r dir1 dir2 # dir1의 모든파일을 잘라내어 dir2로 이동. \n- 디렉토리 생성\nmkdir temp\nmkdir temp1, temp2, temp3 # 여러개를 만듬\n- 삭제\nrm file1 # file1삭제 \nrm -r file1 dir1 # file1삭제 dir1폴더삭제 \nrm -rf file1 dir1 # 위와 동일한데 file1이나 dir1이 존재하지 않더라고 rm이 실행\n- -v(verbose)를 쓰면 친절한 느낌이 든다.\n(base) cgb2@cgb2-desktop:~/Dropbox$ cp *.txt temppp -v\n'colab.txt' -&gt; 'temppp/colab.txt'"
  },
  {
    "objectID": "메모/2000-01-04-우분투 익히기.html#scp",
    "href": "메모/2000-01-04-우분투 익히기.html#scp",
    "title": "(메모) – 우분투 익히기",
    "section": "scp",
    "text": "scp\n- cgb2에 있는 lm.txt를 cgb5로 옮김. 포트는 cgb5에 대응하는 포트\ncgb2@cgb2-desktop:~$ scp -P 4653 lm.txt cgb5@210.117.173.185:~\n- cgb2에 있는 lm.txt를 맥으로 가져옴. 포트는 cgb2에 대응하는 포트"
  },
  {
    "objectID": "메모/2000-01-04-우분투 익히기.html#find",
    "href": "메모/2000-01-04-우분투 익히기.html#find",
    "title": "(메모) – 우분투 익히기",
    "section": "find",
    "text": "find\n- Dropbox라는 이름이 포함된 폴더 찾기\nfind ~ -type d -name \"Dropbox\"\n\n여기에서 ~는 검색을 시작할 최상위 디렉토리를 쓴다.\n여기에서 -type d는 디렉토리라는 의미이다.\n\n- sy.tex이라는 파일찾기\nfind ~ -type f -name \"sy.tex\"\n\n여기에서 ~는 검색을 시작할 최상위 디렉토리를 쓴다.\n여기에서 -type d는 디렉토리라는 의미이다."
  },
  {
    "objectID": "메모/2000-01-04-우분투 익히기.html#wget",
    "href": "메모/2000-01-04-우분투 익히기.html#wget",
    "title": "(메모) – 우분투 익히기",
    "section": "wget",
    "text": "wget\n- 인터넷에서 파일 다운로드\nwget https://download2.rstudio.org/server/bionic/amd64/rstudio-server-1.2.5033-amd64.deb"
  },
  {
    "objectID": "메모/2000-01-04-우분투 익히기.html#gdebi-deb",
    "href": "메모/2000-01-04-우분투 익히기.html#gdebi-deb",
    "title": "(메모) – 우분투 익히기",
    "section": "gdebi, deb",
    "text": "gdebi, deb\n- deb파일을 gdebi로 설치하는 방법\nsudo gdebi rstudio-server-1.2.5033-amd64.deb\n- deb파일을 dpkg를 이용하여 설치하는 방법\ndpkg -i quarto-1.2.335-linux-amd64.deb # 설치\ndpkg -r quarto # 삭제 \n- gdebi, deb의 차이\n\ngdebi는 관련패키지를 모두 찾아서 설치 dpkg는 하나의 패키지만 설치. 즉 gdebi는 conda 느낌이고 dpkg는 pip 느낌\ngdebi는 별도의 삭제옵션을 지원하지 않음. 따라서 gdebi로 설치한 deb을 삭제하려면 머리아플수도?\n\n- gdebi로 설치한 패키지를 삭제하는 방법\n\n\n\n\n\n\nChat-GPT 답변\n\n\n\ngdebi로 패키지를 삭제하는 것은 아쉽게도 직접적으로 지원하지 않습니다. gdebi는 주로 패키지를 설치할 때 사용되는 도구이며, 패키지의 삭제에는 사용되지 않습니다. 패키지를 삭제하려면 다른 도구인 dpkg나 패키지 관리자 명령을 사용해야 합니다.\n패키지를 삭제하는 방법은 아래와 같습니다. 패키지를 삭제하기 전에 해당 패키지가 다른 의존하는 패키지에 영향을 주지 않는지 주의깊게 확인하시기 바랍니다.\ndpkg를 사용하여 패키지 삭제하기:\nsudo dpkg -r 패키지이름\n여기서 패키지이름은 삭제하려는 패키지의 이름입니다. 이 명령을 실행하면 해당 패키지가 삭제됩니다.\napt를 사용하여 패키지 삭제하기 (의존성 관리 포함):\nsudo apt remove 패키지이름\n위 명령은 apt를 통해 패키지를 삭제하며, 의존성을 포함하여 관련된 패키지들도 자동으로 처리합니다. 이 방법은 일반적으로 패키지 삭제에 더 효과적입니다.\n위의 방법 중 하나를 선택하여 패키지를 삭제할 수 있습니다. 패키지 삭제 시에는 주의하여 의존성 문제가 발생하지 않도록 해야 합니다."
  },
  {
    "objectID": "메모/2000-01-04-우분투 익히기.html#apt",
    "href": "메모/2000-01-04-우분투 익히기.html#apt",
    "title": "(메모) – 우분투 익히기",
    "section": "apt",
    "text": "apt\nsudo apt-get remove r-base-core\nsudo apt purge r-base* r-recommended r-cran-*\nsudo apt autoremove\nsudo apt list \nsudo apt update\nsudo apt install openssh-server \nsudo apt-get install gdebi-core\n- sudo apt-get과 sudo apt 차이? 별 차이 없는듯\n\nhttps://askubuntu.com/questions/445384/what-is-the-difference-between-apt-and-apt-get\n\n\nThey are very similar command line tools available in Trusty (14.04) and later. apt-get and apt-cache’s most commonly used commands are available in apt. apt-get may be considered as lower-level and “back-end”, and support other APT-based tools. apt is designed for end-users (human) and its output may be changed between versions."
  },
  {
    "objectID": "메모/2000-01-04-우분투 익히기.html#conda",
    "href": "메모/2000-01-04-우분투 익히기.html#conda",
    "title": "(메모) – 우분투 익히기",
    "section": "conda",
    "text": "conda\nconda \nconda env -h \nconda install -h \nconda remove -h  \nconda update -h \nconda env list\nconda create -n py38r40 python=3.8\nconda env remove -n py38r40 \nconda install -c conda-forge jupyterlab \nconda remove jupyterlab \nconda remove r-base -y \nconda remove -n py38r40 jupyterlab \nconda update scipy\nconda update -n py38r40 scipy\nconda list"
  },
  {
    "objectID": "메모/2000-01-04-우분투 익히기.html#pip",
    "href": "메모/2000-01-04-우분투 익히기.html#pip",
    "title": "(메모) – 우분투 익히기",
    "section": "pip",
    "text": "pip\npip\npip list\npip list &gt; list.txt\npip freeze # 좀 더 자세히 나온다 \npip freeze &gt; list.txt \npip show matplotlib # 설치된패키지 정보가 나옴. 좋음.\npip install rpy2\npip install -r list.txt \npip install dash==1.13.3\npip install jupyterlab \"ipywidgets&gt;=7.5\"\npip install -U numpy\npip install --upgrade pip\npip install --upgrade tensorflow\npip uninstall matplotlib"
  },
  {
    "objectID": "메모/2000-01-04-우분투 익히기.html#a1.-덜-중요한-명령어",
    "href": "메모/2000-01-04-우분투 익히기.html#a1.-덜-중요한-명령어",
    "title": "(메모) – 우분투 익히기",
    "section": "A1. 덜 중요한 명령어",
    "text": "A1. 덜 중요한 명령어\n\nfile\n- 뭐하는 파일인지 알고싶다면?\n(base) cgb2@cgb2-desktop:~/Dropbox/03_yechan3$ file 1_essays.qmd \n1_essays.qmd: ASCII text\n\n\ndate, cal\n- 날짜\n(base) cgb2@cgb2-desktop:~$ date\n2023. 08. 03. (목) 16:10:38 KST\n- 달력\n(base) cgb2@cgb2-desktop:~$ cal\n      8월 2023         \n일 월 화 수 목 금 토  \n       1  2  3  4  5  \n 6  7  8  9 10 11 12  \n13 14 15 16 17 18 19  \n20 21 22 23 24 25 26  \n27 28 29 30 31"
  },
  {
    "objectID": "메모/2000-01-02-우분투 포맷 및 개발용 서버 셋팅2.html",
    "href": "메모/2000-01-02-우분투 포맷 및 개발용 서버 셋팅2.html",
    "title": "(메모) – 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "",
    "text": "- 우분투에서 여러가지 개발환경을 설정하는 방법을 포스팅 (시대가 너무 바뀌어서 새로정리)"
  },
  {
    "objectID": "메모/2000-01-02-우분투 포맷 및 개발용 서버 셋팅2.html#rpython-사용가능한-개발환경",
    "href": "메모/2000-01-02-우분투 포맷 및 개발용 서버 셋팅2.html#rpython-사용가능한-개발환경",
    "title": "(메모) – 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "6-1. R+Python 사용가능한 개발환경",
    "text": "6-1. R+Python 사용가능한 개발환경\n- 아래를 실행\n(base) conda create -n rpy \n(base) conda activate rpy\n(rpy) conda install -c conda-forge r-essentials\n(rpy) conda install -c conda-forge plotly\n(rpy) conda install -c conda-forge rpy2\n- 여기에서 conda install -c conda-forge r-essentials로 인하여 R, Python, Jupyter 가 모두 최신버전으로 설치된다.\n- 또한 R에는 이미 tidyverse, IRkernel 등의 패키지가 기본으로 깔려있다.\n- R은 아래의 경로에 설치되어있다.\n\n- 실행파일은 bin 폴더에 있다.\n\n(base) 환경이지만 이곳의 실행파일에 직접 접근하여 실행할 수도 있다.\n\n- 설치한 패키지는 library 폴더에 있다. /// EPT도 보인다.."
  },
  {
    "objectID": "메모/2000-01-02-우분투 포맷 및 개발용 서버 셋팅2.html#torch",
    "href": "메모/2000-01-02-우분투 포맷 및 개발용 서버 셋팅2.html#torch",
    "title": "(메모) – 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "6-2. torch",
    "text": "6-2. torch\n- 아래를 실행\n(base) conda create -n torch\n(base) conda activate torch\n#---#\n(torch) conda install -c conda-forge notebook \n(torch) conda install -c conda-forge plotly \n#---torch--#\n(torch) conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n#---pyg---#\n#(torch) conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n(torch) conda install pyg -c pyg \n#---stgcn---#\n#(torch) conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n#(torch) conda install pyg -c pyg \n(torch) sudo apt install gcc\n(torch) sudo apt install build-essential\n(torch) pip install torch-geometric-temporal\n#---ctgan---#\n#(torch) conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n(torch) conda install -c pytorch -c conda-forge ctgan  \n#---gym---#\n#(torch) conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n(torch) pip install gymnasium \n#(torch) sudo apt install gcc\n#(torch) sudo apt install build-essential\n(torch) sudo apt-get install swig\n(torch) pip install gymnasium[box2d]\nrefs\n\nPyTorch: https://pytorch.org/get-started/locally/\nPyG: https://pytorch-geometric.readthedocs.io/en/latest/install/installation.html\nPyTorch Geometric Temporal1: https://pytorch-geometric-temporal.readthedocs.io/en/latest/notes/installation.html\nCTGAN: https://github.com/sdv-dev/CTGAN\nGymnasium: https://gymnasium.farama.org/index.html2"
  },
  {
    "objectID": "메모/2000-01-02-우분투 포맷 및 개발용 서버 셋팅2.html#a.-주피터-원격제어-설정",
    "href": "메모/2000-01-02-우분투 포맷 및 개발용 서버 셋팅2.html#a.-주피터-원격제어-설정",
    "title": "(메모) – 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "A. 주피터 원격제어 설정",
    "text": "A. 주피터 원격제어 설정\n- 설정파일 생성\n(rpy) jupyter notebook --generate-config\n- 패스워드 설정\n(rpy) jupyter notebook password\n## 패스워드 치고\n## 확인해야함\n- 설정파일을 열고\nnano /home/cgb2/.jupyter/jupyter_notebook_config.py\n아래의 내용을 수정한다.\nc.ServerApp.ip = '192.168.0.4'\nc.ServerApp.port = 1306\nc.ServerApp.open_browser=False \nc.ExtensionApp.open_browser=False\nc.ServerApp.allow_origin = '*'\nc.ServerApp.allow_remote_access = True"
  },
  {
    "objectID": "메모/2000-01-02-우분투 포맷 및 개발용 서버 셋팅2.html#b.-vscode",
    "href": "메모/2000-01-02-우분투 포맷 및 개발용 서버 셋팅2.html#b.-vscode",
    "title": "(메모) – 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "B. vscode",
    "text": "B. vscode\n- ref: https://code.visualstudio.com/docs/remote/tunnels\n- 아래를 실행하면 된다.\ncurl -Lk 'https://code.visualstudio.com/sha/download?build=stable&os=cli-alpine-x64' --output vscode_cli.tar.gz\ntar -xf vscode_cli.tar.gz\n- 이후로는 ./code tunnel을 실행할것!\n- 백엔드에서 하려면\nnohup ./code tunnel &gt; /dev/null 2&gt;&1 &\n- 패키지설치"
  },
  {
    "objectID": "메모/2000-01-02-우분투 포맷 및 개발용 서버 셋팅2.html#a1.-r-삭제하는-방법",
    "href": "메모/2000-01-02-우분투 포맷 및 개발용 서버 셋팅2.html#a1.-r-삭제하는-방법",
    "title": "(메모) – 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "A1. R 삭제하는 방법",
    "text": "A1. R 삭제하는 방법\n- R 삭제\nconda remove r-base -y \nsudo apt-get remove r-base-core \nsudo apt purge r-base* r-recommended r-cran-*\nsudo apt autoremove"
  },
  {
    "objectID": "메모/2000-01-02-우분투 포맷 및 개발용 서버 셋팅2.html#a2.-r-패키지-설치",
    "href": "메모/2000-01-02-우분투 포맷 및 개발용 서버 셋팅2.html#a2.-r-패키지-설치",
    "title": "(메모) – 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "A2. R 패키지 설치",
    "text": "A2. R 패키지 설치\n- 주피터등에서 직접설치\n- conda를 이용한 설치\nconda install -c r package-name\n\nhttps://docs.anaconda.com/free/anaconda/reference/packages/r-language-pkg-docs/"
  },
  {
    "objectID": "메모/2000-01-02-우분투 포맷 및 개발용 서버 셋팅2.html#a3.-우분투를-주컴퓨터로-사용할-경우-한글설정",
    "href": "메모/2000-01-02-우분투 포맷 및 개발용 서버 셋팅2.html#a3.-우분투를-주컴퓨터로-사용할-경우-한글설정",
    "title": "(메모) – 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "A3. 우분투를 주컴퓨터로 사용할 경우 한글설정",
    "text": "A3. 우분투를 주컴퓨터로 사용할 경우 한글설정\n- 아래와 같이 커맨드에 친다.\nibus-setup\n이걸 치면 IBus Preferences 라는 창이 나오는데 여기에서 (1) Input Method 탭 클릭 (2) Add 버튼 클릭 (3) Korean 선택 (4) Hangul 선택을 한다.\n- 위의 단계에서 Korean이 안보이면 Language Support로 가서 한국어팩을 설치하고 리부팅 하면 된다. (보통 실행하자마자 알아서 설치되더라.. 설치가 안되면 Install / Remove Languages... 이라는 탭을 클릭해서 설치하자) 리부팅을 꼭 해야한다는 것에 주의하자.\n- 이제 Region & Language로 가서 설정하면 된다."
  },
  {
    "objectID": "메모/2000-01-02-우분투 포맷 및 개발용 서버 셋팅2.html#a4.-sublime-text-and-tex",
    "href": "메모/2000-01-02-우분투 포맷 및 개발용 서버 셋팅2.html#a4.-sublime-text-and-tex",
    "title": "(메모) – 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "A4. sublime text and TeX",
    "text": "A4. sublime text and TeX\n- ‘Ubuntu Software’에 가서 ’sublime Text’를 치면 다운받을 수 있다. 다운받은뒤에 ’file’ -&gt; ’open folder’를 활용하여 깃허브의 로칼저장소를 열어두면 편리하다.\n- 아래를 실행하여 TeX을 깐다.\nsudo apt install texlive-full\n- 이제 sublime과 latex을 연결하여보자. 여기를 참고하자. (1) sublime을 키고 ‘컨트롤+쉬프트+p’를 눌러 ’Install Package Control’ 선택 (2) 다시 ‘컨트롤+쉬프트+p’ 를 눌러 ‘Package Control: Install Package’를 실행 (3) 그러면 바로 검색창이 나오는데 거기서 ’LaTeXTools’를 입력해서 실행 (4) 다시 ’컨트롤+쉬프트+p’를 누르고 ’LaTeXTools: Check system’ 선택. 모두 ’available’이 나오면 잘 설치된 것이다.\n- *.tex파일을 열고 ’컨트롤+b’를 누르자. 처음이면 어떤 메뉴들이 보일텐데 그냥 ’Latex’을 선택하자. 그러면 코딩결과가 pdf로 나온다.\n- (수식미리보기) ‘Perferences’ &gt; ‘Packages Setting’ &gt; ‘LaTeXTools’ &gt; ‘Settings-User’를 선택한다. ’93번째라인’에 ’preview_math_mode’를 “all”로 바꾼다. 그러면 수식들이 미리 출력된다. 그외에도 자유롭게 셋팅을 조정할 수 있다. 원래셋팅은 ’Perferences’ &gt; ‘Packages Setting’ &gt; ‘LaTeXTools’ &gt; ‘Settings-Defaults’ 에 있다."
  },
  {
    "objectID": "메모/2000-01-02-우분투 포맷 및 개발용 서버 셋팅2.html#a5.-터미널-예쁘게-만들기",
    "href": "메모/2000-01-02-우분투 포맷 및 개발용 서버 셋팅2.html#a5.-터미널-예쁘게-만들기",
    "title": "(메모) – 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "A5. 터미널 예쁘게 만들기",
    "text": "A5. 터미널 예쁘게 만들기\n- zsh 설치 + oh my zsh 설치\nsudo install zsh \nsh -c \"$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\"\n- 테마변경\n\n.zshrc 파일 열기\n\nnano ~/.zshrc \n\n아래의 내용 수정\n\n...\nZSH_THEME=\"agnoster\"\n...\n- 색상변경\n\n아래의 파일 열기\n\ncd ~/.oh-my-zsh/themes/\nnano agnoster.zsh-theme  \n\n내용수정\n\n...\nprompt_dir() {\n  prompt_segment 39d $CURRENT_FG '%~'\n}\n..."
  },
  {
    "objectID": "메모/2000-01-02-우분투 포맷 및 개발용 서버 셋팅2.html#footnotes",
    "href": "메모/2000-01-02-우분투 포맷 및 개발용 서버 셋팅2.html#footnotes",
    "title": "(메모) – 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n이 패키지는 꼭 PyG 이후에 설치할것↩︎\n설치방법은 따로 없음..↩︎"
  },
  {
    "objectID": "연구/지윤/2023-06-28-커널리그레션.html",
    "href": "연구/지윤/2023-06-28-커널리그레션.html",
    "title": "(공부 & 지윤) – 커널리그레션",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\n\nx = np.linspace(0,1,5)\nx\n\narray([0.  , 0.25, 0.5 , 0.75, 1.  ])\n\n\n\ny = x*2 + np.random.randn(5)*0.3\ny\n\narray([0.01044984, 0.93755458, 0.43942577, 1.0639859 , 2.1133726 ])\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,2*x,'--')\n\n\n\n\n\n\n\n\n\\[y_i= \\sum_{i=1}^{5}\\theta_i\\exp\\left(-\\frac{|x-x_i|^2}{2h^2}\\right)\\]\n\nh= 0.15\nx0 = lambda xstar: np.exp(-(xstar-x[0])**2 / 2 / (h**2))\nx1 = lambda xstar: np.exp(-(xstar-x[1])**2 / 2 / (h**2))\nx2 = lambda xstar: np.exp(-(xstar-x[2])**2 / 2 / (h**2))\nx3 = lambda xstar: np.exp(-(xstar-x[3])**2 / 2 / (h**2))\nx4 = lambda xstar: np.exp(-(xstar-x[4])**2 / 2 / (h**2))\n\n\nθ0 = 0\nθ1 = 0.2\nθ2 = 0.5\nθ3 = 1.0\nθ4 = 1.5\n\n\nxstar = 0.6 \n\n\nθ0*x0(0.6)+θ1*x1(0.6)+θ2*x2(0.6)+θ3*x3(0.6)+θ4*x4(0.6)\n\n1.062893318071169\n\n\n\n_yhat = lambda xstar : θ0*x0(xstar)+\\\nθ1*x1(xstar)+\\\nθ2*x2(xstar)+\\\nθ3*x3(xstar)+\\\nθ4*x4(xstar)\n\n\n(_yhat(0)-y[0])**2\n\n0.0017104251892816106\n\n\n\nloss = (_yhat(0)-y[0])**2 + (_yhat(0.25)-y[1])**2+ \\\n(_yhat(0.5)-y[2])**2+(_yhat(0.75)-y[3])**2+\\\n(_yhat(1)-y[4])**2\n\n\\(loss(\\theta_0,\\theta_1,\\theta_2,\\theta_3,\\theta_4)\\) 를 최소화하는 \\({\\boldsymbol \\theta}\\)를 구한다.\n\n_x = np.linspace(0,1,1000)\nplt.plot(x,y,'o')\nplt.plot(x,2*x,'--')\nplt.plot(_x,_yhat(_x))"
  },
  {
    "objectID": "연구/지윤/SOLAR/2023-08-14-EPT-GConvLSTM-setting-Copy1.out.html",
    "href": "연구/지윤/SOLAR/2023-08-14-EPT-GConvLSTM-setting-Copy1.out.html",
    "title": "(연구) 지윤 – 태양광자료분석, GConvLSTM +++++++ 이거!!! ++++++++++++",
    "section": "",
    "text": "변경사항: RGCN_Learner 수정 – 일부기능추가\n\n\n포인트: 배치학습을 적용하여 update가 빨리이루어지도록 코드수정\n\n\n\n\n# modules \nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nimport eptstgcn\nimport eptstgcn.planner\nimport torch_geometric_temporal\nfrom torch_geometric_temporal.signal.static_graph_temporal_signal import StaticGraphTemporalSignal\nimport mplcyberpunk\n\n# torch\nimport torch\nimport torch.nn.functional as F\n#import torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvLSTM\n# from torch_geometric_temporal.nn.recurrent import GCLSTM\n# from torch_geometric_temporal.nn.recurrent import LRGCN\n# from torch_geometric_temporal.nn.recurrent import TGCN\n# from torch_geometric_temporal.nn.recurrent import DCRNN\n\n# read data\ndef makedict(FX,W=None,node_ids=None):\n    T,N = np.array(FX).shape\n    if W==None:\n        W = pd.DataFrame(FX).corr().to_numpy().reshape(-1).tolist() # corr 로 weights\n    if node_ids==None:\n        node_ids = ['node'+str(n) for n in range(N)]\n    _dict={\n        'edges':[[i,j] for i in range(N) for j in range(N)], \n        'node_ids': node_ids,\n        'weights':W,\n        'FX':FX\n    }\n    return _dict\n\nclass Loader(object):\n    def __init__(self, data_dict):\n        self._dataset = data_dict\n    \n    def _get_edges(self):\n        self._edges = np.array(self._dataset[\"edges\"]).T\n\n    def _get_edge_weights(self):\n        # self._edge_weights = np.array(self._dataset[\"weights\"]).T\n        edge_weights = np.array(self._dataset[\"weights\"]).T\n        #scaled_edge_weights = minmaxscaler(edge_weights)\n        self._edge_weights = edge_weights\n\n    def _get_targets_and_features(self):\n        stacked_target = np.stack(self._dataset[\"FX\"])\n        self.features = np.stack([\n            stacked_target[i : i + self.lags, :].T\n            for i in range(stacked_target.shape[0] - self.lags)\n        ])\n        self.targets = np.stack([\n            stacked_target[i + self.lags, :].T\n            for i in range(stacked_target.shape[0] - self.lags)\n        ])\n\n\n    def get_dataset(self, lags: int = 4) -&gt; StaticGraphTemporalSignal:\n        self.lags = lags\n        self._get_edges()\n        self._get_edge_weights()\n        self._get_targets_and_features()\n        dataset = StaticGraphTemporalSignal(\n            self._edges, self._edge_weights, self.features, self.targets\n        )\n        dataset.node_ids = self._dataset['node_ids']\n        return dataset\n    \nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvLSTM(in_channels = node_features, out_channels = filters, K = 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight, h, c):\n        h_0, c_0 = self.recurrent(x, edge_index, edge_weight, h, c)\n        h = F.relu(h_0)\n        h = self.linear(h)\n        return h, h_0, c_0\n    \n    \n# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\ndevice = torch.device('cpu')\n\nclass RGCN_Learner:\n    def __init__(self):\n        self.method = 'RecurrentGCN'\n        self.figs = []\n        self.epochs = 0\n        self.losses = []\n        self._node_idx = 0\n    def load(self,y): \n        if (self.lags is None) or (self.train_ratio is None):\n            self.lags = 4\n            self.train_ratio = 0.8 \n        self.t,self.n = y.shape\n        dct = makedict(FX=y.tolist())\n        self.loader = Loader(dct)\n        self.dataset = self.loader.get_dataset(lags=self.lags)\n        self.X = torch.tensor(self.dataset.features).float()\n        self.y = torch.tensor(self.dataset.targets).float()\n        self.train_dataset, self.test_dataset = eptstgcn.utils.temporal_signal_split(self.dataset, train_ratio = self.train_ratio)\n        self.len_test = self.test_dataset.snapshot_count\n        self.len_tr = self.train_dataset.snapshot_count\n        #self.dataset_name = str(self.train_dataset) if dataset_name is None else dataset_name\n    def get_batches(self, batch_size=256):\n        num_batches =  self.len_tr // batch_size + (1 if self.len_tr % batch_size != 0 else 0)\n        self.batches = []\n        for i in range(num_batches):\n            start_idx = i * batch_size\n            end_idx = start_idx + batch_size\n            self.batches.append(self.train_dataset[start_idx:end_idx])\n    \n    def learn(self,epoch=1):\n        self.model.train()\n        for e in range(epoch):\n            losses_batch = []\n            for b,batch in enumerate(self.batches):\n                loss = 0\n                self.h, self.c = None, None\n                for t, snapshot in enumerate(batch):\n                    snapshot = snapshot.to(device)\n                    yt_hat, self.h, self.c = self.model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, self.h, self.c)\n                    loss = loss + torch.mean((yt_hat.reshape(-1)-snapshot.y.reshape(-1))**2)\n                    print(f'\\rbatch={b}\\t t={t+1}\\t loss={loss/(t+1)}\\t', end='', flush=True)\n                loss = loss / (t+1)\n                loss.backward()\n                self.optimizer.step()\n                self.optimizer.zero_grad()\n                losses_batch.append(loss.item())\n            self.epochs = self.epochs + 1\n            print(f'\\repoch={self.epochs}\\t loss={np.mean(losses_batch)}\\n', end='', flush=True)\n        self.losses.append(np.mean(losses_batch))\n        self._savefigs() \n    def _savefigs(self): \n        self.__call__()\n        self._node_idx\n        with plt.style.context('default'): \n            plt.ioff()\n            plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n            fig,ax = plt.subplots()\n            ax.plot(self.y[:,self._node_idx],label='real',lw=0.5)\n            ax.plot(self.yhat[:,self._node_idx],'--',label='predited',alpha=0.5)\n            ax.set_title(f'Epoch={self.epochs}, node_idx={self._node_idx}',size=15)\n            ax.legend()\n            #mplcyberpunk.add_glow_effects()  \n        self.figs.append(fig)\n        plt.close()\n    def __call__(self,dataset=None):\n        if dataset == None: \n            dataset = self.dataset\n        self.yhat = torch.stack([self.model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, self.h, self.c)[0] for snapshot in dataset]).detach().squeeze().float()\n        return {'X':self.X, 'y':self.y, 'yhat':self.yhat} \n\n# learn \n# def rgcn(FX,train_ratio,lags,filters,epoch):\n#     dct = makedict(FX=FX.tolist())\n#     loader = Loader(dct)\n#     dataset = loader.get_dataset(lags=lags)\n#     dataset_tr, dataset_test = eptstgcn.utils.temporal_signal_split(dataset, train_ratio = train_ratio)\n#     lrnr = RGCN_Learner(dataset_tr, dataset_name = 'org & arbitrary')\n#     lrnr.learn(filters=filters, epoch=epoch)\n#     yhat = np.array(lrnr(dataset)['yhat'])\n#     yhat = np.concatenate([np.array([list(yhat[0])]*lags),yhat],axis=0)\n#     return yhat\n\n\n\n\n\n# read dataframe \ndf = pd.read_csv('data_eng_230710.csv')\n# make y, y_upper, y_period, time, regions \ny = df.loc[:,'Bukchoncheon':'Gyeongju-si'].to_numpy()\nyU = df.loc[:,'Bukchoncheon_Upper':'Gyeongju-si_Upper'].to_numpy()\nyP = np.divide(y, yU+1e-10)\n\n\n\n\n- 예시1: y를 학습\n학습~\n\n# step1: create lrnr object\nlrnr = RGCN_Learner()\n# step2: load data \nlrnr.lags = 4 \nlrnr.train_ratio = 0.8\nlrnr.load(y) \n# step3: construct networks \nlrnr.nof_filters = 16\nlrnr.model = RecurrentGCN(node_features=lrnr.lags, filters=lrnr.nof_filters).to(device)\nlrnr.optimizer = torch.optim.Adam(lrnr.model.parameters(),lr=10/1000)\n# step4: learn \nlrnr.get_batches(batch_size=24)\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=1  loss=0.348616252371738191366577        \nepoch=2  loss=0.096857151493083602352905            \nepoch=3  loss=0.085899897092996645071335            \nepoch=4  loss=0.082436966038374011698761            \nepoch=5  loss=0.080951251696015514699783            \n\n\n\nlrnr.y.shape\n\ntorch.Size([2564, 44])\n\n\n\nlrnr.get_batches(batch_size=24)\n\n\nlrnr.batches[-1]\n\n&lt;torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal at 0x7fa2cfbc7cd0&gt;\n\n\n\nplt.plot(y[:100,0])\n\n에폭별 적합결과(\\(\\hat{y}\\)) 시각화\n\nlrnr.figs[0]\n\n\n\n\n\n\n\n\n\nlrnr.figs[1]\n\n\n\n\n\n\n\n\n\nlrnr.figs[-1]\n\n\n\n\n\n\n\n\n- 예시2: yU 학습\n\n# step1: create lrnr object\nlrnr = RGCN_Learner()\n# step2: load data \nlrnr.lags = 4 \nlrnr.train_ratio = 0.8\nlrnr.load(yU) \n# step3: construct networks \nlrnr.nof_filters = 16\nlrnr.model = RecurrentGCN(node_features=lrnr.lags, filters=lrnr.nof_filters).to(device)\nlrnr.optimizer = torch.optim.Adam(lrnr.model.parameters(),lr=10/1000)\n# step4: learn \nlrnr.get_batches(batch_size=24)\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=1  loss=1.98579962707536175294647     \nepoch=2  loss=0.202098417204133351100159        \nepoch=3  loss=0.052548440736393594218872        \nepoch=4  loss=0.0272646296531135271772957   \nepoch=5  loss=0.0191931016526596582006645   \n\n\n\nlrnr.figs[-1]\n\n\n\n\n\n\n\n\n5번정도 더 돌려보자\n\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=6  loss=0.0169690931215882312923717       \nepoch=7  loss=0.0141667058247379891905975       \nepoch=8  loss=0.0124263072353896015870743       \nepoch=9  loss=0.0103476242200189951082373       \nepoch=10     loss=0.009508996026937005688799        \n\n\n\nlrnr.figs[-1]\n\n\n\n\n\n\n\n\n- 예시3: yP 학습\n\n# step1: create lrnr object\nlrnr = RGCN_Learner()\n# step2: load data \nlrnr.lags = 4 \nlrnr.train_ratio = 0.8\nlrnr.load(yP) \n# step3: construct networks \nlrnr.nof_filters = 16\nlrnr.model = RecurrentGCN(node_features=lrnr.lags, filters=lrnr.nof_filters).to(device)\nlrnr.optimizer = torch.optim.Adam(lrnr.model.parameters(),lr=10/1000)\n# step4: learn \nlrnr.get_batches(batch_size=24)\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=1  loss=0.030719049366970748393135            \nepoch=2  loss=0.0119630681123411254793358       \nepoch=3  loss=0.0109235838672882638420868       \nepoch=4  loss=0.0107088599754714682600975       \nepoch=5  loss=0.0105961727974719788335514       \n\n\n\nlrnr.figs[-1]"
  },
  {
    "objectID": "연구/지윤/SOLAR/2023-08-14-EPT-GConvLSTM-setting-Copy1.out.html#import",
    "href": "연구/지윤/SOLAR/2023-08-14-EPT-GConvLSTM-setting-Copy1.out.html#import",
    "title": "(연구) 지윤 – 태양광자료분석, GConvLSTM +++++++ 이거!!! ++++++++++++",
    "section": "",
    "text": "# modules \nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nimport eptstgcn\nimport eptstgcn.planner\nimport torch_geometric_temporal\nfrom torch_geometric_temporal.signal.static_graph_temporal_signal import StaticGraphTemporalSignal\nimport mplcyberpunk\n\n# torch\nimport torch\nimport torch.nn.functional as F\n#import torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvLSTM\n# from torch_geometric_temporal.nn.recurrent import GCLSTM\n# from torch_geometric_temporal.nn.recurrent import LRGCN\n# from torch_geometric_temporal.nn.recurrent import TGCN\n# from torch_geometric_temporal.nn.recurrent import DCRNN\n\n# read data\ndef makedict(FX,W=None,node_ids=None):\n    T,N = np.array(FX).shape\n    if W==None:\n        W = pd.DataFrame(FX).corr().to_numpy().reshape(-1).tolist() # corr 로 weights\n    if node_ids==None:\n        node_ids = ['node'+str(n) for n in range(N)]\n    _dict={\n        'edges':[[i,j] for i in range(N) for j in range(N)], \n        'node_ids': node_ids,\n        'weights':W,\n        'FX':FX\n    }\n    return _dict\n\nclass Loader(object):\n    def __init__(self, data_dict):\n        self._dataset = data_dict\n    \n    def _get_edges(self):\n        self._edges = np.array(self._dataset[\"edges\"]).T\n\n    def _get_edge_weights(self):\n        # self._edge_weights = np.array(self._dataset[\"weights\"]).T\n        edge_weights = np.array(self._dataset[\"weights\"]).T\n        #scaled_edge_weights = minmaxscaler(edge_weights)\n        self._edge_weights = edge_weights\n\n    def _get_targets_and_features(self):\n        stacked_target = np.stack(self._dataset[\"FX\"])\n        self.features = np.stack([\n            stacked_target[i : i + self.lags, :].T\n            for i in range(stacked_target.shape[0] - self.lags)\n        ])\n        self.targets = np.stack([\n            stacked_target[i + self.lags, :].T\n            for i in range(stacked_target.shape[0] - self.lags)\n        ])\n\n\n    def get_dataset(self, lags: int = 4) -&gt; StaticGraphTemporalSignal:\n        self.lags = lags\n        self._get_edges()\n        self._get_edge_weights()\n        self._get_targets_and_features()\n        dataset = StaticGraphTemporalSignal(\n            self._edges, self._edge_weights, self.features, self.targets\n        )\n        dataset.node_ids = self._dataset['node_ids']\n        return dataset\n    \nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvLSTM(in_channels = node_features, out_channels = filters, K = 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight, h, c):\n        h_0, c_0 = self.recurrent(x, edge_index, edge_weight, h, c)\n        h = F.relu(h_0)\n        h = self.linear(h)\n        return h, h_0, c_0\n    \n    \n# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\ndevice = torch.device('cpu')\n\nclass RGCN_Learner:\n    def __init__(self):\n        self.method = 'RecurrentGCN'\n        self.figs = []\n        self.epochs = 0\n        self.losses = []\n        self._node_idx = 0\n    def load(self,y): \n        if (self.lags is None) or (self.train_ratio is None):\n            self.lags = 4\n            self.train_ratio = 0.8 \n        self.t,self.n = y.shape\n        dct = makedict(FX=y.tolist())\n        self.loader = Loader(dct)\n        self.dataset = self.loader.get_dataset(lags=self.lags)\n        self.X = torch.tensor(self.dataset.features).float()\n        self.y = torch.tensor(self.dataset.targets).float()\n        self.train_dataset, self.test_dataset = eptstgcn.utils.temporal_signal_split(self.dataset, train_ratio = self.train_ratio)\n        self.len_test = self.test_dataset.snapshot_count\n        self.len_tr = self.train_dataset.snapshot_count\n        #self.dataset_name = str(self.train_dataset) if dataset_name is None else dataset_name\n    def get_batches(self, batch_size=256):\n        num_batches =  self.len_tr // batch_size + (1 if self.len_tr % batch_size != 0 else 0)\n        self.batches = []\n        for i in range(num_batches):\n            start_idx = i * batch_size\n            end_idx = start_idx + batch_size\n            self.batches.append(self.train_dataset[start_idx:end_idx])\n    \n    def learn(self,epoch=1):\n        self.model.train()\n        for e in range(epoch):\n            losses_batch = []\n            for b,batch in enumerate(self.batches):\n                loss = 0\n                self.h, self.c = None, None\n                for t, snapshot in enumerate(batch):\n                    snapshot = snapshot.to(device)\n                    yt_hat, self.h, self.c = self.model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, self.h, self.c)\n                    loss = loss + torch.mean((yt_hat.reshape(-1)-snapshot.y.reshape(-1))**2)\n                    print(f'\\rbatch={b}\\t t={t+1}\\t loss={loss/(t+1)}\\t', end='', flush=True)\n                loss = loss / (t+1)\n                loss.backward()\n                self.optimizer.step()\n                self.optimizer.zero_grad()\n                losses_batch.append(loss.item())\n            self.epochs = self.epochs + 1\n            print(f'\\repoch={self.epochs}\\t loss={np.mean(losses_batch)}\\n', end='', flush=True)\n        self.losses.append(np.mean(losses_batch))\n        self._savefigs() \n    def _savefigs(self): \n        self.__call__()\n        self._node_idx\n        with plt.style.context('default'): \n            plt.ioff()\n            plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n            fig,ax = plt.subplots()\n            ax.plot(self.y[:,self._node_idx],label='real',lw=0.5)\n            ax.plot(self.yhat[:,self._node_idx],'--',label='predited',alpha=0.5)\n            ax.set_title(f'Epoch={self.epochs}, node_idx={self._node_idx}',size=15)\n            ax.legend()\n            #mplcyberpunk.add_glow_effects()  \n        self.figs.append(fig)\n        plt.close()\n    def __call__(self,dataset=None):\n        if dataset == None: \n            dataset = self.dataset\n        self.yhat = torch.stack([self.model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, self.h, self.c)[0] for snapshot in dataset]).detach().squeeze().float()\n        return {'X':self.X, 'y':self.y, 'yhat':self.yhat} \n\n# learn \n# def rgcn(FX,train_ratio,lags,filters,epoch):\n#     dct = makedict(FX=FX.tolist())\n#     loader = Loader(dct)\n#     dataset = loader.get_dataset(lags=lags)\n#     dataset_tr, dataset_test = eptstgcn.utils.temporal_signal_split(dataset, train_ratio = train_ratio)\n#     lrnr = RGCN_Learner(dataset_tr, dataset_name = 'org & arbitrary')\n#     lrnr.learn(filters=filters, epoch=epoch)\n#     yhat = np.array(lrnr(dataset)['yhat'])\n#     yhat = np.concatenate([np.array([list(yhat[0])]*lags),yhat],axis=0)\n#     return yhat"
  },
  {
    "objectID": "연구/지윤/SOLAR/2023-08-14-EPT-GConvLSTM-setting-Copy1.out.html#load-data",
    "href": "연구/지윤/SOLAR/2023-08-14-EPT-GConvLSTM-setting-Copy1.out.html#load-data",
    "title": "(연구) 지윤 – 태양광자료분석, GConvLSTM +++++++ 이거!!! ++++++++++++",
    "section": "",
    "text": "# read dataframe \ndf = pd.read_csv('data_eng_230710.csv')\n# make y, y_upper, y_period, time, regions \ny = df.loc[:,'Bukchoncheon':'Gyeongju-si'].to_numpy()\nyU = df.loc[:,'Bukchoncheon_Upper':'Gyeongju-si_Upper'].to_numpy()\nyP = np.divide(y, yU+1e-10)"
  },
  {
    "objectID": "연구/지윤/SOLAR/2023-08-14-EPT-GConvLSTM-setting-Copy1.out.html#sample_codes",
    "href": "연구/지윤/SOLAR/2023-08-14-EPT-GConvLSTM-setting-Copy1.out.html#sample_codes",
    "title": "(연구) 지윤 – 태양광자료분석, GConvLSTM +++++++ 이거!!! ++++++++++++",
    "section": "",
    "text": "- 예시1: y를 학습\n학습~\n\n# step1: create lrnr object\nlrnr = RGCN_Learner()\n# step2: load data \nlrnr.lags = 4 \nlrnr.train_ratio = 0.8\nlrnr.load(y) \n# step3: construct networks \nlrnr.nof_filters = 16\nlrnr.model = RecurrentGCN(node_features=lrnr.lags, filters=lrnr.nof_filters).to(device)\nlrnr.optimizer = torch.optim.Adam(lrnr.model.parameters(),lr=10/1000)\n# step4: learn \nlrnr.get_batches(batch_size=24)\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=1  loss=0.348616252371738191366577        \nepoch=2  loss=0.096857151493083602352905            \nepoch=3  loss=0.085899897092996645071335            \nepoch=4  loss=0.082436966038374011698761            \nepoch=5  loss=0.080951251696015514699783            \n\n\n\nlrnr.y.shape\n\ntorch.Size([2564, 44])\n\n\n\nlrnr.get_batches(batch_size=24)\n\n\nlrnr.batches[-1]\n\n&lt;torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal at 0x7fa2cfbc7cd0&gt;\n\n\n\nplt.plot(y[:100,0])\n\n에폭별 적합결과(\\(\\hat{y}\\)) 시각화\n\nlrnr.figs[0]\n\n\n\n\n\n\n\n\n\nlrnr.figs[1]\n\n\n\n\n\n\n\n\n\nlrnr.figs[-1]\n\n\n\n\n\n\n\n\n- 예시2: yU 학습\n\n# step1: create lrnr object\nlrnr = RGCN_Learner()\n# step2: load data \nlrnr.lags = 4 \nlrnr.train_ratio = 0.8\nlrnr.load(yU) \n# step3: construct networks \nlrnr.nof_filters = 16\nlrnr.model = RecurrentGCN(node_features=lrnr.lags, filters=lrnr.nof_filters).to(device)\nlrnr.optimizer = torch.optim.Adam(lrnr.model.parameters(),lr=10/1000)\n# step4: learn \nlrnr.get_batches(batch_size=24)\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=1  loss=1.98579962707536175294647     \nepoch=2  loss=0.202098417204133351100159        \nepoch=3  loss=0.052548440736393594218872        \nepoch=4  loss=0.0272646296531135271772957   \nepoch=5  loss=0.0191931016526596582006645   \n\n\n\nlrnr.figs[-1]\n\n\n\n\n\n\n\n\n5번정도 더 돌려보자\n\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=6  loss=0.0169690931215882312923717       \nepoch=7  loss=0.0141667058247379891905975       \nepoch=8  loss=0.0124263072353896015870743       \nepoch=9  loss=0.0103476242200189951082373       \nepoch=10     loss=0.009508996026937005688799        \n\n\n\nlrnr.figs[-1]\n\n\n\n\n\n\n\n\n- 예시3: yP 학습\n\n# step1: create lrnr object\nlrnr = RGCN_Learner()\n# step2: load data \nlrnr.lags = 4 \nlrnr.train_ratio = 0.8\nlrnr.load(yP) \n# step3: construct networks \nlrnr.nof_filters = 16\nlrnr.model = RecurrentGCN(node_features=lrnr.lags, filters=lrnr.nof_filters).to(device)\nlrnr.optimizer = torch.optim.Adam(lrnr.model.parameters(),lr=10/1000)\n# step4: learn \nlrnr.get_batches(batch_size=24)\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=1  loss=0.030719049366970748393135            \nepoch=2  loss=0.0119630681123411254793358       \nepoch=3  loss=0.0109235838672882638420868       \nepoch=4  loss=0.0107088599754714682600975       \nepoch=5  loss=0.0105961727974719788335514       \n\n\n\nlrnr.figs[-1]"
  },
  {
    "objectID": "메모/2000-01-02-(메모) -- 우분투 포맷 및 개발용 서버 셋팅2.html",
    "href": "메모/2000-01-02-(메모) -- 우분투 포맷 및 개발용 서버 셋팅2.html",
    "title": "(메모) – 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "",
    "text": "- 우분투에서 여러가지 개발환경을 설정하는 방법을 포스팅 (시대가 너무 바뀌어서 새로정리)"
  },
  {
    "objectID": "메모/2000-01-02-(메모) -- 우분투 포맷 및 개발용 서버 셋팅2.html#rpython-사용가능한-개발환경",
    "href": "메모/2000-01-02-(메모) -- 우분투 포맷 및 개발용 서버 셋팅2.html#rpython-사용가능한-개발환경",
    "title": "(메모) – 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "6-1. R+Python 사용가능한 개발환경",
    "text": "6-1. R+Python 사용가능한 개발환경\n- 아래를 실행\n(base) conda create -n rpy \n(base) conda activate rpy\n(rpy) conda install -c conda-forge r-essentials\n(rpy) conda install -c conda-forge plotly\n(rpy) conda install -c conda-forge rpy2\n- 여기에서 conda install -c conda-forge r-essentials로 인하여 R, Python, Jupyter 가 모두 최신버전으로 설치된다.\n- 또한 R에는 이미 tidyverse, IRkernel 등의 패키지가 기본으로 깔려있다.\n- R은 아래의 경로에 설치되어있다.\n\n- 실행파일은 bin 폴더에 있다.\n\n(base) 환경이지만 이곳의 실행파일에 직접 접근하여 실행할 수도 있다.\n\n- 설치한 패키지는 library 폴더에 있다. /// EPT도 보인다.."
  },
  {
    "objectID": "메모/2000-01-02-(메모) -- 우분투 포맷 및 개발용 서버 셋팅2.html#torch",
    "href": "메모/2000-01-02-(메모) -- 우분투 포맷 및 개발용 서버 셋팅2.html#torch",
    "title": "(메모) – 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "6-2. torch",
    "text": "6-2. torch\n- 아래를 실행\n(base) conda create -n torch\n(base) conda activate torch\n#---#\n(torch) conda install -c conda-forge notebook \n(torch) conda install -c conda-forge plotly \n#---torch--#\n(torch) conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n#---pyg---#\n#(torch) conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n(torch) conda install pyg -c pyg \n#---stgcn---#\n#(torch) conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n#(torch) conda install pyg -c pyg \n(torch) sudo apt install gcc\n(torch) sudo apt install build-essential\n(torch) pip install torch-geometric-temporal\n#---ctgan---#\n#(torch) conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n(torch) conda install -c pytorch -c conda-forge ctgan  \n#---gym---#\n#(torch) conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n(torch) pip install gymnasium \n#(torch) sudo apt install gcc\n#(torch) sudo apt install build-essential\n(torch) sudo apt-get install swig\n(torch) pip install gymnasium[box2d]\nrefs\n\nPyTorch: https://pytorch.org/get-started/locally/\nPyG: https://pytorch-geometric.readthedocs.io/en/latest/install/installation.html\nPyTorch Geometric Temporal1: https://pytorch-geometric-temporal.readthedocs.io/en/latest/notes/installation.html\nCTGAN: https://github.com/sdv-dev/CTGAN\nGymnasium: https://gymnasium.farama.org/index.html2"
  },
  {
    "objectID": "메모/2000-01-02-(메모) -- 우분투 포맷 및 개발용 서버 셋팅2.html#a.-주피터-원격제어-설정",
    "href": "메모/2000-01-02-(메모) -- 우분투 포맷 및 개발용 서버 셋팅2.html#a.-주피터-원격제어-설정",
    "title": "(메모) – 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "A. 주피터 원격제어 설정",
    "text": "A. 주피터 원격제어 설정\n- 설정파일 생성\n(rpy) jupyter notebook --generate-config\n- 패스워드 설정\n(rpy) jupyter notebook password\n## 패스워드 치고\n## 확인해야함\n- 설정파일을 열고\nnano /home/cgb2/.jupyter/jupyter_notebook_config.py\n아래의 내용을 수정한다.\nc.ServerApp.ip = '192.168.0.4'\nc.ServerApp.port = 1306\nc.ServerApp.open_browser=False \nc.ExtensionApp.open_browser=False\nc.ServerApp.allow_origin = '*'\nc.ServerApp.allow_remote_access = True"
  },
  {
    "objectID": "메모/2000-01-02-(메모) -- 우분투 포맷 및 개발용 서버 셋팅2.html#b.-vscode",
    "href": "메모/2000-01-02-(메모) -- 우분투 포맷 및 개발용 서버 셋팅2.html#b.-vscode",
    "title": "(메모) – 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "B. vscode",
    "text": "B. vscode\n- ref: https://code.visualstudio.com/docs/remote/tunnels\n- 아래를 실행하면 된다.\ncurl -Lk 'https://code.visualstudio.com/sha/download?build=stable&os=cli-alpine-x64' --output vscode_cli.tar.gz\ntar -xf vscode_cli.tar.gz\n- 이후로는 ./code tunnel을 실행할것!\n- 백엔드에서 하려면\nnohup ./code tunnel &gt; /dev/null 2&gt;&1 &\n- 패키지설치"
  },
  {
    "objectID": "메모/2000-01-02-(메모) -- 우분투 포맷 및 개발용 서버 셋팅2.html#a1.-r-삭제하는-방법",
    "href": "메모/2000-01-02-(메모) -- 우분투 포맷 및 개발용 서버 셋팅2.html#a1.-r-삭제하는-방법",
    "title": "(메모) – 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "A1. R 삭제하는 방법",
    "text": "A1. R 삭제하는 방법\n- R 삭제\nconda remove r-base -y \nsudo apt-get remove r-base-core \nsudo apt purge r-base* r-recommended r-cran-*\nsudo apt autoremove"
  },
  {
    "objectID": "메모/2000-01-02-(메모) -- 우분투 포맷 및 개발용 서버 셋팅2.html#a2.-r-패키지-설치",
    "href": "메모/2000-01-02-(메모) -- 우분투 포맷 및 개발용 서버 셋팅2.html#a2.-r-패키지-설치",
    "title": "(메모) – 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "A2. R 패키지 설치",
    "text": "A2. R 패키지 설치\n- 주피터등에서 직접설치\n- conda를 이용한 설치\nconda install -c r package-name\n\nhttps://docs.anaconda.com/free/anaconda/reference/packages/r-language-pkg-docs/"
  },
  {
    "objectID": "메모/2000-01-02-(메모) -- 우분투 포맷 및 개발용 서버 셋팅2.html#a3.-우분투를-주컴퓨터로-사용할-경우-한글설정",
    "href": "메모/2000-01-02-(메모) -- 우분투 포맷 및 개발용 서버 셋팅2.html#a3.-우분투를-주컴퓨터로-사용할-경우-한글설정",
    "title": "(메모) – 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "A3. 우분투를 주컴퓨터로 사용할 경우 한글설정",
    "text": "A3. 우분투를 주컴퓨터로 사용할 경우 한글설정\n- 아래와 같이 커맨드에 친다.\nibus-setup\n이걸 치면 IBus Preferences 라는 창이 나오는데 여기에서 (1) Input Method 탭 클릭 (2) Add 버튼 클릭 (3) Korean 선택 (4) Hangul 선택을 한다.\n- 위의 단계에서 Korean이 안보이면 Language Support로 가서 한국어팩을 설치하고 리부팅 하면 된다. (보통 실행하자마자 알아서 설치되더라.. 설치가 안되면 Install / Remove Languages... 이라는 탭을 클릭해서 설치하자) 리부팅을 꼭 해야한다는 것에 주의하자.\n- 이제 Region & Language로 가서 설정하면 된다."
  },
  {
    "objectID": "메모/2000-01-02-(메모) -- 우분투 포맷 및 개발용 서버 셋팅2.html#a4.-sublime-text-and-tex",
    "href": "메모/2000-01-02-(메모) -- 우분투 포맷 및 개발용 서버 셋팅2.html#a4.-sublime-text-and-tex",
    "title": "(메모) – 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "A4. sublime text and TeX",
    "text": "A4. sublime text and TeX\n- ‘Ubuntu Software’에 가서 ’sublime Text’를 치면 다운받을 수 있다. 다운받은뒤에 ’file’ -&gt; ’open folder’를 활용하여 깃허브의 로칼저장소를 열어두면 편리하다.\n- 아래를 실행하여 TeX을 깐다.\nsudo apt install texlive-full\n- 이제 sublime과 latex을 연결하여보자. 여기를 참고하자. (1) sublime을 키고 ‘컨트롤+쉬프트+p’를 눌러 ’Install Package Control’ 선택 (2) 다시 ‘컨트롤+쉬프트+p’ 를 눌러 ‘Package Control: Install Package’를 실행 (3) 그러면 바로 검색창이 나오는데 거기서 ’LaTeXTools’를 입력해서 실행 (4) 다시 ’컨트롤+쉬프트+p’를 누르고 ’LaTeXTools: Check system’ 선택. 모두 ’available’이 나오면 잘 설치된 것이다.\n- *.tex파일을 열고 ’컨트롤+b’를 누르자. 처음이면 어떤 메뉴들이 보일텐데 그냥 ’Latex’을 선택하자. 그러면 코딩결과가 pdf로 나온다.\n- (수식미리보기) ‘Perferences’ &gt; ‘Packages Setting’ &gt; ‘LaTeXTools’ &gt; ‘Settings-User’를 선택한다. ’93번째라인’에 ’preview_math_mode’를 “all”로 바꾼다. 그러면 수식들이 미리 출력된다. 그외에도 자유롭게 셋팅을 조정할 수 있다. 원래셋팅은 ’Perferences’ &gt; ‘Packages Setting’ &gt; ‘LaTeXTools’ &gt; ‘Settings-Defaults’ 에 있다."
  },
  {
    "objectID": "메모/2000-01-02-(메모) -- 우분투 포맷 및 개발용 서버 셋팅2.html#a5.-터미널-예쁘게-만들기",
    "href": "메모/2000-01-02-(메모) -- 우분투 포맷 및 개발용 서버 셋팅2.html#a5.-터미널-예쁘게-만들기",
    "title": "(메모) – 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "A5. 터미널 예쁘게 만들기",
    "text": "A5. 터미널 예쁘게 만들기\n- zsh 설치 + oh my zsh 설치\nsudo install zsh \nsh -c \"$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\"\n- 테마변경\n\n.zshrc 파일 열기\n\nnano ~/.zshrc \n\n아래의 내용 수정\n\n...\nZSH_THEME=\"agnoster\"\n...\n- 색상변경\n\n아래의 파일 열기\n\ncd ~/.oh-my-zsh/themes/\nnano agnoster.zsh-theme  \n\n내용수정\n\n...\nprompt_dir() {\n  prompt_segment 39d $CURRENT_FG '%~'\n}\n..."
  },
  {
    "objectID": "메모/2000-01-02-(메모) -- 우분투 포맷 및 개발용 서버 셋팅2.html#footnotes",
    "href": "메모/2000-01-02-(메모) -- 우분투 포맷 및 개발용 서버 셋팅2.html#footnotes",
    "title": "(메모) – 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n이 패키지는 꼭 PyG 이후에 설치할것↩︎\n설치방법은 따로 없음..↩︎"
  },
  {
    "objectID": "메모/2000-01-07-(메모) -- 줄리아 설치 및 실행.html",
    "href": "메모/2000-01-07-(메모) -- 줄리아 설치 및 실행.html",
    "title": "(메모) – 줄리아 설치 및 실행",
    "section": "",
    "text": "설치\n- 여기에 접속한다. 스크롤링하여 ’Generic Linux Binaries for x86 / 64-bit(GPG)’를 찾는다. 그리고 ’64-bit’를 클릭해서 다운받는다. (참고로 왼쪽에 ’help’를 누르면 설치페이지 설명서가 나온다.) 그러면 아래와 같은 파일이 나온다.\njulia-1.3.1-linux-x86_64.tar.gz\n이 파일을 더블클릭해서 압축을 풀어준다. 압축을 풀면 julia-1.3.1라는 폴더가 생긴다. 이 폴더를 원하는 위치로 (줄리아가 설치되기를 원하는 위치) 이동시킨다. 나는 home에 이동시켰다.\n- 아래를 실행하면 줄리아가 실행된다. (둘중 아무거나)\n/home/cgb/julia-1.3.1/bin/julia\n~/julia-1.3.1/bin/julia\n\n\n주피터와 연결\n- 아래중 하나를 실행하여 줄리아를 킨다.\n/home/cgb/julia-1.3.1/bin/julia\n~/julia-1.3.1/bin/julia\n- 줄리아를 실행한뒤에 아래를 입력하면 주피터노트북에 연결된다.\nusing Pkg\nPkg.add(\"IJulia\")\n- 한 가지 의문점이 있다. 나같은 경우는 ’(base)’에서 줄리아를 실행하고 연결하였다. 그런데 혹시 몰라서 (py38r40)에서도 줄리아를 실행해봤는데 잘 실행되었다. 줄리아를 실행시키고 위의 명령 Pkg.add(\"IJulia\")를 다시쳤는데, 이미 연결되어서 더이상 변화시킨게 없다는 메시지가 떴다. 이러면 (base)에 설치된 줄리아가 (py38r40)에서도 실행된 줄리아와 동일하다는 의미일까? \\(\\Longrightarrow\\) 그렇다. 왜냐하면 줄리아는 anaconda내의 폴더에 설치한 것이 아니기 때문에. home에 보통 설치하니깐.\n\n\n환경변수 조정\n- 참고로 어디서든 줄리아를 실행시키고 싶다면 환경변수를 조작하면 된다. 아래를 실행해서 나노에디터를 킨다.\nsudo nano /etc/environment\n맨끝에 다음과 같이 되어있을 것이다.\n~~ usr/local/games\"\n마지막에 /home/cgb/julia-1.3.1/bin/julia를 추가한다. 즉 아래와 같이 만든다.\n~~ usr/local/games:/home/cgb/julia-1.3.1/bin/julia\"\n세이브하고 나온다. (그런데 이 과정을 안거쳐도 되는것 같음.) 이제 커맨드에서 아래를 실행한다.\nexport PATH=$PATH:/home/cgb/julia-1.3.1/bin\n이렇게하면 이제 단순히 julia라고만 쳐도 julia가 실행된다.\n\n\n플루토에서 강의영상 넣는 방법\n- 아래를 삽입\nhtml\"\"\"\n&lt;div style=\"display: flex; justify-content: center;\"&gt;\n&lt;div  notthestyle=\"position: relative; right: 0; top: 0; z-index: 300;\"&gt;\n&lt;iframe src=\n\"\nhttps://www.youtube.com/embed/\n\"\nwidth=600 height=375  frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen&gt;&lt;/iframe&gt;\n\"\"\"\n\n\n플루토를 이용한 홈페이지 만드는 방법\n- 단계1: https://github.com/JuliaPluto/static-export-template 에 가서 Clone\n- 단계2: Setting -&gt; GitHub Pages -&gt; Source -&gt; gh-pages / root\n\n\n플루토 키는 방법\nimport Pluto\nPluto.run(host=\"0.0.0.0\",port=1234,launch_browser=false,require_secret_for_open_links=false,require_secret_for_access=false,threads=\"8\")"
  },
  {
    "objectID": "메모/2000-01-06-(메모) -- 깃 익히기.html",
    "href": "메모/2000-01-06-(메모) -- 깃 익히기.html",
    "title": "(메모) – 깃 익히기",
    "section": "",
    "text": "clone\ngithub repository \\(\\to\\) code \\(\\to\\) clone tab, ssh를 복사 (git@github.com:miruetoto/yechan.git처럼 생김)\n터미널에서 아래를 입력\ngit clone git@github.com:miruetoto/yechan.git 01_yechan\n\n\npull\n- 깃이 설치된 가장 상위폴더(Documents/Github/miruetoto.github.io)에 가서 아래를 입력한다.\ngit pull\n\n\nbranch\n- 서버에 이미 guebin이라는 브랜치가 있다면 아래와 같이 동기화 시킨다.\ngit chechout guebin\ngit push -u origin guebin\n여기에서 git push -u origin guebin을 안해도 동기화가 잘될때도 있는데 아닐때도 있다.\n\n\nremote\n- 깃이 설치된 가장 상위폴더(Documents/Github/miruetoto.github.io)에 가서 아래를 입력하면 깃허브의 url 주소를 확인할 수 있다.\n(base) lgcgb2@lgcgb2:~/Documents/GitHub/miruetoto.github.io$ git remote -v\norigin https://github.com/miruetoto/miruetoto.github.io.git (fetch)\norigin https://github.com/miruetoto/miruetoto.github.io.git (push)\nupstream https://github.com/daattali/beautiful-jekyll.git (fetch)\nupstream https://github.com/daattali/beautiful-jekyll.git (push)\n\n\nconfig\n- 설정보기\ngit config —list \n- 설정삭제\ngit config --unset user.name\ngit config --unser user.email\n- 전역설정삭제\ngit config --unset --global user.name\ngit config --unset --global user.email\n- 중복값 설정삭제\ngit config --unset-all user.name\ngit config --unset-all user.email\n- 중복값 전역으로 설정삭제\ngit config --unset-all --global user.name\ngit config --unset-all --global user.email\n- 비번안치고 푸쉬하는법?\ngit config credential.helper store\n입력이후에 git push\n\n\nGit token\nhttps://github.com/settings/tokens 에서 확인가능\n\nAppendix\n\n리눅스에서 github desktop 설치\n\n여기로 간다.\n한 챕터의 (2.3.1 Linux RC1 와 같이 되어있음) 아래쪽에 보면 ▶ Assets 라고 되어있는데 이걸 클릭하면 다운받을 수 있는 파일들이 나온다. 확장자가 .deb로 끝나는걸 골라서 다운받은뒤에 실행한다."
  },
  {
    "objectID": "메모/2000-01-01-(메모) -- 우분투 포맷 및 개발용 서버 셋팅(old).html",
    "href": "메모/2000-01-01-(메모) -- 우분투 포맷 및 개발용 서버 셋팅(old).html",
    "title": "(메모) – 우분투 포맷 및 개발용 서버 셋팅 (old)",
    "section": "",
    "text": "About this doc\n- 우분투에서 여러가지 개발환경을 설정하는 방법을 포스팅 하겠다.\n- 이 포스트는 우분투를 메인OS(사무용+연구용)로 사용하고 싶은 사람, 우분투를 활용하여 개발용 서버를 구축하고 싶은 사람에게 모두 유용한다.\n- 이 포스트는 2080 이상의 GPU를 활용한 학습을 원하는 사람에게 유용하다.\n- 이 포스트는 R과 파이썬을 동시에 쓰는 사람에게 유용하다.\n- 이 포스트는 Rstudio, Jupyter Lab을 동시에 쓰는 사람에게 유용하다.\n- 매년 조금씩 셋팅방법이 다른것 같다.\n- 가장 최근에는 2023년 3월8일에 이 블로그 내용으로 셋팅해보았음.\n\n\n우분투설치\n- 22.04부터는 파티션 나누지 않고 그냥 설치해도 잘 되는것 같다.\n\n\n네트워크 설정\n- ?표시있는 아이콘 \\(\\to\\) Wired Connected \\(\\to\\) Wired Settings \\(\\to\\) Connection의 설정 \\(\\to\\) IPv4 \\(\\to\\) Manual \\(\\to\\) Address, Netmask, Gateway, DNS 설정 \\(\\to\\) 네트워크 토글\n\n\n한글설정 (개발용 서버일 경우 생략 가능)\n- 아래와 같이 커맨드에 친다.\nibus-setup\n이걸 치면 IBus Preferences 라는 창이 나오는데 여기에서 (1) Input Method 탭 클릭 (2) Add 버튼 클릭 (3) Korean 선택 (4) Hangul 선택을 한다.\n- 위의 단계에서 Korean이 안보이면 Language Support로 가서 한국어팩을 설치하고 리부팅 하면 된다. (보통 실행하자마자 알아서 설치되더라.. 설치가 안되면 Install / Remove Languages... 이라는 탭을 클릭해서 설치하자) 리부팅을 꼭 해야한다는 것에 주의하자.\n- 이제 Region & Language로 가서 설정하면 된다.\n\n\n그래픽카드 드라이버설치\n- 전체적인 내용은 여기를 참고하자.\n- 준비작업\nsudo apt update \nsudo apt install gcc\nsudo apt install build-essential\n- 우선 gedit를 열고 아래를 복사해서 붙여넣는다.\nblacklist nouveau\noptions nouveau modeset=0\n파일이름을 blacklist-nouveau.conf로 home에 저장\n- 루트권한획득\nsudo -i\n아이디와 비밀번호를 입력하고 루트권한을 얻는다.\n- 아래를 입력한다.\nsudo cp /home/cgb2/blacklist-nouveau.conf /etc/modprobe.d\nsudo update-initramfs -u\nsudo reboot \n- 그래픽카드 다운로드: 드라이버 설치파일을 다운받는다. 앤비디아공식홈페이지에서 다운받자. OS를 리눅스 64-bit으로 선택하고 검색을 누르면 다운받아진다.\n- 그래픽키다 설치: 다운받은뒤에는 파일이 있는 폴더로 이동하여\nchmod +x NVIDIA-Linux-x86_64-410.78.run\n를 실행하자. 보통 NVI까지치고 적당히 탭을 누르면 알아서 뒷부분이 완성된다. 이 과정은 추후에 드라이버를 실행할수 있도록 권한을 풀어두는 것이다. 그리고 아래를 실행한다.\nsudo ./NVIDIA-Linux-x86_64-410.78.run\n그 다음 드라이버가 잘 설치되었는지 확인한다.\nnvidia-smi\n\n\n아나콘다\n- (아나콘다 설치) 아나콘다를 다운받은 폴더로 가서 아래와 같이 실행한다.\nbash Anaconda3-2019.03-Linux-x86_64.sh\n대충 bash Ana 정도까지만 치고 tab을 누르면 알아서 완성된다.\n- (환경만들기) 커맨드를 키고 아래를 실행한다.\n(base) conda create -n py38r40 python=3.8\n(base) conda create --name py38r40 python=3.8\n둘 중 아무거나 실행해도 된다. 파이썬 환경이 너무 높으면 나중에 conda tensorflow-gpu가 먹히지 않으니 환경을 만들때 파이썬버전을 3.8.x로 하자. (현시점 2021년 2월25일기준 3.9.x이면 conda tensorflow-gpu 가 동작하지 않음.)\n\n\nssh연결\n- 처음에 ssh를 연결하기위해서는 연결당하는 컴퓨터에 가서 아래를 실행해야 한다.\nsudo apt install openssh-server\n22번포트 우회하기\n- step1: /etc/ssh/sshd_config 파일을 연다.\nsudo vi /etc/ssh/sshd_config \n- step2: Port 22 라고 된 부분의 주석을 풀고 원하는 포트번호 설정\n...\n\n#Port 22\n#AddressFamily any\n#ListenAddress 0.0.0.0\n#ListenAddress ::\n\n...\n- step3: 수정내용을 적용\nsudo systemctl restart ssh.service\n- step4: 수정한 포트로 ssh접속\n\n\n주피터 원격제어\n- 1단계: 주피랩설치\n(py38) conda install -c conda-forge jupyterlab\n\nNote: 사실 위에서 주피터랩을 따로 설치안해도 주피터랩이 잘만 실행된다. 하지만 이렇게하니까 나중에 R커널을 만들기위해 IRkernel::installspec()을 실행할때 에러가 난다.\n\n- 2단계: 패스워드 설정\n(py38) jupyter lab --generate-config\n(py38) jupyter lab password\n- 3단계: jupyter lab 환경설정\nnano /home/cgb/.jupyter/jupyter_lab_config.py \n아래를 변경\nc.ServerApp.ip = '192.168.0.4'\nc.ServerApp.port = 1306\nc.ServerApp.open_browser = False\n여기에서 192.168.0.4 는 내부아이피다. 고정아피이가 있다면 고정아이피 주소를 쓰면 된다.\n\n\n주피터노트북 원격제어\n- 1단계: 주피터노트북 설치 (보통 lab을 설치하면 이미 설치되어있음)\n(py38) conda install -c conda-forge notebook \n- 2단계: 패스워드 설정\nfrom notebook.auth import passwd\npasswd()\nEnter password: \nVerify password: \n생성된값 (argon 어쩌고..)을 복사\n- 3단계: 환경설정\njupyter notebook --generate-config\nnano /home/cgb/.jupyter/jupyter_notebook_config.py\n아이피주소와 패스워드를 바꾼다. (port는 선택, browser도 선택 )\nc.NotebookApp.open_browser = False\nc.NotebookApp.ip = '192.168.0.4'\nc.NotebookApp.port = 1307\nc.NotebookApp.password = ''\n여기에서 192.168.0.4 는 내부아이피다. 고정아피이가 있다면 고정아이피 주소를 쓰면 된다.\n\nTip: 주피터노트북과 랩을 양쪽으로 셋팅후 주피터 노트북으로 실행하면 2개를 모두 쓸 수 있음\n\n\n\nR설치ver1: (base)에 설치\n- 설치전: 기존의 R 삭제\nconda remove r-base -y \nsudo apt-get remove r-base-core \nsudo apt purge r-base* r-recommended r-cran-*\nsudo apt autoremove\n- R설치전 준비작업: 나노에디터를 키고 /etc/apt/sources.list를 연다.\nsudo nano /etc/apt/sources.list\n화살표로 이동하여 맨아래로 간뒤에 아래중 하나를 추가한다. (나는 focal-cran40으로 추가함)\ndeb https://cloud.r-project.org/bin/linux/ubuntu impish-cran40/\ndeb https://cloud.r-project.org/bin/linux/ubuntu hirsute-cran40/\ndeb https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/\ndeb https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/\ndeb https://cloud.r-project.org/bin/linux/ubuntu xenial-cran40/\n저장후 나노에디터 종료. 그리고 아래를 실행.\nsudo apt-get update\n경우에 따라서 아래와 같은 에러메시지가 뜰 수 있다.\n...\nW: GPG error: https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9 \n...\n공개키가 없어서 생기는 에러이므로 아래와 같이 가져온다.\nwget -qO- https://cloud.r-project.org/bin/linux/ubuntu/marutter_pubkey.asc | sudo tee -a /etc/apt/trusted.gpg.d/cran_ubuntu_key.asc\nsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9\n#sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 51716619E084DAB9\n그리고 다시 아래를 실행\nsudo apt-get update\n에러가 없이 뭔가 마무리 되어야한다.\n(base) cgb3@cgb3:~$ sudo apt-get update\nIgn:1 http://linux.dropbox.com/ubuntu disco InRelease\nHit:2 http://security.ubuntu.com/ubuntu focal-security InRelease  \nHit:3 http://kr.archive.ubuntu.com/ubuntu focal InRelease                                 \nHit:4 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease                \nHit:5 http://linux.dropbox.com/ubuntu disco Release                 \nGet:6 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\nHit:8 http://kr.archive.ubuntu.com/ubuntu focal-updates InRelease\nGet:9 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ Packages [46.4 kB]\nHit:10 http://kr.archive.ubuntu.com/ubuntu focal-backports InRelease\nFetched 50.0 kB in 1s (36.5 kB/s)                   \nReading package lists... Done\n- R설치\nwget http://security.ubuntu.com/ubuntu/pool/main/i/icu/libicu66_66.1-2ubuntu2_amd64.deb\nsudo dpkg -i libicu66_66.1-2ubuntu2_amd64.deb\nsudo apt-get install r-base\n- tidyverse 설치 (R studio 설치전에 tidyverse 설치해야함)\n- Rstudio 설치: https://www.rstudio.com/products/rstudio/download-server/debian-ubuntu/\n\n우분투22로 설정할것!!\n\nsudo apt remove rstudio-server\nsudo apt-get install gdebi-core\nwget https://download2.rstudio.org/server/jammy/amd64/rstudio-server-2022.12.0-353-amd64.deb\nsudo gdebi rstudio-server-2022.12.0-353-amd64.deb\n- Rstudio를 설치하면 ~/R/x86_64-conda-linux-gnu-library/4.1이 새로 생성된다.\n\nRstudio에서 설치한 패키지는 이 폴더에 저장된다.\n\n- 주피터와 R커널 연결\nR # sudo R \ninstall.packages(\"IRkernel\")\nIRkernel::installspec()\n\n\nR설치ver2: (py38r40)에 설치\n- R설치\n(py38r40) conda install -c conda-forge r-essentials=4.0\n이러면 콘다환경에는 R이 깔리고 base에는 R이 깔리지 않는다.\n- 커널연결\n콘다환경에서 R을 실행한다. Rstudio가 아니라 커맨드에서 R을 실행해야한다. 그리고 아래를 실행하면 주피터랩과 R환경이 연결된다.\nIRkernel::installspec()\n이제 주피터랩에서 R kernel을 사용할 수 있다.\n\n\n가상환경에서 Rstudio server 설치 (어려움)\n- 이제 Rstudio server를 설치하는 방법을 다룬다.\n- 먼저 Rstudio를 설치한다. 참고로 Rstudio server 설치하는법은 여기를 참고하라. 요약하면 터미널에서 아래3줄을 입력하기만 하면된다.\n(py38r40) sudo apt-get install gdebi-core\n(py38r40) wget https://download2.rstudio.org/server/bionic/amd64/rstudio-server-1.2.5033-amd64.deb\n(py38r40) sudo gdebi rstudio-server-1.2.5033-amd64.deb\n\nWarning: Rstudio 1.3x 이상을 설치하지말고 1.2x를 설치해야 한다. 이상하게 1.3x이상은 후에 서술할 Gregor Strurm가 그의 깃허브에서 제안하는 방식이 잘 동작하지 않았다. 이는 알려진 문제였고 이를 해결하는 해결책을 서술한 스레드가 있어보이긴 했지만 나는 그냥 Rstudio 1.2x를 설치하고 쓰는 것을 선택했다.\n\n\nNote: 이미 rstudio server 가 다른버전으로 깔려있다면 sudo apt remove rstudio-server 를 통하여 삭제하고 설치하자.\n\n- 이제 Rstudio 설치가 끝났다. 설치된 Rstudio를 아나콘다 가상환경에 설치된 R과 연결해보자. 우선 아래를 실행한다.\n(py38r40) sudo apt install uuid\n(py38r40) sudo apt install git\n(py38r40) git clone https://github.com/grst/rstudio-server-conda.git\n위에 두줄은 Gregor Sturm이 만든 어떤 프로그램을 쓰기 위한 사전준비작업이다. 마지막줄을 실행하면 Gregor Sturm이 만든 프로그램이 다운받아진다. 이게 프로그램 설치가 완료된것이다. 이제 컴퓨터 껐다 킬때마다 아래를 실행한다.\n(py38r40) ./rstudio-server-conda/local/start_rstudio_server.sh 8787 # use any free port number here. \n이제 192.168.0.4:8787 따위의 주소로 접속하면 Rstudio를 쓸 수 있다. 참고로 system-wide Rstudio server를 죽여야 할 때가 있다. 그럴땐 아래 명령을 치면 된다.\n(py38r40) sudo systemctl disable rstudio-server.service\n(py38r40) sudo systemctl stop rstudio-server.service\n\n\n자주 설치하는 패키지 리스트\n- 아래를 미리 깔아두자..\n# conda install -c conda-forge notebook\nconda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch\nconda install -c conda-forge plotly \npip install plotnine\npip install seaborn\npip install opencv-python\npip install folium\npip install pandas_datareader\nconda install -c conda-forge r-essentials=4 \npip install rpy2\nconda install -c conda-forge python-graphviz\n- tensorflow-gpu 는 현재(2022-03-06) python=3.10 에서 동작함\nconda create -n py310 python=3.10 \nconda activate py310 \nconda install -c conda-forge tensorflow-gpu \n- 아래를 설치하면 좋음\nsudo apt install mc \n\n\n터미널 예쁘게 만들기\n- zsh 설치 + oh my zsh 설치\nsudo install zsh \nsh -c \"$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\"\n- 테마변경\n\n.zshrc 파일 열기\n\nnano ~/.zshrc \n\n아래의 내용 수정\n\n...\nZSH_THEME=\"agnoster\"\n...\n- 색상변경\n\n아래의 파일 열기\n\ncd ~/.oh-my-zsh/themes/\nnano agnoster.zsh-theme  \n\n내용수정\n\n...\nprompt_dir() {\n  prompt_segment 39d $CURRENT_FG '%~'\n}\n...\n\n\nsublime text and TeX (개발용 서버일 경우 생략 가능)\n- ‘Ubuntu Software’에 가서 ’sublime Text’를 치면 다운받을 수 있다. 다운받은뒤에 ’file’ -&gt; ’open folder’를 활용하여 깃허브의 로칼저장소를 열어두면 편리하다.\n- 아래를 실행하여 TeX을 깐다.\nsudo apt install texlive-full\n- 이제 sublime과 latex을 연결하여보자. 여기를 참고하자. (1) sublime을 키고 ‘컨트롤+쉬프트+p’를 눌러 ’Install Package Control’ 선택 (2) 다시 ‘컨트롤+쉬프트+p’ 를 눌러 ‘Package Control: Install Package’를 실행 (3) 그러면 바로 검색창이 나오는데 거기서 ’LaTeXTools’를 입력해서 실행 (4) 다시 ’컨트롤+쉬프트+p’를 누르고 ’LaTeXTools: Check system’ 선택. 모두 ’available’이 나오면 잘 설치된 것이다.\n- *.tex파일을 열고 ’컨트롤+b’를 누르자. 처음이면 어떤 메뉴들이 보일텐데 그냥 ’Latex’을 선택하자. 그러면 코딩결과가 pdf로 나온다.\n- (수식미리보기) ‘Perferences’ &gt; ‘Packages Setting’ &gt; ‘LaTeXTools’ &gt; ‘Settings-User’를 선택한다. ’93번째라인’에 ’preview_math_mode’를 “all”로 바꾼다. 그러면 수식들이 미리 출력된다. 그외에도 자유롭게 셋팅을 조정할 수 있다. 원래셋팅은 ’Perferences’ &gt; ‘Packages Setting’ &gt; ‘LaTeXTools’ &gt; ‘Settings-Defaults’ 에 있다."
  },
  {
    "objectID": "메모/2000-01-08-(메모) -- 주피터랩, 설정 및 몇가지 팁.html",
    "href": "메모/2000-01-08-(메모) -- 주피터랩, 설정 및 몇가지 팁.html",
    "title": "(메모) – 주피터랩, 설정 및 몇가지 팁",
    "section": "",
    "text": "주피터에 R커널을 연결할 경우 그림크기 조정\noptions(repr.plot.width=10, repr.plot.height=3,repr.plot.res=300)\n\n\n깃허브에서 *.py파일 불러오기\nimport requests\nexec(requests.get('http://miruetoto.github.io/my_code/datahandling.py').text)\n\n\nrpy2 magic\nimport rpy2\n%load_ext rpy2.ipython\n\n\n깃허브에서 *.R파일 불러오기\nimport rpy2\n%load_ext rpy2.ipython\n%R library(devtools)\n%R source_url(\"http://miruetoto.github.io/my_code/datahandling.r\")\n\n\nmatplotlib 그림크기조정\nimport matplotlib as mpl \nimport matplotlib.pyplot as plt \nIpython_default=plt.rcParams.copy() # save initial value \nfrom matplotlib import cycler\nplt.rc('figure',dpi=150) # default value 4 figure.dpi is 72.0 \n# plt.rcParams.update(Ipython_default) # load initial value \n\n\n깃랩관련 (회사아니면 필요없음)\n- load *.py from gitlab\nimport gitlab\ngl = gitlab.Gitlab('http://10.178.145.54:9000', private_token='RkZz465zdyyEChamLKy8')\ngl.auth()\nproject = gl.projects.get(2)\n\n# (1) load RF.py, RF_withGIT.py, RF_withR.py\nRF_py = project.files.get(file_path='modeling/RF.py', ref='fridge').decode()\nRF_GIT_py = project.files.get(file_path='utils/RF_withGIT.py', ref='fridge').decode()\nRF_R_py = project.files.get(file_path='utils/RF_withR.py', ref='fridge').decode()\nexec(str(RF_py, 'utf-8'))\nexec(str(RF_GIT_py, 'utf-8'))\nexec(str(RF_R_py, 'utf-8'))\n- load *.R in gitlab\nimport gitlab\ngl = gitlab.Gitlab('http://10.178.145.54:9000', private_token='RkZz465zdyyEChamLKy8')\ngl.auth()\nproject = gl.projects.get(2)\nRF_R_rcode = project.files.get(file_path='utils/RF_Rfunctions.r', ref='fridge').decode()\n# tricks for source('Rfunctions.r')\nfile1 = open(\"RF_Rfunctions.r\",\"w\") \nfile1.write(str(RF_R_rcode, 'utf-8'))\nfile1.close() \nro.r(\"source('RF_Rfunctions.r')\")\nimport os\nos.remove('RF_Rfunctions.r')\n\n\n& 옵션으로 주피터 실행\n- 서버에 접속한다.\nssh lgcgb@10.178.144.65\n아래와 같이 끝에 &을 붙이면 된다.\nconda activate py20190129\njupyter lab &\n실행하고 난뒤에는 엔터를 쳐서 빠져나온다. 이렇게 하면 서버자체에 모니터를 연결하고 커널창을 띄운것과 같은 효과를 준다. 즉 서버에 접속한 컴퓨터를 끄는것과 상관없이 서버에서는 항상 주피터가 열려 있게 된다.\n\n\n& 옵션으로 실행한 주피터프로세스 죽이기\n- 서버에 접속한다.\nssh lgcgb@10.178.144.65\n실행된 프로세스를 찾기위해 아래를 실행한다.\nps aux | grep jupyter-lab\n결과는 아래와 같이 나온다.\nlgcgb    26888  0.2  0.1 326760 86724 ?        Sl   10:14   0:12 /home/lgcgb/anaconda3/envs/py20190129/bin/python3.7 /home/lgcgb/anaconda3/envs/py20190129/bin/jupyter-lab\nlgcgb    27146  0.0  0.0  15720  1008 pts/3    S+   11:56   0:00 grep --color=auto jupyter-lab\n26888에 해당하는 것이 주피터를 띄운 커널이다. 이 번호를 기억했다가 프로세스를 아래와 같은 명령으로 죽인다.\nkill 26888\n\n\n패스워드 없이 주피터 실행\n- 아래와 같이 하면 외부에서 접속할때 패스워드를 입력하지 않음.\njupyter notebook --ServerApp.token='' --ServerApp.password=''"
  },
  {
    "objectID": "메모/2000-01-09-(메모) -- docker.html",
    "href": "메모/2000-01-09-(메모) -- docker.html",
    "title": "(메모) – docker",
    "section": "",
    "text": "- 우분투에서 설치\nref: https://docs.docker.com/engine/install/ubuntu/\n- 기본명령들\ndocker run penguin\ndocker stop penguin\ndocker image pull penguin \ndocker container start penguin\ndocker container run penguin\n- Docker에서 다운로드한 이미지와 실행 중인 컨테이너를 확인하기 위한 명령어를 소개하겠습니다:\n\n이미지 관련 명령어:\n\ndocker images: 현재 시스템에 다운로드된 모든 도커 이미지를 확인할 수 있습니다.\ndocker image ls: “docker images”와 동일한 결과를 출력합니다.\ndocker image ls &lt;이미지_이름&gt;: 특정 이미지의 버전을 명시하여 해당 이미지의 정보를 확인할 수 있습니다.\ndocker image history &lt;이미지_이름&gt;: 특정 이미지의 레이어별 변경 내역을 확인할 수 있습니다.\n\n컨테이너 관련 명령어:\n\ndocker ps: 현재 실행 중인 컨테이너의 목록을 확인합니다.\ndocker ps -a: 모든 컨테이너의 목록을 확인합니다 (실행 중인 것과 중지된 것 모두 포함).\ndocker container ls: “docker ps”와 동일한 결과를 출력합니다.\ndocker container ls -a: “docker ps -a”와 동일한 결과를 출력합니다.\ndocker container inspect &lt;컨테이너_ID 또는 이름&gt;: 특정 컨테이너의 자세한 정보를 확인할 수 있습니다.\ndocker logs &lt;컨테이너_ID 또는 이름&gt;: 컨테이너의 로그를 확인할 수 있습니다.\ndocker container stats: 실행 중인 컨테이너의 실시간 리소스 사용량을 모니터링할 수 있습니다.\n\n\n이 명령어들을 사용하여 이미지와 컨테이너에 대한 정보를 확인하고 관리할 수 있습니다.\n- docker run -ti --rm r-base 명령어에서 사용된 옵션들은 다음과 같은 의미를 갖습니다:\n\n-ti: 이 옵션은 두 개의 플래그인 -t와 -i를 결합한 것입니다.\n\n-t (또는 --tty): 이 플래그는 유사 터미널을 할당하고 터미널 상호작용을 가능하게 합니다. 컨테이너 내부에서 터미널 환경을 사용할 수 있게 해줍니다.\n-i (또는 --interactive): 이 플래그는 컨테이너와 상호작용할 수 있도록 표준 입력(STDIN)을 열어줍니다. 컨테이너 내부에서 입력을 주고 받을 수 있게 해줍니다.\n\n–rm: 이 옵션은 컨테이너가 실행을 마칠 때 자동으로 컨테이너를 삭제합니다. 컨테이너가 종료되면 그 내용과 상태는 모두 삭제됩니다. 주로 임시 작업을 수행하는데 사용됩니다.\n\n따라서 docker run -ti --rm r-base 명령어는 R 언어 기반의 컨테이너를 실행하는 명령어로, 터미널 환경을 제공하며 컨테이너가 종료될 때 컨테이너를 자동으로 삭제합니다. 이를 통해 R 언어를 실행하고 테스트하거나 실험할 수 있는 환경을 구성할 수 있습니다.\n- docker run -ti --rm -v \"$PWD\":/home/docker -w /home/docker -u docker r-base R CMD check 명령어에서 사용된 각 옵션에 대한 설명은 다음과 같습니다:\n\n-ti: 이 옵션은 터미널 상호작용을 위한 옵션입니다. -t는 유사 터미널 할당을 의미하고, -i는 터미널 입력 상호작용을 허용하는 것을 의미합니다.\n–rm: 컨테이너가 실행을 마칠 때 자동으로 컨테이너를 삭제합니다.\n-v “$PWD”:/home/docker: 이 옵션은 호스트 시스템의 현재 작업 디렉토리를 컨테이너 내의 /home/docker 디렉토리와 공유 마운트합니다. 이렇게 함으로써 호스트 시스템의 파일을 컨테이너 내부에서 사용할 수 있게 됩니다.\n-w /home/docker: 컨테이너가 실행될 작업 디렉토리를 /home/docker로 설정합니다. 즉, 컨테이너가 실행될 때 기본 디렉토리가 /home/docker가 됩니다.\n-u docker: 이 옵션은 컨테이너 안에서 사용자를 변경하여 실행하는 것을 의미합니다. docker라는 사용자로 컨테이너를 실행하게 됩니다.\nr-base: Docker 이미지 이름입니다. 여기서는 R 언어를 기반으로한 이미지를 사용합니다.\nR CMD check: 실제로 실행되는 컨테이너 내부의 명령어입니다. 이 경우 R 패키지를 체크하는 R 명령어 R CMD check가 실행됩니다.\n\n이 명령어는 호스트 시스템의 현재 작업 디렉토리에 있는 R 패키지를 컨테이너 내부에서 R CMD check 명령으로 체크하고자 할 때 사용될 수 있습니다.\n- “docker container start penguin”과 “docker container run penguin” 두 명령어의 차이점은 다음과 같습니다:\n\ndocker container start penguin:\n\n이 명령은 이미 생성된 (stopped 또는 exited 상태의) 컨테이너를 시작시킬 때 사용됩니다.\n컨테이너의 상태를 변경하지 않고, 중단된 상태에서 다시 실행합니다.\n이미지에서 컨테이너를 생성한 후, 실행 중인 컨테이너를 중단하고 다시 시작할 때 유용합니다.\n\ndocker container run penguin:\n\n이 명령은 도커 이미지를 기반으로 새로운 컨테이너를 생성하고 실행시킬 때 사용됩니다.\n이미지에서 새로운 컨테이너를 생성하고, 컨테이너를 시작합니다.\n이미 실행 중인 컨테이너가 아닌, 새로운 컨테이너를 생성하고 실행할 때 사용됩니다.\n\n\n요약하면, “docker container start penguin”은 이미 생성된 컨테이너를 다시 시작하고, “docker container run penguin”은 새로운 컨테이너를 생성하고 시작하는 데 사용됩니다."
  },
  {
    "objectID": "메모/2000-01-05-(메모) -- vi 익히기.html",
    "href": "메모/2000-01-05-(메모) -- vi 익히기.html",
    "title": "(메모) – vi 익히기",
    "section": "",
    "text": "예제: vi를 이용하여 파일 만들고 asdf 입력 후 저장 및 종료를 수행하여 보자.\n\n\nstep1step2step3step4step5\n\n\n- 파일생성\nvim test230803.txt \n\n\n\n- 편집모드로 전환: i를 누른다.\n\n아래에 -- INSERT -- 라고 표현되어 있으면 편집모드라는 의미\n\n\n\n\n- asdf 입력\n\n\n\n- 편집모드 종료, 노말모드 진입:esc 입력\n\n아래에 -- INSERT -- 라는 표현이 사라져있음. 이 상황에서 명령어 입력가능.\n\n\n\n\n- 저장(w)+종료(q): : 입력하여 명령모드로 진입. w+ q + Enter 입력\n\n\n\n\n\n\n\n\n예제: vi 에서 좌우로 커서를 이동해보자.\n\n\nstep1step2step3\n\n\n- 생성된 파일로 들어가기\nvim test230803.txt \n\n\n\n- l을 세번눌러서 오른쪽으로 3칸 이동\n\nl이 아니라 실수로 ㅣ를 누르면 동작하지 않음.\n대충 화살표 눌러도 동작함\n\n\n\n\n- h을 세번눌러서 왼쪽으로 3칸 이동\n\nh가 아니라 실수로 ㅗ를 누르면 동작하지 않음.\n대충 화살표 눌러도 동작함\n\n\n\n\n\n\n\n\n\n예제: vi에서 새로운라인을 추가하고 asdf2입력하여 보자.\n\n\nstep1step2step3\n\n\n- 준비작업: 명령모드에서 다음라인을 만들고 싶은 라인에 커서를 위치\n\n\n\n- o를 누른다: 편집모드로 전환 + 새로운 라인이 추가의 효과\n\n\n\n- asdf2입력\n\n\n\n\n\n\n\n\n예제: vi에서 j,k를 이용하여 커서를 이동하여 보자. (풀이는 생략)\n\n\n\n\n\n예제: vi에서 home/end 와 같은 방식으로 커서를 이동해보자\n\n\nstep1step2step3\n\n\n- 준비작업: 명령모드에서 home/end를 사용할 line으로 커서를 이동시킴\n\n\n\n- 라인의 맨 마지막으로 가고싶다면? $를 입력한다.\n\n\n\n- 다시 라인의 맨 처음으로 가고싶다면? 숫자 0을 입력한다.\n\n\n\n\n\n\n\n\n예제: vi에서 하나의 줄을 복사하고 아래로 붙여넣기 해보자.\n\n\nstep1step2step3\n\n\n- 복사하고싶은 라인으로 이동 + yy 입력\n\n\n\n- 아래로 붙여넣을 라인으로 이동\n\n\n\n- p 입력\n\n\n\n\n\n\n\n\n예제: vi에서 w와 b를 이용하여 단어단위로 커서를 이동시켜보자. (풀이생략)\n\n\n\n\n\n예제: vi에서 원하는 단어는 찾아보자.\n\n\nstep1step2step3step4\n\n\n- /asdf2 입력\n\n\n\n- Enter 입력\n\n\n\n- n 입력하여 다음단어로 이동\n\n\n\n- shift+n 입력하여 이전단어로 이동 (?로 검색할 경우 n와 shift+n의 역할이 뒤바뀜)"
  },
  {
    "objectID": "메모/2000-01-05-(메모) -- vi 익히기.html#i-esc-w-q-편집-명령-저장-종료",
    "href": "메모/2000-01-05-(메모) -- vi 익히기.html#i-esc-w-q-편집-명령-저장-종료",
    "title": "(메모) – vi 익히기",
    "section": "",
    "text": "예제: vi를 이용하여 파일 만들고 asdf 입력 후 저장 및 종료를 수행하여 보자.\n\n\nstep1step2step3step4step5\n\n\n- 파일생성\nvim test230803.txt \n\n\n\n- 편집모드로 전환: i를 누른다.\n\n아래에 -- INSERT -- 라고 표현되어 있으면 편집모드라는 의미\n\n\n\n\n- asdf 입력\n\n\n\n- 편집모드 종료, 노말모드 진입:esc 입력\n\n아래에 -- INSERT -- 라는 표현이 사라져있음. 이 상황에서 명령어 입력가능.\n\n\n\n\n- 저장(w)+종료(q): : 입력하여 명령모드로 진입. w+ q + Enter 입력"
  },
  {
    "objectID": "메모/2000-01-05-(메모) -- vi 익히기.html#hl-좌우로-커서이동",
    "href": "메모/2000-01-05-(메모) -- vi 익히기.html#hl-좌우로-커서이동",
    "title": "(메모) – vi 익히기",
    "section": "",
    "text": "예제: vi 에서 좌우로 커서를 이동해보자.\n\n\nstep1step2step3\n\n\n- 생성된 파일로 들어가기\nvim test230803.txt \n\n\n\n- l을 세번눌러서 오른쪽으로 3칸 이동\n\nl이 아니라 실수로 ㅣ를 누르면 동작하지 않음.\n대충 화살표 눌러도 동작함\n\n\n\n\n- h을 세번눌러서 왼쪽으로 3칸 이동\n\nh가 아니라 실수로 ㅗ를 누르면 동작하지 않음.\n대충 화살표 눌러도 동작함"
  },
  {
    "objectID": "메모/2000-01-05-(메모) -- vi 익히기.html#o-새로운라인-추가",
    "href": "메모/2000-01-05-(메모) -- vi 익히기.html#o-새로운라인-추가",
    "title": "(메모) – vi 익히기",
    "section": "",
    "text": "예제: vi에서 새로운라인을 추가하고 asdf2입력하여 보자.\n\n\nstep1step2step3\n\n\n- 준비작업: 명령모드에서 다음라인을 만들고 싶은 라인에 커서를 위치\n\n\n\n- o를 누른다: 편집모드로 전환 + 새로운 라인이 추가의 효과\n\n\n\n- asdf2입력"
  },
  {
    "objectID": "메모/2000-01-05-(메모) -- vi 익히기.html#jk-위-아래-이동",
    "href": "메모/2000-01-05-(메모) -- vi 익히기.html#jk-위-아래-이동",
    "title": "(메모) – vi 익히기",
    "section": "",
    "text": "예제: vi에서 j,k를 이용하여 커서를 이동하여 보자. (풀이는 생략)"
  },
  {
    "objectID": "메모/2000-01-05-(메모) -- vi 익히기.html#homeend와-같은-기능",
    "href": "메모/2000-01-05-(메모) -- vi 익히기.html#homeend와-같은-기능",
    "title": "(메모) – vi 익히기",
    "section": "",
    "text": "예제: vi에서 home/end 와 같은 방식으로 커서를 이동해보자\n\n\nstep1step2step3\n\n\n- 준비작업: 명령모드에서 home/end를 사용할 line으로 커서를 이동시킴\n\n\n\n- 라인의 맨 마지막으로 가고싶다면? $를 입력한다.\n\n\n\n- 다시 라인의 맨 처음으로 가고싶다면? 숫자 0을 입력한다."
  },
  {
    "objectID": "메모/2000-01-05-(메모) -- vi 익히기.html#yy-p-라인복사-붙여넣기",
    "href": "메모/2000-01-05-(메모) -- vi 익히기.html#yy-p-라인복사-붙여넣기",
    "title": "(메모) – vi 익히기",
    "section": "",
    "text": "예제: vi에서 하나의 줄을 복사하고 아래로 붙여넣기 해보자.\n\n\nstep1step2step3\n\n\n- 복사하고싶은 라인으로 이동 + yy 입력\n\n\n\n- 아래로 붙여넣을 라인으로 이동\n\n\n\n- p 입력"
  },
  {
    "objectID": "메모/2000-01-05-(메모) -- vi 익히기.html#wb-다음단어로-점프-이전단어로-점프",
    "href": "메모/2000-01-05-(메모) -- vi 익히기.html#wb-다음단어로-점프-이전단어로-점프",
    "title": "(메모) – vi 익히기",
    "section": "",
    "text": "예제: vi에서 w와 b를 이용하여 단어단위로 커서를 이동시켜보자. (풀이생략)"
  },
  {
    "objectID": "메모/2000-01-05-(메모) -- vi 익히기.html#단어-찾기",
    "href": "메모/2000-01-05-(메모) -- vi 익히기.html#단어-찾기",
    "title": "(메모) – vi 익히기",
    "section": "",
    "text": "예제: vi에서 원하는 단어는 찾아보자.\n\n\nstep1step2step3step4\n\n\n- /asdf2 입력\n\n\n\n- Enter 입력\n\n\n\n- n 입력하여 다음단어로 이동\n\n\n\n- shift+n 입력하여 이전단어로 이동 (?로 검색할 경우 n와 shift+n의 역할이 뒤바뀜)"
  },
  {
    "objectID": "메모/2000-01-05-(메모) -- vi 익히기.html#esc-normal-모드",
    "href": "메모/2000-01-05-(메모) -- vi 익히기.html#esc-normal-모드",
    "title": "(메모) – vi 익히기",
    "section": "esc: normal 모드",
    "text": "esc: normal 모드\n- 기능1: 되돌리기, 되돌리기를 되돌리기\n- 기능2: 커서이동 (기본) – 방향키, 쉬프트+방향키, home/end, pageup/pagedown 으로 대체가능\n\nk,j,h,l: 상,하,좌,우\nw,b: 다음 단어의 시작으로 이동, 이전 단어의 시작으로 이동\n0 (숫자 0), $: 줄의 맨 앞, 맨 끝으로 이동\ncontrol + d, control + u: 반페이지씩 page down, page up\n{, }: 문단 시작, 끝으로 이동\n\n- 기눙3: 커서이동 (고급)\n\n%: 현재 괄호의 짝으로 이동\ne: 현재단어의 끝으로 이동\ngg: 파일의 첫 줄로 이동\nG: 파일의 마지막 줄로 이동\n\n- 기능4: 다른모드로 진입하기 위한 중간허브\n\nv,V: 선택모드, 줄단위선택모드로 변환\ni, I, a, A: 커서앞, 줄맨앞, 커서뒤, 줄맨뒤에서 삽입모드로 전환\nr, R: 한글자 수정후 복귀, 수정모드로 진입\n\n- 기능5: 들여쓰기, 내어쓰기\n\n&gt; + Enter, &lt; + Enter: 들여쓰기, 내어쓰기"
  },
  {
    "objectID": "메모/2000-01-05-(메모) -- vi 익히기.html#i-삽입모드",
    "href": "메모/2000-01-05-(메모) -- vi 익히기.html#i-삽입모드",
    "title": "(메모) – vi 익히기",
    "section": "i: 삽입모드",
    "text": "i: 삽입모드"
  },
  {
    "objectID": "메모/2000-01-05-(메모) -- vi 익히기.html#d-삭제모드",
    "href": "메모/2000-01-05-(메모) -- vi 익히기.html#d-삭제모드",
    "title": "(메모) – vi 익히기",
    "section": "d: 삭제모드",
    "text": "d: 삭제모드"
  },
  {
    "objectID": "메모/2000-01-05-(메모) -- vi 익히기.html#명령모드",
    "href": "메모/2000-01-05-(메모) -- vi 익히기.html#명령모드",
    "title": "(메모) – vi 익히기",
    "section": ":: 명령모드",
    "text": ":: 명령모드"
  },
  {
    "objectID": "메모/2000-01-05-(메모) -- vi 익히기.html#검색모드",
    "href": "메모/2000-01-05-(메모) -- vi 익히기.html#검색모드",
    "title": "(메모) – vi 익히기",
    "section": "/: 검색모드",
    "text": "/: 검색모드"
  },
  {
    "objectID": "메모/2000-01-05-(메모) -- vi 익히기.html#v-비주얼모드선택모드",
    "href": "메모/2000-01-05-(메모) -- vi 익히기.html#v-비주얼모드선택모드",
    "title": "(메모) – vi 익히기",
    "section": "v: 비주얼모드(선택모드)",
    "text": "v: 비주얼모드(선택모드)"
  },
  {
    "objectID": "메모/2000-01-05-(메모) -- vi 익히기.html#r-수정모드",
    "href": "메모/2000-01-05-(메모) -- vi 익히기.html#r-수정모드",
    "title": "(메모) – vi 익히기",
    "section": "R: 수정모드",
    "text": "R: 수정모드"
  },
  {
    "objectID": "메모/2000-01-04-(메모) -- 우분투 익히기.html",
    "href": "메모/2000-01-04-(메모) -- 우분투 익히기.html",
    "title": "(메모) – 우분투 익히기",
    "section": "",
    "text": "/root\n\n루트사용자의 홈 디렉토리\nsudo로도 들어갈 수 없음\n\n/etc\n\n리눅스 시스템 전반적인 환경설정 파일들을 모은 디렉터리임.\n이 디렉터리의 모든 파일은 텍스트형식임.\n/etc/password 사용자 계정정보\n\n/home\n\n사용자의 홈 디렉터리\n\n/mnt\n\n다른 파일 시스템이 파일 시스템에 연결되거나 마운트 되는 위치\n\n/media\n\nCD, USB 장치가 파일 시스템에 연결되거나 마운트되는 위치임\n\n/bin\n\n시스템 부팅과 실행에 필요한 바이너리(=윈도도의 실행파일=macOS의 애플리케이션)들을 포함\n\n/lib\n\n시스템 프로그램에서 사용하는 공유 라이브러리가 저장. 윈도우즈의 DLL과 비슷한 것.\n\n/usr\n\n사용자가 사용하는 모든 프로그램과 지원파일들 (Program files + 프로그램들의 설정값)\n/usr/bin 리눅스 배포판이 설치한 실행 프로그램들이 있다. (여기에 R이 깔린다!!)\n\nhp-align, hp-check, hp-config_usb-printer …\nX11\nvi\ngcc\nsu, sudo\nsar\nssh, ssh-agent, ssh-keygen, ….\nnvidia-smi\n\n/usr/lib 여기에는 /usr/bin에 있는 프로그램들을 위한 공유라이브러리가 저장된다. 여기에 R folder가 있다. (R패키지는 여기말고 다른데 깔림)\n/usr/local/bin 소스코드로 컴파일된 파일, 보통 비어있음\n/usr/local/lib/R/site-library R패키지가 설치되어있음, 예를들면 tidyverse"
  },
  {
    "objectID": "메모/2000-01-04-(메모) -- 우분투 익히기.html#pwd-whoami",
    "href": "메모/2000-01-04-(메모) -- 우분투 익히기.html#pwd-whoami",
    "title": "(메모) – 우분투 익히기",
    "section": "pwd, whoami",
    "text": "pwd, whoami\n- 현재위치확인\n(base) cgb2@cgb2-desktop:~$ pwd\n/home/cgb2\n- 유저확인\n### 예시1: 유저확인 \n(base) cgb2@cgb2-desktop:~$ whoami \ncgb2 \n\n### 예시2: 루트권한 획득이후 유저확인 \n(base) cgb2@cgb2-desktop:~$ sudo -i # 루트권한 획득\nroot@cgb2-desktop:~# whoami \nroot \n\n### 예시3: 일반유저로 전환후 유저확인\nroot@cgb2-desktop:~# su - cgb2 \n(base) cgb2@cgb2-desktop:~$ whoami\ncgb2"
  },
  {
    "objectID": "메모/2000-01-04-(메모) -- 우분투 익히기.html#cd-ls",
    "href": "메모/2000-01-04-(메모) -- 우분투 익히기.html#cd-ls",
    "title": "(메모) – 우분투 익히기",
    "section": "cd, ls",
    "text": "cd, ls\n- 홈디렉토리로 이동 + 목록\n(base) cgb2@cgb2-desktop:~/Dropbox$ cd ~\n(base) cgb2@cgb2-desktop:~$ ls\nDesktop                 julia-1.8.5\nDocuments               julia-1.8.5-linux-x86_64.tar.gz\nDownloads               lm.txt\nDropbox                 nbdev_tst\nMusic                   quarto-1.0.37-linux-amd64.deb\nPictures                rstudio-server-2021.09.2-382-amd64.deb\nPublic                  scikit_learn_data\nR                       snap\nTemplates               test.txt\nVideos                  v3net\nanaconda3               v3net-linux-3.6.10.11.805.tar.Z\nblacklist-nouveau.conf  vscode_cli.tar.gz\ncode\n- 루트로 이동 + 목록\n(base) cgb2@cgb2-desktop:~/Dropbox$ cd /\n(base) cgb2@cgb2-desktop:/$ ls\nbin    dev   lib    libx32      media  proc  sbin  swapfile  usr\nboot   etc   lib32  log         mnt    root  snap  sys       var\ncdrom  home  lib64  lost+found  opt    run   srv   tmp\n- ls 자세하게\n(base) cgb2@cgb2-desktop:/$ ls -l\ntotal 2097256\nlrwxrwxrwx   1 root  root           7  2월 11  2022 bin -&gt; usr/bin\ndrwxr-xr-x   3 root  root        4096  7월 27 12:19 boot\ndrwxrwxr-x   2 root  root        4096  2월 11  2022 cdrom\ndrwxr-xr-x  19 root  root        4480  7월 28 12:19 dev\ndrwxr-xr-x 143 root  root       12288  7월 27 21:08 etc\ndrwxr-xr-x   6 root  root        4096  7월  7 11:14 home\nlrwxrwxrwx   1 root  root           7  2월 11  2022 lib -&gt; usr/lib\nlrwxrwxrwx   1 root  root           9  2월 11  2022 lib32 -&gt; usr/lib32\nlrwxrwxrwx   1 root  root           9  2월 11  2022 lib64 -&gt; usr/lib64\nlrwxrwxrwx   1 root  root          10  2월 11  2022 libx32 -&gt; usr/libx32\ndrwxr-x---   2 root  root        4096  2월 11  2022 log\ndrwx------   2 root  root       16384  2월 11  2022 lost+found\ndrwxr-xr-x   2 root  root        4096  8월 19  2021 media\ndrwxr-xr-x   2 root  root        4096  8월 19  2021 mnt\ndrwxr-xr-x   4 jaein saned       4096  7월 16 11:21 opt\ndr-xr-xr-x 418 root  root           0  7월 28 12:16 proc\ndrwx------   6 root  root        4096  7월 27 12:21 root\ndrwxr-xr-x  40 root  root        1220  8월  3 13:31 run\nlrwxrwxrwx   1 root  root           8  2월 11  2022 sbin -&gt; usr/sbin\ndrwxr-xr-x  14 root  root        4096  7월 16 11:10 snap\ndrwxr-xr-x   2 root  root        4096  8월 19  2021 srv\n-rw-------   1 root  root  2147483648  2월 11  2022 swapfile\ndr-xr-xr-x  13 root  root           0  7월 28 12:16 sys\ndrwxrwxrwt  19 root  root       20480  8월  3 13:29 tmp\ndrwxr-xr-x  14 root  root        4096  8월 19  2021 usr\ndrwxr-xr-x  15 root  root        4096  7월 30  2022 var"
  },
  {
    "objectID": "메모/2000-01-04-(메모) -- 우분투 익히기.html#h-man",
    "href": "메모/2000-01-04-(메모) -- 우분투 익히기.html#h-man",
    "title": "(메모) – 우분투 익히기",
    "section": "-h, man",
    "text": "-h, man\n- 도움말확인\n(base) cgb2@cgb2-desktop:~$ git --help\nusage: git [--version] [--help] [-C &lt;path&gt;] [-c &lt;name&gt;=&lt;value&gt;]\n           [--exec-path[=&lt;path&gt;]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=&lt;path&gt;] [--work-tree=&lt;path&gt;] [--namespace=&lt;name&gt;]\n           &lt;command&gt; [&lt;args&gt;]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help &lt;command&gt;' or 'git help &lt;concept&gt;'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n- 메뉴얼 확인\n(base) cgb2@cgb2-desktop:~$ man git"
  },
  {
    "objectID": "메모/2000-01-04-(메모) -- 우분투 익히기.html#cp-mv-mkdir-rm",
    "href": "메모/2000-01-04-(메모) -- 우분투 익히기.html#cp-mv-mkdir-rm",
    "title": "(메모) – 우분투 익히기",
    "section": "cp, mv, mkdir, rm",
    "text": "cp, mv, mkdir, rm\n- 카피\ncp file1 file2 # file1을 복사하여 file2를 새로 만듬. file2가 이미 있다면 file1의 내용을 덮어씀 \ncp -r dir1 dir2 # dir1의 모든파일을 복사하여 dir2로 이동한뒤 붙어넣음. dir2가 없다면 새로 만듬. 기존의 dir2에 있던 파일이 삭제되는건 아님 \n- 이동\nmv file1 file2 # file1을 이동하여 file2로 이름바꿈. file2가 이미 있다면 file1의 내용을 덮어씀 \nmv -r dir1 dir2 # dir1의 모든파일을 잘라내어 dir2로 이동. \n- 디렉토리 생성\nmkdir temp\nmkdir temp1, temp2, temp3 # 여러개를 만듬\n- 삭제\nrm file1 # file1삭제 \nrm -r file1 dir1 # file1삭제 dir1폴더삭제 \nrm -rf file1 dir1 # 위와 동일한데 file1이나 dir1이 존재하지 않더라고 rm이 실행\n- -v(verbose)를 쓰면 친절한 느낌이 든다.\n(base) cgb2@cgb2-desktop:~/Dropbox$ cp *.txt temppp -v\n'colab.txt' -&gt; 'temppp/colab.txt'"
  },
  {
    "objectID": "메모/2000-01-04-(메모) -- 우분투 익히기.html#scp",
    "href": "메모/2000-01-04-(메모) -- 우분투 익히기.html#scp",
    "title": "(메모) – 우분투 익히기",
    "section": "scp",
    "text": "scp\n- cgb2에 있는 lm.txt를 cgb5로 옮김. 포트는 cgb5에 대응하는 포트\ncgb2@cgb2-desktop:~$ scp -P 4653 lm.txt cgb5@210.117.173.185:~\n- cgb2에 있는 lm.txt를 맥으로 가져옴. 포트는 cgb2에 대응하는 포트"
  },
  {
    "objectID": "메모/2000-01-04-(메모) -- 우분투 익히기.html#find",
    "href": "메모/2000-01-04-(메모) -- 우분투 익히기.html#find",
    "title": "(메모) – 우분투 익히기",
    "section": "find",
    "text": "find\n- Dropbox라는 이름이 포함된 폴더 찾기\nfind ~ -type d -name \"Dropbox\"\n\n여기에서 ~는 검색을 시작할 최상위 디렉토리를 쓴다.\n여기에서 -type d는 디렉토리라는 의미이다.\n\n- sy.tex이라는 파일찾기\nfind ~ -type f -name \"sy.tex\"\n\n여기에서 ~는 검색을 시작할 최상위 디렉토리를 쓴다.\n여기에서 -type d는 디렉토리라는 의미이다."
  },
  {
    "objectID": "메모/2000-01-04-(메모) -- 우분투 익히기.html#wget",
    "href": "메모/2000-01-04-(메모) -- 우분투 익히기.html#wget",
    "title": "(메모) – 우분투 익히기",
    "section": "wget",
    "text": "wget\n- 인터넷에서 파일 다운로드\nwget https://download2.rstudio.org/server/bionic/amd64/rstudio-server-1.2.5033-amd64.deb"
  },
  {
    "objectID": "메모/2000-01-04-(메모) -- 우분투 익히기.html#gdebi-deb",
    "href": "메모/2000-01-04-(메모) -- 우분투 익히기.html#gdebi-deb",
    "title": "(메모) – 우분투 익히기",
    "section": "gdebi, deb",
    "text": "gdebi, deb\n- deb파일을 gdebi로 설치하는 방법\nsudo gdebi rstudio-server-1.2.5033-amd64.deb\n- deb파일을 dpkg를 이용하여 설치하는 방법\ndpkg -i quarto-1.2.335-linux-amd64.deb # 설치\ndpkg -r quarto # 삭제 \n- gdebi, deb의 차이\n\ngdebi는 관련패키지를 모두 찾아서 설치 dpkg는 하나의 패키지만 설치. 즉 gdebi는 conda 느낌이고 dpkg는 pip 느낌\ngdebi는 별도의 삭제옵션을 지원하지 않음. 따라서 gdebi로 설치한 deb을 삭제하려면 머리아플수도?\n\n- gdebi로 설치한 패키지를 삭제하는 방법\n\n\n\n\n\n\nChat-GPT 답변\n\n\n\ngdebi로 패키지를 삭제하는 것은 아쉽게도 직접적으로 지원하지 않습니다. gdebi는 주로 패키지를 설치할 때 사용되는 도구이며, 패키지의 삭제에는 사용되지 않습니다. 패키지를 삭제하려면 다른 도구인 dpkg나 패키지 관리자 명령을 사용해야 합니다.\n패키지를 삭제하는 방법은 아래와 같습니다. 패키지를 삭제하기 전에 해당 패키지가 다른 의존하는 패키지에 영향을 주지 않는지 주의깊게 확인하시기 바랍니다.\ndpkg를 사용하여 패키지 삭제하기:\nsudo dpkg -r 패키지이름\n여기서 패키지이름은 삭제하려는 패키지의 이름입니다. 이 명령을 실행하면 해당 패키지가 삭제됩니다.\napt를 사용하여 패키지 삭제하기 (의존성 관리 포함):\nsudo apt remove 패키지이름\n위 명령은 apt를 통해 패키지를 삭제하며, 의존성을 포함하여 관련된 패키지들도 자동으로 처리합니다. 이 방법은 일반적으로 패키지 삭제에 더 효과적입니다.\n위의 방법 중 하나를 선택하여 패키지를 삭제할 수 있습니다. 패키지 삭제 시에는 주의하여 의존성 문제가 발생하지 않도록 해야 합니다."
  },
  {
    "objectID": "메모/2000-01-04-(메모) -- 우분투 익히기.html#apt",
    "href": "메모/2000-01-04-(메모) -- 우분투 익히기.html#apt",
    "title": "(메모) – 우분투 익히기",
    "section": "apt",
    "text": "apt\nsudo apt-get remove r-base-core\nsudo apt purge r-base* r-recommended r-cran-*\nsudo apt autoremove\nsudo apt list \nsudo apt update\nsudo apt install openssh-server \nsudo apt-get install gdebi-core\n- sudo apt-get과 sudo apt 차이? 별 차이 없는듯\n\nhttps://askubuntu.com/questions/445384/what-is-the-difference-between-apt-and-apt-get\n\n\nThey are very similar command line tools available in Trusty (14.04) and later. apt-get and apt-cache’s most commonly used commands are available in apt. apt-get may be considered as lower-level and “back-end”, and support other APT-based tools. apt is designed for end-users (human) and its output may be changed between versions."
  },
  {
    "objectID": "메모/2000-01-04-(메모) -- 우분투 익히기.html#conda",
    "href": "메모/2000-01-04-(메모) -- 우분투 익히기.html#conda",
    "title": "(메모) – 우분투 익히기",
    "section": "conda",
    "text": "conda\nconda \nconda env -h \nconda install -h \nconda remove -h  \nconda update -h \nconda env list\nconda create -n py38r40 python=3.8\nconda env remove -n py38r40 \nconda install -c conda-forge jupyterlab \nconda remove jupyterlab \nconda remove r-base -y \nconda remove -n py38r40 jupyterlab \nconda update scipy\nconda update -n py38r40 scipy\nconda list"
  },
  {
    "objectID": "메모/2000-01-04-(메모) -- 우분투 익히기.html#pip",
    "href": "메모/2000-01-04-(메모) -- 우분투 익히기.html#pip",
    "title": "(메모) – 우분투 익히기",
    "section": "pip",
    "text": "pip\npip\npip list\npip list &gt; list.txt\npip freeze # 좀 더 자세히 나온다 \npip freeze &gt; list.txt \npip show matplotlib # 설치된패키지 정보가 나옴. 좋음.\npip install rpy2\npip install -r list.txt \npip install dash==1.13.3\npip install jupyterlab \"ipywidgets&gt;=7.5\"\npip install -U numpy\npip install --upgrade pip\npip install --upgrade tensorflow\npip uninstall matplotlib"
  },
  {
    "objectID": "메모/2000-01-04-(메모) -- 우분투 익히기.html#a1.-덜-중요한-명령어",
    "href": "메모/2000-01-04-(메모) -- 우분투 익히기.html#a1.-덜-중요한-명령어",
    "title": "(메모) – 우분투 익히기",
    "section": "A1. 덜 중요한 명령어",
    "text": "A1. 덜 중요한 명령어\n\nfile\n- 뭐하는 파일인지 알고싶다면?\n(base) cgb2@cgb2-desktop:~/Dropbox/03_yechan3$ file 1_essays.qmd \n1_essays.qmd: ASCII text\n\n\ndate, cal\n- 날짜\n(base) cgb2@cgb2-desktop:~$ date\n2023. 08. 03. (목) 16:10:38 KST\n- 달력\n(base) cgb2@cgb2-desktop:~$ cal\n      8월 2023         \n일 월 화 수 목 금 토  \n       1  2  3  4  5  \n 6  7  8  9 10 11 12  \n13 14 15 16 17 18 19  \n20 21 22 23 24 25 26  \n27 28 29 30 31"
  },
  {
    "objectID": "메모/2000-01-10-(메모) -- DGX staion.html",
    "href": "메모/2000-01-10-(메모) -- DGX staion.html",
    "title": "(메모) – DGX station 설정",
    "section": "",
    "text": "- root 획득\nsudo -i \n- 모든 GPU enable\nnvidia-smi -mig 1 \nsudo systemctl stop nvidia-mig-manager.service\nsudo systemctl disable nvidia-mig-manager.service\nreboot\n- 모든 특정 GPU만 enable\n#nvidia-smi -i {GPUdev-ID} -mig 1\nnvidia-smi -i 0 -mig 1 \nsudo systemctl stop nvidia-mig-manager.service\nsudo systemctl disable nvidia-mig-manager.service\nreboot \n- GPU가 MIG 모드로 되면 아래와 같이 GPU-Util 에 N/A로 표시된다. 아래는 0,1,2,4 에 대응하는 GPU가 MIG모드로 설정된 상태임\n\n\n\n\n- 용어정리\n\nGPU: 말 그대로 GPU\nGI: GPU INSTANCE, 하나의 GPU에 여러개의 GPU INSTANCE가 존재할 수 있음.\nCI: COMPUTE INSTANCE, 하나의 GPU INSTANCE에 여러개의 COMPUTE INSTANCE를 만들 수 있음.\n\n- 상황확인\nnvidia-smi \n\n- GPU의 해석\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.141.03   Driver Version: 470.141.03   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA A100-SXM...  On   | 00000000:01:00.0 Off |                   On |\n| N/A   37C    P0    53W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n|   1  NVIDIA A100-SXM...  On   | 00000000:47:00.0 Off |                   On |\n| N/A   38C    P0    52W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n|   2  NVIDIA A100-SXM...  On   | 00000000:81:00.0 Off |                   On |\n| N/A   37C    P0    54W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n|   3  NVIDIA DGX Display  On   | 00000000:C1:00.0 Off |                  N/A |\n| 36%   39C    P8    N/A /  50W |      1MiB /  3911MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   4  NVIDIA A100-SXM...  On   | 00000000:C2:00.0 Off |                   On |\n| N/A   37C    P0    55W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n총 4개의 GPU가 있으며 아이디는 0,1,2,4 임을 알 수 있다.\n- GPUdev-ID, GI-ID, CI-ID, MIGdev-ID 확인\n+-----------------------------------------------------------------------------+\n| MIG devices:                                                                |\n+------------------+----------------------+-----------+-----------------------+\n| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |\n|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|\n|                  |                      |        ECC|                       |\n|==================+======================+===========+=======================|\n|  1    0   0   0  |      0MiB / 81251MiB | 98      0 |  7   0    5    1    1 |\n|                  |      1MiB / 13107... |           |                       |\n+------------------+----------------------+-----------+-----------------------+\n|  2    0   0   0  |      0MiB / 81251MiB | 98      0 |  7   0    5    1    1 |\n|                  |      1MiB / 13107... |           |                       |\n+------------------+----------------------+-----------+-----------------------+\n아래와 같은 상황을 유추할 수 있다.\n\n\n\nGPUdev ID\nGI ID\nCI ID\nMIGdev ID\n\n\n\n\n1\n0 (80G)\n0 (98SM)\n0\n\n\n2\n0 (80G)\n0 (98SM)\n0\n\n\n\n- 생성가능한 gi 확인\n\n- 생성가능한 ci 확인\n\n\n\nNote: GPU 1,2 에만 GI가 존재하므로, 목록에는 GPU 1,2 만 보임\n\n\n\n\n\n- GPUdev = 4 에서 생성가능한 GI 조회\n#nvidia-smi mig -i {GPUdev-ID} -lgip\nnvidia-smi mig -i 4 -lgip\n\n- 아래에 해당하는 GI를 2개 생성하고 싶다고 하자. (GPU-INSTANCE-PROFILE-ID=9 임을 유의)\n+-----------------------------------------------------------------------------+\n| GPU instance profiles:                                                      |\n| GPU   Name             ID    Instances   Memory     P2P    SM    DEC   ENC  |\n|                              Free/Total   GiB              CE    JPEG  OFA  |\n|=============================================================================|\n|   4  MIG 3g.40gb        9     0/2        39.50      No     42     2     0   |\n|                                                             3     0     0   |\n+-----------------------------------------------------------------------------+\n#nvidia-smi mig -i {GPUdev-ID} -cgi {GPU-INSTANCE-PROFILE-ID}\nnvidia-smi mig -i 4 -cgi 9 \nnvidia-smi mig -i 4 -cgi 9 \n\n\n\nNote: 2개까지는 잘 ㅁ나들어지고 그 이후에는 리소스 부족으로 에러가 발생한다.\n\n\n\n2개까지는 잘 만들어지고 그 이후에는 리소스부족으로 에러발생\n\n- 만들어진 GI 확인\n\n\n\nNote: 1,2번 GPU에 각각 GI가 1개씩 있고 4번 GPU에 GI가 2개 있다.\n\n\n- 생성가능한 CI 확인\nnvidia-smi mig -lcip\n\n\n\nNote: {GPU ID: GPU INSTANCE ID} 의 조합에서 {1:0}, {2:0}, {4:1}, {4:2} 에 해당하는 GI에서 생성가능한 CI들이 각각 출력된다. 4번 GPU의 GI들은 40기가가 한계이므로 생성가능 CI목록이 상대적으로 제한적임을 캐치하라\n\n\n\n\n\n- GPUdev=4 에서 생성가능한 CI 조회\n#nvidia-smi mig -i {GPU ID} -lcip\nnvidia-smi mig -i 4 -lcip\n\n\n\nNote: 각 GPU-인스턴스(GI)에서는 3개 계산-인스턴스(CI)를 만들수 있음. 만약에 Profile ID = 0 으로 만든다면 14의 계산능력을 가진 CI를 3개까지 만들수 있음, 만약 Profile ID = 2* 로 만든다면 42개의 계산능력을 가진 CI를 1개만 만들 수 있음\n\n\n- {GPUdev-ID:GI-ID} = {4:1} 에서 COMPUTE-INSTANCE-PROFILE-ID=0 에 해당하는 CI를 3개 생성\n#nvidia-smi mig -i {GPUdev-ID} -gi {GI-ID} -cci {COMPUTE-INSTANCE-PROFILE-ID}\nnvidia-smi mig -i 4 -gi 1 -cci 0\n\n\n\nNote: 자원부족으로 3개까지 밖에 못만든다..\n\n\n- {GPUdev-ID:GI-ID}={4:2} 에서 COMPUTE-INSTANCE-PROFILE-ID=2 에 해당하는 CI를 1개 생성\n#nvidia-smi mig -i {GPUdev-ID} -gi {GI-ID} -cci {COMPUTE-INSTANCE-PROFILE-ID}\nnvidia-smi mig -i 4 -gi 2 -cci 2 \n\n\n\nNote: 자원이 부족해서 1개밖에 못 만든다.\n\n\n- 현재 상황\n\n\n\n\nGPUdev ID\nGI ID\nCI ID\nMIGdev ID\n\n\n\n\n1\n0 (80G)\n0 (98SM)\n0\n\n\n2\n0 (80G)\n0 (98SM)\n0\n\n\n4\n1 (80G)\n0 (14SM)\n0\n\n\n4\n1 (80G)\n1 (14SM)\n1\n\n\n4\n1 (80G)\n2 (14SM)\n2\n\n\n4\n2 (80G)\n0 (42SM)\n3"
  },
  {
    "objectID": "메모/2000-01-10-(메모) -- DGX staion.html#a.-mig-모드-enable",
    "href": "메모/2000-01-10-(메모) -- DGX staion.html#a.-mig-모드-enable",
    "title": "(메모) – DGX station 설정",
    "section": "",
    "text": "- root 획득\nsudo -i \n- 모든 GPU enable\nnvidia-smi -mig 1 \nsudo systemctl stop nvidia-mig-manager.service\nsudo systemctl disable nvidia-mig-manager.service\nreboot\n- 모든 특정 GPU만 enable\n#nvidia-smi -i {GPUdev-ID} -mig 1\nnvidia-smi -i 0 -mig 1 \nsudo systemctl stop nvidia-mig-manager.service\nsudo systemctl disable nvidia-mig-manager.service\nreboot \n- GPU가 MIG 모드로 되면 아래와 같이 GPU-Util 에 N/A로 표시된다. 아래는 0,1,2,4 에 대응하는 GPU가 MIG모드로 설정된 상태임"
  },
  {
    "objectID": "메모/2000-01-10-(메모) -- DGX staion.html#b.-gpu-gi-ci-확인",
    "href": "메모/2000-01-10-(메모) -- DGX staion.html#b.-gpu-gi-ci-확인",
    "title": "(메모) – DGX station 설정",
    "section": "",
    "text": "- 용어정리\n\nGPU: 말 그대로 GPU\nGI: GPU INSTANCE, 하나의 GPU에 여러개의 GPU INSTANCE가 존재할 수 있음.\nCI: COMPUTE INSTANCE, 하나의 GPU INSTANCE에 여러개의 COMPUTE INSTANCE를 만들 수 있음.\n\n- 상황확인\nnvidia-smi \n\n- GPU의 해석\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.141.03   Driver Version: 470.141.03   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA A100-SXM...  On   | 00000000:01:00.0 Off |                   On |\n| N/A   37C    P0    53W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n|   1  NVIDIA A100-SXM...  On   | 00000000:47:00.0 Off |                   On |\n| N/A   38C    P0    52W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n|   2  NVIDIA A100-SXM...  On   | 00000000:81:00.0 Off |                   On |\n| N/A   37C    P0    54W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n|   3  NVIDIA DGX Display  On   | 00000000:C1:00.0 Off |                  N/A |\n| 36%   39C    P8    N/A /  50W |      1MiB /  3911MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   4  NVIDIA A100-SXM...  On   | 00000000:C2:00.0 Off |                   On |\n| N/A   37C    P0    55W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n총 4개의 GPU가 있으며 아이디는 0,1,2,4 임을 알 수 있다.\n- GPUdev-ID, GI-ID, CI-ID, MIGdev-ID 확인\n+-----------------------------------------------------------------------------+\n| MIG devices:                                                                |\n+------------------+----------------------+-----------+-----------------------+\n| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |\n|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|\n|                  |                      |        ECC|                       |\n|==================+======================+===========+=======================|\n|  1    0   0   0  |      0MiB / 81251MiB | 98      0 |  7   0    5    1    1 |\n|                  |      1MiB / 13107... |           |                       |\n+------------------+----------------------+-----------+-----------------------+\n|  2    0   0   0  |      0MiB / 81251MiB | 98      0 |  7   0    5    1    1 |\n|                  |      1MiB / 13107... |           |                       |\n+------------------+----------------------+-----------+-----------------------+\n아래와 같은 상황을 유추할 수 있다.\n\n\n\nGPUdev ID\nGI ID\nCI ID\nMIGdev ID\n\n\n\n\n1\n0 (80G)\n0 (98SM)\n0\n\n\n2\n0 (80G)\n0 (98SM)\n0\n\n\n\n- 생성가능한 gi 확인\n\n- 생성가능한 ci 확인\n\n\n\nNote: GPU 1,2 에만 GI가 존재하므로, 목록에는 GPU 1,2 만 보임"
  },
  {
    "objectID": "메모/2000-01-10-(메모) -- DGX staion.html#c.-gi-생성",
    "href": "메모/2000-01-10-(메모) -- DGX staion.html#c.-gi-생성",
    "title": "(메모) – DGX station 설정",
    "section": "",
    "text": "- GPUdev = 4 에서 생성가능한 GI 조회\n#nvidia-smi mig -i {GPUdev-ID} -lgip\nnvidia-smi mig -i 4 -lgip\n\n- 아래에 해당하는 GI를 2개 생성하고 싶다고 하자. (GPU-INSTANCE-PROFILE-ID=9 임을 유의)\n+-----------------------------------------------------------------------------+\n| GPU instance profiles:                                                      |\n| GPU   Name             ID    Instances   Memory     P2P    SM    DEC   ENC  |\n|                              Free/Total   GiB              CE    JPEG  OFA  |\n|=============================================================================|\n|   4  MIG 3g.40gb        9     0/2        39.50      No     42     2     0   |\n|                                                             3     0     0   |\n+-----------------------------------------------------------------------------+\n#nvidia-smi mig -i {GPUdev-ID} -cgi {GPU-INSTANCE-PROFILE-ID}\nnvidia-smi mig -i 4 -cgi 9 \nnvidia-smi mig -i 4 -cgi 9 \n\n\n\nNote: 2개까지는 잘 ㅁ나들어지고 그 이후에는 리소스 부족으로 에러가 발생한다.\n\n\n\n2개까지는 잘 만들어지고 그 이후에는 리소스부족으로 에러발생\n\n- 만들어진 GI 확인\n\n\n\nNote: 1,2번 GPU에 각각 GI가 1개씩 있고 4번 GPU에 GI가 2개 있다.\n\n\n- 생성가능한 CI 확인\nnvidia-smi mig -lcip\n\n\n\nNote: {GPU ID: GPU INSTANCE ID} 의 조합에서 {1:0}, {2:0}, {4:1}, {4:2} 에 해당하는 GI에서 생성가능한 CI들이 각각 출력된다. 4번 GPU의 GI들은 40기가가 한계이므로 생성가능 CI목록이 상대적으로 제한적임을 캐치하라"
  },
  {
    "objectID": "메모/2000-01-10-(메모) -- DGX staion.html#d.-ci-생성",
    "href": "메모/2000-01-10-(메모) -- DGX staion.html#d.-ci-생성",
    "title": "(메모) – DGX station 설정",
    "section": "",
    "text": "- GPUdev=4 에서 생성가능한 CI 조회\n#nvidia-smi mig -i {GPU ID} -lcip\nnvidia-smi mig -i 4 -lcip\n\n\n\nNote: 각 GPU-인스턴스(GI)에서는 3개 계산-인스턴스(CI)를 만들수 있음. 만약에 Profile ID = 0 으로 만든다면 14의 계산능력을 가진 CI를 3개까지 만들수 있음, 만약 Profile ID = 2* 로 만든다면 42개의 계산능력을 가진 CI를 1개만 만들 수 있음\n\n\n- {GPUdev-ID:GI-ID} = {4:1} 에서 COMPUTE-INSTANCE-PROFILE-ID=0 에 해당하는 CI를 3개 생성\n#nvidia-smi mig -i {GPUdev-ID} -gi {GI-ID} -cci {COMPUTE-INSTANCE-PROFILE-ID}\nnvidia-smi mig -i 4 -gi 1 -cci 0\n\n\n\nNote: 자원부족으로 3개까지 밖에 못만든다..\n\n\n- {GPUdev-ID:GI-ID}={4:2} 에서 COMPUTE-INSTANCE-PROFILE-ID=2 에 해당하는 CI를 1개 생성\n#nvidia-smi mig -i {GPUdev-ID} -gi {GI-ID} -cci {COMPUTE-INSTANCE-PROFILE-ID}\nnvidia-smi mig -i 4 -gi 2 -cci 2 \n\n\n\nNote: 자원이 부족해서 1개밖에 못 만든다.\n\n\n- 현재 상황\n\n\n\n\nGPUdev ID\nGI ID\nCI ID\nMIGdev ID\n\n\n\n\n1\n0 (80G)\n0 (98SM)\n0\n\n\n2\n0 (80G)\n0 (98SM)\n0\n\n\n4\n1 (80G)\n0 (14SM)\n0\n\n\n4\n1 (80G)\n1 (14SM)\n1\n\n\n4\n1 (80G)\n2 (14SM)\n2\n\n\n4\n2 (80G)\n0 (42SM)\n3"
  },
  {
    "objectID": "메모/2000-01-10-(메모) -- DGX staion.html#a.-컨테이너-생성",
    "href": "메모/2000-01-10-(메모) -- DGX staion.html#a.-컨테이너-생성",
    "title": "(메모) – DGX station 설정",
    "section": "A. 컨테이너 생성",
    "text": "A. 컨테이너 생성\n- 아래와 같은 방식으로 컨테이너 생성\n# nvidia-docker run --gpus '\"device={GPUdev-ID}:{MIGdev-ID}\"' -ti --rm -d -t -p {HOST-PORT}:{CONTAINER-PORT} {DOCKER-IMAGE-NAME} /bin/bash\nnvidia-docker run --gpus '\"device=1:0\"' -ti --rm -d -t -p 7749:7749  -p 1307:1307 ubuntu /bin/bash\nnvidia-docker run --gpus '\"device=2:0\"' -ti -d -t -p 4653:4653  -p 1212:1212 -p 1213:1213 -p 1214:1214 ubuntu /bin/bash\n\n-ti: 컨테이너를 대화형(interactive) 모드로 실행. 이 모드에서 컨테이너와 상호작용할 수 있음.\n--rm: 컨테이너가 종료되면 자동으로 컨테이너를 삭제. 이 옵션을 사용하면 컨테이너를 실행한 후 자동으로 정리.\n-d: 컨테이너를 백그라운드(background) 모드로 실행. 이 옵션을 사용하면 컨테이너가 백그라운드에서 실행되며 터미널이 차지되지 않음.\n-t: 컨테이너에 tty (터미널)를 할당. 이것은 대화형 모드와 함께 사용.\n/bin/bash: 컨테이너가 시작될 때 실행할 명령어. 이 경우, Bash 셸을 실행."
  },
  {
    "objectID": "메모/2000-01-10-(메모) -- DGX staion.html#b.-컨테이너-실행",
    "href": "메모/2000-01-10-(메모) -- DGX staion.html#b.-컨테이너-실행",
    "title": "(메모) – DGX station 설정",
    "section": "B. 컨테이너 실행",
    "text": "B. 컨테이너 실행\ndocker exec -ti {CONTAINER-ID} bash\n\n여기에서 {CONTAINER-ID}는 docker ps 혹은 docker ps -a로 확인한다."
  },
  {
    "objectID": "메모/2000-01-10-(메모) -- DGX staion.html#a.-passwd",
    "href": "메모/2000-01-10-(메모) -- DGX staion.html#a.-passwd",
    "title": "(메모) – DGX station 설정",
    "section": "A. passwd",
    "text": "A. passwd\n- 아래를 실행하여 비밀번호를 바꿀것\npasswd root"
  },
  {
    "objectID": "메모/2000-01-10-(메모) -- DGX staion.html#b.-update",
    "href": "메모/2000-01-10-(메모) -- DGX staion.html#b.-update",
    "title": "(메모) – DGX station 설정",
    "section": "B. update",
    "text": "B. update\n- 아래를 실행\napt update \napt install gcc\napt install build-essential"
  },
  {
    "objectID": "메모/2000-01-10-(메모) -- DGX staion.html#c.-쓸만한-패키지-설치",
    "href": "메모/2000-01-10-(메모) -- DGX staion.html#c.-쓸만한-패키지-설치",
    "title": "(메모) – DGX station 설정",
    "section": "C. 쓸만한 패키지 설치",
    "text": "C. 쓸만한 패키지 설치\n- 아래를 설치하면 좋음..\napt install vim \napt install openssh-server\napt install git"
  },
  {
    "objectID": "메모/2000-01-10-(메모) -- DGX staion.html#d.-ssh",
    "href": "메모/2000-01-10-(메모) -- DGX staion.html#d.-ssh",
    "title": "(메모) – DGX station 설정",
    "section": "D. ssh",
    "text": "D. ssh\n# apt install openssh-server\nvi /etc/ssh/sshd_config \nPort {My-SSH-Port}\nPermitRootLogin yes\nPasswordAuthentication yes\nservice ssh restart"
  },
  {
    "objectID": "메모/2000-01-10-(메모) -- DGX staion.html#e.-anaconda",
    "href": "메모/2000-01-10-(메모) -- DGX staion.html#e.-anaconda",
    "title": "(메모) – DGX station 설정",
    "section": "E. anaconda",
    "text": "E. anaconda\n- 생략"
  },
  {
    "objectID": "메모/2000-01-10-(메모) -- DGX staion.html#f.-vscode",
    "href": "메모/2000-01-10-(메모) -- DGX staion.html#f.-vscode",
    "title": "(메모) – DGX station 설정",
    "section": "F. vscode",
    "text": "F. vscode\n- 아래를 이용하여 설치\ncurl -Lk 'https://code.visualstudio.com/sha/download?build=stable&os=cli-alpine-x64' --output vscode_cli.tar.gz\ntar -xf vscode_cli.tar.gz\n- 아래를 이용하여 초기 설정 (깃헙아이디로 인증)\n./code tunnel \n- 초기설정 이후 아래를 이용하여 백그라운드에서 실행\nnohup ./code tunnel &gt; /dev/null 2&gt;&1 &\n- 패키지설치"
  },
  {
    "objectID": "메모/2000-01-10-(메모) -- DGX staion.html#g.-jupyter",
    "href": "메모/2000-01-10-(메모) -- DGX staion.html#g.-jupyter",
    "title": "(메모) – DGX station 설정",
    "section": "G. Jupyter",
    "text": "G. Jupyter\n- 암호설정: 여기로..\n- 주피터 실행할때 아래로 실행\nnohup jupyter lab --ip=\"0.0.0.0\" --port={MY-PORT} --no-browser --allow-root &gt; /dev/null 2&gt;&1 &"
  },
  {
    "objectID": "공부/2023-06-28-(공부&지윤) -- 커널리그레션.html",
    "href": "공부/2023-06-28-(공부&지윤) -- 커널리그레션.html",
    "title": "(공부&지윤) – 커널리그레션",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\n\nx = np.linspace(0,1,5)\nx\n\narray([0.  , 0.25, 0.5 , 0.75, 1.  ])\n\n\n\ny = x*2 + np.random.randn(5)*0.3\ny\n\narray([0.01044984, 0.93755458, 0.43942577, 1.0639859 , 2.1133726 ])\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,2*x,'--')\n\n\n\n\n\n\n\n\n\\[y_i= \\sum_{i=1}^{5}\\theta_i\\exp\\left(-\\frac{|x-x_i|^2}{2h^2}\\right)\\]\n\nh= 0.15\nx0 = lambda xstar: np.exp(-(xstar-x[0])**2 / 2 / (h**2))\nx1 = lambda xstar: np.exp(-(xstar-x[1])**2 / 2 / (h**2))\nx2 = lambda xstar: np.exp(-(xstar-x[2])**2 / 2 / (h**2))\nx3 = lambda xstar: np.exp(-(xstar-x[3])**2 / 2 / (h**2))\nx4 = lambda xstar: np.exp(-(xstar-x[4])**2 / 2 / (h**2))\n\n\nθ0 = 0\nθ1 = 0.2\nθ2 = 0.5\nθ3 = 1.0\nθ4 = 1.5\n\n\nxstar = 0.6 \n\n\nθ0*x0(0.6)+θ1*x1(0.6)+θ2*x2(0.6)+θ3*x3(0.6)+θ4*x4(0.6)\n\n1.062893318071169\n\n\n\n_yhat = lambda xstar : θ0*x0(xstar)+\\\nθ1*x1(xstar)+\\\nθ2*x2(xstar)+\\\nθ3*x3(xstar)+\\\nθ4*x4(xstar)\n\n\n(_yhat(0)-y[0])**2\n\n0.0017104251892816106\n\n\n\nloss = (_yhat(0)-y[0])**2 + (_yhat(0.25)-y[1])**2+ \\\n(_yhat(0.5)-y[2])**2+(_yhat(0.75)-y[3])**2+\\\n(_yhat(1)-y[4])**2\n\n\\(loss(\\theta_0,\\theta_1,\\theta_2,\\theta_3,\\theta_4)\\) 를 최소화하는 \\({\\boldsymbol \\theta}\\)를 구한다.\n\n_x = np.linspace(0,1,1000)\nplt.plot(x,y,'o')\nplt.plot(x,2*x,'--')\nplt.plot(_x,_yhat(_x))"
  },
  {
    "objectID": "연구/지윤/SOLAR/2023-08-14-(연구) 지윤 -- 태양광자료분석, GConvLSTM +++++++ 이거!!! ++++++++++++.html",
    "href": "연구/지윤/SOLAR/2023-08-14-(연구) 지윤 -- 태양광자료분석, GConvLSTM +++++++ 이거!!! ++++++++++++.html",
    "title": "(연구&지윤) 태양광자료분석 – GConvLSTM +++++++ 이거!!! ++++++++++++",
    "section": "",
    "text": "변경사항: RGCN_Learner 수정 – 일부기능추가\n\n\n포인트: 배치학습을 적용하여 update가 빨리이루어지도록 코드수정\n\n\n\n\n# modules \nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nimport eptstgcn\nimport eptstgcn.planner\nimport torch_geometric_temporal\nfrom torch_geometric_temporal.signal.static_graph_temporal_signal import StaticGraphTemporalSignal\nimport mplcyberpunk\n\n# torch\nimport torch\nimport torch.nn.functional as F\n#import torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvLSTM\n# from torch_geometric_temporal.nn.recurrent import GCLSTM\n# from torch_geometric_temporal.nn.recurrent import LRGCN\n# from torch_geometric_temporal.nn.recurrent import TGCN\n# from torch_geometric_temporal.nn.recurrent import DCRNN\n\n# read data\ndef makedict(FX,W=None,node_ids=None):\n    T,N = np.array(FX).shape\n    if W==None:\n        W = pd.DataFrame(FX).corr().to_numpy().reshape(-1).tolist() # corr 로 weights\n    if node_ids==None:\n        node_ids = ['node'+str(n) for n in range(N)]\n    _dict={\n        'edges':[[i,j] for i in range(N) for j in range(N)], \n        'node_ids': node_ids,\n        'weights':W,\n        'FX':FX\n    }\n    return _dict\n\nclass Loader(object):\n    def __init__(self, data_dict):\n        self._dataset = data_dict\n    \n    def _get_edges(self):\n        self._edges = np.array(self._dataset[\"edges\"]).T\n\n    def _get_edge_weights(self):\n        # self._edge_weights = np.array(self._dataset[\"weights\"]).T\n        edge_weights = np.array(self._dataset[\"weights\"]).T\n        #scaled_edge_weights = minmaxscaler(edge_weights)\n        self._edge_weights = edge_weights\n\n    def _get_targets_and_features(self):\n        stacked_target = np.stack(self._dataset[\"FX\"])\n        self.features = np.stack([\n            stacked_target[i : i + self.lags, :].T\n            for i in range(stacked_target.shape[0] - self.lags)\n        ])\n        self.targets = np.stack([\n            stacked_target[i + self.lags, :].T\n            for i in range(stacked_target.shape[0] - self.lags)\n        ])\n\n\n    def get_dataset(self, lags: int = 4) -&gt; StaticGraphTemporalSignal:\n        self.lags = lags\n        self._get_edges()\n        self._get_edge_weights()\n        self._get_targets_and_features()\n        dataset = StaticGraphTemporalSignal(\n            self._edges, self._edge_weights, self.features, self.targets\n        )\n        dataset.node_ids = self._dataset['node_ids']\n        return dataset\n    \nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvLSTM(in_channels = node_features, out_channels = filters, K = 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight, h, c):\n        h_0, c_0 = self.recurrent(x, edge_index, edge_weight, h, c)\n        h = F.relu(h_0)\n        h = self.linear(h)\n        return h, h_0, c_0\n    \n    \n# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\ndevice = torch.device('cpu')\n\nclass RGCN_Learner:\n    def __init__(self):\n        self.method = 'RecurrentGCN'\n        self.figs = []\n        self.epochs = 0\n        self.losses = []\n        self._node_idx = 0\n    def load(self,y): \n        if (self.lags is None) or (self.train_ratio is None):\n            self.lags = 4\n            self.train_ratio = 0.8 \n        self.t,self.n = y.shape\n        dct = makedict(FX=y.tolist())\n        self.loader = Loader(dct)\n        self.dataset = self.loader.get_dataset(lags=self.lags)\n        self.X = torch.tensor(self.dataset.features).float()\n        self.y = torch.tensor(self.dataset.targets).float()\n        self.train_dataset, self.test_dataset = eptstgcn.utils.temporal_signal_split(self.dataset, train_ratio = self.train_ratio)\n        self.len_test = self.test_dataset.snapshot_count\n        self.len_tr = self.train_dataset.snapshot_count\n        #self.dataset_name = str(self.train_dataset) if dataset_name is None else dataset_name\n    def get_batches(self, batch_size=256):\n        num_batches =  self.len_tr // batch_size + (1 if self.len_tr % batch_size != 0 else 0)\n        self.batches = []\n        for i in range(num_batches):\n            start_idx = i * batch_size\n            end_idx = start_idx + batch_size\n            self.batches.append(self.train_dataset[start_idx:end_idx])\n    \n    def learn(self,epoch=1):\n        self.model.train()\n        for e in range(epoch):\n            losses_batch = []\n            for b,batch in enumerate(self.batches):\n                loss = 0\n                self.h, self.c = None, None\n                for t, snapshot in enumerate(batch):\n                    snapshot = snapshot.to(device)\n                    yt_hat, self.h, self.c = self.model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, self.h, self.c)\n                    loss = loss + torch.mean((yt_hat.reshape(-1)-snapshot.y.reshape(-1))**2)\n                    print(f'\\rbatch={b}\\t t={t+1}\\t loss={loss/(t+1)}\\t', end='', flush=True)\n                loss = loss / (t+1)\n                loss.backward()\n                self.optimizer.step()\n                self.optimizer.zero_grad()\n                losses_batch.append(loss.item())\n            self.epochs = self.epochs + 1\n            print(f'\\repoch={self.epochs}\\t loss={np.mean(losses_batch)}\\n', end='', flush=True)\n        self.losses.append(np.mean(losses_batch))\n        self._savefigs() \n    def _savefigs(self): \n        self.__call__()\n        self._node_idx\n        with plt.style.context('default'): \n            plt.ioff()\n            plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n            fig,ax = plt.subplots()\n            ax.plot(self.y[:,self._node_idx],label='real',lw=0.5)\n            ax.plot(self.yhat[:,self._node_idx],'--',label='predited',alpha=0.5)\n            ax.set_title(f'Epoch={self.epochs}, node_idx={self._node_idx}',size=15)\n            ax.legend()\n            #mplcyberpunk.add_glow_effects()  \n        self.figs.append(fig)\n        plt.close()\n    def __call__(self,dataset=None):\n        if dataset == None: \n            dataset = self.dataset\n        self.yhat = torch.stack([self.model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, self.h, self.c)[0] for snapshot in dataset]).detach().squeeze().float()\n        return {'X':self.X, 'y':self.y, 'yhat':self.yhat} \n\n# learn \n# def rgcn(FX,train_ratio,lags,filters,epoch):\n#     dct = makedict(FX=FX.tolist())\n#     loader = Loader(dct)\n#     dataset = loader.get_dataset(lags=lags)\n#     dataset_tr, dataset_test = eptstgcn.utils.temporal_signal_split(dataset, train_ratio = train_ratio)\n#     lrnr = RGCN_Learner(dataset_tr, dataset_name = 'org & arbitrary')\n#     lrnr.learn(filters=filters, epoch=epoch)\n#     yhat = np.array(lrnr(dataset)['yhat'])\n#     yhat = np.concatenate([np.array([list(yhat[0])]*lags),yhat],axis=0)\n#     return yhat\n\n\n\n\n\n# read dataframe \ndf = pd.read_csv('data_eng_230710.csv')\n# make y, y_upper, y_period, time, regions \ny = df.loc[:,'Bukchoncheon':'Gyeongju-si'].to_numpy()\nyU = df.loc[:,'Bukchoncheon_Upper':'Gyeongju-si_Upper'].to_numpy()\nyP = np.divide(y, yU+1e-10)\n\n\n\n\n- 예시1: y를 학습\n학습~\n\n# step1: create lrnr object\nlrnr = RGCN_Learner()\n# step2: load data \nlrnr.lags = 4 \nlrnr.train_ratio = 0.8\nlrnr.load(y) \n# step3: construct networks \nlrnr.nof_filters = 16\nlrnr.model = RecurrentGCN(node_features=lrnr.lags, filters=lrnr.nof_filters).to(device)\nlrnr.optimizer = torch.optim.Adam(lrnr.model.parameters(),lr=10/1000)\n# step4: learn \nlrnr.get_batches(batch_size=24)\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=1  loss=0.348616252371738191366577        \nepoch=2  loss=0.096857151493083602352905            \nepoch=3  loss=0.085899897092996645071335            \nepoch=4  loss=0.082436966038374011698761            \nepoch=5  loss=0.080951251696015514699783            \n\n\n\nlrnr.y.shape\n\ntorch.Size([2564, 44])\n\n\n\nlrnr.get_batches(batch_size=24)\n\n\nlrnr.batches[-1]\n\n&lt;torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal at 0x7fa2cfbc7cd0&gt;\n\n\n\nplt.plot(y[:100,0])\n\n에폭별 적합결과(\\(\\hat{y}\\)) 시각화\n\nlrnr.figs[0]\n\n\n\n\n\n\n\n\n\nlrnr.figs[1]\n\n\n\n\n\n\n\n\n\nlrnr.figs[-1]\n\n\n\n\n\n\n\n\n- 예시2: yU 학습\n\n# step1: create lrnr object\nlrnr = RGCN_Learner()\n# step2: load data \nlrnr.lags = 4 \nlrnr.train_ratio = 0.8\nlrnr.load(yU) \n# step3: construct networks \nlrnr.nof_filters = 16\nlrnr.model = RecurrentGCN(node_features=lrnr.lags, filters=lrnr.nof_filters).to(device)\nlrnr.optimizer = torch.optim.Adam(lrnr.model.parameters(),lr=10/1000)\n# step4: learn \nlrnr.get_batches(batch_size=24)\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=1  loss=1.98579962707536175294647     \nepoch=2  loss=0.202098417204133351100159        \nepoch=3  loss=0.052548440736393594218872        \nepoch=4  loss=0.0272646296531135271772957   \nepoch=5  loss=0.0191931016526596582006645   \n\n\n\nlrnr.figs[-1]\n\n\n\n\n\n\n\n\n5번정도 더 돌려보자\n\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=6  loss=0.0169690931215882312923717       \nepoch=7  loss=0.0141667058247379891905975       \nepoch=8  loss=0.0124263072353896015870743       \nepoch=9  loss=0.0103476242200189951082373       \nepoch=10     loss=0.009508996026937005688799        \n\n\n\nlrnr.figs[-1]\n\n\n\n\n\n\n\n\n- 예시3: yP 학습\n\n# step1: create lrnr object\nlrnr = RGCN_Learner()\n# step2: load data \nlrnr.lags = 4 \nlrnr.train_ratio = 0.8\nlrnr.load(yP) \n# step3: construct networks \nlrnr.nof_filters = 16\nlrnr.model = RecurrentGCN(node_features=lrnr.lags, filters=lrnr.nof_filters).to(device)\nlrnr.optimizer = torch.optim.Adam(lrnr.model.parameters(),lr=10/1000)\n# step4: learn \nlrnr.get_batches(batch_size=24)\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=1  loss=0.030719049366970748393135            \nepoch=2  loss=0.0119630681123411254793358       \nepoch=3  loss=0.0109235838672882638420868       \nepoch=4  loss=0.0107088599754714682600975       \nepoch=5  loss=0.0105961727974719788335514       \n\n\n\nlrnr.figs[-1]"
  },
  {
    "objectID": "연구/지윤/SOLAR/2023-08-14-(연구) 지윤 -- 태양광자료분석, GConvLSTM +++++++ 이거!!! ++++++++++++.html#import",
    "href": "연구/지윤/SOLAR/2023-08-14-(연구) 지윤 -- 태양광자료분석, GConvLSTM +++++++ 이거!!! ++++++++++++.html#import",
    "title": "(연구&지윤) 태양광자료분석 – GConvLSTM +++++++ 이거!!! ++++++++++++",
    "section": "",
    "text": "# modules \nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nimport eptstgcn\nimport eptstgcn.planner\nimport torch_geometric_temporal\nfrom torch_geometric_temporal.signal.static_graph_temporal_signal import StaticGraphTemporalSignal\nimport mplcyberpunk\n\n# torch\nimport torch\nimport torch.nn.functional as F\n#import torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvLSTM\n# from torch_geometric_temporal.nn.recurrent import GCLSTM\n# from torch_geometric_temporal.nn.recurrent import LRGCN\n# from torch_geometric_temporal.nn.recurrent import TGCN\n# from torch_geometric_temporal.nn.recurrent import DCRNN\n\n# read data\ndef makedict(FX,W=None,node_ids=None):\n    T,N = np.array(FX).shape\n    if W==None:\n        W = pd.DataFrame(FX).corr().to_numpy().reshape(-1).tolist() # corr 로 weights\n    if node_ids==None:\n        node_ids = ['node'+str(n) for n in range(N)]\n    _dict={\n        'edges':[[i,j] for i in range(N) for j in range(N)], \n        'node_ids': node_ids,\n        'weights':W,\n        'FX':FX\n    }\n    return _dict\n\nclass Loader(object):\n    def __init__(self, data_dict):\n        self._dataset = data_dict\n    \n    def _get_edges(self):\n        self._edges = np.array(self._dataset[\"edges\"]).T\n\n    def _get_edge_weights(self):\n        # self._edge_weights = np.array(self._dataset[\"weights\"]).T\n        edge_weights = np.array(self._dataset[\"weights\"]).T\n        #scaled_edge_weights = minmaxscaler(edge_weights)\n        self._edge_weights = edge_weights\n\n    def _get_targets_and_features(self):\n        stacked_target = np.stack(self._dataset[\"FX\"])\n        self.features = np.stack([\n            stacked_target[i : i + self.lags, :].T\n            for i in range(stacked_target.shape[0] - self.lags)\n        ])\n        self.targets = np.stack([\n            stacked_target[i + self.lags, :].T\n            for i in range(stacked_target.shape[0] - self.lags)\n        ])\n\n\n    def get_dataset(self, lags: int = 4) -&gt; StaticGraphTemporalSignal:\n        self.lags = lags\n        self._get_edges()\n        self._get_edge_weights()\n        self._get_targets_and_features()\n        dataset = StaticGraphTemporalSignal(\n            self._edges, self._edge_weights, self.features, self.targets\n        )\n        dataset.node_ids = self._dataset['node_ids']\n        return dataset\n    \nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvLSTM(in_channels = node_features, out_channels = filters, K = 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight, h, c):\n        h_0, c_0 = self.recurrent(x, edge_index, edge_weight, h, c)\n        h = F.relu(h_0)\n        h = self.linear(h)\n        return h, h_0, c_0\n    \n    \n# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\ndevice = torch.device('cpu')\n\nclass RGCN_Learner:\n    def __init__(self):\n        self.method = 'RecurrentGCN'\n        self.figs = []\n        self.epochs = 0\n        self.losses = []\n        self._node_idx = 0\n    def load(self,y): \n        if (self.lags is None) or (self.train_ratio is None):\n            self.lags = 4\n            self.train_ratio = 0.8 \n        self.t,self.n = y.shape\n        dct = makedict(FX=y.tolist())\n        self.loader = Loader(dct)\n        self.dataset = self.loader.get_dataset(lags=self.lags)\n        self.X = torch.tensor(self.dataset.features).float()\n        self.y = torch.tensor(self.dataset.targets).float()\n        self.train_dataset, self.test_dataset = eptstgcn.utils.temporal_signal_split(self.dataset, train_ratio = self.train_ratio)\n        self.len_test = self.test_dataset.snapshot_count\n        self.len_tr = self.train_dataset.snapshot_count\n        #self.dataset_name = str(self.train_dataset) if dataset_name is None else dataset_name\n    def get_batches(self, batch_size=256):\n        num_batches =  self.len_tr // batch_size + (1 if self.len_tr % batch_size != 0 else 0)\n        self.batches = []\n        for i in range(num_batches):\n            start_idx = i * batch_size\n            end_idx = start_idx + batch_size\n            self.batches.append(self.train_dataset[start_idx:end_idx])\n    \n    def learn(self,epoch=1):\n        self.model.train()\n        for e in range(epoch):\n            losses_batch = []\n            for b,batch in enumerate(self.batches):\n                loss = 0\n                self.h, self.c = None, None\n                for t, snapshot in enumerate(batch):\n                    snapshot = snapshot.to(device)\n                    yt_hat, self.h, self.c = self.model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, self.h, self.c)\n                    loss = loss + torch.mean((yt_hat.reshape(-1)-snapshot.y.reshape(-1))**2)\n                    print(f'\\rbatch={b}\\t t={t+1}\\t loss={loss/(t+1)}\\t', end='', flush=True)\n                loss = loss / (t+1)\n                loss.backward()\n                self.optimizer.step()\n                self.optimizer.zero_grad()\n                losses_batch.append(loss.item())\n            self.epochs = self.epochs + 1\n            print(f'\\repoch={self.epochs}\\t loss={np.mean(losses_batch)}\\n', end='', flush=True)\n        self.losses.append(np.mean(losses_batch))\n        self._savefigs() \n    def _savefigs(self): \n        self.__call__()\n        self._node_idx\n        with plt.style.context('default'): \n            plt.ioff()\n            plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n            fig,ax = plt.subplots()\n            ax.plot(self.y[:,self._node_idx],label='real',lw=0.5)\n            ax.plot(self.yhat[:,self._node_idx],'--',label='predited',alpha=0.5)\n            ax.set_title(f'Epoch={self.epochs}, node_idx={self._node_idx}',size=15)\n            ax.legend()\n            #mplcyberpunk.add_glow_effects()  \n        self.figs.append(fig)\n        plt.close()\n    def __call__(self,dataset=None):\n        if dataset == None: \n            dataset = self.dataset\n        self.yhat = torch.stack([self.model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, self.h, self.c)[0] for snapshot in dataset]).detach().squeeze().float()\n        return {'X':self.X, 'y':self.y, 'yhat':self.yhat} \n\n# learn \n# def rgcn(FX,train_ratio,lags,filters,epoch):\n#     dct = makedict(FX=FX.tolist())\n#     loader = Loader(dct)\n#     dataset = loader.get_dataset(lags=lags)\n#     dataset_tr, dataset_test = eptstgcn.utils.temporal_signal_split(dataset, train_ratio = train_ratio)\n#     lrnr = RGCN_Learner(dataset_tr, dataset_name = 'org & arbitrary')\n#     lrnr.learn(filters=filters, epoch=epoch)\n#     yhat = np.array(lrnr(dataset)['yhat'])\n#     yhat = np.concatenate([np.array([list(yhat[0])]*lags),yhat],axis=0)\n#     return yhat"
  },
  {
    "objectID": "연구/지윤/SOLAR/2023-08-14-(연구) 지윤 -- 태양광자료분석, GConvLSTM +++++++ 이거!!! ++++++++++++.html#load-data",
    "href": "연구/지윤/SOLAR/2023-08-14-(연구) 지윤 -- 태양광자료분석, GConvLSTM +++++++ 이거!!! ++++++++++++.html#load-data",
    "title": "(연구&지윤) 태양광자료분석 – GConvLSTM +++++++ 이거!!! ++++++++++++",
    "section": "",
    "text": "# read dataframe \ndf = pd.read_csv('data_eng_230710.csv')\n# make y, y_upper, y_period, time, regions \ny = df.loc[:,'Bukchoncheon':'Gyeongju-si'].to_numpy()\nyU = df.loc[:,'Bukchoncheon_Upper':'Gyeongju-si_Upper'].to_numpy()\nyP = np.divide(y, yU+1e-10)"
  },
  {
    "objectID": "연구/지윤/SOLAR/2023-08-14-(연구) 지윤 -- 태양광자료분석, GConvLSTM +++++++ 이거!!! ++++++++++++.html#sample_codes",
    "href": "연구/지윤/SOLAR/2023-08-14-(연구) 지윤 -- 태양광자료분석, GConvLSTM +++++++ 이거!!! ++++++++++++.html#sample_codes",
    "title": "(연구&지윤) 태양광자료분석 – GConvLSTM +++++++ 이거!!! ++++++++++++",
    "section": "",
    "text": "- 예시1: y를 학습\n학습~\n\n# step1: create lrnr object\nlrnr = RGCN_Learner()\n# step2: load data \nlrnr.lags = 4 \nlrnr.train_ratio = 0.8\nlrnr.load(y) \n# step3: construct networks \nlrnr.nof_filters = 16\nlrnr.model = RecurrentGCN(node_features=lrnr.lags, filters=lrnr.nof_filters).to(device)\nlrnr.optimizer = torch.optim.Adam(lrnr.model.parameters(),lr=10/1000)\n# step4: learn \nlrnr.get_batches(batch_size=24)\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=1  loss=0.348616252371738191366577        \nepoch=2  loss=0.096857151493083602352905            \nepoch=3  loss=0.085899897092996645071335            \nepoch=4  loss=0.082436966038374011698761            \nepoch=5  loss=0.080951251696015514699783            \n\n\n\nlrnr.y.shape\n\ntorch.Size([2564, 44])\n\n\n\nlrnr.get_batches(batch_size=24)\n\n\nlrnr.batches[-1]\n\n&lt;torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal at 0x7fa2cfbc7cd0&gt;\n\n\n\nplt.plot(y[:100,0])\n\n에폭별 적합결과(\\(\\hat{y}\\)) 시각화\n\nlrnr.figs[0]\n\n\n\n\n\n\n\n\n\nlrnr.figs[1]\n\n\n\n\n\n\n\n\n\nlrnr.figs[-1]\n\n\n\n\n\n\n\n\n- 예시2: yU 학습\n\n# step1: create lrnr object\nlrnr = RGCN_Learner()\n# step2: load data \nlrnr.lags = 4 \nlrnr.train_ratio = 0.8\nlrnr.load(yU) \n# step3: construct networks \nlrnr.nof_filters = 16\nlrnr.model = RecurrentGCN(node_features=lrnr.lags, filters=lrnr.nof_filters).to(device)\nlrnr.optimizer = torch.optim.Adam(lrnr.model.parameters(),lr=10/1000)\n# step4: learn \nlrnr.get_batches(batch_size=24)\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=1  loss=1.98579962707536175294647     \nepoch=2  loss=0.202098417204133351100159        \nepoch=3  loss=0.052548440736393594218872        \nepoch=4  loss=0.0272646296531135271772957   \nepoch=5  loss=0.0191931016526596582006645   \n\n\n\nlrnr.figs[-1]\n\n\n\n\n\n\n\n\n5번정도 더 돌려보자\n\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=6  loss=0.0169690931215882312923717       \nepoch=7  loss=0.0141667058247379891905975       \nepoch=8  loss=0.0124263072353896015870743       \nepoch=9  loss=0.0103476242200189951082373       \nepoch=10     loss=0.009508996026937005688799        \n\n\n\nlrnr.figs[-1]\n\n\n\n\n\n\n\n\n- 예시3: yP 학습\n\n# step1: create lrnr object\nlrnr = RGCN_Learner()\n# step2: load data \nlrnr.lags = 4 \nlrnr.train_ratio = 0.8\nlrnr.load(yP) \n# step3: construct networks \nlrnr.nof_filters = 16\nlrnr.model = RecurrentGCN(node_features=lrnr.lags, filters=lrnr.nof_filters).to(device)\nlrnr.optimizer = torch.optim.Adam(lrnr.model.parameters(),lr=10/1000)\n# step4: learn \nlrnr.get_batches(batch_size=24)\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=1  loss=0.030719049366970748393135            \nepoch=2  loss=0.0119630681123411254793358       \nepoch=3  loss=0.0109235838672882638420868       \nepoch=4  loss=0.0107088599754714682600975       \nepoch=5  loss=0.0105961727974719788335514       \n\n\n\nlrnr.figs[-1]"
  },
  {
    "objectID": "연구/지윤/SOLAR/2023-07-20-시뮬레이션.html",
    "href": "연구/지윤/SOLAR/2023-07-20-시뮬레이션.html",
    "title": "(연구) 지윤 – 태양광자료분석, EPT + RGCN (시뮬레이션)",
    "section": "",
    "text": "%run 0807.py\n\n\nimport os\n\n\ns=Simulator()\n\n\nclass GConv_GRU(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(GConv_GRU, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n        \ns.simulate(\n    n_iteration = 1,\n    lags = [1],\n    filters = [4,6],\n    epoch = [1],\n    Model = GConv_GRU\n)\n\nmethod:classic lag:1 filters:4 epoch:1 is done\nmethod:classic lag:1 filters:6 epoch:1 is done\nmethod:proposed lag:1 filters:4 epoch:1 is done\nmethod:proposed lag:1 filters:6 epoch:1 is done\nsave results\n\n\n\nfnames = ['./results/'+l for l in os.listdir('./results/') if l[0] != '.']\nfnames \n\n['./results/SOLAR_2023-08-07 16:12:29.037623.csv',\n './results/SOLAR_2023-08-07 15:48:50.109743.csv',\n './results/SOLAR_2023-08-07 16:08:41.687843.csv',\n './results/SOLAR_2023-08-07 15:48:25.728993.csv',\n './results/SOLAR_2023-08-07 16:28:55.929269.csv']\n\n\n\npd.concat([pd.read_csv(fname) for fname in fnames]).reset_index(drop=True)\n\n\n\n\n\n\n\n\nindex_time\nmse_mean\nmodel\nmethod\nlags\nnof_filters\nepoch\ncalculation_time\nnode\nmse\n\n\n\n\n0\n2023-08-07 16:11:11.072667\n0.419854\nRecurrentGCN\nclassic\n1\n4\n1\n15.519606\nBukchoncheon\n0.491867\n\n\n1\n2023-08-07 16:11:11.072667\n0.419854\nRecurrentGCN\nclassic\n1\n4\n1\n15.519606\nCheorwon\n0.474034\n\n\n2\n2023-08-07 16:11:11.072667\n0.419854\nRecurrentGCN\nclassic\n1\n4\n1\n15.519606\nDaegwallyeong\n0.468020\n\n\n3\n2023-08-07 16:11:11.072667\n0.419854\nRecurrentGCN\nclassic\n1\n4\n1\n15.519606\nChuncheon\n0.433953\n\n\n4\n2023-08-07 16:11:11.072667\n0.419854\nRecurrentGCN\nclassic\n1\n4\n1\n15.519606\nBaengnyeongdo\n0.620410\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n875\n2023-08-07 16:28:55.924567\n0.139105\nGConvGRU\nproposed\n1\n6\n1\n30.982189\nUiryeong-gun\n0.140765\n\n\n876\n2023-08-07 16:28:55.924567\n0.139105\nGConvGRU\nproposed\n1\n6\n1\n30.982189\nHamyang-gun\n0.122213\n\n\n877\n2023-08-07 16:28:55.924567\n0.139105\nGConvGRU\nproposed\n1\n6\n1\n30.982189\nGwangyang-si\n0.144140\n\n\n878\n2023-08-07 16:28:55.924567\n0.139105\nGConvGRU\nproposed\n1\n6\n1\n30.982189\nCheongsong-gun\n0.143174\n\n\n879\n2023-08-07 16:28:55.924567\n0.139105\nGConvGRU\nproposed\n1\n6\n1\n30.982189\nGyeongju-si\n0.109372\n\n\n\n\n880 rows × 10 columns"
  },
  {
    "objectID": "연구/지윤/SOLAR/2023-07-20-(연구) 지윤 -- 태양광자료분석, EPT + RGCN (시뮬레이션).html",
    "href": "연구/지윤/SOLAR/2023-07-20-(연구) 지윤 -- 태양광자료분석, EPT + RGCN (시뮬레이션).html",
    "title": "(연구&지윤) 태양광자료분석 – EPT + RGCN (시뮬레이션)",
    "section": "",
    "text": "%run 0807.py\n\n\nimport os\n\n\ns=Simulator()\n\n\nclass GConv_GRU(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(GConv_GRU, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n        \ns.simulate(\n    n_iteration = 1,\n    lags = [1],\n    filters = [4,6],\n    epoch = [1],\n    Model = GConv_GRU\n)\n\nmethod:classic lag:1 filters:4 epoch:1 is done\nmethod:classic lag:1 filters:6 epoch:1 is done\nmethod:proposed lag:1 filters:4 epoch:1 is done\nmethod:proposed lag:1 filters:6 epoch:1 is done\nsave results\n\n\n\nfnames = ['./results/'+l for l in os.listdir('./results/') if l[0] != '.']\nfnames \n\n['./results/SOLAR_2023-08-07 16:12:29.037623.csv',\n './results/SOLAR_2023-08-07 15:48:50.109743.csv',\n './results/SOLAR_2023-08-07 16:08:41.687843.csv',\n './results/SOLAR_2023-08-07 15:48:25.728993.csv',\n './results/SOLAR_2023-08-07 16:28:55.929269.csv']\n\n\n\npd.concat([pd.read_csv(fname) for fname in fnames]).reset_index(drop=True)\n\n\n\n\n\n\n\n\nindex_time\nmse_mean\nmodel\nmethod\nlags\nnof_filters\nepoch\ncalculation_time\nnode\nmse\n\n\n\n\n0\n2023-08-07 16:11:11.072667\n0.419854\nRecurrentGCN\nclassic\n1\n4\n1\n15.519606\nBukchoncheon\n0.491867\n\n\n1\n2023-08-07 16:11:11.072667\n0.419854\nRecurrentGCN\nclassic\n1\n4\n1\n15.519606\nCheorwon\n0.474034\n\n\n2\n2023-08-07 16:11:11.072667\n0.419854\nRecurrentGCN\nclassic\n1\n4\n1\n15.519606\nDaegwallyeong\n0.468020\n\n\n3\n2023-08-07 16:11:11.072667\n0.419854\nRecurrentGCN\nclassic\n1\n4\n1\n15.519606\nChuncheon\n0.433953\n\n\n4\n2023-08-07 16:11:11.072667\n0.419854\nRecurrentGCN\nclassic\n1\n4\n1\n15.519606\nBaengnyeongdo\n0.620410\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n875\n2023-08-07 16:28:55.924567\n0.139105\nGConvGRU\nproposed\n1\n6\n1\n30.982189\nUiryeong-gun\n0.140765\n\n\n876\n2023-08-07 16:28:55.924567\n0.139105\nGConvGRU\nproposed\n1\n6\n1\n30.982189\nHamyang-gun\n0.122213\n\n\n877\n2023-08-07 16:28:55.924567\n0.139105\nGConvGRU\nproposed\n1\n6\n1\n30.982189\nGwangyang-si\n0.144140\n\n\n878\n2023-08-07 16:28:55.924567\n0.139105\nGConvGRU\nproposed\n1\n6\n1\n30.982189\nCheongsong-gun\n0.143174\n\n\n879\n2023-08-07 16:28:55.924567\n0.139105\nGConvGRU\nproposed\n1\n6\n1\n30.982189\nGyeongju-si\n0.109372\n\n\n\n\n880 rows × 10 columns"
  },
  {
    "objectID": "연구/지윤/SOLAR/2023-07-17-(연구) 지윤 -- 태양광자료분석, EPT + RGCN.html",
    "href": "연구/지윤/SOLAR/2023-07-17-(연구) 지윤 -- 태양광자료분석, EPT + RGCN.html",
    "title": "(연구) 지윤 – 태양광자료분석, EPT + RGCN",
    "section": "",
    "text": "Import\n- source\n\nhttps://github.com/miruetoto/yechan3/blob/main/posts/3_Researches/PINKOCTO/SOLAR/0720.py\n\n- download source\n\n# https://github.com/miruetoto/yechan3/blob/main/posts/3_Researches/PINKOCTO/SOLAR/0720.py\n\n- run\n\n%run 0720.py\n\n\n\nLoad data\n\n# read dataframe \ndf = pd.read_csv('https://media.githubusercontent.com/media/miruetoto/yechan3/main/posts/3_Researches/PINKOCTO/SOLAR/data_eng_230710.csv')\n\n# make y, y_upper, y_period, time, regions \ny = df.loc[:,'Bukchoncheon':'Gyeongju-si'].to_numpy()\nyU = df.loc[:,'Bukchoncheon_Upper':'Gyeongju-si_Upper'].to_numpy()\nyP = np.divide(y, yU+1e-10)\nt = df.loc[:,'date']\nregions = list(df.loc[:,'Bukchoncheon':'Gyeongju-si'].columns)\n\n# plot rawdata \nstart = 50 \nend = 50+24*3\ncity = 19 # 광주 \nwith plt.style.context('cyberpunk'):\n    plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n    plt.plot(t[start:end],y[start:end,city],'o',label='y')\n    plt.plot(t[start:end],yU[start:end,city],'--',label='yU')\n    plt.plot(t[start:end],yP[start:end,city],'o',label='y/yU')\n    tick_interval = 4\n    plt.xticks(range(1, len(t) + 1, tick_interval),rotation=25)        \n    plt.legend()\n    plt.title(\"The solar radiation data in {} from {} to {} \".format(regions[city],t.to_list()[0][:10],t.to_list()[-1][:10]))\n    mplcyberpunk.add_glow_effects()    \n\n\n\n\n\n\n\n\n\n\nLearn\n- y \\(\\to\\) yhat\n\n# hyper params\nLAGS = 4\nFILTERS = 8\nEPOCH = 5\n\n# global params\nTRAIN_RATIO = 0.8\nT,N = len(t),len(regions) \nLEN_TEST = int(np.floor(T*(1-TRAIN_RATIO)))\nLEN_TR = T - LEN_TEST\n\n# 방법1\nmodel = RecurrentGCN(node_features=LAGS, filters=FILTERS)\nyhat = rgcn(y, model = model, train_ratio = TRAIN_RATIO, lags=LAGS, epoch=EPOCH)\nyhat[yhat &lt; 0]= 0 \n\n# 방법2 \nmodel = RecurrentGCN(node_features=LAGS, filters=FILTERS)\nyUhat = rgcn(yU, model = model, train_ratio = TRAIN_RATIO, lags=LAGS, epoch=EPOCH)\n\nmodel = RecurrentGCN(node_features=LAGS, filters=FILTERS)\nyPhat = rgcn(yP, model = model, train_ratio = TRAIN_RATIO, lags=LAGS, epoch=EPOCH)\nyPhat[yPhat &lt; 0] =0 \n\n\nclassic = ((y - yhat)[LEN_TR:, :] ** 2)\nproposed = ((y - yUhat*yPhat)[LEN_TR:, :] ** 2)\n\n# print mse\nprint(\"\"\"\ntotal_mse(classic): {:.4f}\ntotal_mse(proposed): {:.4f}\n\"\"\".format(classic.mean(), proposed.mean()))\n\n5/5\ntotal_mse(classic): 0.0573\ntotal_mse(proposed): 0.0476\n\n\n\n\n# plot \nstart = LEN_TR \nend = LEN_TR + LEN_TEST \ncity = 20\ntick_interval = 24 \n\nclassic = (y - yhat)[start:end, :] ** 2\nproposed = (y - yUhat*yPhat)[start:end, :] ** 2\n\nprint(\"\"\"\ntotal_mse(classic): {:.4f}\ntotal_mse(proposed): {:.4f}\n\"\"\".format(classic.mean(), proposed.mean()))\n\nwith plt.style.context('cyberpunk'): \n    plt.rcParams['figure.figsize'] = [20, 4]  # [가로 크기, 세로 크기]\n    plt.plot(t[start:end],y[start:end,city],'-',label='real')\n    plt.plot(t[start:end],yhat[start:end,city],'--',label='predited(classic)')\n    plt.plot(t[start:end],(yUhat*yPhat)[start:end,city],'--',label='predited(proposed)')\n    plt.xticks(range(1, len(t[start:end]) + 1, tick_interval),rotation=25,ha='right')\n    plt.title(\"The predicted results in {} from {} to {} \".format(regions[city],t[start:end].to_list()[0][:10],t[start:end].to_list()[-1][:10]))    \n    plt.legend()\n    mplcyberpunk.add_glow_effects()\n\n\ntotal_mse(classic): 0.0573\ntotal_mse(proposed): 0.0476\n\n\n\n\n\n\n\n\n\n\n\n\nAnalyze\n- y vs yhat\n\nwith plt.style.context('seaborn-bright'): \n    plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n    plt.plot(y[50:150,0],'o-',label='real')\n    plt.plot(yhat[50:150,0],'o--',label='predited')\n    plt.legend()\n    mplcyberpunk.add_glow_effects()    \n\n\n\n\n\n\n\n\n- yU vs yUhat\n\nwith plt.style.context('seaborn-bright'): \n    plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n    plt.plot(yU[:,25],label='real')\n    plt.plot(yUhat[:,25],label='predited')\n    plt.legend()\n    mplcyberpunk.add_glow_effects()    \n\n\n\n\n\n\n\n\n- yP vs yPhat\n\nwith plt.style.context('seaborn-bright'): \n    plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n    plt.plot(yP[50:150,city],'o-',label='real')\n    plt.plot(yPhat[50:150,city],'o--',label='predited')\n    plt.legend()\n    mplcyberpunk.add_glow_effects()    \n\n\n\n\n\n\n\n\n- y vs (yUhat*yPhat)\n\nwith plt.style.context('seaborn-bright'): \n    plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n    plt.plot(y[50:150,0],'o-',label='real')\n    plt.plot((yUhat*yPhat)[50:150,0],'o--',label='predited')\n    plt.legend()\n    mplcyberpunk.add_glow_effects()    \n\n\n\n\n\n\n\n\n- 지역별분석\n\nwith plt.style.context('cyberpunk'):\n    plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n    plt.plot(regions,classic.mean(axis=0)-proposed.mean(axis=0),'--o');\n    plt.xticks(regions, rotation=55, ha='right');    \n    mplcyberpunk.add_glow_effects()"
  },
  {
    "objectID": "연구/지윤/SOLAR/2023-04-04-(연구) 지윤 -- 태양광자료분석, EPT.html",
    "href": "연구/지윤/SOLAR/2023-04-04-(연구) 지윤 -- 태양광자료분석, EPT.html",
    "title": "(연구) 지윤 – 태양광자료분석",
    "section": "",
    "text": "ref: https://www.sciencedirect.com/science/article/pii/S2352711021000492\n\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(EPT)\n\n\nurl = 'https://raw.githubusercontent.com/miruetoto/yechan3/main/posts/3_Researches/SOLAR/solar_radiation.csv'\ndf = read_csv(url)\n\nRows: 803000 Columns: 3\n── Column specification ────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): region, date\ndbl (1): solar_radiation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\ndf = df |&gt; filter(region == '북춘천') |&gt; mutate(date=ymd_hm(date))\ndf\n\n\nA tibble: 18250 × 3\n\n\nregion\nsolar_radiation\ndate\n\n\n&lt;chr&gt;\n&lt;dbl&gt;\n&lt;dttm&gt;\n\n\n\n\n북춘천\n0.00\n2021-01-01 00:00:00\n\n\n북춘천\n0.00\n2021-01-01 01:00:00\n\n\n북춘천\n0.00\n2021-01-01 02:00:00\n\n\n북춘천\n0.00\n2021-01-01 03:00:00\n\n\n북춘천\n0.00\n2021-01-01 04:00:00\n\n\n북춘천\n0.00\n2021-01-01 05:00:00\n\n\n북춘천\n0.00\n2021-01-01 06:00:00\n\n\n북춘천\n0.00\n2021-01-01 07:00:00\n\n\n북춘천\n0.00\n2021-01-01 08:00:00\n\n\n북춘천\n0.37\n2021-01-01 09:00:00\n\n\n북춘천\n0.96\n2021-01-01 10:00:00\n\n\n북춘천\n1.40\n2021-01-01 11:00:00\n\n\n북춘천\n1.72\n2021-01-01 12:00:00\n\n\n북춘천\n1.84\n2021-01-01 13:00:00\n\n\n북춘천\n1.74\n2021-01-01 14:00:00\n\n\n북춘천\n1.30\n2021-01-01 15:00:00\n\n\n북춘천\n0.93\n2021-01-01 16:00:00\n\n\n북춘천\n0.29\n2021-01-01 17:00:00\n\n\n북춘천\n0.01\n2021-01-01 18:00:00\n\n\n북춘천\n0.00\n2021-01-01 19:00:00\n\n\n북춘천\n0.00\n2021-01-01 07:00:00\n\n\n북춘천\n0.00\n2021-01-01 20:00:00\n\n\n북춘천\n0.00\n2021-01-01 06:00:00\n\n\n북춘천\n0.00\n2021-01-01 21:00:00\n\n\n북춘천\n0.00\n2021-01-01 05:00:00\n\n\n북춘천\n0.00\n2021-01-02 00:00:00\n\n\n북춘천\n0.00\n2021-01-02 01:00:00\n\n\n북춘천\n0.00\n2021-01-02 02:00:00\n\n\n북춘천\n0.00\n2021-01-02 03:00:00\n\n\n북춘천\n0.00\n2021-01-02 04:00:00\n\n\n⋮\n⋮\n⋮\n\n\n북춘천\n0.00\n2022-12-30 07:00:00\n\n\n북춘천\n0.00\n2022-12-30 20:00:00\n\n\n북춘천\n0.00\n2022-12-30 06:00:00\n\n\n북춘천\n0.00\n2022-12-30 21:00:00\n\n\n북춘천\n0.00\n2022-12-30 05:00:00\n\n\n북춘천\n0.00\n2022-12-31 00:00:00\n\n\n북춘천\n0.00\n2022-12-31 01:00:00\n\n\n북춘천\n0.00\n2022-12-31 02:00:00\n\n\n북춘천\n0.00\n2022-12-31 03:00:00\n\n\n북춘천\n0.00\n2022-12-31 04:00:00\n\n\n북춘천\n0.00\n2022-12-31 05:00:00\n\n\n북춘천\n0.00\n2022-12-31 06:00:00\n\n\n북춘천\n0.00\n2022-12-31 07:00:00\n\n\n북춘천\n0.00\n2022-12-31 08:00:00\n\n\n북춘천\n0.22\n2022-12-31 09:00:00\n\n\n북춘천\n0.50\n2022-12-31 10:00:00\n\n\n북춘천\n0.80\n2022-12-31 11:00:00\n\n\n북춘천\n2.13\n2022-12-31 12:00:00\n\n\n북춘천\n1.78\n2022-12-31 13:00:00\n\n\n북춘천\n1.45\n2022-12-31 14:00:00\n\n\n북춘천\n0.78\n2022-12-31 15:00:00\n\n\n북춘천\n0.38\n2022-12-31 16:00:00\n\n\n북춘천\n0.15\n2022-12-31 17:00:00\n\n\n북춘천\n0.00\n2022-12-31 18:00:00\n\n\n북춘천\n0.00\n2022-12-31 19:00:00\n\n\n북춘천\n0.00\n2022-12-31 07:00:00\n\n\n북춘천\n0.00\n2022-12-31 20:00:00\n\n\n북춘천\n0.00\n2022-12-31 06:00:00\n\n\n북춘천\n0.00\n2022-12-31 21:00:00\n\n\n북춘천\n0.00\n2022-12-31 05:00:00\n\n\n\n\n\n- 지역을 북춘천으로 고정\n\ndf2 = df |&gt; filter(region =='북춘천') \ndf2 = df2[order(df2$date),]\n\n\ny = df2$solar_radiation\ny\n\n\n0000000000000.370.961.41.721.841.741.30.930.290.010000000000000000.320.951.461.791.911.821.50.970.370.010000000000000000.290.891.41.751.761.350.820.520.30.010000000000000000.330.931.321.531.671.5110.790.1900000000000000000.190.791.411.761.931.851.561.050.450.020000000000000000.511.381.811.881.931.851.5210.410.020000000000000000.110.741.441.811.981.911.611.090.450.020000000000000000.360.971.491.8521.911.611.10.480.03000⋯000000000000.010.471.31.711.871.881.721.380.880.3200000000000000000.190.681.351.712.191.891.380.820.2600000000000000000.150.420.931.071.181.051.160.830.300000000000000000.080.280.430.741.41.841.530.850.2700000000000000000.411.021.841.921.851.721.420.930.340.010000000000000000.471.281.681.81.851.741.40.890.30.010000000000000000.150.641.11.732.121.741.290.860.310.010000000000000000.220.50.82.131.781.450.780.380.150000\n\n\n\nplot(y[1:500])\nlines(y[1:500],lty=2)\n\n\n\n\n\n\n\n\n- EPT 수행\n\nept = function(y){\n    EpM = eptransf(signal=y,tau=24,process=c(\"envelope\",\"average\"))$EpM\n    EpM*2\n}\n\n\nyU = ept(y)\n\n\nplot(y[1:500])\nlines(yU[1:500],col=2,lty=2)\n\n\n\n\n\n\n\n\n- todo: 모든 지역에대하여 yU를 구하여 저장"
  },
  {
    "objectID": "연구/지윤/SOLAR/2023-04-03-(연구&지윤) 태양광자료분석 -- 일사량자료정리.html",
    "href": "연구/지윤/SOLAR/2023-04-03-(연구&지윤) 태양광자료분석 -- 일사량자료정리.html",
    "title": "(연구&지윤) 태양광자료분석 – 일사량자료정리",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport itertools\n\n\ndf0 = pd.read_csv('https://raw.githubusercontent.com/pinkocto/noteda/main/posts/data/OBS_ASOS_TIM_data0.csv', encoding='cp949') # 2021-01-01 ~ 2021-12-31\ndf1 = pd.read_csv('https://raw.githubusercontent.com/pinkocto/noteda/main/posts/data/OBS_ASOS_TIM_data1.csv') # 2022-01-01 ~ 2023-12-31\ndf2 = pd.read_csv('https://raw.githubusercontent.com/pinkocto/noteda/main/posts/data/test_raw.csv', encoding='cp949') # 2023-01-01 ~ 2023-01-15\n\n- df_raw\n\ndf_raw = pd.concat([df0, df1])\ndf_raw\n\n\n\n\n\n\n\n\n지점\n지점명\n일시\n일사(MJ/m2)\n\n\n\n\n0\n93\n북춘천\n2021-01-01 08:00\n0.00\n\n\n1\n93\n북춘천\n2021-01-01 09:00\n0.37\n\n\n2\n93\n북춘천\n2021-01-01 10:00\n0.96\n\n\n3\n93\n북춘천\n2021-01-01 11:00\n1.40\n\n\n4\n93\n북춘천\n2021-01-01 12:00\n1.72\n\n\n...\n...\n...\n...\n...\n\n\n229672\n283\n경주시\n2022-12-31 14:00:00\n1.82\n\n\n229673\n283\n경주시\n2022-12-31 15:00:00\n1.52\n\n\n229674\n283\n경주시\n2022-12-31 16:00:00\n0.96\n\n\n229675\n283\n경주시\n2022-12-31 17:00:00\n0.35\n\n\n229676\n283\n경주시\n2022-12-31 18:00:00\n0.01\n\n\n\n\n444720 rows × 4 columns\n\n\n\n- 지점칼럼 삭제 // 일시 \\(\\to\\) 날짜,시간 으로 분리\n\ndf_temp = df_raw.assign(날짜= list(map(lambda x: x[:10],df_raw['일시'])))\\\n.assign(시간= list(map(lambda x: x[11:16],df_raw['일시'])))\\\n.drop(['일시','지점'],axis=1).rename({'일사(MJ/m2)':'일사'},axis=1).reset_index(drop=True)\ndf_temp\n\n\n\n\n\n\n\n\n지점명\n일사\n날짜\n시간\n\n\n\n\n0\n북춘천\n0.00\n2021-01-01\n08:00\n\n\n1\n북춘천\n0.37\n2021-01-01\n09:00\n\n\n2\n북춘천\n0.96\n2021-01-01\n10:00\n\n\n3\n북춘천\n1.40\n2021-01-01\n11:00\n\n\n4\n북춘천\n1.72\n2021-01-01\n12:00\n\n\n...\n...\n...\n...\n...\n\n\n444715\n경주시\n1.82\n2022-12-31\n14:00\n\n\n444716\n경주시\n1.52\n2022-12-31\n15:00\n\n\n444717\n경주시\n0.96\n2022-12-31\n16:00\n\n\n444718\n경주시\n0.35\n2022-12-31\n17:00\n\n\n444719\n경주시\n0.01\n2022-12-31\n18:00\n\n\n\n\n444720 rows × 4 columns\n\n\n\n- 파주,상주,동두천,충주,제천은 삭제\n\ndf_temp = df_temp.query(\"지점명 not in ['파주','상주','동두천','충주','제천']\").reset_index(drop=True)\ndf_temp\n\n\n\n\n\n\n\n\n지점명\n일사\n날짜\n시간\n\n\n\n\n0\n북춘천\n0.00\n2021-01-01\n08:00\n\n\n1\n북춘천\n0.37\n2021-01-01\n09:00\n\n\n2\n북춘천\n0.96\n2021-01-01\n10:00\n\n\n3\n북춘천\n1.40\n2021-01-01\n11:00\n\n\n4\n북춘천\n1.72\n2021-01-01\n12:00\n\n\n...\n...\n...\n...\n...\n\n\n420955\n경주시\n1.82\n2022-12-31\n14:00\n\n\n420956\n경주시\n1.52\n2022-12-31\n15:00\n\n\n420957\n경주시\n0.96\n2022-12-31\n16:00\n\n\n420958\n경주시\n0.35\n2022-12-31\n17:00\n\n\n420959\n경주시\n0.01\n2022-12-31\n18:00\n\n\n\n\n420960 rows × 4 columns\n\n\n\n- 시간이 비어있지 않도록..\n\nreg = df_temp['지점명'].unique().tolist() \nday = df_temp['날짜'].unique().tolist() \ntime = list(df_temp['시간'].unique())\ntime = ['0{}:00'.format(i) for i in range(0,8)] + time\n\n\ndf_temp2 = pd.DataFrame(itertools.product(reg,day,time)).rename({0:'지점명',1:'날짜',2:'시간'},axis=1).merge(df_temp,how='left').fillna(0)\ndf_temp2\n\n\n\n\n\n\n\n\n지점명\n날짜\n시간\n일사\n\n\n\n\n0\n북춘천\n2021-01-01\n00:00\n0.0\n\n\n1\n북춘천\n2021-01-01\n01:00\n0.0\n\n\n2\n북춘천\n2021-01-01\n02:00\n0.0\n\n\n3\n북춘천\n2021-01-01\n03:00\n0.0\n\n\n4\n북춘천\n2021-01-01\n04:00\n0.0\n\n\n...\n...\n...\n...\n...\n\n\n802995\n경주시\n2022-12-31\n07:00\n0.0\n\n\n802996\n경주시\n2022-12-31\n20:00\n0.0\n\n\n802997\n경주시\n2022-12-31\n06:00\n0.0\n\n\n802998\n경주시\n2022-12-31\n21:00\n0.0\n\n\n802999\n경주시\n2022-12-31\n05:00\n0.0\n\n\n\n\n803000 rows × 4 columns\n\n\n\n\ndf_temp2[:20]\n\n\n\n\n\n\n\n\n지점명\n날짜\n시간\n일사\n\n\n\n\n0\n북춘천\n2021-01-01\n00:00\n0.00\n\n\n1\n북춘천\n2021-01-01\n01:00\n0.00\n\n\n2\n북춘천\n2021-01-01\n02:00\n0.00\n\n\n3\n북춘천\n2021-01-01\n03:00\n0.00\n\n\n4\n북춘천\n2021-01-01\n04:00\n0.00\n\n\n5\n북춘천\n2021-01-01\n05:00\n0.00\n\n\n6\n북춘천\n2021-01-01\n06:00\n0.00\n\n\n7\n북춘천\n2021-01-01\n07:00\n0.00\n\n\n8\n북춘천\n2021-01-01\n08:00\n0.00\n\n\n9\n북춘천\n2021-01-01\n09:00\n0.37\n\n\n10\n북춘천\n2021-01-01\n10:00\n0.96\n\n\n11\n북춘천\n2021-01-01\n11:00\n1.40\n\n\n12\n북춘천\n2021-01-01\n12:00\n1.72\n\n\n13\n북춘천\n2021-01-01\n13:00\n1.84\n\n\n14\n북춘천\n2021-01-01\n14:00\n1.74\n\n\n15\n북춘천\n2021-01-01\n15:00\n1.30\n\n\n16\n북춘천\n2021-01-01\n16:00\n0.93\n\n\n17\n북춘천\n2021-01-01\n17:00\n0.29\n\n\n18\n북춘천\n2021-01-01\n18:00\n0.01\n\n\n19\n북춘천\n2021-01-01\n19:00\n0.00\n\n\n\n\n\n\n\n\ndf_temp2[-20:]\n\n\n\n\n\n\n\n\n지점명\n날짜\n시간\n일사\n\n\n\n\n802980\n경주시\n2022-12-31\n05:00\n0.00\n\n\n802981\n경주시\n2022-12-31\n06:00\n0.00\n\n\n802982\n경주시\n2022-12-31\n07:00\n0.00\n\n\n802983\n경주시\n2022-12-31\n08:00\n0.02\n\n\n802984\n경주시\n2022-12-31\n09:00\n0.41\n\n\n802985\n경주시\n2022-12-31\n10:00\n1.05\n\n\n802986\n경주시\n2022-12-31\n11:00\n1.52\n\n\n802987\n경주시\n2022-12-31\n12:00\n1.86\n\n\n802988\n경주시\n2022-12-31\n13:00\n1.93\n\n\n802989\n경주시\n2022-12-31\n14:00\n1.82\n\n\n802990\n경주시\n2022-12-31\n15:00\n1.52\n\n\n802991\n경주시\n2022-12-31\n16:00\n0.96\n\n\n802992\n경주시\n2022-12-31\n17:00\n0.35\n\n\n802993\n경주시\n2022-12-31\n18:00\n0.01\n\n\n802994\n경주시\n2022-12-31\n19:00\n0.00\n\n\n802995\n경주시\n2022-12-31\n07:00\n0.00\n\n\n802996\n경주시\n2022-12-31\n20:00\n0.00\n\n\n802997\n경주시\n2022-12-31\n06:00\n0.00\n\n\n802998\n경주시\n2022-12-31\n21:00\n0.00\n\n\n802999\n경주시\n2022-12-31\n05:00\n0.00\n\n\n\n\n\n\n\n\ndf_temp2\n\n\n\n\n\n\n\n\n지점명\n날짜\n시간\n일사\n\n\n\n\n0\n북춘천\n2021-01-01\n00:00\n0.0\n\n\n1\n북춘천\n2021-01-01\n01:00\n0.0\n\n\n2\n북춘천\n2021-01-01\n02:00\n0.0\n\n\n3\n북춘천\n2021-01-01\n03:00\n0.0\n\n\n4\n북춘천\n2021-01-01\n04:00\n0.0\n\n\n...\n...\n...\n...\n...\n\n\n802995\n경주시\n2022-12-31\n07:00\n0.0\n\n\n802996\n경주시\n2022-12-31\n20:00\n0.0\n\n\n802997\n경주시\n2022-12-31\n06:00\n0.0\n\n\n802998\n경주시\n2022-12-31\n21:00\n0.0\n\n\n802999\n경주시\n2022-12-31\n05:00\n0.0\n\n\n\n\n803000 rows × 4 columns\n\n\n\n- 시간,날짜 \\(\\to\\) 일시\n\ndf_temp3=df_temp2.assign(일시 = list(map(lambda x,y: x+'-'+y,df_temp2['날짜'],df_temp2['시간'])))\\\n.drop(['날짜','시간'],axis=1)\ndf_temp3\n\n\n\n\n\n\n\n\n지점명\n일사\n일시\n\n\n\n\n0\n북춘천\n0.0\n2021-01-01-00:00\n\n\n1\n북춘천\n0.0\n2021-01-01-01:00\n\n\n2\n북춘천\n0.0\n2021-01-01-02:00\n\n\n3\n북춘천\n0.0\n2021-01-01-03:00\n\n\n4\n북춘천\n0.0\n2021-01-01-04:00\n\n\n...\n...\n...\n...\n\n\n802995\n경주시\n0.0\n2022-12-31-07:00\n\n\n802996\n경주시\n0.0\n2022-12-31-20:00\n\n\n802997\n경주시\n0.0\n2022-12-31-06:00\n\n\n802998\n경주시\n0.0\n2022-12-31-21:00\n\n\n802999\n경주시\n0.0\n2022-12-31-05:00\n\n\n\n\n803000 rows × 3 columns\n\n\n\n- 저장\n\ndf_temp3.rename({'지점명':'region','일사':'solar_radiation','일시':'date'},axis=1)\n\n\n\n\n\n\n\n\nregion\nsolar_radiation\ndate\n\n\n\n\n0\n북춘천\n0.0\n2021-01-01-00:00\n\n\n1\n북춘천\n0.0\n2021-01-01-01:00\n\n\n2\n북춘천\n0.0\n2021-01-01-02:00\n\n\n3\n북춘천\n0.0\n2021-01-01-03:00\n\n\n4\n북춘천\n0.0\n2021-01-01-04:00\n\n\n...\n...\n...\n...\n\n\n802995\n경주시\n0.0\n2022-12-31-07:00\n\n\n802996\n경주시\n0.0\n2022-12-31-20:00\n\n\n802997\n경주시\n0.0\n2022-12-31-06:00\n\n\n802998\n경주시\n0.0\n2022-12-31-21:00\n\n\n802999\n경주시\n0.0\n2022-12-31-05:00\n\n\n\n\n803000 rows × 3 columns\n\n\n\n\ndf = df_temp3.rename({'지점명':'region','일사':'solar_radiation','일시':'date'},axis=1)\ndf.to_csv(\"solar_radiation.csv\",index=False)\n!git add .\n!git commit -m .\n!git push \n\n[main 299d058] .\n 3 files changed, 806273 insertions(+)\n create mode 100644 \"posts/3_Researches/SOLAR/.ipynb_checkpoints/2023-04-03-\\354\\235\\274\\354\\202\\254\\353\\237\\211-checkpoint.ipynb\"\n create mode 100644 \"posts/3_Researches/SOLAR/2023-04-03-\\354\\235\\274\\354\\202\\254\\353\\237\\211.ipynb\"\n create mode 100644 posts/3_Researches/SOLAR/solar_radiation.csv\nEnumerating objects: 10, done.\nCounting objects: 100% (10/10), done.\nDelta compression using up to 16 threads\nCompressing objects: 100% (7/7), done.\nWriting objects: 100% (7/7), 8.74 KiB | 8.74 MiB/s, done.\nTotal 7 (delta 2), reused 0 (delta 0)\nremote: Resolving deltas: 100% (2/2), completed with 2 local objects.\nTo https://github.com/miruetoto/yechan3.git\n   495d9ce..299d058  main -&gt; main\n\n\n- 불러오기\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/miruetoto/yechan3/main/posts/3_Researches/SOLAR/solar_radiation.csv\")\ndf\n\n\n\n\n\n\n\n\nregion\nsolar_radiation\ndate\n\n\n\n\n0\n북춘천\n0.0\n2021-01-01-00:00\n\n\n1\n북춘천\n0.0\n2021-01-01-01:00\n\n\n2\n북춘천\n0.0\n2021-01-01-02:00\n\n\n3\n북춘천\n0.0\n2021-01-01-03:00\n\n\n4\n북춘천\n0.0\n2021-01-01-04:00\n\n\n...\n...\n...\n...\n\n\n802995\n경주시\n0.0\n2022-12-31-07:00\n\n\n802996\n경주시\n0.0\n2022-12-31-20:00\n\n\n802997\n경주시\n0.0\n2022-12-31-06:00\n\n\n802998\n경주시\n0.0\n2022-12-31-21:00\n\n\n802999\n경주시\n0.0\n2022-12-31-05:00\n\n\n\n\n803000 rows × 3 columns\n\n\n\n- 다운로드\n!wget https://raw.githubusercontent.com/miruetoto/yechan3/main/posts/3_Researches/SOLAR/solar_radiation.csv"
  },
  {
    "objectID": "연구/지윤/SOLAR/2023-07-20-(연구&지윤) 태양광자료분석 -- EPT + RGCN (시뮬레이션).html",
    "href": "연구/지윤/SOLAR/2023-07-20-(연구&지윤) 태양광자료분석 -- EPT + RGCN (시뮬레이션).html",
    "title": "(연구&지윤) 태양광자료분석 – EPT + RGCN (시뮬레이션)",
    "section": "",
    "text": "%run 0807.py\n\n\nimport os\n\n\ns=Simulator()\n\n\nclass GConv_GRU(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(GConv_GRU, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n        \ns.simulate(\n    n_iteration = 1,\n    lags = [1],\n    filters = [4,6],\n    epoch = [1],\n    Model = GConv_GRU\n)\n\nmethod:classic lag:1 filters:4 epoch:1 is done\nmethod:classic lag:1 filters:6 epoch:1 is done\nmethod:proposed lag:1 filters:4 epoch:1 is done\nmethod:proposed lag:1 filters:6 epoch:1 is done\nsave results\n\n\n\nfnames = ['./results/'+l for l in os.listdir('./results/') if l[0] != '.']\nfnames \n\n['./results/SOLAR_2023-08-07 16:12:29.037623.csv',\n './results/SOLAR_2023-08-07 15:48:50.109743.csv',\n './results/SOLAR_2023-08-07 16:08:41.687843.csv',\n './results/SOLAR_2023-08-07 15:48:25.728993.csv',\n './results/SOLAR_2023-08-07 16:28:55.929269.csv']\n\n\n\npd.concat([pd.read_csv(fname) for fname in fnames]).reset_index(drop=True)\n\n\n\n\n\n\n\n\nindex_time\nmse_mean\nmodel\nmethod\nlags\nnof_filters\nepoch\ncalculation_time\nnode\nmse\n\n\n\n\n0\n2023-08-07 16:11:11.072667\n0.419854\nRecurrentGCN\nclassic\n1\n4\n1\n15.519606\nBukchoncheon\n0.491867\n\n\n1\n2023-08-07 16:11:11.072667\n0.419854\nRecurrentGCN\nclassic\n1\n4\n1\n15.519606\nCheorwon\n0.474034\n\n\n2\n2023-08-07 16:11:11.072667\n0.419854\nRecurrentGCN\nclassic\n1\n4\n1\n15.519606\nDaegwallyeong\n0.468020\n\n\n3\n2023-08-07 16:11:11.072667\n0.419854\nRecurrentGCN\nclassic\n1\n4\n1\n15.519606\nChuncheon\n0.433953\n\n\n4\n2023-08-07 16:11:11.072667\n0.419854\nRecurrentGCN\nclassic\n1\n4\n1\n15.519606\nBaengnyeongdo\n0.620410\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n875\n2023-08-07 16:28:55.924567\n0.139105\nGConvGRU\nproposed\n1\n6\n1\n30.982189\nUiryeong-gun\n0.140765\n\n\n876\n2023-08-07 16:28:55.924567\n0.139105\nGConvGRU\nproposed\n1\n6\n1\n30.982189\nHamyang-gun\n0.122213\n\n\n877\n2023-08-07 16:28:55.924567\n0.139105\nGConvGRU\nproposed\n1\n6\n1\n30.982189\nGwangyang-si\n0.144140\n\n\n878\n2023-08-07 16:28:55.924567\n0.139105\nGConvGRU\nproposed\n1\n6\n1\n30.982189\nCheongsong-gun\n0.143174\n\n\n879\n2023-08-07 16:28:55.924567\n0.139105\nGConvGRU\nproposed\n1\n6\n1\n30.982189\nGyeongju-si\n0.109372\n\n\n\n\n880 rows × 10 columns"
  },
  {
    "objectID": "연구/지윤/SOLAR/2023-04-04-(연구&지윤) 태양광자료분석 -- EPT.html",
    "href": "연구/지윤/SOLAR/2023-04-04-(연구&지윤) 태양광자료분석 -- EPT.html",
    "title": "(연구&지윤) 태양광자료분석",
    "section": "",
    "text": "ref: https://www.sciencedirect.com/science/article/pii/S2352711021000492\n\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(EPT)\n\n\nurl = 'https://raw.githubusercontent.com/miruetoto/yechan3/main/posts/3_Researches/SOLAR/solar_radiation.csv'\ndf = read_csv(url)\n\nRows: 803000 Columns: 3\n── Column specification ────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): region, date\ndbl (1): solar_radiation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\ndf = df |&gt; filter(region == '북춘천') |&gt; mutate(date=ymd_hm(date))\ndf\n\n\nA tibble: 18250 × 3\n\n\nregion\nsolar_radiation\ndate\n\n\n&lt;chr&gt;\n&lt;dbl&gt;\n&lt;dttm&gt;\n\n\n\n\n북춘천\n0.00\n2021-01-01 00:00:00\n\n\n북춘천\n0.00\n2021-01-01 01:00:00\n\n\n북춘천\n0.00\n2021-01-01 02:00:00\n\n\n북춘천\n0.00\n2021-01-01 03:00:00\n\n\n북춘천\n0.00\n2021-01-01 04:00:00\n\n\n북춘천\n0.00\n2021-01-01 05:00:00\n\n\n북춘천\n0.00\n2021-01-01 06:00:00\n\n\n북춘천\n0.00\n2021-01-01 07:00:00\n\n\n북춘천\n0.00\n2021-01-01 08:00:00\n\n\n북춘천\n0.37\n2021-01-01 09:00:00\n\n\n북춘천\n0.96\n2021-01-01 10:00:00\n\n\n북춘천\n1.40\n2021-01-01 11:00:00\n\n\n북춘천\n1.72\n2021-01-01 12:00:00\n\n\n북춘천\n1.84\n2021-01-01 13:00:00\n\n\n북춘천\n1.74\n2021-01-01 14:00:00\n\n\n북춘천\n1.30\n2021-01-01 15:00:00\n\n\n북춘천\n0.93\n2021-01-01 16:00:00\n\n\n북춘천\n0.29\n2021-01-01 17:00:00\n\n\n북춘천\n0.01\n2021-01-01 18:00:00\n\n\n북춘천\n0.00\n2021-01-01 19:00:00\n\n\n북춘천\n0.00\n2021-01-01 07:00:00\n\n\n북춘천\n0.00\n2021-01-01 20:00:00\n\n\n북춘천\n0.00\n2021-01-01 06:00:00\n\n\n북춘천\n0.00\n2021-01-01 21:00:00\n\n\n북춘천\n0.00\n2021-01-01 05:00:00\n\n\n북춘천\n0.00\n2021-01-02 00:00:00\n\n\n북춘천\n0.00\n2021-01-02 01:00:00\n\n\n북춘천\n0.00\n2021-01-02 02:00:00\n\n\n북춘천\n0.00\n2021-01-02 03:00:00\n\n\n북춘천\n0.00\n2021-01-02 04:00:00\n\n\n⋮\n⋮\n⋮\n\n\n북춘천\n0.00\n2022-12-30 07:00:00\n\n\n북춘천\n0.00\n2022-12-30 20:00:00\n\n\n북춘천\n0.00\n2022-12-30 06:00:00\n\n\n북춘천\n0.00\n2022-12-30 21:00:00\n\n\n북춘천\n0.00\n2022-12-30 05:00:00\n\n\n북춘천\n0.00\n2022-12-31 00:00:00\n\n\n북춘천\n0.00\n2022-12-31 01:00:00\n\n\n북춘천\n0.00\n2022-12-31 02:00:00\n\n\n북춘천\n0.00\n2022-12-31 03:00:00\n\n\n북춘천\n0.00\n2022-12-31 04:00:00\n\n\n북춘천\n0.00\n2022-12-31 05:00:00\n\n\n북춘천\n0.00\n2022-12-31 06:00:00\n\n\n북춘천\n0.00\n2022-12-31 07:00:00\n\n\n북춘천\n0.00\n2022-12-31 08:00:00\n\n\n북춘천\n0.22\n2022-12-31 09:00:00\n\n\n북춘천\n0.50\n2022-12-31 10:00:00\n\n\n북춘천\n0.80\n2022-12-31 11:00:00\n\n\n북춘천\n2.13\n2022-12-31 12:00:00\n\n\n북춘천\n1.78\n2022-12-31 13:00:00\n\n\n북춘천\n1.45\n2022-12-31 14:00:00\n\n\n북춘천\n0.78\n2022-12-31 15:00:00\n\n\n북춘천\n0.38\n2022-12-31 16:00:00\n\n\n북춘천\n0.15\n2022-12-31 17:00:00\n\n\n북춘천\n0.00\n2022-12-31 18:00:00\n\n\n북춘천\n0.00\n2022-12-31 19:00:00\n\n\n북춘천\n0.00\n2022-12-31 07:00:00\n\n\n북춘천\n0.00\n2022-12-31 20:00:00\n\n\n북춘천\n0.00\n2022-12-31 06:00:00\n\n\n북춘천\n0.00\n2022-12-31 21:00:00\n\n\n북춘천\n0.00\n2022-12-31 05:00:00\n\n\n\n\n\n- 지역을 북춘천으로 고정\n\ndf2 = df |&gt; filter(region =='북춘천') \ndf2 = df2[order(df2$date),]\n\n\ny = df2$solar_radiation\ny\n\n\n0000000000000.370.961.41.721.841.741.30.930.290.010000000000000000.320.951.461.791.911.821.50.970.370.010000000000000000.290.891.41.751.761.350.820.520.30.010000000000000000.330.931.321.531.671.5110.790.1900000000000000000.190.791.411.761.931.851.561.050.450.020000000000000000.511.381.811.881.931.851.5210.410.020000000000000000.110.741.441.811.981.911.611.090.450.020000000000000000.360.971.491.8521.911.611.10.480.03000⋯000000000000.010.471.31.711.871.881.721.380.880.3200000000000000000.190.681.351.712.191.891.380.820.2600000000000000000.150.420.931.071.181.051.160.830.300000000000000000.080.280.430.741.41.841.530.850.2700000000000000000.411.021.841.921.851.721.420.930.340.010000000000000000.471.281.681.81.851.741.40.890.30.010000000000000000.150.641.11.732.121.741.290.860.310.010000000000000000.220.50.82.131.781.450.780.380.150000\n\n\n\nplot(y[1:500])\nlines(y[1:500],lty=2)\n\n\n\n\n\n\n\n\n- EPT 수행\n\nept = function(y){\n    EpM = eptransf(signal=y,tau=24,process=c(\"envelope\",\"average\"))$EpM\n    EpM*2\n}\n\n\nyU = ept(y)\n\n\nplot(y[1:500])\nlines(yU[1:500],col=2,lty=2)\n\n\n\n\n\n\n\n\n- todo: 모든 지역에대하여 yU를 구하여 저장"
  },
  {
    "objectID": "연구/지윤/SOLAR/2023-07-17-(연구&지윤) 태양광자료분석 -- EPT + RGCN.html",
    "href": "연구/지윤/SOLAR/2023-07-17-(연구&지윤) 태양광자료분석 -- EPT + RGCN.html",
    "title": "(연구&지윤) 태양광자료분석 – EPT + RGCN",
    "section": "",
    "text": "Import\n- source\n\nhttps://github.com/miruetoto/yechan3/blob/main/posts/3_Researches/PINKOCTO/SOLAR/0720.py\n\n- download source\n\n# https://github.com/miruetoto/yechan3/blob/main/posts/3_Researches/PINKOCTO/SOLAR/0720.py\n\n- run\n\n%run 0720.py\n\n\n\nLoad data\n\n# read dataframe \ndf = pd.read_csv('https://media.githubusercontent.com/media/miruetoto/yechan3/main/posts/3_Researches/PINKOCTO/SOLAR/data_eng_230710.csv')\n\n# make y, y_upper, y_period, time, regions \ny = df.loc[:,'Bukchoncheon':'Gyeongju-si'].to_numpy()\nyU = df.loc[:,'Bukchoncheon_Upper':'Gyeongju-si_Upper'].to_numpy()\nyP = np.divide(y, yU+1e-10)\nt = df.loc[:,'date']\nregions = list(df.loc[:,'Bukchoncheon':'Gyeongju-si'].columns)\n\n# plot rawdata \nstart = 50 \nend = 50+24*3\ncity = 19 # 광주 \nwith plt.style.context('cyberpunk'):\n    plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n    plt.plot(t[start:end],y[start:end,city],'o',label='y')\n    plt.plot(t[start:end],yU[start:end,city],'--',label='yU')\n    plt.plot(t[start:end],yP[start:end,city],'o',label='y/yU')\n    tick_interval = 4\n    plt.xticks(range(1, len(t) + 1, tick_interval),rotation=25)        \n    plt.legend()\n    plt.title(\"The solar radiation data in {} from {} to {} \".format(regions[city],t.to_list()[0][:10],t.to_list()[-1][:10]))\n    mplcyberpunk.add_glow_effects()    \n\n\n\n\n\n\n\n\n\n\nLearn\n- y \\(\\to\\) yhat\n\n# hyper params\nLAGS = 4\nFILTERS = 8\nEPOCH = 5\n\n# global params\nTRAIN_RATIO = 0.8\nT,N = len(t),len(regions) \nLEN_TEST = int(np.floor(T*(1-TRAIN_RATIO)))\nLEN_TR = T - LEN_TEST\n\n# 방법1\nmodel = RecurrentGCN(node_features=LAGS, filters=FILTERS)\nyhat = rgcn(y, model = model, train_ratio = TRAIN_RATIO, lags=LAGS, epoch=EPOCH)\nyhat[yhat &lt; 0]= 0 \n\n# 방법2 \nmodel = RecurrentGCN(node_features=LAGS, filters=FILTERS)\nyUhat = rgcn(yU, model = model, train_ratio = TRAIN_RATIO, lags=LAGS, epoch=EPOCH)\n\nmodel = RecurrentGCN(node_features=LAGS, filters=FILTERS)\nyPhat = rgcn(yP, model = model, train_ratio = TRAIN_RATIO, lags=LAGS, epoch=EPOCH)\nyPhat[yPhat &lt; 0] =0 \n\n\nclassic = ((y - yhat)[LEN_TR:, :] ** 2)\nproposed = ((y - yUhat*yPhat)[LEN_TR:, :] ** 2)\n\n# print mse\nprint(\"\"\"\ntotal_mse(classic): {:.4f}\ntotal_mse(proposed): {:.4f}\n\"\"\".format(classic.mean(), proposed.mean()))\n\n5/5\ntotal_mse(classic): 0.0573\ntotal_mse(proposed): 0.0476\n\n\n\n\n# plot \nstart = LEN_TR \nend = LEN_TR + LEN_TEST \ncity = 20\ntick_interval = 24 \n\nclassic = (y - yhat)[start:end, :] ** 2\nproposed = (y - yUhat*yPhat)[start:end, :] ** 2\n\nprint(\"\"\"\ntotal_mse(classic): {:.4f}\ntotal_mse(proposed): {:.4f}\n\"\"\".format(classic.mean(), proposed.mean()))\n\nwith plt.style.context('cyberpunk'): \n    plt.rcParams['figure.figsize'] = [20, 4]  # [가로 크기, 세로 크기]\n    plt.plot(t[start:end],y[start:end,city],'-',label='real')\n    plt.plot(t[start:end],yhat[start:end,city],'--',label='predited(classic)')\n    plt.plot(t[start:end],(yUhat*yPhat)[start:end,city],'--',label='predited(proposed)')\n    plt.xticks(range(1, len(t[start:end]) + 1, tick_interval),rotation=25,ha='right')\n    plt.title(\"The predicted results in {} from {} to {} \".format(regions[city],t[start:end].to_list()[0][:10],t[start:end].to_list()[-1][:10]))    \n    plt.legend()\n    mplcyberpunk.add_glow_effects()\n\n\ntotal_mse(classic): 0.0573\ntotal_mse(proposed): 0.0476\n\n\n\n\n\n\n\n\n\n\n\n\nAnalyze\n- y vs yhat\n\nwith plt.style.context('seaborn-bright'): \n    plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n    plt.plot(y[50:150,0],'o-',label='real')\n    plt.plot(yhat[50:150,0],'o--',label='predited')\n    plt.legend()\n    mplcyberpunk.add_glow_effects()    \n\n\n\n\n\n\n\n\n- yU vs yUhat\n\nwith plt.style.context('seaborn-bright'): \n    plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n    plt.plot(yU[:,25],label='real')\n    plt.plot(yUhat[:,25],label='predited')\n    plt.legend()\n    mplcyberpunk.add_glow_effects()    \n\n\n\n\n\n\n\n\n- yP vs yPhat\n\nwith plt.style.context('seaborn-bright'): \n    plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n    plt.plot(yP[50:150,city],'o-',label='real')\n    plt.plot(yPhat[50:150,city],'o--',label='predited')\n    plt.legend()\n    mplcyberpunk.add_glow_effects()    \n\n\n\n\n\n\n\n\n- y vs (yUhat*yPhat)\n\nwith plt.style.context('seaborn-bright'): \n    plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n    plt.plot(y[50:150,0],'o-',label='real')\n    plt.plot((yUhat*yPhat)[50:150,0],'o--',label='predited')\n    plt.legend()\n    mplcyberpunk.add_glow_effects()    \n\n\n\n\n\n\n\n\n- 지역별분석\n\nwith plt.style.context('cyberpunk'):\n    plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n    plt.plot(regions,classic.mean(axis=0)-proposed.mean(axis=0),'--o');\n    plt.xticks(regions, rotation=55, ha='right');    \n    mplcyberpunk.add_glow_effects()"
  },
  {
    "objectID": "연구/지윤/SOLAR/2023-08-14-(연구&지윤) 태양광자료분석 -- GConvLSTM +++++++ 이거!!! ++++++++++++.html",
    "href": "연구/지윤/SOLAR/2023-08-14-(연구&지윤) 태양광자료분석 -- GConvLSTM +++++++ 이거!!! ++++++++++++.html",
    "title": "(연구&지윤) 태양광자료분석 – GConvLSTM +++++++ 이거!!! ++++++++++++",
    "section": "",
    "text": "변경사항: RGCN_Learner 수정 – 일부기능추가\n\n\n포인트: 배치학습을 적용하여 update가 빨리이루어지도록 코드수정\n\n\n\n\n# modules \nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nimport eptstgcn\nimport eptstgcn.planner\nimport torch_geometric_temporal\nfrom torch_geometric_temporal.signal.static_graph_temporal_signal import StaticGraphTemporalSignal\nimport mplcyberpunk\n\n# torch\nimport torch\nimport torch.nn.functional as F\n#import torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvLSTM\n# from torch_geometric_temporal.nn.recurrent import GCLSTM\n# from torch_geometric_temporal.nn.recurrent import LRGCN\n# from torch_geometric_temporal.nn.recurrent import TGCN\n# from torch_geometric_temporal.nn.recurrent import DCRNN\n\n# read data\ndef makedict(FX,W=None,node_ids=None):\n    T,N = np.array(FX).shape\n    if W==None:\n        W = pd.DataFrame(FX).corr().to_numpy().reshape(-1).tolist() # corr 로 weights\n    if node_ids==None:\n        node_ids = ['node'+str(n) for n in range(N)]\n    _dict={\n        'edges':[[i,j] for i in range(N) for j in range(N)], \n        'node_ids': node_ids,\n        'weights':W,\n        'FX':FX\n    }\n    return _dict\n\nclass Loader(object):\n    def __init__(self, data_dict):\n        self._dataset = data_dict\n    \n    def _get_edges(self):\n        self._edges = np.array(self._dataset[\"edges\"]).T\n\n    def _get_edge_weights(self):\n        # self._edge_weights = np.array(self._dataset[\"weights\"]).T\n        edge_weights = np.array(self._dataset[\"weights\"]).T\n        #scaled_edge_weights = minmaxscaler(edge_weights)\n        self._edge_weights = edge_weights\n\n    def _get_targets_and_features(self):\n        stacked_target = np.stack(self._dataset[\"FX\"])\n        self.features = np.stack([\n            stacked_target[i : i + self.lags, :].T\n            for i in range(stacked_target.shape[0] - self.lags)\n        ])\n        self.targets = np.stack([\n            stacked_target[i + self.lags, :].T\n            for i in range(stacked_target.shape[0] - self.lags)\n        ])\n\n\n    def get_dataset(self, lags: int = 4) -&gt; StaticGraphTemporalSignal:\n        self.lags = lags\n        self._get_edges()\n        self._get_edge_weights()\n        self._get_targets_and_features()\n        dataset = StaticGraphTemporalSignal(\n            self._edges, self._edge_weights, self.features, self.targets\n        )\n        dataset.node_ids = self._dataset['node_ids']\n        return dataset\n    \nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvLSTM(in_channels = node_features, out_channels = filters, K = 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight, h, c):\n        h_0, c_0 = self.recurrent(x, edge_index, edge_weight, h, c)\n        h = F.relu(h_0)\n        h = self.linear(h)\n        return h, h_0, c_0\n    \n    \n# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\ndevice = torch.device('cpu')\n\nclass RGCN_Learner:\n    def __init__(self):\n        self.method = 'RecurrentGCN'\n        self.figs = []\n        self.epochs = 0\n        self.losses = []\n        self._node_idx = 0\n    def load(self,y): \n        if (self.lags is None) or (self.train_ratio is None):\n            self.lags = 4\n            self.train_ratio = 0.8 \n        self.t,self.n = y.shape\n        dct = makedict(FX=y.tolist())\n        self.loader = Loader(dct)\n        self.dataset = self.loader.get_dataset(lags=self.lags)\n        self.X = torch.tensor(self.dataset.features).float()\n        self.y = torch.tensor(self.dataset.targets).float()\n        self.train_dataset, self.test_dataset = eptstgcn.utils.temporal_signal_split(self.dataset, train_ratio = self.train_ratio)\n        self.len_test = self.test_dataset.snapshot_count\n        self.len_tr = self.train_dataset.snapshot_count\n        #self.dataset_name = str(self.train_dataset) if dataset_name is None else dataset_name\n    def get_batches(self, batch_size=256):\n        num_batches =  self.len_tr // batch_size + (1 if self.len_tr % batch_size != 0 else 0)\n        self.batches = []\n        for i in range(num_batches):\n            start_idx = i * batch_size\n            end_idx = start_idx + batch_size\n            self.batches.append(self.train_dataset[start_idx:end_idx])\n    \n    def learn(self,epoch=1):\n        self.model.train()\n        for e in range(epoch):\n            losses_batch = []\n            for b,batch in enumerate(self.batches):\n                loss = 0\n                self.h, self.c = None, None\n                for t, snapshot in enumerate(batch):\n                    snapshot = snapshot.to(device)\n                    yt_hat, self.h, self.c = self.model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, self.h, self.c)\n                    loss = loss + torch.mean((yt_hat.reshape(-1)-snapshot.y.reshape(-1))**2)\n                    print(f'\\rbatch={b}\\t t={t+1}\\t loss={loss/(t+1)}\\t', end='', flush=True)\n                loss = loss / (t+1)\n                loss.backward()\n                self.optimizer.step()\n                self.optimizer.zero_grad()\n                losses_batch.append(loss.item())\n            self.epochs = self.epochs + 1\n            print(f'\\repoch={self.epochs}\\t loss={np.mean(losses_batch)}\\n', end='', flush=True)\n        self.losses.append(np.mean(losses_batch))\n        self._savefigs() \n    def _savefigs(self): \n        self.__call__()\n        self._node_idx\n        with plt.style.context('default'): \n            plt.ioff()\n            plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n            fig,ax = plt.subplots()\n            ax.plot(self.y[:,self._node_idx],label='real',lw=0.5)\n            ax.plot(self.yhat[:,self._node_idx],'--',label='predited',alpha=0.5)\n            ax.set_title(f'Epoch={self.epochs}, node_idx={self._node_idx}',size=15)\n            ax.legend()\n            #mplcyberpunk.add_glow_effects()  \n        self.figs.append(fig)\n        plt.close()\n    def __call__(self,dataset=None):\n        if dataset == None: \n            dataset = self.dataset\n        self.yhat = torch.stack([self.model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, self.h, self.c)[0] for snapshot in dataset]).detach().squeeze().float()\n        return {'X':self.X, 'y':self.y, 'yhat':self.yhat} \n\n# learn \n# def rgcn(FX,train_ratio,lags,filters,epoch):\n#     dct = makedict(FX=FX.tolist())\n#     loader = Loader(dct)\n#     dataset = loader.get_dataset(lags=lags)\n#     dataset_tr, dataset_test = eptstgcn.utils.temporal_signal_split(dataset, train_ratio = train_ratio)\n#     lrnr = RGCN_Learner(dataset_tr, dataset_name = 'org & arbitrary')\n#     lrnr.learn(filters=filters, epoch=epoch)\n#     yhat = np.array(lrnr(dataset)['yhat'])\n#     yhat = np.concatenate([np.array([list(yhat[0])]*lags),yhat],axis=0)\n#     return yhat\n\n\n\n\n\n# read dataframe \ndf = pd.read_csv('data_eng_230710.csv')\n# make y, y_upper, y_period, time, regions \ny = df.loc[:,'Bukchoncheon':'Gyeongju-si'].to_numpy()\nyU = df.loc[:,'Bukchoncheon_Upper':'Gyeongju-si_Upper'].to_numpy()\nyP = np.divide(y, yU+1e-10)\n\n\n\n\n- 예시1: y를 학습\n학습~\n\n# step1: create lrnr object\nlrnr = RGCN_Learner()\n# step2: load data \nlrnr.lags = 4 \nlrnr.train_ratio = 0.8\nlrnr.load(y) \n# step3: construct networks \nlrnr.nof_filters = 16\nlrnr.model = RecurrentGCN(node_features=lrnr.lags, filters=lrnr.nof_filters).to(device)\nlrnr.optimizer = torch.optim.Adam(lrnr.model.parameters(),lr=10/1000)\n# step4: learn \nlrnr.get_batches(batch_size=24)\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=1  loss=0.348616252371738191366577        \nepoch=2  loss=0.096857151493083602352905            \nepoch=3  loss=0.085899897092996645071335            \nepoch=4  loss=0.082436966038374011698761            \nepoch=5  loss=0.080951251696015514699783            \n\n\n\nlrnr.y.shape\n\ntorch.Size([2564, 44])\n\n\n\nlrnr.get_batches(batch_size=24)\n\n\nlrnr.batches[-1]\n\n&lt;torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal at 0x7fa2cfbc7cd0&gt;\n\n\n\nplt.plot(y[:100,0])\n\n에폭별 적합결과(\\(\\hat{y}\\)) 시각화\n\nlrnr.figs[0]\n\n\n\n\n\n\n\n\n\nlrnr.figs[1]\n\n\n\n\n\n\n\n\n\nlrnr.figs[-1]\n\n\n\n\n\n\n\n\n- 예시2: yU 학습\n\n# step1: create lrnr object\nlrnr = RGCN_Learner()\n# step2: load data \nlrnr.lags = 4 \nlrnr.train_ratio = 0.8\nlrnr.load(yU) \n# step3: construct networks \nlrnr.nof_filters = 16\nlrnr.model = RecurrentGCN(node_features=lrnr.lags, filters=lrnr.nof_filters).to(device)\nlrnr.optimizer = torch.optim.Adam(lrnr.model.parameters(),lr=10/1000)\n# step4: learn \nlrnr.get_batches(batch_size=24)\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=1  loss=1.98579962707536175294647     \nepoch=2  loss=0.202098417204133351100159        \nepoch=3  loss=0.052548440736393594218872        \nepoch=4  loss=0.0272646296531135271772957   \nepoch=5  loss=0.0191931016526596582006645   \n\n\n\nlrnr.figs[-1]\n\n\n\n\n\n\n\n\n5번정도 더 돌려보자\n\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=6  loss=0.0169690931215882312923717       \nepoch=7  loss=0.0141667058247379891905975       \nepoch=8  loss=0.0124263072353896015870743       \nepoch=9  loss=0.0103476242200189951082373       \nepoch=10     loss=0.009508996026937005688799        \n\n\n\nlrnr.figs[-1]\n\n\n\n\n\n\n\n\n- 예시3: yP 학습\n\n# step1: create lrnr object\nlrnr = RGCN_Learner()\n# step2: load data \nlrnr.lags = 4 \nlrnr.train_ratio = 0.8\nlrnr.load(yP) \n# step3: construct networks \nlrnr.nof_filters = 16\nlrnr.model = RecurrentGCN(node_features=lrnr.lags, filters=lrnr.nof_filters).to(device)\nlrnr.optimizer = torch.optim.Adam(lrnr.model.parameters(),lr=10/1000)\n# step4: learn \nlrnr.get_batches(batch_size=24)\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=1  loss=0.030719049366970748393135            \nepoch=2  loss=0.0119630681123411254793358       \nepoch=3  loss=0.0109235838672882638420868       \nepoch=4  loss=0.0107088599754714682600975       \nepoch=5  loss=0.0105961727974719788335514       \n\n\n\nlrnr.figs[-1]"
  },
  {
    "objectID": "연구/지윤/SOLAR/2023-08-14-(연구&지윤) 태양광자료분석 -- GConvLSTM +++++++ 이거!!! ++++++++++++.html#import",
    "href": "연구/지윤/SOLAR/2023-08-14-(연구&지윤) 태양광자료분석 -- GConvLSTM +++++++ 이거!!! ++++++++++++.html#import",
    "title": "(연구&지윤) 태양광자료분석 – GConvLSTM +++++++ 이거!!! ++++++++++++",
    "section": "",
    "text": "# modules \nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nimport eptstgcn\nimport eptstgcn.planner\nimport torch_geometric_temporal\nfrom torch_geometric_temporal.signal.static_graph_temporal_signal import StaticGraphTemporalSignal\nimport mplcyberpunk\n\n# torch\nimport torch\nimport torch.nn.functional as F\n#import torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvLSTM\n# from torch_geometric_temporal.nn.recurrent import GCLSTM\n# from torch_geometric_temporal.nn.recurrent import LRGCN\n# from torch_geometric_temporal.nn.recurrent import TGCN\n# from torch_geometric_temporal.nn.recurrent import DCRNN\n\n# read data\ndef makedict(FX,W=None,node_ids=None):\n    T,N = np.array(FX).shape\n    if W==None:\n        W = pd.DataFrame(FX).corr().to_numpy().reshape(-1).tolist() # corr 로 weights\n    if node_ids==None:\n        node_ids = ['node'+str(n) for n in range(N)]\n    _dict={\n        'edges':[[i,j] for i in range(N) for j in range(N)], \n        'node_ids': node_ids,\n        'weights':W,\n        'FX':FX\n    }\n    return _dict\n\nclass Loader(object):\n    def __init__(self, data_dict):\n        self._dataset = data_dict\n    \n    def _get_edges(self):\n        self._edges = np.array(self._dataset[\"edges\"]).T\n\n    def _get_edge_weights(self):\n        # self._edge_weights = np.array(self._dataset[\"weights\"]).T\n        edge_weights = np.array(self._dataset[\"weights\"]).T\n        #scaled_edge_weights = minmaxscaler(edge_weights)\n        self._edge_weights = edge_weights\n\n    def _get_targets_and_features(self):\n        stacked_target = np.stack(self._dataset[\"FX\"])\n        self.features = np.stack([\n            stacked_target[i : i + self.lags, :].T\n            for i in range(stacked_target.shape[0] - self.lags)\n        ])\n        self.targets = np.stack([\n            stacked_target[i + self.lags, :].T\n            for i in range(stacked_target.shape[0] - self.lags)\n        ])\n\n\n    def get_dataset(self, lags: int = 4) -&gt; StaticGraphTemporalSignal:\n        self.lags = lags\n        self._get_edges()\n        self._get_edge_weights()\n        self._get_targets_and_features()\n        dataset = StaticGraphTemporalSignal(\n            self._edges, self._edge_weights, self.features, self.targets\n        )\n        dataset.node_ids = self._dataset['node_ids']\n        return dataset\n    \nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvLSTM(in_channels = node_features, out_channels = filters, K = 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight, h, c):\n        h_0, c_0 = self.recurrent(x, edge_index, edge_weight, h, c)\n        h = F.relu(h_0)\n        h = self.linear(h)\n        return h, h_0, c_0\n    \n    \n# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\ndevice = torch.device('cpu')\n\nclass RGCN_Learner:\n    def __init__(self):\n        self.method = 'RecurrentGCN'\n        self.figs = []\n        self.epochs = 0\n        self.losses = []\n        self._node_idx = 0\n    def load(self,y): \n        if (self.lags is None) or (self.train_ratio is None):\n            self.lags = 4\n            self.train_ratio = 0.8 \n        self.t,self.n = y.shape\n        dct = makedict(FX=y.tolist())\n        self.loader = Loader(dct)\n        self.dataset = self.loader.get_dataset(lags=self.lags)\n        self.X = torch.tensor(self.dataset.features).float()\n        self.y = torch.tensor(self.dataset.targets).float()\n        self.train_dataset, self.test_dataset = eptstgcn.utils.temporal_signal_split(self.dataset, train_ratio = self.train_ratio)\n        self.len_test = self.test_dataset.snapshot_count\n        self.len_tr = self.train_dataset.snapshot_count\n        #self.dataset_name = str(self.train_dataset) if dataset_name is None else dataset_name\n    def get_batches(self, batch_size=256):\n        num_batches =  self.len_tr // batch_size + (1 if self.len_tr % batch_size != 0 else 0)\n        self.batches = []\n        for i in range(num_batches):\n            start_idx = i * batch_size\n            end_idx = start_idx + batch_size\n            self.batches.append(self.train_dataset[start_idx:end_idx])\n    \n    def learn(self,epoch=1):\n        self.model.train()\n        for e in range(epoch):\n            losses_batch = []\n            for b,batch in enumerate(self.batches):\n                loss = 0\n                self.h, self.c = None, None\n                for t, snapshot in enumerate(batch):\n                    snapshot = snapshot.to(device)\n                    yt_hat, self.h, self.c = self.model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, self.h, self.c)\n                    loss = loss + torch.mean((yt_hat.reshape(-1)-snapshot.y.reshape(-1))**2)\n                    print(f'\\rbatch={b}\\t t={t+1}\\t loss={loss/(t+1)}\\t', end='', flush=True)\n                loss = loss / (t+1)\n                loss.backward()\n                self.optimizer.step()\n                self.optimizer.zero_grad()\n                losses_batch.append(loss.item())\n            self.epochs = self.epochs + 1\n            print(f'\\repoch={self.epochs}\\t loss={np.mean(losses_batch)}\\n', end='', flush=True)\n        self.losses.append(np.mean(losses_batch))\n        self._savefigs() \n    def _savefigs(self): \n        self.__call__()\n        self._node_idx\n        with plt.style.context('default'): \n            plt.ioff()\n            plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n            fig,ax = plt.subplots()\n            ax.plot(self.y[:,self._node_idx],label='real',lw=0.5)\n            ax.plot(self.yhat[:,self._node_idx],'--',label='predited',alpha=0.5)\n            ax.set_title(f'Epoch={self.epochs}, node_idx={self._node_idx}',size=15)\n            ax.legend()\n            #mplcyberpunk.add_glow_effects()  \n        self.figs.append(fig)\n        plt.close()\n    def __call__(self,dataset=None):\n        if dataset == None: \n            dataset = self.dataset\n        self.yhat = torch.stack([self.model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, self.h, self.c)[0] for snapshot in dataset]).detach().squeeze().float()\n        return {'X':self.X, 'y':self.y, 'yhat':self.yhat} \n\n# learn \n# def rgcn(FX,train_ratio,lags,filters,epoch):\n#     dct = makedict(FX=FX.tolist())\n#     loader = Loader(dct)\n#     dataset = loader.get_dataset(lags=lags)\n#     dataset_tr, dataset_test = eptstgcn.utils.temporal_signal_split(dataset, train_ratio = train_ratio)\n#     lrnr = RGCN_Learner(dataset_tr, dataset_name = 'org & arbitrary')\n#     lrnr.learn(filters=filters, epoch=epoch)\n#     yhat = np.array(lrnr(dataset)['yhat'])\n#     yhat = np.concatenate([np.array([list(yhat[0])]*lags),yhat],axis=0)\n#     return yhat"
  },
  {
    "objectID": "연구/지윤/SOLAR/2023-08-14-(연구&지윤) 태양광자료분석 -- GConvLSTM +++++++ 이거!!! ++++++++++++.html#load-data",
    "href": "연구/지윤/SOLAR/2023-08-14-(연구&지윤) 태양광자료분석 -- GConvLSTM +++++++ 이거!!! ++++++++++++.html#load-data",
    "title": "(연구&지윤) 태양광자료분석 – GConvLSTM +++++++ 이거!!! ++++++++++++",
    "section": "",
    "text": "# read dataframe \ndf = pd.read_csv('data_eng_230710.csv')\n# make y, y_upper, y_period, time, regions \ny = df.loc[:,'Bukchoncheon':'Gyeongju-si'].to_numpy()\nyU = df.loc[:,'Bukchoncheon_Upper':'Gyeongju-si_Upper'].to_numpy()\nyP = np.divide(y, yU+1e-10)"
  },
  {
    "objectID": "연구/지윤/SOLAR/2023-08-14-(연구&지윤) 태양광자료분석 -- GConvLSTM +++++++ 이거!!! ++++++++++++.html#sample_codes",
    "href": "연구/지윤/SOLAR/2023-08-14-(연구&지윤) 태양광자료분석 -- GConvLSTM +++++++ 이거!!! ++++++++++++.html#sample_codes",
    "title": "(연구&지윤) 태양광자료분석 – GConvLSTM +++++++ 이거!!! ++++++++++++",
    "section": "",
    "text": "- 예시1: y를 학습\n학습~\n\n# step1: create lrnr object\nlrnr = RGCN_Learner()\n# step2: load data \nlrnr.lags = 4 \nlrnr.train_ratio = 0.8\nlrnr.load(y) \n# step3: construct networks \nlrnr.nof_filters = 16\nlrnr.model = RecurrentGCN(node_features=lrnr.lags, filters=lrnr.nof_filters).to(device)\nlrnr.optimizer = torch.optim.Adam(lrnr.model.parameters(),lr=10/1000)\n# step4: learn \nlrnr.get_batches(batch_size=24)\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=1  loss=0.348616252371738191366577        \nepoch=2  loss=0.096857151493083602352905            \nepoch=3  loss=0.085899897092996645071335            \nepoch=4  loss=0.082436966038374011698761            \nepoch=5  loss=0.080951251696015514699783            \n\n\n\nlrnr.y.shape\n\ntorch.Size([2564, 44])\n\n\n\nlrnr.get_batches(batch_size=24)\n\n\nlrnr.batches[-1]\n\n&lt;torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal at 0x7fa2cfbc7cd0&gt;\n\n\n\nplt.plot(y[:100,0])\n\n에폭별 적합결과(\\(\\hat{y}\\)) 시각화\n\nlrnr.figs[0]\n\n\n\n\n\n\n\n\n\nlrnr.figs[1]\n\n\n\n\n\n\n\n\n\nlrnr.figs[-1]\n\n\n\n\n\n\n\n\n- 예시2: yU 학습\n\n# step1: create lrnr object\nlrnr = RGCN_Learner()\n# step2: load data \nlrnr.lags = 4 \nlrnr.train_ratio = 0.8\nlrnr.load(yU) \n# step3: construct networks \nlrnr.nof_filters = 16\nlrnr.model = RecurrentGCN(node_features=lrnr.lags, filters=lrnr.nof_filters).to(device)\nlrnr.optimizer = torch.optim.Adam(lrnr.model.parameters(),lr=10/1000)\n# step4: learn \nlrnr.get_batches(batch_size=24)\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=1  loss=1.98579962707536175294647     \nepoch=2  loss=0.202098417204133351100159        \nepoch=3  loss=0.052548440736393594218872        \nepoch=4  loss=0.0272646296531135271772957   \nepoch=5  loss=0.0191931016526596582006645   \n\n\n\nlrnr.figs[-1]\n\n\n\n\n\n\n\n\n5번정도 더 돌려보자\n\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=6  loss=0.0169690931215882312923717       \nepoch=7  loss=0.0141667058247379891905975       \nepoch=8  loss=0.0124263072353896015870743       \nepoch=9  loss=0.0103476242200189951082373       \nepoch=10     loss=0.009508996026937005688799        \n\n\n\nlrnr.figs[-1]\n\n\n\n\n\n\n\n\n- 예시3: yP 학습\n\n# step1: create lrnr object\nlrnr = RGCN_Learner()\n# step2: load data \nlrnr.lags = 4 \nlrnr.train_ratio = 0.8\nlrnr.load(yP) \n# step3: construct networks \nlrnr.nof_filters = 16\nlrnr.model = RecurrentGCN(node_features=lrnr.lags, filters=lrnr.nof_filters).to(device)\nlrnr.optimizer = torch.optim.Adam(lrnr.model.parameters(),lr=10/1000)\n# step4: learn \nlrnr.get_batches(batch_size=24)\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=1  loss=0.030719049366970748393135            \nepoch=2  loss=0.0119630681123411254793358       \nepoch=3  loss=0.0109235838672882638420868       \nepoch=4  loss=0.0107088599754714682600975       \nepoch=5  loss=0.0105961727974719788335514       \n\n\n\nlrnr.figs[-1]"
  },
  {
    "objectID": "연구/규빈/EPT_DISSIM/2023-08-18-데이터전처리.html",
    "href": "연구/규빈/EPT_DISSIM/2023-08-18-데이터전처리.html",
    "title": "(연구) EPT-DISSIM – PRCP_KOR2 데이터정리",
    "section": "",
    "text": "import pandas as pd\n\n\ndf = pd.read_csv('PRCP_KOR.csv')\ndf\n\n\n\n\n\n\n\n\nStation_ID\nStation_Name\nDate\nPrecipitation\n\n\n\n\n0\n90\n속초\n2013-08-09\n15.5\n\n\n1\n90\n속초\n2013-08-10\n9.5\n\n\n2\n90\n속초\n2013-08-16\n0.1\n\n\n3\n90\n속초\n2013-08-18\n0.0\n\n\n4\n90\n속초\n2013-08-19\n9.0\n\n\n...\n...\n...\n...\n...\n\n\n127200\n295\n남해\n2023-07-22\n4.3\n\n\n127201\n295\n남해\n2023-07-23\n13.4\n\n\n127202\n295\n남해\n2023-07-24\n17.0\n\n\n127203\n295\n남해\n2023-07-25\n4.7\n\n\n127204\n295\n남해\n2023-07-26\n42.5\n\n\n\n\n127205 rows × 4 columns\n\n\n\n\n# 'Date' 칼럼의 데이터 타입을 datetime으로 변경\ndf['Date'] = pd.to_datetime(df['Date'])\n\n# 다시 각 기상 관측소별로 누락된 날짜를 찾아 0으로 채움\nfilled_dfs = []\nfor (station_id, station_name), group in df.groupby(['Station_ID', 'Station_Name']):\n    all_dates = pd.date_range(start=group['Date'].min(), end=group['Date'].max())\n    filled_data = all_dates.to_frame(name='Date').merge(group, on='Date', how='left')\n    filled_data['Station_ID'].fillna(station_id, inplace=True)\n    filled_data['Station_Name'].fillna(station_name, inplace=True)\n    filled_data['Precipitation'].fillna(0, inplace=True)\n    filled_dfs.append(filled_data)\n\n# 모든 기상 관측소의 보정된 데이터를 결합\ndf2 = pd.concat(filled_dfs)\n\ndf2.head()\n\n\n\n\n\n\n\n\nDate\nStation_ID\nStation_Name\nPrecipitation\n\n\n\n\n0\n2013-08-09\n90.0\n속초\n15.5\n\n\n1\n2013-08-10\n90.0\n속초\n9.5\n\n\n2\n2013-08-11\n90.0\n속초\n0.0\n\n\n3\n2013-08-12\n90.0\n속초\n0.0\n\n\n4\n2013-08-13\n90.0\n속초\n0.0\n\n\n\n\n\n\n\n\ndf2.to_csv(\"PRCP_KOR2.csv\")"
  },
  {
    "objectID": "연구/규빈/2023-07-07-(연구) 다중척도방법.html",
    "href": "연구/규빈/2023-07-07-(연구) 다중척도방법.html",
    "title": "(연구) 다중척도방법",
    "section": "",
    "text": "\\({\\boldsymbol y}={\\boldsymbol X}^\\top\\)\n\n이 논문에서는 몇 가지 멀티스케일 방법을 리뷰하고자 한다.\n멀티스케일 방법이란 ~ + 왜 멀티스케일 방법을 써야하는가.\n우리는 그중에서 시각화와 분해에 관심이 있다. + 다른 접근법들도 소개\n시각화가 사용되는 사례, 어떻게 이용할 수 있는가?\n분해가 이용되는 사례, 어떻게 이용할 수 있는가?\n많은 멀티스케일 방법 중 우리는 TPT, EPT, EBT 를 중점적으로 소개하는데 초점을 맞출 것이다.\n각각의 transform은 어떠한 공통점이 있는가?\n왜 이렇게 많은 트랜스폼이 있어야하는가?\n미래에는 어떠한 트랜스폼을 만드는 것이 좋을까?"
  },
  {
    "objectID": "연구/규빈/2023-07-07-(연구) 다중척도방법.html#motivation-of-emd",
    "href": "연구/규빈/2023-07-07-(연구) 다중척도방법.html#motivation-of-emd",
    "title": "(연구) 다중척도방법",
    "section": "Motivation of EMD",
    "text": "Motivation of EMD\n- A necessary condition to define a meaningful instantaneous frequency is that signals are symmetric with respect to the local zero mean.\n- EMD is developed to decompose signals so that HT works well.\n- Suppose we have a signal \\(x(t) = 0.5 t + \\sin(\\pi t) + \\sin(2 \\pi t) + \\sin(6 \\pi t)\\).\n\n\n\nimage.png"
  },
  {
    "objectID": "연구/규빈/2023-07-07-(연구) 다중척도방법.html#sifting-process-for-extracting-imfs",
    "href": "연구/규빈/2023-07-07-(연구) 다중척도방법.html#sifting-process-for-extracting-imfs",
    "title": "(연구) 다중척도방법",
    "section": "Sifting process for extracting IMF’s",
    "text": "Sifting process for extracting IMF’s\n\nIdentify local extrema.\nObtain two functions interpolated by local maxima and minima.\nTake an average of envelopes.\nAn oscillated signal is extracted by subtracting the envelope mean from the original signal \\(x(t)\\).\n\n\n\n\nimage.png\n\n\n- One iteration of the above procedure does not guarantee that the signal is an IMF. The same procedure is applied to the signal until the properties of IMF are satisfied\n- This iterative algorithm is called sifting process.\n- Sifting makes the remaining signal more symmetric with respect to the local zero mean.\n- Finally, we have \\(L\\) empirical modes and a residue, \\[\nx(t) = \\sum_{\\ell=1}^{L} \\text{imf}_\\ell(t) + r(t).\n\\]\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n\n\n\nimage.png"
  },
  {
    "objectID": "연구/규빈/EPT_DISSIM/2023-08-08-진행사항.html",
    "href": "연구/규빈/EPT_DISSIM/2023-08-08-진행사항.html",
    "title": "(연구) EPT-DISSIM – 진행사항",
    "section": "",
    "text": "진행사항\nEPT_DISSIM: visualization (23.08.07) – 현재 중단\n\nPRCP_KOR 자료에 대한 시각화\n\nPRCP_KOR2.csv\n\ndownload: https://github.com/miruetoto/yechan3/blob/main/posts/3_Researches/YECHAN/EPT_DISSIM/PRCP_KOR2.csv\n결측치를 0으로 채움"
  },
  {
    "objectID": "연구/규빈/EPT_DISSIM/2023-08-07-PRCP_KOR 데이터정리.html",
    "href": "연구/규빈/EPT_DISSIM/2023-08-07-PRCP_KOR 데이터정리.html",
    "title": "(연구) EPT-DISSIM – PRCP_KOR 데이터정리",
    "section": "",
    "text": "import pandas as pd\n\n1. load raw-data\n\ndf = pd.read_csv(\"OBS_ASOS_DD_20230807193646.csv\", encoding='EUC-KR')\ndf = df.rename({'지점':'Station_ID','지점명':'Station_Name','일시':'Date','일강수량(mm)':'Precipitation'},axis=1)\ndf\n\n\n\n\n\n\n\n\nStation_ID\nStation_Name\nDate\nPrecipitation\n\n\n\n\n0\n90\n속초\n2013-08-09\n15.5\n\n\n1\n90\n속초\n2013-08-10\n9.5\n\n\n2\n90\n속초\n2013-08-16\n0.1\n\n\n3\n90\n속초\n2013-08-18\n0.0\n\n\n4\n90\n속초\n2013-08-19\n9.0\n\n\n...\n...\n...\n...\n...\n\n\n127200\n295\n남해\n2023-07-22\n4.3\n\n\n127201\n295\n남해\n2023-07-23\n13.4\n\n\n127202\n295\n남해\n2023-07-24\n17.0\n\n\n127203\n295\n남해\n2023-07-25\n4.7\n\n\n127204\n295\n남해\n2023-07-26\n42.5\n\n\n\n\n127205 rows × 4 columns\n\n\n\n2. save dataframe as PRCP_KOR.csv\n\ndf.to_csv('PRCP_KOR.csv',index=False)"
  },
  {
    "objectID": "연구/재인/2023-10-12-MBTI.html",
    "href": "연구/재인/2023-10-12-MBTI.html",
    "title": "(연구&재인) MBTI – MBTI",
    "section": "",
    "text": "import pandas as pd\nimport sklearn.model_selection \n\n\ndf = pd.read_csv('mbti_1.csv')\ndf_train, df_test = sklearn.model_selection.train_test_split(df,test_size=0.3)\n\n\ndf[:1]\n\n\n\n\n\n\n\n\ntype\nposts\n\n\n\n\n0\nINFJ\n'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n\n\n\n\n\n\n\n\nfrom autogluon.multimodal import MultiModalPredictor\nimport uuid\nmodel_path = f\"./tmp/{uuid.uuid4().hex}-automm_sst\"\npredictor = MultiModalPredictor(label='type', eval_metric='acc', path=model_path)\npredictor.fit(df_train)\n\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libc10_cuda.so: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n  warn(\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\nAutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n    First 10 (of 16) unique label values:  ['INFJ', 'ENTJ', 'ENFP', 'INFP', 'ISTJ', 'ISTP', 'ESFJ', 'INTP', 'INTJ', 'ISFP']\n    If 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\nGlobal seed set to 0\nAutoMM starts to create your model. ✨\n\n- AutoGluon version is 0.8.2.\n\n- Pytorch version is 2.0.0.post2.\n\n- Model will be saved to \"/home/cgb2/Dropbox/03_yechan3/posts/3_Researches/JAEIN/tmp/1c22bc85561c4fad9dbff452305364e5-automm_sst\".\n\n- Validation metric is \"acc\".\n\n- To track the learning progress, you can open a terminal and launch Tensorboard:\n    ```shell\n    # Assume you have installed tensorboard\n    tensorboard --logdir /home/cgb2/Dropbox/03_yechan3/posts/3_Researches/JAEIN/tmp/1c22bc85561c4fad9dbff452305364e5-automm_sst\n    ```\n\nEnjoy your coffee, and let AutoMM do the job ☕☕☕ Learn more at https://auto.gluon.ai\n\n0 GPUs are detected, and 0 GPUs will be used.\n\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/autogluon/multimodal/utils/environment.py:91: UserWarning: Only CPU is detected in the instance. This may result in slow speed for MultiModalPredictor. Consider using an instance with GPU support.\n  warnings.warn(\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\n\n  | Name              | Type                         | Params\n-------------------------------------------------------------------\n0 | model             | HFAutoModelForTextPrediction | 108 M \n1 | validation_metric | MulticlassAccuracy           | 0     \n2 | loss_func         | CrossEntropyLoss             | 0     \n-------------------------------------------------------------------\n108 M     Trainable params\n0         Non-trainable params\n108 M     Total params\n435.616   Total estimated model params size (MB)\nEpoch 0, global step 21: 'val_acc' reached 0.18750 (best 0.18750), saving model to '/home/cgb2/Dropbox/03_yechan3/posts/3_Researches/JAEIN/tmp/1c22bc85561c4fad9dbff452305364e5-automm_sst/epoch=0-step=21.ckpt' as top 3\n[rank: 0] Received SIGTERM: 15\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n\n\nEpoch 0:  50%|████▉     | 341/683 [1:30:43&lt;1:30:59, 15.96s/it]             Epoch 0:  73%|███████▎  | 501/683 [2:11:46&lt;47:52, 15.78s/it]  Epoch 0:  73%|███████▎  | 502/683 [2:12:01&lt;47:36, 15.78s/it]\n\n\nSIGTERMException: \n\n\n: \n\n\n\npost1 = \"http://www.youtube.com/watch?v=qsXHcwe3krw|||http://41.media.tumblr.com/tumblr_lfouy03PMA1qa1rooo1_500.jpg|||enfp and intj moments  https://www.youtube.com/watch?v=iz7lE1g4XM4  sportscenter not top ten plays  https://www.youtube.com/watch?v=uCdfze1etec  pranks|||What has been the most life-changing experience in your life?|||http://www.youtube.com/watch?v=vXZeYwwRDw8   http://www.youtube.com/watch?v=u8ejam5DP3E  On repeat for most of today.|||May the PerC Experience immerse you.|||The last thing my INFJ friend posted on his facebook before committing suicide the next day. Rest in peace~   http://vimeo.com/22842206|||Hello ENFJ7. Sorry to hear of your distress. It's only natural for a relationship to not be perfection all the time in every moment of existence. Try to figure the hard times as times of growth, as...|||84389  84390  http://wallpaperpassion.com/upload/23700/friendship-boy-and-girl-wallpaper.jpg  http://assets.dornob.com/wp-content/uploads/2010/04/round-home-design.jpg ...|||Welcome and stuff.|||http://playeressence.com/wp-content/uploads/2013/08/RED-red-the-pokemon-master-32560474-450-338.jpg  Game. Set. Match.|||Prozac, wellbrutin, at least thirty minutes of moving your legs (and I don't mean moving them while sitting in your same desk chair), weed in moderation (maybe try edibles as a healthier alternative...|||Basically come up with three items you've determined that each type (or whichever types you want to do) would more than likely use, given each types' cognitive functions and whatnot, when left by...|||All things in moderation.  Sims is indeed a video game, and a good one at that. Note: a good one at that is somewhat subjective in that I am not completely promoting the death of any given Sim...|||Dear ENFP:  What were your favorite video games growing up and what are your now, current favorite video games? :cool:|||https://www.youtube.com/watch?v=QyPqT8umzmY|||It appears to be too late. :sad:|||There's someone out there for everyone.|||Wait... I thought confidence was a good thing.|||I just cherish the time of solitude b/c i revel within my inner world more whereas most other time i'd be workin... just enjoy the me time while you can. Don't worry, people will always be around to...|||Yo entp ladies... if you're into a complimentary personality,well, hey.|||... when your main social outlet is xbox live conversations and even then you verbally fatigue quickly.|||http://www.youtube.com/watch?v=gDhy7rdfm14  I really dig the part from 1:46 to 2:50|||http://www.youtube.com/watch?v=msqXffgh7b8|||Banned because this thread requires it of me.|||Get high in backyard, roast and eat marshmellows in backyard while conversing over something intellectual, followed by massages and kisses.|||http://www.youtube.com/watch?v=Mw7eoU3BMbE|||http://www.youtube.com/watch?v=4V2uYORhQOk|||http://www.youtube.com/watch?v=SlVmgFQQ0TI|||Banned for too many b's in that sentence. How could you! Think of the B!|||Banned for watching movies in the corner with the dunces.|||Banned because Health class clearly taught you nothing about peer pressure.|||Banned for a whole host of reasons!|||http://www.youtube.com/watch?v=IRcrv41hgz4|||1) Two baby deer on left and right munching on a beetle in the middle.  2) Using their own blood, two cavemen diary today's latest happenings on their designated cave diary wall.  3) I see it as...|||a pokemon world  an infj society  everyone becomes an optimist|||49142|||http://www.youtube.com/watch?v=ZRCEq_JFeFM|||http://discovermagazine.com/2012/jul-aug/20-things-you-didnt-know-about-deserts/desert.jpg|||http://oyster.ignimgs.com/mediawiki/apis.ign.com/pokemon-silver-version/d/dd/Ditto.gif|||http://www.serebii.net/potw-dp/Scizor.jpg|||Not all artists are artists because they draw. It's the idea that counts in forming something of your own... like a signature.|||Welcome to the robot ranks, person who downed my self-esteem cuz I'm not an avid signature artist like herself. :proud:|||Banned for taking all the room under my bed. Ya gotta learn to share with the roaches.|||http://www.youtube.com/watch?v=w8IgImn57aQ|||Banned for being too much of a thundering, grumbling kind of storm... yep.|||Ahh... old high school music I haven't heard in ages.   http://www.youtube.com/watch?v=dcCRUPCdB1w|||I failed a public speaking class a few years ago and I've sort of learned what I could do better were I to be in that position again. A big part of my failure was just overloading myself with too...|||I like this person's mentality. He's a confirmed INTJ by the way. http://www.youtube.com/watch?v=hGKLI-GEc6M|||Move to the Denver area and start a new life for myself.\"\npredictions = predictor.predict({'posts': [post1]})\npredictions\n\narray(['ENTP'], dtype=object)"
  },
  {
    "objectID": "연구/재인/2023-10-11-감성분석.html",
    "href": "연구/재인/2023-10-11-감성분석.html",
    "title": "(연구&재인) MBTI – 감성분석",
    "section": "",
    "text": "from autogluon.core.utils.loaders import load_pd\ntrain_data = load_pd.load('https://autogluon-text.s3-accelerate.amazonaws.com/glue/sst/train.parquet')\ntest_data = load_pd.load('https://autogluon-text.s3-accelerate.amazonaws.com/glue/sst/dev.parquet')\nsubsample_size = 1000  # subsample data for faster demo, try setting this to larger values\ntrain_data = train_data.sample(n=subsample_size, random_state=0)\ntrain_data.head(10)\n\n\n\n\n\n\n\n\nsentence\nlabel\n\n\n\n\n43787\nvery pleasing at its best moments\n1\n\n\n16159\n, american chai is enough to make you put away...\n0\n\n\n59015\ntoo much like an infomercial for ram dass 's l...\n0\n\n\n5108\na stirring visual sequence\n1\n\n\n67052\ncool visual backmasking\n1\n\n\n35938\nhard ground\n0\n\n\n49879\nthe striking , quietly vulnerable personality ...\n1\n\n\n51591\npan nalin 's exposition is beautiful and myste...\n1\n\n\n56780\nwonderfully loopy\n1\n\n\n28518\nmost beautiful , evocative\n1\n\n\n\n\n\n\n\n\nfrom autogluon.multimodal import MultiModalPredictor\nimport uuid\nmodel_path = f\"./tmp/{uuid.uuid4().hex}-automm_sst\"\npredictor = MultiModalPredictor(label='label', eval_metric='acc', path=model_path)\npredictor.fit(train_data, time_limit=180)\n\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libc10_cuda.so: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n  warn(\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\nAutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n    2 unique label values:  [0, 1]\n    If 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\nGlobal seed set to 0\nAutoMM starts to create your model. ✨\n\n- AutoGluon version is 0.8.2.\n\n- Pytorch version is 2.0.0.post2.\n\n- Model will be saved to \"/home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst\".\n\n- Validation metric is \"acc\".\n\n- To track the learning progress, you can open a terminal and launch Tensorboard:\n    ```shell\n    # Assume you have installed tensorboard\n    tensorboard --logdir /home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst\n    ```\n\nEnjoy your coffee, and let AutoMM do the job ☕☕☕ Learn more at https://auto.gluon.ai\n\nDownloading (…)lve/main/config.json: 100%|██████████| 666/666 [00:00&lt;00:00, 1.35MB/s]\nDownloading pytorch_model.bin: 100%|██████████| 440M/440M [00:21&lt;00:00, 20.0MB/s] \nDownloading (…)okenizer_config.json: 100%|██████████| 27.0/27.0 [00:00&lt;00:00, 59.8kB/s]\nDownloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00&lt;00:00, 1.16MB/s]\nDownloading (…)/main/tokenizer.json: 100%|██████████| 466k/466k [00:00&lt;00:00, 58.6MB/s]\n0 GPUs are detected, and 0 GPUs will be used.\n\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/autogluon/multimodal/utils/environment.py:91: UserWarning: Only CPU is detected in the instance. This may result in slow speed for MultiModalPredictor. Consider using an instance with GPU support.\n  warnings.warn(\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\n\n  | Name              | Type                         | Params\n-------------------------------------------------------------------\n0 | model             | HFAutoModelForTextPrediction | 108 M \n1 | validation_metric | MulticlassAccuracy           | 0     \n2 | loss_func         | CrossEntropyLoss             | 0     \n-------------------------------------------------------------------\n108 M     Trainable params\n0         Non-trainable params\n108 M     Total params\n435.573   Total estimated model params size (MB)\nEpoch 0, global step 3: 'val_acc' reached 0.46500 (best 0.46500), saving model to '/home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst/epoch=0-step=3.ckpt' as top 3\nEpoch 0, global step 7: 'val_acc' reached 0.57000 (best 0.57000), saving model to '/home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst/epoch=0-step=7.ckpt' as top 3\nEpoch 1, global step 10: 'val_acc' reached 0.77500 (best 0.77500), saving model to '/home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst/epoch=1-step=10.ckpt' as top 3\nEpoch 1, global step 14: 'val_acc' reached 0.79500 (best 0.79500), saving model to '/home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst/epoch=1-step=14.ckpt' as top 3\nTime limit reached. Elapsed time is 0:03:01. Signaling Trainer to stop.\nStart to fuse 3 checkpoints via the greedy soup algorithm.\nAutoMM has created your model 🎉🎉🎉\n\n- To load the model, use the code below:\n    ```python\n    from autogluon.multimodal import MultiModalPredictor\n    predictor = MultiModalPredictor.load(\"/home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst\")\n    ```\n\n- You can open a terminal and launch Tensorboard to visualize the training log:\n    ```shell\n    # Assume you have installed tensorboard\n    tensorboard --logdir /home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst\n    ```\n\n- If you are not satisfied with the model, try to increase the training time, \nadjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\nor post issues on GitHub: https://github.com/autogluon/autogluon\n\n\n\n\nEpoch 0:  50%|█████     | 50/100 [00:38&lt;00:38,  1.29it/s]                  Epoch 0: 100%|██████████| 100/100 [01:25&lt;00:00,  1.18it/s]Epoch 1:  50%|█████     | 50/100 [00:43&lt;00:43,  1.14it/s] Epoch 1: 100%|██████████| 100/100 [01:30&lt;00:00,  1.10it/s]Epoch 2:   0%|          | 0/100 [00:00&lt;?, ?it/s]          Epoch 2:   1%|          | 1/100 [00:06&lt;10:45,  6.52s/it]\nPredicting DataLoader 0: 100%|██████████| 7/7 [00:05&lt;00:00,  1.25it/s]\nPredicting DataLoader 0: 100%|██████████| 7/7 [00:05&lt;00:00,  1.29it/s]\nPredicting DataLoader 0: 100%|██████████| 7/7 [00:05&lt;00:00,  1.25it/s]\n\n\n&lt;autogluon.multimodal.predictor.MultiModalPredictor at 0x7f8acd4349a0&gt;\n\n\n\nsentence1 = \"it's a charming and often affecting journey.\"\nsentence2 = \"It's slow, very, very, very slow.\"\npredictions = predictor.predict({'sentence': [sentence1, sentence2]})\nprint('\"Sentence\":', sentence1, '\"Predicted Sentiment\":', predictions[0])\nprint('\"Sentence\":', sentence2, '\"Predicted Sentiment\":', predictions[1])\n\n\"Sentence\": it's a charming and often affecting journey. \"Predicted Sentiment\": 1\n\"Sentence\": It's slow, very, very, very slow. \"Predicted Sentiment\": 0"
  },
  {
    "objectID": "연구/규빈/EPT_DISSIM/2023-08-07-(연구) EPT-DISSIM -- PRCP_KOR 데이터정리.html",
    "href": "연구/규빈/EPT_DISSIM/2023-08-07-(연구) EPT-DISSIM -- PRCP_KOR 데이터정리.html",
    "title": "(연구) EPT-DISSIM – PRCP_KOR 데이터정리",
    "section": "",
    "text": "import pandas as pd\n\n1. load raw-data\n\ndf = pd.read_csv(\"OBS_ASOS_DD_20230807193646.csv\", encoding='EUC-KR')\ndf = df.rename({'지점':'Station_ID','지점명':'Station_Name','일시':'Date','일강수량(mm)':'Precipitation'},axis=1)\ndf\n\n\n\n\n\n\n\n\nStation_ID\nStation_Name\nDate\nPrecipitation\n\n\n\n\n0\n90\n속초\n2013-08-09\n15.5\n\n\n1\n90\n속초\n2013-08-10\n9.5\n\n\n2\n90\n속초\n2013-08-16\n0.1\n\n\n3\n90\n속초\n2013-08-18\n0.0\n\n\n4\n90\n속초\n2013-08-19\n9.0\n\n\n...\n...\n...\n...\n...\n\n\n127200\n295\n남해\n2023-07-22\n4.3\n\n\n127201\n295\n남해\n2023-07-23\n13.4\n\n\n127202\n295\n남해\n2023-07-24\n17.0\n\n\n127203\n295\n남해\n2023-07-25\n4.7\n\n\n127204\n295\n남해\n2023-07-26\n42.5\n\n\n\n\n127205 rows × 4 columns\n\n\n\n2. save dataframe as PRCP_KOR.csv\n\ndf.to_csv('PRCP_KOR.csv',index=False)"
  },
  {
    "objectID": "연구/규빈/EPT_DISSIM/2023-08-18-(연구) EPT-DISSIM -- 데이터전처리.html",
    "href": "연구/규빈/EPT_DISSIM/2023-08-18-(연구) EPT-DISSIM -- 데이터전처리.html",
    "title": "(연구) EPT-DISSIM – PRCP_KOR2 데이터정리",
    "section": "",
    "text": "import pandas as pd\n\n\ndf = pd.read_csv('PRCP_KOR.csv')\ndf\n\n\n\n\n\n\n\n\nStation_ID\nStation_Name\nDate\nPrecipitation\n\n\n\n\n0\n90\n속초\n2013-08-09\n15.5\n\n\n1\n90\n속초\n2013-08-10\n9.5\n\n\n2\n90\n속초\n2013-08-16\n0.1\n\n\n3\n90\n속초\n2013-08-18\n0.0\n\n\n4\n90\n속초\n2013-08-19\n9.0\n\n\n...\n...\n...\n...\n...\n\n\n127200\n295\n남해\n2023-07-22\n4.3\n\n\n127201\n295\n남해\n2023-07-23\n13.4\n\n\n127202\n295\n남해\n2023-07-24\n17.0\n\n\n127203\n295\n남해\n2023-07-25\n4.7\n\n\n127204\n295\n남해\n2023-07-26\n42.5\n\n\n\n\n127205 rows × 4 columns\n\n\n\n\n# 'Date' 칼럼의 데이터 타입을 datetime으로 변경\ndf['Date'] = pd.to_datetime(df['Date'])\n\n# 다시 각 기상 관측소별로 누락된 날짜를 찾아 0으로 채움\nfilled_dfs = []\nfor (station_id, station_name), group in df.groupby(['Station_ID', 'Station_Name']):\n    all_dates = pd.date_range(start=group['Date'].min(), end=group['Date'].max())\n    filled_data = all_dates.to_frame(name='Date').merge(group, on='Date', how='left')\n    filled_data['Station_ID'].fillna(station_id, inplace=True)\n    filled_data['Station_Name'].fillna(station_name, inplace=True)\n    filled_data['Precipitation'].fillna(0, inplace=True)\n    filled_dfs.append(filled_data)\n\n# 모든 기상 관측소의 보정된 데이터를 결합\ndf2 = pd.concat(filled_dfs)\n\ndf2.head()\n\n\n\n\n\n\n\n\nDate\nStation_ID\nStation_Name\nPrecipitation\n\n\n\n\n0\n2013-08-09\n90.0\n속초\n15.5\n\n\n1\n2013-08-10\n90.0\n속초\n9.5\n\n\n2\n2013-08-11\n90.0\n속초\n0.0\n\n\n3\n2013-08-12\n90.0\n속초\n0.0\n\n\n4\n2013-08-13\n90.0\n속초\n0.0\n\n\n\n\n\n\n\n\ndf2.to_csv(\"PRCP_KOR2.csv\")"
  },
  {
    "objectID": "연구/규빈/EPT_DISSIM/2023-08-08-(연구) EPT-DISSIM -- 진행사항.html",
    "href": "연구/규빈/EPT_DISSIM/2023-08-08-(연구) EPT-DISSIM -- 진행사항.html",
    "title": "(연구) EPT-DISSIM – 진행사항",
    "section": "",
    "text": "진행사항\nEPT_DISSIM: visualization (23.08.07) – 현재 중단\n\nPRCP_KOR 자료에 대한 시각화\n\nPRCP_KOR2.csv\n\ndownload: https://github.com/miruetoto/yechan3/blob/main/posts/3_Researches/YECHAN/EPT_DISSIM/PRCP_KOR2.csv\n결측치를 0으로 채움"
  },
  {
    "objectID": "연구/서연/2023-03-01-수통문제-Type1 Err, Type2 Err.html",
    "href": "연구/서연/2023-03-01-수통문제-Type1 Err, Type2 Err.html",
    "title": "(공부&서연) – 지수분포 가설검정",
    "section": "",
    "text": "using Distributions, Plots\n\n(문제) \\(X_1,X_2\\)가 평균이 \\(\\theta\\)인 지수분포에서 추출한 랜덤표본이라고 하자. 가설 \\(H_0: \\theta=2\\) vs \\(H_1:\\theta=1\\) 에 대하여, \\(H_0\\)에 대한 기각영역을\n\\[\\frac{f(x_1;\\theta=2)f(x_2;\\theta=2)}{f(x_1;\\theta=1)f(x_2;\\theta=1)}&lt;\\frac{1}{2}\\]\n와 같이 설정하자. 이와 같은 검정법에 대한 \\(\\alpha\\)와 \\(\\beta\\)를 구하라.\n(풀이)\n문제요약\n\n\\(f(x) = \\frac{1}{\\theta} \\exp(-\\frac{x}{\\theta})\\) -&gt; 평균이 \\(\\theta\\) 인 지수분포\n검정통계량: \\(T=\\frac{f(x_1;2)f(x_2;2)}{f(x_1;1)f(x_2;1)}\\)\n\\(\\alpha = P(\\text{Reject $H_0$|$H_0$ is true}) = P(T&lt;\\frac{1}{2} | \\text{$H_0$ is true})\\)\n\\(\\beta = P(\\text{Accept $H_0$|$H_1$ is true}) = P(T&gt;\\frac{1}{2} | \\text{$H_1$ is true})\\)\n\n풀이시작\n\nT= x -&gt; 0.5*exp(-0.5*x[1]) * 0.5*exp(-0.5*x[2])  / (exp(-x[1])*exp(-x[2]))\n\n#1 (generic function with 1 method)\n\n\n\\(\\alpha\\)를 구해보자. (시뮬)\n\nθ=2 \nx = rand(Exponential(θ),2)\n\n2-element Vector{Float64}:\n 1.4932782791687658\n 3.904496314340747\n\n\n\nT(x)\n\n3.715796051759978\n\n\n\nTs = [rand(Exponential(θ),2) |&gt; T for i in 1:1400000]\nmean(Ts .&lt; 1/2)\n\n0.1535007142857143\n\n\n\\(\\beta\\)를 구해보자. (시뮬)\n\nθ=1\nx = rand(Exponential(θ),2)\n\n2-element Vector{Float64}:\n 1.0915718974295616\n 3.322182470278192\n\n\n\nTs = [rand(Exponential(θ),2) |&gt; T for i in 1:1400000]\nmean(Ts .&gt; 1/2)\n\n0.5967985714285714\n\n\n\\(\\alpha\\)를 구해보자. (이론)\n\\(T(X_1,X_2) = \\frac{0.25\\exp(-0.5X_1 -0.5X_2)}{\\exp(-X_1-X_2)}=0.25\\exp(0.5X_1+0.5X_2)\\)\n$T(X_1,X_2)&lt; (0.5X_1+0.5X_2) &lt; 2 X_1+X_2&lt; 2 $\n그런데 \\(X_1+X_2 \\sim \\chi^2(4)\\) under \\(H_0\\)\n\\(P(X_1+X_2 &lt; 2\\ln2) = \\int_0^{2\\ln2} \\frac{1}{4\\Gamma(2)}x e^{-x/2}dx=\\int_0^{\\ln2} t e^{-t}dt=\\big[t(-e^{-t})-e^{-t}\\big]_0^{\\ln2}\\)\n\nt = log(2) \nu = t*(-exp(-t)) - exp(-t)\nt = 0\nl = t*(-exp(-t)) - exp(-t)\n\n-1.0\n\n\n\nu-l\n\n0.1534264097200273\n\n\n\\(\\beta\\)를 구해보자. (이론)\n$T(X_1,X_2)&gt; (0.5X_1+0.5X_2) &gt; 2 (X_1+X_2)&gt; 4 $\n그런데 \\(2(X_1+X_2) \\sim \\chi^2(4)\\) under \\(H_1\\)\n\\(P(2(X_1+X_2) &gt; 4\\ln2) = \\int_{4\\ln2}^{\\infty}\\frac{1}{4\\Gamma(2)}x e^{-x/2}dx=\\int_{2\\ln2}^{\\infty} t e^{-t}dt=\\big[t(-e^{-t})-e^{-t}\\big]_{2\\ln2}^{\\infty}\\)\n\nu = 0\nt = 2*log(2)\nl = t*(-exp(-t)) - exp(-t)\nu-l\n\n0.5965735902799727"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2023-09-14-논문리비전.html",
    "href": "연구/서연/ITSTGCN/2023-09-14-논문리비전.html",
    "title": "(연구&서연) IT-STGCN – 논문리비전",
    "section": "",
    "text": "image.png\n\n\n- 초록색은 나쁘지 않음. 하지만 아래의 내용을 보완하는게 좋음.\n\n분야의 예시로 신경과학, 환경데이터, 교통자료가 있는데 우리가 실제로 분석한 자료들이 사용된 논문을 찾아보며 예시를 들것 (Chickenpox, …) 사용하지 않더라도 예시를 들것.\n이러한 자료를 분석하는것이 왜 어려운지 설명할 것. 즉 단순히 시계열로 해석하거나 공간자료로 해석하면 어떠한 문제가 있는지 간단히 서술할 것. (1~2문장) 레퍼런스 찾을것. (torch_geometric_temporal 의 도입부분 활용)\n\n- 붉은부분\n\n의도는 좋으나 sparse data 는 올바르지 않은 표현임. missing, irregulary observed data 등으로 설명할 것.\n이러한 자료가 왜 발생하는지 설명할 것. (이부분은 레퍼런스 필요) 이러한 자료를 처리하는 것이 어려운 이유를 설명할 것.1\n우리의 아이디어는 “호모지니우스하지 않은 그래프 -&gt; 호모지니우스화 시킴” 인데 이러한 방식은 이상한방식이 아님. Yu et al. (2017) and Guo et al. (2019) Bai et al. (2020), Li et al. (2019), Zhao et al. (2019) 이 우리와 비슷한 연구를 했음.\n\n- 아래식은 틀렸음. 이건 회귀모형이 아님.. GNAR의 notation을 사용하여 모형을 다시표현해볼것..\n\n\n\nimage.png\n\n\n\n이부분이 아주 클리어 해야함\n사용하는 대부분의 Notations들이 정리되어야함.\nintro에 쓰는 것이 부담스러우면 제외해도 무방\n뒤에 self consistence estimator에 사용할 Notation을 함께 고려\n\n- 빨간부분 삭제후 다시 작성 (혹은 공부할 것)\n\n\n\nimage.png\n\n\n- 초록색부분은 나쁘지 않음\n\n\n\nimage.png"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2023-09-14-논문리비전.html#footnotes",
    "href": "연구/서연/ITSTGCN/2023-09-14-논문리비전.html#footnotes",
    "title": "(연구&서연) IT-STGCN – 논문리비전",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n보통 결측없이 모두 관측한상태에서는 모형이 잘 동작함, 대부분의 spatio temporal data는 각각의 스냅샷마다 동일한 그래프구조를 가진다는 가정을 사용함. 스냅샷마다 그래프구조가 다른 경우를 가정하는 모형도 있음. 그러한 모형의 예시는 A,B,C,…. 등이 있음. 하지만 이러한 연구는 애초에 데이터가 스냅샷마다 non-호모지니우스하게 생겼으면 효율적일 수 있으나, 실제true model은 스냅샷마다 그래프구조가 동일하다고 여겨지지만 결측치로 인하여 스냅샷마다 호모지니우스가 깨지는 경우는 효율적이지 않을 수 있음. 우리는 이 부분에 초점을 맞추었음. 우리의 아이디어는 호모지니우스 하지 않은 그래프를 A,B,C, 등을 이용하여 그대로 처리하는것 보다 missing을 처리하여 호모지니우스하게 강제로 만들고 그 자료를 분석하자는 아이디어임.↩︎"
  },
  {
    "objectID": "공부/2023-03-01-(공부&서연) -- 지수분포 가설검정.html",
    "href": "공부/2023-03-01-(공부&서연) -- 지수분포 가설검정.html",
    "title": "(공부&서연) – 지수분포 가설검정",
    "section": "",
    "text": "using Distributions, Plots\n\n(문제) \\(X_1,X_2\\)가 평균이 \\(\\theta\\)인 지수분포에서 추출한 랜덤표본이라고 하자. 가설 \\(H_0: \\theta=2\\) vs \\(H_1:\\theta=1\\) 에 대하여, \\(H_0\\)에 대한 기각영역을\n\\[\\frac{f(x_1;\\theta=2)f(x_2;\\theta=2)}{f(x_1;\\theta=1)f(x_2;\\theta=1)}&lt;\\frac{1}{2}\\]\n와 같이 설정하자. 이와 같은 검정법에 대한 \\(\\alpha\\)와 \\(\\beta\\)를 구하라.\n(풀이)\n문제요약\n\n\\(f(x) = \\frac{1}{\\theta} \\exp(-\\frac{x}{\\theta})\\) -&gt; 평균이 \\(\\theta\\) 인 지수분포\n검정통계량: \\(T=\\frac{f(x_1;2)f(x_2;2)}{f(x_1;1)f(x_2;1)}\\)\n\\(\\alpha = P(\\text{Reject $H_0$|$H_0$ is true}) = P(T&lt;\\frac{1}{2} | \\text{$H_0$ is true})\\)\n\\(\\beta = P(\\text{Accept $H_0$|$H_1$ is true}) = P(T&gt;\\frac{1}{2} | \\text{$H_1$ is true})\\)\n\n풀이시작\n\nT= x -&gt; 0.5*exp(-0.5*x[1]) * 0.5*exp(-0.5*x[2])  / (exp(-x[1])*exp(-x[2]))\n\n#1 (generic function with 1 method)\n\n\n\\(\\alpha\\)를 구해보자. (시뮬)\n\nθ=2 \nx = rand(Exponential(θ),2)\n\n2-element Vector{Float64}:\n 1.4932782791687658\n 3.904496314340747\n\n\n\nT(x)\n\n3.715796051759978\n\n\n\nTs = [rand(Exponential(θ),2) |&gt; T for i in 1:1400000]\nmean(Ts .&lt; 1/2)\n\n0.1535007142857143\n\n\n\\(\\beta\\)를 구해보자. (시뮬)\n\nθ=1\nx = rand(Exponential(θ),2)\n\n2-element Vector{Float64}:\n 1.0915718974295616\n 3.322182470278192\n\n\n\nTs = [rand(Exponential(θ),2) |&gt; T for i in 1:1400000]\nmean(Ts .&gt; 1/2)\n\n0.5967985714285714\n\n\n\\(\\alpha\\)를 구해보자. (이론)\n\\(T(X_1,X_2) = \\frac{0.25\\exp(-0.5X_1 -0.5X_2)}{\\exp(-X_1-X_2)}=0.25\\exp(0.5X_1+0.5X_2)\\)\n$T(X_1,X_2)&lt; (0.5X_1+0.5X_2) &lt; 2 X_1+X_2&lt; 2 $\n그런데 \\(X_1+X_2 \\sim \\chi^2(4)\\) under \\(H_0\\)\n\\(P(X_1+X_2 &lt; 2\\ln2) = \\int_0^{2\\ln2} \\frac{1}{4\\Gamma(2)}x e^{-x/2}dx=\\int_0^{\\ln2} t e^{-t}dt=\\big[t(-e^{-t})-e^{-t}\\big]_0^{\\ln2}\\)\n\nt = log(2) \nu = t*(-exp(-t)) - exp(-t)\nt = 0\nl = t*(-exp(-t)) - exp(-t)\n\n-1.0\n\n\n\nu-l\n\n0.1534264097200273\n\n\n\\(\\beta\\)를 구해보자. (이론)\n$T(X_1,X_2)&gt; (0.5X_1+0.5X_2) &gt; 2 (X_1+X_2)&gt; 4 $\n그런데 \\(2(X_1+X_2) \\sim \\chi^2(4)\\) under \\(H_1\\)\n\\(P(2(X_1+X_2) &gt; 4\\ln2) = \\int_{4\\ln2}^{\\infty}\\frac{1}{4\\Gamma(2)}x e^{-x/2}dx=\\int_{2\\ln2}^{\\infty} t e^{-t}dt=\\big[t(-e^{-t})-e^{-t}\\big]_{2\\ln2}^{\\infty}\\)\n\nu = 0\nt = 2*log(2)\nl = t*(-exp(-t)) - exp(-t)\nu-l\n\n0.5965735902799727"
  },
  {
    "objectID": "연구/재인/2023-10-11-(연구&재인) MBTI -- 감성분석.html",
    "href": "연구/재인/2023-10-11-(연구&재인) MBTI -- 감성분석.html",
    "title": "(연구&재인) MBTI – 감성분석",
    "section": "",
    "text": "from autogluon.core.utils.loaders import load_pd\ntrain_data = load_pd.load('https://autogluon-text.s3-accelerate.amazonaws.com/glue/sst/train.parquet')\ntest_data = load_pd.load('https://autogluon-text.s3-accelerate.amazonaws.com/glue/sst/dev.parquet')\nsubsample_size = 1000  # subsample data for faster demo, try setting this to larger values\ntrain_data = train_data.sample(n=subsample_size, random_state=0)\ntrain_data.head(10)\n\n\n\n\n\n\n\n\nsentence\nlabel\n\n\n\n\n43787\nvery pleasing at its best moments\n1\n\n\n16159\n, american chai is enough to make you put away...\n0\n\n\n59015\ntoo much like an infomercial for ram dass 's l...\n0\n\n\n5108\na stirring visual sequence\n1\n\n\n67052\ncool visual backmasking\n1\n\n\n35938\nhard ground\n0\n\n\n49879\nthe striking , quietly vulnerable personality ...\n1\n\n\n51591\npan nalin 's exposition is beautiful and myste...\n1\n\n\n56780\nwonderfully loopy\n1\n\n\n28518\nmost beautiful , evocative\n1\n\n\n\n\n\n\n\n\nfrom autogluon.multimodal import MultiModalPredictor\nimport uuid\nmodel_path = f\"./tmp/{uuid.uuid4().hex}-automm_sst\"\npredictor = MultiModalPredictor(label='label', eval_metric='acc', path=model_path)\npredictor.fit(train_data, time_limit=180)\n\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libc10_cuda.so: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n  warn(\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\nAutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n    2 unique label values:  [0, 1]\n    If 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\nGlobal seed set to 0\nAutoMM starts to create your model. ✨\n\n- AutoGluon version is 0.8.2.\n\n- Pytorch version is 2.0.0.post2.\n\n- Model will be saved to \"/home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst\".\n\n- Validation metric is \"acc\".\n\n- To track the learning progress, you can open a terminal and launch Tensorboard:\n    ```shell\n    # Assume you have installed tensorboard\n    tensorboard --logdir /home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst\n    ```\n\nEnjoy your coffee, and let AutoMM do the job ☕☕☕ Learn more at https://auto.gluon.ai\n\nDownloading (…)lve/main/config.json: 100%|██████████| 666/666 [00:00&lt;00:00, 1.35MB/s]\nDownloading pytorch_model.bin: 100%|██████████| 440M/440M [00:21&lt;00:00, 20.0MB/s] \nDownloading (…)okenizer_config.json: 100%|██████████| 27.0/27.0 [00:00&lt;00:00, 59.8kB/s]\nDownloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00&lt;00:00, 1.16MB/s]\nDownloading (…)/main/tokenizer.json: 100%|██████████| 466k/466k [00:00&lt;00:00, 58.6MB/s]\n0 GPUs are detected, and 0 GPUs will be used.\n\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/autogluon/multimodal/utils/environment.py:91: UserWarning: Only CPU is detected in the instance. This may result in slow speed for MultiModalPredictor. Consider using an instance with GPU support.\n  warnings.warn(\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\n\n  | Name              | Type                         | Params\n-------------------------------------------------------------------\n0 | model             | HFAutoModelForTextPrediction | 108 M \n1 | validation_metric | MulticlassAccuracy           | 0     \n2 | loss_func         | CrossEntropyLoss             | 0     \n-------------------------------------------------------------------\n108 M     Trainable params\n0         Non-trainable params\n108 M     Total params\n435.573   Total estimated model params size (MB)\nEpoch 0, global step 3: 'val_acc' reached 0.46500 (best 0.46500), saving model to '/home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst/epoch=0-step=3.ckpt' as top 3\nEpoch 0, global step 7: 'val_acc' reached 0.57000 (best 0.57000), saving model to '/home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst/epoch=0-step=7.ckpt' as top 3\nEpoch 1, global step 10: 'val_acc' reached 0.77500 (best 0.77500), saving model to '/home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst/epoch=1-step=10.ckpt' as top 3\nEpoch 1, global step 14: 'val_acc' reached 0.79500 (best 0.79500), saving model to '/home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst/epoch=1-step=14.ckpt' as top 3\nTime limit reached. Elapsed time is 0:03:01. Signaling Trainer to stop.\nStart to fuse 3 checkpoints via the greedy soup algorithm.\nAutoMM has created your model 🎉🎉🎉\n\n- To load the model, use the code below:\n    ```python\n    from autogluon.multimodal import MultiModalPredictor\n    predictor = MultiModalPredictor.load(\"/home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst\")\n    ```\n\n- You can open a terminal and launch Tensorboard to visualize the training log:\n    ```shell\n    # Assume you have installed tensorboard\n    tensorboard --logdir /home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst\n    ```\n\n- If you are not satisfied with the model, try to increase the training time, \nadjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\nor post issues on GitHub: https://github.com/autogluon/autogluon\n\n\n\n\nEpoch 0:  50%|█████     | 50/100 [00:38&lt;00:38,  1.29it/s]                  Epoch 0: 100%|██████████| 100/100 [01:25&lt;00:00,  1.18it/s]Epoch 1:  50%|█████     | 50/100 [00:43&lt;00:43,  1.14it/s] Epoch 1: 100%|██████████| 100/100 [01:30&lt;00:00,  1.10it/s]Epoch 2:   0%|          | 0/100 [00:00&lt;?, ?it/s]          Epoch 2:   1%|          | 1/100 [00:06&lt;10:45,  6.52s/it]\nPredicting DataLoader 0: 100%|██████████| 7/7 [00:05&lt;00:00,  1.25it/s]\nPredicting DataLoader 0: 100%|██████████| 7/7 [00:05&lt;00:00,  1.29it/s]\nPredicting DataLoader 0: 100%|██████████| 7/7 [00:05&lt;00:00,  1.25it/s]\n\n\n&lt;autogluon.multimodal.predictor.MultiModalPredictor at 0x7f8acd4349a0&gt;\n\n\n\nsentence1 = \"it's a charming and often affecting journey.\"\nsentence2 = \"It's slow, very, very, very slow.\"\npredictions = predictor.predict({'sentence': [sentence1, sentence2]})\nprint('\"Sentence\":', sentence1, '\"Predicted Sentiment\":', predictions[0])\nprint('\"Sentence\":', sentence2, '\"Predicted Sentiment\":', predictions[1])\n\n\"Sentence\": it's a charming and often affecting journey. \"Predicted Sentiment\": 1\n\"Sentence\": It's slow, very, very, very slow. \"Predicted Sentiment\": 0"
  },
  {
    "objectID": "연구/재인/2023-10-12-(연구&재인) MBTI -- MBTI.html",
    "href": "연구/재인/2023-10-12-(연구&재인) MBTI -- MBTI.html",
    "title": "(연구&재인) MBTI – MBTI",
    "section": "",
    "text": "import pandas as pd\nimport sklearn.model_selection \n\n\ndf = pd.read_csv('mbti_1.csv')\ndf_train, df_test = sklearn.model_selection.train_test_split(df,test_size=0.3)\n\n\ndf[:1]\n\n\n\n\n\n\n\n\ntype\nposts\n\n\n\n\n0\nINFJ\n'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n\n\n\n\n\n\n\n\nfrom autogluon.multimodal import MultiModalPredictor\nimport uuid\nmodel_path = f\"./tmp/{uuid.uuid4().hex}-automm_sst\"\npredictor = MultiModalPredictor(label='type', eval_metric='acc', path=model_path)\npredictor.fit(df_train)\n\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libc10_cuda.so: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n  warn(\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\nAutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n    First 10 (of 16) unique label values:  ['INFJ', 'ENTJ', 'ENFP', 'INFP', 'ISTJ', 'ISTP', 'ESFJ', 'INTP', 'INTJ', 'ISFP']\n    If 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\nGlobal seed set to 0\nAutoMM starts to create your model. ✨\n\n- AutoGluon version is 0.8.2.\n\n- Pytorch version is 2.0.0.post2.\n\n- Model will be saved to \"/home/cgb2/Dropbox/03_yechan3/posts/3_Researches/JAEIN/tmp/1c22bc85561c4fad9dbff452305364e5-automm_sst\".\n\n- Validation metric is \"acc\".\n\n- To track the learning progress, you can open a terminal and launch Tensorboard:\n    ```shell\n    # Assume you have installed tensorboard\n    tensorboard --logdir /home/cgb2/Dropbox/03_yechan3/posts/3_Researches/JAEIN/tmp/1c22bc85561c4fad9dbff452305364e5-automm_sst\n    ```\n\nEnjoy your coffee, and let AutoMM do the job ☕☕☕ Learn more at https://auto.gluon.ai\n\n0 GPUs are detected, and 0 GPUs will be used.\n\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/autogluon/multimodal/utils/environment.py:91: UserWarning: Only CPU is detected in the instance. This may result in slow speed for MultiModalPredictor. Consider using an instance with GPU support.\n  warnings.warn(\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\n\n  | Name              | Type                         | Params\n-------------------------------------------------------------------\n0 | model             | HFAutoModelForTextPrediction | 108 M \n1 | validation_metric | MulticlassAccuracy           | 0     \n2 | loss_func         | CrossEntropyLoss             | 0     \n-------------------------------------------------------------------\n108 M     Trainable params\n0         Non-trainable params\n108 M     Total params\n435.616   Total estimated model params size (MB)\nEpoch 0, global step 21: 'val_acc' reached 0.18750 (best 0.18750), saving model to '/home/cgb2/Dropbox/03_yechan3/posts/3_Researches/JAEIN/tmp/1c22bc85561c4fad9dbff452305364e5-automm_sst/epoch=0-step=21.ckpt' as top 3\n[rank: 0] Received SIGTERM: 15\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n\n\nEpoch 0:  50%|████▉     | 341/683 [1:30:43&lt;1:30:59, 15.96s/it]             Epoch 0:  73%|███████▎  | 501/683 [2:11:46&lt;47:52, 15.78s/it]  Epoch 0:  73%|███████▎  | 502/683 [2:12:01&lt;47:36, 15.78s/it]\n\n\nSIGTERMException: \n\n\n: \n\n\n\npost1 = \"http://www.youtube.com/watch?v=qsXHcwe3krw|||http://41.media.tumblr.com/tumblr_lfouy03PMA1qa1rooo1_500.jpg|||enfp and intj moments  https://www.youtube.com/watch?v=iz7lE1g4XM4  sportscenter not top ten plays  https://www.youtube.com/watch?v=uCdfze1etec  pranks|||What has been the most life-changing experience in your life?|||http://www.youtube.com/watch?v=vXZeYwwRDw8   http://www.youtube.com/watch?v=u8ejam5DP3E  On repeat for most of today.|||May the PerC Experience immerse you.|||The last thing my INFJ friend posted on his facebook before committing suicide the next day. Rest in peace~   http://vimeo.com/22842206|||Hello ENFJ7. Sorry to hear of your distress. It's only natural for a relationship to not be perfection all the time in every moment of existence. Try to figure the hard times as times of growth, as...|||84389  84390  http://wallpaperpassion.com/upload/23700/friendship-boy-and-girl-wallpaper.jpg  http://assets.dornob.com/wp-content/uploads/2010/04/round-home-design.jpg ...|||Welcome and stuff.|||http://playeressence.com/wp-content/uploads/2013/08/RED-red-the-pokemon-master-32560474-450-338.jpg  Game. Set. Match.|||Prozac, wellbrutin, at least thirty minutes of moving your legs (and I don't mean moving them while sitting in your same desk chair), weed in moderation (maybe try edibles as a healthier alternative...|||Basically come up with three items you've determined that each type (or whichever types you want to do) would more than likely use, given each types' cognitive functions and whatnot, when left by...|||All things in moderation.  Sims is indeed a video game, and a good one at that. Note: a good one at that is somewhat subjective in that I am not completely promoting the death of any given Sim...|||Dear ENFP:  What were your favorite video games growing up and what are your now, current favorite video games? :cool:|||https://www.youtube.com/watch?v=QyPqT8umzmY|||It appears to be too late. :sad:|||There's someone out there for everyone.|||Wait... I thought confidence was a good thing.|||I just cherish the time of solitude b/c i revel within my inner world more whereas most other time i'd be workin... just enjoy the me time while you can. Don't worry, people will always be around to...|||Yo entp ladies... if you're into a complimentary personality,well, hey.|||... when your main social outlet is xbox live conversations and even then you verbally fatigue quickly.|||http://www.youtube.com/watch?v=gDhy7rdfm14  I really dig the part from 1:46 to 2:50|||http://www.youtube.com/watch?v=msqXffgh7b8|||Banned because this thread requires it of me.|||Get high in backyard, roast and eat marshmellows in backyard while conversing over something intellectual, followed by massages and kisses.|||http://www.youtube.com/watch?v=Mw7eoU3BMbE|||http://www.youtube.com/watch?v=4V2uYORhQOk|||http://www.youtube.com/watch?v=SlVmgFQQ0TI|||Banned for too many b's in that sentence. How could you! Think of the B!|||Banned for watching movies in the corner with the dunces.|||Banned because Health class clearly taught you nothing about peer pressure.|||Banned for a whole host of reasons!|||http://www.youtube.com/watch?v=IRcrv41hgz4|||1) Two baby deer on left and right munching on a beetle in the middle.  2) Using their own blood, two cavemen diary today's latest happenings on their designated cave diary wall.  3) I see it as...|||a pokemon world  an infj society  everyone becomes an optimist|||49142|||http://www.youtube.com/watch?v=ZRCEq_JFeFM|||http://discovermagazine.com/2012/jul-aug/20-things-you-didnt-know-about-deserts/desert.jpg|||http://oyster.ignimgs.com/mediawiki/apis.ign.com/pokemon-silver-version/d/dd/Ditto.gif|||http://www.serebii.net/potw-dp/Scizor.jpg|||Not all artists are artists because they draw. It's the idea that counts in forming something of your own... like a signature.|||Welcome to the robot ranks, person who downed my self-esteem cuz I'm not an avid signature artist like herself. :proud:|||Banned for taking all the room under my bed. Ya gotta learn to share with the roaches.|||http://www.youtube.com/watch?v=w8IgImn57aQ|||Banned for being too much of a thundering, grumbling kind of storm... yep.|||Ahh... old high school music I haven't heard in ages.   http://www.youtube.com/watch?v=dcCRUPCdB1w|||I failed a public speaking class a few years ago and I've sort of learned what I could do better were I to be in that position again. A big part of my failure was just overloading myself with too...|||I like this person's mentality. He's a confirmed INTJ by the way. http://www.youtube.com/watch?v=hGKLI-GEc6M|||Move to the Denver area and start a new life for myself.\"\npredictions = predictor.predict({'posts': [post1]})\npredictions\n\narray(['ENTP'], dtype=object)"
  },
  {
    "objectID": "공부/2023-02-14-(공부&서연) -- 지수분포 평균검정.html",
    "href": "공부/2023-02-14-(공부&서연) -- 지수분포 평균검정.html",
    "title": "(공부&서연) – 지수분포 평균검정",
    "section": "",
    "text": "using Distributions, Plots\n다음의 분포를 따르는\n모집단으로부터 랜덤표본 \\(X_1,\\dots,X_n\\)을 이용하여 \\(\\theta\\)에 대한 신뢰구간을 구하고, 다음 가설\n을 검정하고자 한다. 다음에 답하라.\n(a) \\(\\theta\\)에 대한 적절한 추축변량을 구하고, 해당 추축변량의 분포를 명시하라.\n(풀이)\n추축변량은 \\(2n\\bar{X}\\theta\\) 이며 분포는 자유도가 \\(2n\\)인 카이제곱분포를 따름. 왜냐하면\n이기 떄문에.\n(시뮬레이션)\nn = 10\nθ = 2\npivotal_variable = [mean(rand(Exponential(1/2),n))*2*n*θ for i in 1:140000]\n# pivotal_variable = 추축변량\n\n140000-element Vector{Float64}:\n 19.866862184254465\n 17.492982610528998\n 13.463211578260314\n 19.472994478042697\n 13.424495255444352\n 21.744281289967418\n 22.929701779207697\n 13.561641745647645\n 25.277641996704048\n 16.566359730027052\n 19.550767074240074\n  9.914621718787568\n 11.857966801675106\n  ⋮\n 38.05226144210052\n 17.120691971399836\n 21.66831336505733\n 26.476356317147957\n 21.930886178263727\n 18.33570158249295\n 22.39822061516168\n 27.42899896779973\n 14.770009603430982\n 13.776401174299512\n 21.511825086436673\n 21.867878699644073\nhistogram(pivotal_variable)\nhistogram!(rand(Chisq(2*n),140000))\n(b) \\(\\theta\\)에 대한 95% 신뢰구간을 구하라.\n(풀이)\n\\(P\\left(\\chi^2_{0.025}(2n) \\leq 2n\\bar{X}\\theta \\leq \\chi^2_{0.975}(2n) \\right) =0.95\\)\nThus the CI of \\(\\theta\\): \\(\\left(\\frac{\\chi^2_{0.025}(2n)}{2n\\bar{X}},\\frac{\\chi^2_{0.975}(2n)}{2n\\bar{X}} \\right)\\)\n(시뮬레이션)\nl = quantile(Chisq(2*n),0.025) ./ (pivotal_variable./θ)\nu = quantile(Chisq(2*n),0.975) ./ (pivotal_variable./θ)\n[l[i]&lt;θ&lt;u[i] for i in 1:140000] |&gt; mean\n\n0.95035\n(c) \\(P(X&gt;1)\\)에 대한 95% 신뢰구간\n(풀이)\n\\(P(X&gt;1) = \\int_{1}^{\\infty}\\theta \\exp(-x\\theta)dx =\\left[e^{-x\\theta} \\right]_1^{\\infty}=e^{-\\theta}\\)\nThus the CI of \\(P(X&gt;1)\\): \\(\\left(\\exp\\big(-\\frac{\\chi^2_{0.975}(2n)}{2n\\bar{X}}\\big),\\exp\\big(-\\frac{\\chi^2_{0.025}(2n)}{2n\\bar{X}}\\big) \\right)\\)\n(시뮬레이션)\n검토1: \\(P(X&gt;1)=E[I(X&gt;1)]=e^{-\\theta}\\) 임을 검토\nexp(-θ)\n\n0.1353352832366127\nmean(rand(Exponential(1/2),1000000) .&gt; 1)\n\n0.135678\n검토2: 신뢰구간\nu2 = exp.(-l)\nl2 = exp.(-u)\n[l2[i]&lt;exp(-θ)&lt;u2[i] for i in 1:140000] |&gt; mean\n\n0.95035\n(d)\n\\(\\Omega = \\{\\theta: \\theta&gt;0\\}\\), \\(\\Omega_0 =\\{2\\}\\)\n(e) \\(\\theta\\)의 가능도 함수를 기술하시오\n(풀이)\n\\(L(\\theta)=\\theta^n\\exp(-\\theta n\\bar{x})\\)\n(f) \\(\\theta\\)의 \\(\\Omega\\)에서의 최대가능도 추정량과 \\(\\Omega_0\\)에서의 최대가능도 추정량을 구하시오\n(풀이)\n\\(\\hat{\\theta}^{\\Omega}=1/\\bar{x}\\), \\(\\hat{\\theta}^{\\Omega_0}=\\theta_0\\)\n(g) 일반화 가능도 비1 \\(\\Lambda\\)를 구하시오.\n(풀이)\n\\(\\frac{L\\big(\\hat{\\theta}^{\\Omega}\\big)}{L\\big(\\hat{\\theta}^{\\Omega_0}\\big)}=\\frac{1/\\bar{x}^n\\exp(-n)}{\\theta_0^n\\exp(-\\theta_0n\\bar{x})}\\)\n(h) 유의수준 \\(\\alpha\\)의 가능도비 검정법의 기각역을 \\(\\chi^2\\)의 분위수를 사용하여 표현하시오.\n(풀이)"
  },
  {
    "objectID": "공부/2023-02-14-(공부&서연) -- 지수분포 평균검정.html#footnotes",
    "href": "공부/2023-02-14-(공부&서연) -- 지수분포 평균검정.html#footnotes",
    "title": "(공부&서연) – 지수분포 평균검정",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n이게 뭐지..?↩︎"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html",
    "href": "연구/서연/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html",
    "title": "(연구&서연) IT-STGCN – SimualtionPlanner-Tutorial",
    "section": "",
    "text": "import itstgcn\nimport torch\nimport itstgcn.planner"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_stgcn_rand",
    "href": "연구/서연/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_stgcn_rand",
    "title": "(연구&서연) IT-STGCN – SimualtionPlanner-Tutorial",
    "section": "PLNR_STGCN_RAND",
    "text": "PLNR_STGCN_RAND\n\nplans_stgcn_rand = {\n    'max_iteration': 2, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mrate': [0.0, 0.2],\n    'lags': [2, 4], \n    'nof_filters': [4, 8], \n    'inter_method': ['nearest'],\n    'epoch': [3]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader,dataset_name='five_nodes')\n\n\nplnr.simulate()\n\n1/2 is done\n2/2 is done\nAll results are stored in ./simulation_results/2023-03-18_11-56-03.csv"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_stgcn_manual",
    "href": "연구/서연/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_stgcn_manual",
    "title": "(연구&서연) IT-STGCN – SimualtionPlanner-Tutorial",
    "section": "PLNR_STGCN_MANUAL",
    "text": "PLNR_STGCN_MANUAL\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\nloader = itstgcn.DatasetLoader(data_dict)\n\n\nmindex= [list(range(10,100)),[],list(range(50,80)),[],[]]\nplans_stgcn_block = {\n    'max_iteration': 3, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex],\n    'lags': [2, 4], \n    'nof_filters': [8,16], \n    'inter_method': ['nearest','linear'],\n    'epoch': [1]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader,dataset_name='five_nodes')\n\n\nplnr.simulate(mindex=mindex,mtype='block')\n\n1/3 is done\n2/3 is done\n3/3 is done\nAll results are stored in ./simulation_results/2023-03-18_11-56-55.csv"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_rand",
    "href": "연구/서연/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_rand",
    "title": "(연구&서연) IT-STGCN – SimualtionPlanner-Tutorial",
    "section": "PLNR_GNAR_RAND",
    "text": "PLNR_GNAR_RAND\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\nloader = itstgcn.DatasetLoader(data_dict)\n\n\nplans_gnar_rand = {\n    'max_iteration': 3, \n#    'method': ['GNAR'], \n    'mrate': [0.0, 0.2, 0.4],\n    'lags': [2, 4], \n#    'nof_filters': [8,16], \n    'inter_method': ['nearest','linear'],\n#    'epoch': [1]\n}\n\n\nplnr = itstgcn.planner.PLNR_GNAR_RAND(plans_gnar_rand,loader,dataset_name='five_nodes')\nplnr.simulate()\n\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n1/3 is done\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n2/3 is done\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n3/3 is done\nAll results are stored in ./simulation_results/2023-03-18_11-56-56.csv"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_block",
    "href": "연구/서연/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_block",
    "title": "(연구&서연) IT-STGCN – SimualtionPlanner-Tutorial",
    "section": "PLNR_GNAR_BLOCK",
    "text": "PLNR_GNAR_BLOCK\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\nloader = itstgcn.DatasetLoader(data_dict)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\nplans_gnar_block = {\n    'max_iteration': 3, \n    'method': ['GNAR'], \n    'mindex': [mindex],\n    'lags': [2, 4], \n    'inter_method': ['nearest','linear'],\n}\n\n\nplnr = itstgcn.planner.PLNR_GNAR_MANUAL(plans_gnar_block,loader,dataset_name='five_nodes')\nplnr.simulate(mindex,mtype='block')\n\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n1/3 is done\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n2/3 is done\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n3/3 is done\nAll results are stored in ./simulation_results/2023-03-18_11-56-57.csv"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2023-09-14-(연구&서연) IT-STGCN -- 논문리비전.html",
    "href": "연구/서연/ITSTGCN/2023-09-14-(연구&서연) IT-STGCN -- 논문리비전.html",
    "title": "(연구&서연) IT-STGCN – 논문리비전",
    "section": "",
    "text": "image.png\n\n\n- 초록색은 나쁘지 않음. 하지만 아래의 내용을 보완하는게 좋음.\n\n분야의 예시로 신경과학, 환경데이터, 교통자료가 있는데 우리가 실제로 분석한 자료들이 사용된 논문을 찾아보며 예시를 들것 (Chickenpox, …) 사용하지 않더라도 예시를 들것.\n이러한 자료를 분석하는것이 왜 어려운지 설명할 것. 즉 단순히 시계열로 해석하거나 공간자료로 해석하면 어떠한 문제가 있는지 간단히 서술할 것. (1~2문장) 레퍼런스 찾을것. (torch_geometric_temporal 의 도입부분 활용)\n\n- 붉은부분\n\n의도는 좋으나 sparse data 는 올바르지 않은 표현임. missing, irregulary observed data 등으로 설명할 것.\n이러한 자료가 왜 발생하는지 설명할 것. (이부분은 레퍼런스 필요) 이러한 자료를 처리하는 것이 어려운 이유를 설명할 것.1\n우리의 아이디어는 “호모지니우스하지 않은 그래프 -&gt; 호모지니우스화 시킴” 인데 이러한 방식은 이상한방식이 아님. Yu et al. (2017) and Guo et al. (2019) Bai et al. (2020), Li et al. (2019), Zhao et al. (2019) 이 우리와 비슷한 연구를 했음.\n\n- 아래식은 틀렸음. 이건 회귀모형이 아님.. GNAR의 notation을 사용하여 모형을 다시표현해볼것..\n\n\n\nimage.png\n\n\n\n이부분이 아주 클리어 해야함\n사용하는 대부분의 Notations들이 정리되어야함.\nintro에 쓰는 것이 부담스러우면 제외해도 무방\n뒤에 self consistence estimator에 사용할 Notation을 함께 고려\n\n- 빨간부분 삭제후 다시 작성 (혹은 공부할 것)\n\n\n\nimage.png\n\n\n- 초록색부분은 나쁘지 않음\n\n\n\nimage.png"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2023-09-14-(연구&서연) IT-STGCN -- 논문리비전.html#footnotes",
    "href": "연구/서연/ITSTGCN/2023-09-14-(연구&서연) IT-STGCN -- 논문리비전.html#footnotes",
    "title": "(연구&서연) IT-STGCN – 논문리비전",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n보통 결측없이 모두 관측한상태에서는 모형이 잘 동작함, 대부분의 spatio temporal data는 각각의 스냅샷마다 동일한 그래프구조를 가진다는 가정을 사용함. 스냅샷마다 그래프구조가 다른 경우를 가정하는 모형도 있음. 그러한 모형의 예시는 A,B,C,…. 등이 있음. 하지만 이러한 연구는 애초에 데이터가 스냅샷마다 non-호모지니우스하게 생겼으면 효율적일 수 있으나, 실제true model은 스냅샷마다 그래프구조가 동일하다고 여겨지지만 결측치로 인하여 스냅샷마다 호모지니우스가 깨지는 경우는 효율적이지 않을 수 있음. 우리는 이 부분에 초점을 맞추었음. 우리의 아이디어는 호모지니우스 하지 않은 그래프를 A,B,C, 등을 이용하여 그대로 처리하는것 보다 missing을 처리하여 호모지니우스하게 강제로 만들고 그 자료를 분석하자는 아이디어임.↩︎"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2023-04-27-(연구&서연) IT-STGCN -- Toy Example Figure(Intro).html",
    "href": "연구/서연/ITSTGCN/2023-04-27-(연구&서연) IT-STGCN -- Toy Example Figure(Intro).html",
    "title": "(연구&서연) IT-STGCN – Toy Example Figure(Intro)",
    "section": "",
    "text": "import itstgcn \nimport torch\nimport numpy as np\n\n\nimport matplotlib.pyplot as plt\n\n\nclass Eval_csy:\n    def __init__(self,learner,train_dataset):\n        self.learner = learner\n        # self.learner.model.eval()\n        try:self.learner.model.eval()\n        except:pass\n        self.train_dataset = train_dataset\n        self.lags = self.learner.lags\n        rslt_tr = self.learner(self.train_dataset) \n        self.X_tr = rslt_tr['X']\n        self.y_tr = rslt_tr['y']\n        self.f_tr = torch.concat([self.train_dataset[0].x.T,self.y_tr],axis=0).float()\n        self.yhat_tr = rslt_tr['yhat']\n        self.fhat_tr = torch.concat([self.train_dataset[0].x.T,self.yhat_tr],axis=0).float()\n\n\nimport pickle\nimport pandas as pd\n\n\ndef load_data(fname):\n    with open(fname, 'rb') as outfile:\n        data_dict = pickle.load(outfile)\n    return data_dict\n\ndef save_data(data_dict,fname):\n    with open(fname,'wb') as outfile:\n        pickle.dump(data_dict,outfile)\n\n\nT = 100\nt = np.arange(T)/T * 10 \n\nx = 0.3*np.sin(2*t)+0.1*np.sin(4*t)+0.1*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.5*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n# _FX1 = np.stack([x,y],axis=1).tolist()\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n#data_dict = itstgcn.load_data('./data/fivenodes.pkl')\n\nsave_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\nsave_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\n\n\n\n\ndata_dict1 = itstgcn.load_data('./data/toy_example1.pkl')\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset05031 = loader1.get_dataset(lags=4)\n\n\nmindex05031 = itstgcn.rand_mindex(dataset05031,mrate=0)\ndataset_miss05031 = itstgcn.miss(dataset05031,mindex05031,mtype='rand')\n\n\ndataset_miss05031.edge_index\n\narray([[0],\n       [1]])\n\n\n\ndataset_padded_cubic05031 = itstgcn.padding(dataset_miss05031,imputation_method='cubic')\n\n\ndataset_padded_cubic05031.edge_index\n\narray([[0],\n       [1]])\n\n\n- 학습\n\nlrnr05031 = itstgcn.StgcnLearner(dataset_padded_cubic05031)\n\n\nlrnr05031.train_dataset.edge_index\n\narray([[0],\n       [1]])\n\n\n\nlags4/0.3/filter16\nlags4/0.38/filter8\nlags8/0.38/filter8\n\n\nlrnr05031.learn(filters=16,epoch=50)\n\n50/50\n\n\n- 모형 평가 및 시각화\n\ndf1 = itstgcn.load_data('./data/toy_example_true1.csv')\n\n\nevtor05031 = Eval_csy(lrnr05031,dataset_padded_cubic05031)\n\n\nevtor05031.train_dataset.edge_index\n\narray([[0],\n       [1]])\n\n\n\nfig, ((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8), (ax9, ax10)) = plt.subplots(5, 2,figsize=(30,20))\n# fig.suptitle('Figure 1')\nax1.plot(df1['x'][:],'.',color='C0')\nax2.plot(df1['y'][:],'.',color='C0')\nax3.plot(df1['xer'][:],'.',color='C1')\nax4.plot(df1['yer'][:],'.',color='C1')\nax5.plot(evtor05031.f_tr[:,0],'.',color='C2')\nax6.plot(evtor05031.f_tr[:,1],'.',color='C2')\nax7.plot(df1['x'][:],'.',color='C0')\nax7.plot(evtor05031.fhat_tr[:,0],color='C3')\nax8.plot(df1['y'][:],'.',color='C0')\nax8.plot(evtor05031.fhat_tr[:,1],color='C3')\nax9.plot(df1['x'][:],'.',color='C0')\nax9.plot(df1['xer'][:],'.',color='C1')\nax9.plot(evtor05031.f_tr[:,0],'.',color='C2')\nax9.plot(evtor05031.fhat_tr[:,0],color='C3')\nax10.plot(df1['y'][:],'.',color='C0')\nax10.plot(df1['yer'][:],'.',color='C1')\nax10.plot(evtor05031.f_tr[:,1],'.',color='C2')\nax10.plot(evtor05031.fhat_tr[:,1],color='C3')\n\nfor ax in fig.get_axes():\n    ax.label_outer()"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2023-04-27-(연구&서연) IT-STGCN -- Toy Example Figure(Intro).html#import",
    "href": "연구/서연/ITSTGCN/2023-04-27-(연구&서연) IT-STGCN -- Toy Example Figure(Intro).html#import",
    "title": "(연구&서연) IT-STGCN – Toy Example Figure(Intro)",
    "section": "",
    "text": "import itstgcn \nimport torch\nimport numpy as np\n\n\nimport matplotlib.pyplot as plt\n\n\nclass Eval_csy:\n    def __init__(self,learner,train_dataset):\n        self.learner = learner\n        # self.learner.model.eval()\n        try:self.learner.model.eval()\n        except:pass\n        self.train_dataset = train_dataset\n        self.lags = self.learner.lags\n        rslt_tr = self.learner(self.train_dataset) \n        self.X_tr = rslt_tr['X']\n        self.y_tr = rslt_tr['y']\n        self.f_tr = torch.concat([self.train_dataset[0].x.T,self.y_tr],axis=0).float()\n        self.yhat_tr = rslt_tr['yhat']\n        self.fhat_tr = torch.concat([self.train_dataset[0].x.T,self.yhat_tr],axis=0).float()\n\n\nimport pickle\nimport pandas as pd\n\n\ndef load_data(fname):\n    with open(fname, 'rb') as outfile:\n        data_dict = pickle.load(outfile)\n    return data_dict\n\ndef save_data(data_dict,fname):\n    with open(fname,'wb') as outfile:\n        pickle.dump(data_dict,outfile)\n\n\nT = 100\nt = np.arange(T)/T * 10 \n\nx = 0.3*np.sin(2*t)+0.1*np.sin(4*t)+0.1*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.5*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n# _FX1 = np.stack([x,y],axis=1).tolist()\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n#data_dict = itstgcn.load_data('./data/fivenodes.pkl')\n\nsave_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\nsave_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\n\n\n\n\ndata_dict1 = itstgcn.load_data('./data/toy_example1.pkl')\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset05031 = loader1.get_dataset(lags=4)\n\n\nmindex05031 = itstgcn.rand_mindex(dataset05031,mrate=0)\ndataset_miss05031 = itstgcn.miss(dataset05031,mindex05031,mtype='rand')\n\n\ndataset_miss05031.edge_index\n\narray([[0],\n       [1]])\n\n\n\ndataset_padded_cubic05031 = itstgcn.padding(dataset_miss05031,imputation_method='cubic')\n\n\ndataset_padded_cubic05031.edge_index\n\narray([[0],\n       [1]])\n\n\n- 학습\n\nlrnr05031 = itstgcn.StgcnLearner(dataset_padded_cubic05031)\n\n\nlrnr05031.train_dataset.edge_index\n\narray([[0],\n       [1]])\n\n\n\nlags4/0.3/filter16\nlags4/0.38/filter8\nlags8/0.38/filter8\n\n\nlrnr05031.learn(filters=16,epoch=50)\n\n50/50\n\n\n- 모형 평가 및 시각화\n\ndf1 = itstgcn.load_data('./data/toy_example_true1.csv')\n\n\nevtor05031 = Eval_csy(lrnr05031,dataset_padded_cubic05031)\n\n\nevtor05031.train_dataset.edge_index\n\narray([[0],\n       [1]])\n\n\n\nfig, ((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8), (ax9, ax10)) = plt.subplots(5, 2,figsize=(30,20))\n# fig.suptitle('Figure 1')\nax1.plot(df1['x'][:],'.',color='C0')\nax2.plot(df1['y'][:],'.',color='C0')\nax3.plot(df1['xer'][:],'.',color='C1')\nax4.plot(df1['yer'][:],'.',color='C1')\nax5.plot(evtor05031.f_tr[:,0],'.',color='C2')\nax6.plot(evtor05031.f_tr[:,1],'.',color='C2')\nax7.plot(df1['x'][:],'.',color='C0')\nax7.plot(evtor05031.fhat_tr[:,0],color='C3')\nax8.plot(df1['y'][:],'.',color='C0')\nax8.plot(evtor05031.fhat_tr[:,1],color='C3')\nax9.plot(df1['x'][:],'.',color='C0')\nax9.plot(df1['xer'][:],'.',color='C1')\nax9.plot(evtor05031.f_tr[:,0],'.',color='C2')\nax9.plot(evtor05031.fhat_tr[:,0],color='C3')\nax10.plot(df1['y'][:],'.',color='C0')\nax10.plot(df1['yer'][:],'.',color='C1')\nax10.plot(evtor05031.f_tr[:,1],'.',color='C2')\nax10.plot(evtor05031.fhat_tr[:,1],color='C3')\n\nfor ax in fig.get_axes():\n    ax.label_outer()"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2023-03-17-ITSTGCN-Tutorial.html",
    "href": "연구/서연/ITSTGCN/2023-03-17-ITSTGCN-Tutorial.html",
    "title": "(연구&서연) IT-STGCN – ITSTGCN-Tutorial",
    "section": "",
    "text": "edit\n\n\nimport\n\nimport itstgcn \nimport torch\n\n\n\n예제1: vanilla STGCN\n- 데이터\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n\n\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \n\n\ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.utils.temporal_signal_split(dataset, train_ratio=0.8)\n\n- 학습\n\nlrnr = itstgcn.StgcnLearner(train_dataset,dataset_name='five_nodes')\n\n/home/csy/Dropbox/blog/posts/GCN/itstgcn/learners.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180588308/work/torch/csrc/utils/tensor_new.cpp:201.)\n  self.lags = torch.tensor(train_dataset.features).shape[-1]\n\n\n\nlrnr.learn(filters=4,epoch=5)\n\n5/5\n\n\n- 적합값\n\n#lrnr(train_dataset) \n#lrnr(test_dataset)\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) \nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\n\n\n\n\n예제2: padding missing values\n- 데이터\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.utils.temporal_signal_split(dataset, train_ratio=0.8)\n\n- 임의로 결측치 발생\n\nmindex = itstgcn.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex=mindex,mtype='rand')\n\n\nfig = itstgcn.plot(torch.tensor(train_dataset_miss.targets),'o')\nfig \n\n\n\n\n\n\n\n\n- 적절한 method로 결측치를 채움 (default 는 linear)\n\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n\nfig = itstgcn.plot(torch.tensor(train_dataset_miss.targets),'o')\nitstgcn.plot_add(fig,torch.tensor(train_dataset_padded.targets),'--x',color='C1',alpha=0.5)\n\n\n\n\n\n\n\n\n다른 method로 결측치를 채울수도 있음. 사용할 수 있는 방법들은 아래에 정리되어 있음\n\nref: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html\n\n\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss,interpolation_method='nearest')\n\n\nfig = itstgcn.plot(torch.tensor(train_dataset_miss.targets),'o')\nitstgcn.plot_add(fig,torch.tensor(train_dataset_padded.targets),'--x',color='C1',alpha=0.5)\n\n\n\n\n\n\n\n\n\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss,interpolation_method='quadratic')\n\n\nfig = itstgcn.plot(torch.tensor(train_dataset_miss.targets),'o')\nitstgcn.plot_add(fig,torch.tensor(train_dataset_padded.targets),'--x',color='C1',alpha=0.5)\n\n\n\n\n\n\n\n\n\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss,interpolation_method='cubic')\n\n\nfig = itstgcn.utils.plot(torch.tensor(train_dataset_miss.targets),'o')\nitstgcn.utils.plot_add(fig,torch.tensor(train_dataset_padded.targets),'--x',color='C1',alpha=0.5)\n\n\n\n\n\n\n\n\n- 블락으로 결측치 발생\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='block')\n\n\nfig = itstgcn.utils.plot(torch.tensor(train_dataset_miss.targets),'o')\nfig \n\n\n\n\n\n\n\n\n\n\n예제3: vanilla STGCN with random missing\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.utils.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = itstgcn.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcn.learners.StgcnLearner(train_dataset_padded)\n\n\nlrnr.learn(filters=4,epoch=5)\n\n5/5\n\n\n- 적합값\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=5,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\n\n\n\n\n예제4: vanilla STGCN with block missing\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.utils.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcn.StgcnLearner(train_dataset_padded)\n\n\nlrnr.learn(filters=4,epoch=5)\n\n5/5\n\n\n- 적합값\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=5,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\n\n\n\n\n예제5: threshold example (random)\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.utils.temporal_signal_split(dataset, train_ratio=0.8)\n\n- 결측치 발생 및 패딩\n\nmindex=itstgcn.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss)\n\n\nf_miss,_ = itstgcn.convert_train_dataset(train_dataset_miss)\nf_padded,_ = itstgcn.convert_train_dataset(train_dataset_padded)\n\n\nfig = itstgcn.utils.plot(f_miss,'o')\nitstgcn.utils.plot_add(fig,f_padded,'--x',alpha=0.5)\n\n\n\n\n\n\n\n\n- update by frequency thresholding\n\nfig = itstgcn.plot(f_miss,'o',alpha=0.5)\nitstgcn.plot_add(fig,f_padded,'--x',alpha=0.5)\nf_updated = itstgcn.update_from_freq_domain(f_padded,train_dataset_padded.mindex)\nitstgcn.plot_add(fig,f_updated,'-')\n\n\n\n\n\n\n\n\n\n\n예제6: threshold example (block)\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n- 결측치 발생 및 패딩\n\nmindex=[list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss)\n\n\nf_miss,_ = itstgcn.convert_train_dataset(train_dataset_miss)\nf_padded,_ = itstgcn.convert_train_dataset(train_dataset_padded)\n\n\nfig = itstgcn.plot(f_miss,'o')\nitstgcn.plot_add(fig,f_padded,'--x',alpha=0.5)\n\n\n\n\n\n\n\n\n- update by frequency thresholding\n\nfig = itstgcn.plot(f_miss,'o',alpha=0.5)\nitstgcn.plot_add(fig,f_padded,'--x',alpha=0.5)\nf_updated = itstgcn.update_from_freq_domain(f_padded,train_dataset_padded.mindex)\nitstgcn.plot_add(fig,f_updated,'-')\n\n\n\n\n\n\n\n\n\n\n예제7: iterative thresholded STGCN (IT-STGCN) with random missing\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = itstgcn.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcn.ITStgcnLearner(train_dataset_padded)\n\n\nlrnr.learn(filters=4,epoch=5)\n\n5/5\n\n\n- 적합값\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)['yhat'].shape\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\n\n\n\n\n예제8: iterative thresholded STGCN (IT-STGCN) with block missing\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcn.ITStgcnLearner(train_dataset_padded)\n\n\nlrnr.learn(filters=4,epoch=5)\n\n5/5\n\n\n- 적합값\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)['yhat'].shape\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\n\n\n\n\n예제9: GNAR (random missing)\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex=itstgcn.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcn.GNARLearner(train_dataset_padded)\n\n\nlrnr.learn()\n\nWARNING: diagonal entries present in original matrix, these will be removed\n\n\n- 적합값\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\n\n\n\n\n예제10: GNAR (block missing)\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex=[list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcn.GNARLearner(train_dataset_padded)\n\n\nlrnr.learn()\n\nWARNING: diagonal entries present in original matrix, these will be removed\n\n\n- 적합값\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2023-02-14-Tables.html",
    "href": "연구/서연/ITSTGCN/2023-02-14-Tables.html",
    "title": "(연구&서연) IT-STGCN – Tables",
    "section": "",
    "text": "import pandas as pd\n\n- Dataset 5nodes\n\ncol = ['Dataset','iteration', 'method', 'missingrate', 'missingtype', 'lag', 'number_of_filters', 'interpolation','MSE_train', 'MSE_test',]\n\n\ndf = pd.DataFrame(columns=col)\ndf\n\n\n\n\n\n\n\n\nDataset\niteration\nmethod\nmissingrate\nmissingtype\nlag\nnumber_of_filters\ninterpolation\nMSE_train\nMSE_test\n\n\n\n\n\n\n\n\n\n- 실험마다 아래와 같은식으로 추가\n\ndf_row = pd.DataFrame(columns=col)\ndf_row['Dataset'] = 'fivenodes', # ...\ndf_row['iteration'] = 1, # 1,2,3,...,10 \ndf_row['method'] = 'stgcn', # 'stgcn','estgcn','gnar' \ndf_row['missingrate'] = 0.0, # 0.0, 0.2, 0.4, 0.6, 0.8 \ndf_row['missingtype'] = None,  # None, 'randomly' and 'block' \ndf_row['lag'] = 1, # 1,2,3,4 ... \ndf_row['number_of_filters'] = 16, # 16,24,32, ... \ndf_row['interpolation'] = None, # None, 'mean', 'linear'\ndf_row['MSE_train'] = 0.96 \ndf_row['MSE_test'] = 0.55\n\n\ndf = pd.concat([df,df_row])\ndf\n\n\n\n\n\n\n\n\nDataset\niteration\nmethod\nmissingrate\nmissingtype\nlag\nnumber_of_filters\ninterpolation\nMSE_train\nMSE_test\n\n\n\n\n0\nfivenodes\n1\nstgcn\n0.0\nNone\n1\n16\nNone\n0.96\n0.55\n\n\n\n\n\n\n\n\ndf_row = pd.DataFrame(columns=col)\ndf_row['Dataset'] = 'fivenodes', # ...\ndf_row['iteration'] = 1, # 1,2,3,...,10 \ndf_row['method'] = 'stgcn', # 'stgcn','estgcn','gnar' \ndf_row['missingrate'] = 0.2, # 0.0, 0.2, 0.4, 0.6, 0.8 \ndf_row['missingtype'] = 'randomly',  # None, 'randomly' and 'block' \ndf_row['lag'] = 1, # 1,2,3,4 ... \ndf_row['number_of_filters'] = 16, # 16,24,32, ... \ndf_row['interpolation'] = 'mean', # None, 'mean', 'linear'\ndf_row['MSE_train'] = 1.23\ndf_row['MSE_test'] = 0.88\n\n\ndf = pd.concat([df,df_row])\ndf\n\n\n\n\n\n\n\n\nDataset\niteration\nmethod\nmissingrate\nmissingtype\nlag\nnumber_of_filters\ninterpolation\nMSE_train\nMSE_test\n\n\n\n\n0\nfivenodes\n1\nstgcn\n0.0\nNone\n1\n16\nNone\n0.96\n0.55\n\n\n0\nfivenodes\n1\nstgcn\n0.2\nrandomly\n1\n16\nmean\n1.23\n0.88"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2022-12-30-STGCN-Toy Example.html",
    "href": "연구/서연/ITSTGCN/2022-12-30-STGCN-Toy Example.html",
    "title": "(연구&서연) IT-STGCN – Toy Example",
    "section": "",
    "text": "import networkx as nx\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport torch"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2022-12-30-STGCN-Toy Example.html#data",
    "href": "연구/서연/ITSTGCN/2022-12-30-STGCN-Toy Example.html#data",
    "title": "(연구&서연) IT-STGCN – Toy Example",
    "section": "data",
    "text": "data\n\nfrom torch_geometric_temporal.dataset import WikiMathsDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = WikiMathsDatasetLoader()\n\ndataset = loader.get_dataset(lags=14)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2022-12-30-STGCN-Toy Example.html#recurrentgcn",
    "href": "연구/서연/ITSTGCN/2022-12-30-STGCN-Toy Example.html#recurrentgcn",
    "title": "(연구&서연) IT-STGCN – Toy Example",
    "section": "RecurrentGCN",
    "text": "RecurrentGCN\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2022-12-30-STGCN-Toy Example.html#learn",
    "href": "연구/서연/ITSTGCN/2022-12-30-STGCN-Toy Example.html#learn",
    "title": "(연구&서연) IT-STGCN – Toy Example",
    "section": "Learn",
    "text": "Learn\n\n# from tqdm import tqdm\n\n# model = RecurrentGCN(node_features=14, filters=32)\n\n# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\n# model.train()\n\n# for epoch in tqdm(range(50)):\n#     for time, snapshot in enumerate(train_dataset):\n#         y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n#         cost = torch.mean((y_hat-snapshot.y)**2)\n#         cost.backward()\n#         optimizer.step()\n#         optimizer.zero_grad()\n\n\nmodel = RecurrentGCN(node_features=14, filters=32)\nmodel.train()\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(14, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(14, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(14, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)\n\n\n\nfor s in train_dataset:\n    print((s.y-model(s.x,s.edge_index,s.edge_attr)).shape)\n\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2022-12-30-STGCN-Toy Example.html#예제의-차원-조사",
    "href": "연구/서연/ITSTGCN/2022-12-30-STGCN-Toy Example.html#예제의-차원-조사",
    "title": "(연구&서연) IT-STGCN – Toy Example",
    "section": "예제의 차원 조사",
    "text": "예제의 차원 조사\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([1068, 14])\n\n\n\n1068: number of nodes // 1068개의 노드가 있음\n14: number of features // 하나의 노드에 맵핑된 차원의수\n\n\n_edge_index.shape\n\ntorch.Size([2, 27079])\n\n\n\n_edge_attr.shape\n\ntorch.Size([27079])\n\n\n\n_y.shape\n\ntorch.Size([1068])\n\n\n\n1068: number of nodes\n\n\n_x.shape\n\ntorch.Size([1068, 14])"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2022-12-29-STGCN-tutorial.html",
    "href": "연구/서연/ITSTGCN/2022-12-29-STGCN-tutorial.html",
    "title": "(연구&서연) IT-STGCN – Tutorial",
    "section": "",
    "text": "- 이 문서는 공식홈페이지의 예제와 최서연학생의 블로그 내용을 재구성하여 만듬\n- 이 문서의 목표는 아래와 같다.\n\nSTGCN을 사용할 수 있는 데이터의 형태를 탐구한다.\nSTGCN을 실습할 코드를 확보한다.\n\n- 코랩에서 실습하기 위해서는 아래를 설치해야한다.\n\n!pip install torch-geometric\n!pip install torch-geometric-temporal"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2022-12-29-STGCN-tutorial.html#pyg-의-data-자료형",
    "href": "연구/서연/ITSTGCN/2022-12-29-STGCN-tutorial.html#pyg-의-data-자료형",
    "title": "(연구&서연) IT-STGCN – Tutorial",
    "section": "PyG 의 Data 자료형",
    "text": "PyG 의 Data 자료형\n\nref: https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html#data-handling-of-graphs\n\n- 자료는 PyG의 Data 오브젝트를 기반으로 한다.\n(예제) 아래와 같은 그래프자료를 고려하자.\n\n이러한 자료형은 아래와 같은 형식으로 저장한다.\n\nedge_index = torch.tensor([[0, 1, 1, 2],\n                           [1, 0, 2, 1]], dtype=torch.long)\nx = torch.tensor([[-1], [0], [1]], dtype=torch.float)\ndata = Data(x=x, edge_index=edge_index) # Data는 그래프자료형을 만드는 클래스\n\n\ntype(data)\n\ntorch_geometric.data.data.Data\n\n\n\ndata.x\n\ntensor([[-1.],\n        [ 0.],\n        [ 1.]])\n\n\n\ndata.edge_index\n\ntensor([[0, 1, 1, 2],\n        [1, 0, 2, 1]])"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2022-12-29-STGCN-tutorial.html#pytorch-geometric-temporal-의-자료형",
    "href": "연구/서연/ITSTGCN/2022-12-29-STGCN-tutorial.html#pytorch-geometric-temporal-의-자료형",
    "title": "(연구&서연) IT-STGCN – Tutorial",
    "section": "PyTorch Geometric Temporal 의 자료형",
    "text": "PyTorch Geometric Temporal 의 자료형\n\nref: PyTorch Geometric Temporal Signal\n\n아래의 클래스들중 하나를 이용하여 만든다.\n## Temporal Signal Iterators\ntorch_geometric_temporal.signal.StaticGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphStaticSignal\n## Heterogeneous Temporal Signal Iterators\ntorch_geometric_temporal.signal.StaticHeteroGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicHeteroGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicHeteroGraphStaticSignal\n이중 “Heterogeneous Temporal Signal” 은 우리가 관심이 있는 신호가 아니므로 사실상 아래의 3개만 고려하면 된다.\n\ntorch_geometric_temporal.signal.StaticGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphStaticSignal\n\n여기에서 StaticGraphTemporalSignal 는 시간에 따라서 그래프 구조가 일정한 경우, 즉 \\({\\cal G}_t=\\{{\\cal V},{\\cal E}\\}\\)와 같은 구조를 의미한다.\n(예제1) StaticGraphTemporalSignal 를 이용하여 데이터 셋 만들기\n- json data \\(\\to\\) dict\n\nimport json\nimport urllib\n\n\nurl = \"https://raw.githubusercontent.com/benedekrozemberczki/pytorch_geometric_temporal/master/dataset/chickenpox.json\"\ndata_dict = json.loads(urllib.request.urlopen(url).read())\n# data_dict 출력이 김\n\n\ndata_dict.keys()\n\ndict_keys(['edges', 'node_ids', 'FX'])\n\n\n- 살펴보기\n\nnp.array(data_dict['edges']).T\n\narray([[ 0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  2,  3,\n         3,  3,  3,  3,  3,  4,  4,  5,  5,  5,  5,  6,  6,  6,  6,  6,\n         6,  6,  7,  7,  7,  7,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,\n        10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 12, 12, 12,\n        12, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15,\n        15, 15, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18, 18,\n        18, 18, 19, 19, 19, 19],\n       [10,  6, 13,  1,  0,  5, 16,  0, 16,  1, 14, 10,  8,  2,  5,  8,\n        15, 12,  9, 10,  3,  4, 13,  0, 10,  2,  5,  0, 16,  6, 14, 13,\n        11, 18,  7, 17, 11, 18,  3,  2, 15,  8, 10,  9, 13,  3, 12, 10,\n         5,  9,  8,  3, 10,  2, 13,  0,  6, 11,  7, 13, 18,  3,  9, 13,\n        12, 13,  9,  6,  4, 12,  0, 11, 10, 18, 19,  1, 14,  6, 16,  3,\n        15,  8, 16, 14,  1,  0,  6,  7, 19, 17, 18, 14, 18, 17,  7,  6,\n        19, 11, 18, 14, 19, 17]])\n\n\n\n\\({\\cal E} = \\{(0,10),(0,6), \\dots, (19,17)\\}\\)\n혹은 \\({\\cal E} = \\{(\\tt{BACS},\\tt{JASZ}), ({\\tt BACS},{\\tt FEJER}), \\dots, (\\tt{ZALA},\\tt{VAS})\\}\\)\n\n\ndata_dict['node_ids']\n\n{'BACS': 0,\n 'BARANYA': 1,\n 'BEKES': 2,\n 'BORSOD': 3,\n 'BUDAPEST': 4,\n 'CSONGRAD': 5,\n 'FEJER': 6,\n 'GYOR': 7,\n 'HAJDU': 8,\n 'HEVES': 9,\n 'JASZ': 10,\n 'KOMAROM': 11,\n 'NOGRAD': 12,\n 'PEST': 13,\n 'SOMOGY': 14,\n 'SZABOLCS': 15,\n 'TOLNA': 16,\n 'VAS': 17,\n 'VESZPREM': 18,\n 'ZALA': 19}\n\n\n\n\\({\\cal V}=\\{\\tt{BACS},\\tt{BARANYA} \\dots, \\tt{ZALA}\\}\\)\n\n\nnp.array(data_dict['FX']), np.array(data_dict['FX']).shape\n\n(array([[-1.08135724e-03, -7.11136085e-01, -3.22808515e+00, ...,\n          1.09445310e+00, -7.08747750e-01, -1.82280792e+00],\n        [ 2.85705967e-02, -5.98430173e-01, -2.29097341e-01, ...,\n         -1.59220988e+00, -2.24597623e-01,  7.86330575e-01],\n        [ 3.54742090e-01,  1.90511208e-01,  1.61028185e+00, ...,\n          1.38183225e-01, -7.08747750e-01, -5.61724314e-01],\n        ...,\n        [-4.75512620e-01, -1.19952837e+00, -3.89043358e-01, ...,\n         -1.00023329e+00, -1.71429032e+00,  4.70746677e-02],\n        [-2.08645035e-01,  6.03766218e-01,  1.08216835e-02, ...,\n          4.71099041e-02,  2.45684924e+00, -3.44296107e-01],\n        [ 1.21464875e+00,  7.16472130e-01,  1.29038982e+00, ...,\n          4.56939849e-01,  7.43702632e-01,  1.00375878e+00]]),\n (521, 20))\n\n\n\n\\({\\bf f}=\\begin{bmatrix} {\\bf f}_1\\\\ {\\bf f}_2\\\\ \\dots \\\\ {\\bf f}_{521} \\end{bmatrix}=\\begin{bmatrix} f(t=1,v=\\tt{BACS}) & \\dots & f(t=1,v=\\tt{ZALA}) \\\\ f(t=2,v=\\tt{BACS}) & \\dots & f(t=2,v=\\tt{ZALA}) \\\\ \\dots & \\dots & \\dots \\\\ f(t=521,v=\\tt{BACS}) & \\dots & f(t=521,v=\\tt{ZALA}) \\end{bmatrix}\\)\n\n즉 data_dict는 아래와 같이 구성되어 있음\n\n\n\n\n\n\n\n\n\n\n수학 기호\n코드에 저장된 변수\n자료형\n차원\n설명\n\n\n\n\n\\({\\cal V}\\)\ndata_dict['node_ids']\ndict\n20\n20개의 노드에 대한 설명이 있음\n\n\n\\({\\cal E}\\)\ndata_dict['edges']\nlist (double list)\n(102,2)\n노드들에 대한 102개의 연결을 정의함\n\n\n\\({\\bf f}\\)\ndata_dict['node_ids']\ndict\n(521,20)\n\\(f(t,v)\\) for \\(v \\in {\\cal V}\\) and \\(t = 1,\\dots, T\\)\n\n\n\n- 주어진 자료를 정리하여 그래프신호 \\(\\big(\\{{\\cal V},{\\cal E},{\\bf W}\\},{\\bf f}\\big)\\)를 만들면 아래와 같다.\n\nedges = np.array(data_dict[\"edges\"]).T\nedge_weight = np.ones(edges.shape[1])\nf = np.array(data_dict[\"FX\"])\n\n\n여기에서 edges는 \\({\\cal E}\\)에 대한 정보를\nedges_weight는 \\({\\bf W}\\)에 대한 정보를\nf는 \\({\\bf f}\\)에 대한 정보를 저장한다.\n\n\nNote: 이때 \\({\\bf W}={\\bf E}\\) 로 정의한다. (하지만 꼭 이래야 하는건 아니야)\n\n- data_dict \\(\\to\\) dl\n\nlags = 4\nfeatures = [f[i : i + lags, :].T for i in range(f.shape[0] - lags)]\ntargets = [f[i + lags, :].T for i in range(f.shape[0] - lags)]\n\n\nnp.array(features).shape, np.array(targets).shape\n\n((517, 20, 4), (517, 20))\n\n\n\n\n\n\n\n\n\n설명변수\n반응변수\n\n\n\n\n\\({\\bf X} = {\\tt features} = \\begin{bmatrix} {\\bf f}_1 & {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 \\\\ {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 & {\\bf f}_5 \\\\ \\dots & \\dots & \\dots & \\dots \\\\ {\\bf f}_{517} & {\\bf f}_{518} & {\\bf f}_{519} & {\\bf f}_{520} \\end{bmatrix}\\)\n\\({\\bf y}= {\\tt targets} = \\begin{bmatrix} {\\bf f}_5 \\\\ {\\bf f}_6 \\\\ \\dots \\\\ {\\bf f}_{521} \\end{bmatrix}\\)\n\n\n\n\nAR 느낌으로 표현하면 AR(4) 임\n\n\ndataset = torch_geometric_temporal.signal.StaticGraphTemporalSignal(\n    edge_index= edges,\n    edge_weight = edge_weight,\n    features = features,\n    targets = targets\n)\n\n\ndataset\n\n&lt;torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal at 0x7faad2716a60&gt;\n\n\n- 그런데 이 과정을 아래와 같이 할 수도 있음\n# PyTorch Geometric Temporal 공식홈페이지에 소개된 코드\nloader = torch_geometric_temporal.dataset.ChickenpoxDatasetLoader()\ndataset=loader.get_dataset(lags=4)\n- dataset은 dataset[0], \\(\\dots\\) , dataset[516]과 같은 방식으로 각 시점별 자료에 접근가능\n\ndataset[0]\n\nData(x=[20, 4], edge_index=[2, 102], edge_attr=[102], y=[20])\n\n\n각 시점에 대한 자료형은 아까 살펴보았던 PyG의 Data 자료형과 같음\n\ntype(dataset[0])\n\ntorch_geometric.data.data.Data\n\n\n\ndataset[0].x \n\ntensor([[-1.0814e-03,  2.8571e-02,  3.5474e-01,  2.9544e-01],\n        [-7.1114e-01, -5.9843e-01,  1.9051e-01,  1.0922e+00],\n        [-3.2281e+00, -2.2910e-01,  1.6103e+00, -1.5487e+00],\n        [ 6.4750e-01, -2.2117e+00, -9.6858e-01,  1.1862e+00],\n        [-1.7302e-01, -9.4717e-01,  1.0347e+00, -6.3751e-01],\n        [ 3.6345e-01, -7.5468e-01,  2.9768e-01, -1.6273e-01],\n        [-3.4174e+00,  1.7031e+00, -1.6434e+00,  1.7434e+00],\n        [-1.9641e+00,  5.5208e-01,  1.1811e+00,  6.7002e-01],\n        [-2.2133e+00,  3.0492e+00, -2.3839e+00,  1.8545e+00],\n        [-3.3141e-01,  9.5218e-01, -3.7281e-01, -8.2971e-02],\n        [-1.8380e+00, -5.8728e-01, -3.5514e-02, -7.2298e-02],\n        [-3.4669e-01, -1.9827e-01,  3.9540e-01, -2.4774e-01],\n        [ 1.4219e+00, -1.3266e+00,  5.2338e-01, -1.6374e-01],\n        [-7.7044e-01,  3.2872e-01, -1.0400e+00,  3.4945e-01],\n        [-7.8061e-01, -6.5022e-01,  1.4361e+00, -1.2864e-01],\n        [-1.0993e+00,  1.2732e-01,  5.3621e-01,  1.9023e-01],\n        [ 2.4583e+00, -1.7811e+00,  5.0732e-02, -9.4371e-01],\n        [ 1.0945e+00, -1.5922e+00,  1.3818e-01,  1.1855e+00],\n        [-7.0875e-01, -2.2460e-01, -7.0875e-01,  1.5630e+00],\n        [-1.8228e+00,  7.8633e-01, -5.6172e-01,  1.2647e+00]])\n\n\n\n이 값들은 features[0]의 값들과 같음. 즉 \\([{\\bf f}_1~ {\\bf f}_2~ {\\bf f}_3~ {\\bf f}_4]\\)를 의미함\n\n\ndataset[0].y\n\ntensor([ 0.7106, -0.0725,  2.6099,  1.7870,  0.8024, -0.2614, -0.8370,  1.9674,\n        -0.4212,  0.1655,  1.2519,  2.3743,  0.7877,  0.4531, -0.1721, -0.0614,\n         1.0452,  0.3203, -1.3791,  0.0036])\n\n\n\n이 값들은 targets[0]의 값들과 같음. 즉 \\({\\bf f}_5\\)를 의미함"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2022-12-29-STGCN-tutorial.html#summary-of-data",
    "href": "연구/서연/ITSTGCN/2022-12-29-STGCN-tutorial.html#summary-of-data",
    "title": "(연구&서연) IT-STGCN – Tutorial",
    "section": "summary of data",
    "text": "summary of data\n\n\\(T\\) = 519\n\\(N\\) = 20 # number of nodes\n\\(|{\\cal E}|\\) = 102 # edges\n\\(f(t,v)\\)의 차원? (1,)\n시간에 따라서 Number of nodes가 변하는지? False\n시간에 따라서 Number of nodes가 변하는지? False\n\\({\\bf X}\\): (20,4)\n\\({\\bf y}\\): (20,)\n예제코드적용가능여부: Yes\n\n- Nodes : 20\n\nvertices are counties\n\n-Edges : 102\n\nedges are neighbourhoods\n\n- Time : 519\n\nbetween 2004 and 2014\nper weeks\n\n\nloader = torch_geometric_temporal.dataset.ChickenpoxDatasetLoader()\ndataset = loader.get_dataset(lags=4)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2022-12-29-STGCN-tutorial.html#learn",
    "href": "연구/서연/ITSTGCN/2022-12-29-STGCN-tutorial.html#learn",
    "title": "(연구&서연) IT-STGCN – Tutorial",
    "section": "learn",
    "text": "learn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for t, snapshot in enumerate(train_dataset):\n        yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((yt_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [01:16&lt;00:00,  1.52s/it]\n\n\n\ndataset.features[0].shape\n\n(20, 4)"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2022-12-29-STGCN-tutorial.html#visualization",
    "href": "연구/서연/ITSTGCN/2022-12-29-STGCN-tutorial.html#visualization",
    "title": "(연구&서연) IT-STGCN – Tutorial",
    "section": "visualization",
    "text": "visualization\n\nmodel.eval()\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)\n\n\n\nyhat_train = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in train_dataset]).detach().numpy()\nyhat_test = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in test_dataset]).detach().numpy()\n\n\nV = list(data_dict['node_ids'].keys())\n\n\nfig,ax = plt.subplots(20,1,figsize=(10,50))\nfor k in range(20):\n    ax[k].plot(f[:,k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_train[:,k],label='predicted (tr)')\n    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2022-12-29-STGCN-tutorial.html#footnotes",
    "href": "연구/서연/ITSTGCN/2022-12-29-STGCN-tutorial.html#footnotes",
    "title": "(연구&서연) IT-STGCN – Tutorial",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n일반적인 기하학적 딥러닝을 위한 파이토치 패키지↩︎\nSTGCN을 위한 패키지↩︎"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2022-12-30-(연구&서연) IT-STGCN -- Toy Example.html",
    "href": "연구/서연/ITSTGCN/2022-12-30-(연구&서연) IT-STGCN -- Toy Example.html",
    "title": "(연구&서연) IT-STGCN – Toy Example",
    "section": "",
    "text": "import networkx as nx\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport torch"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2022-12-30-(연구&서연) IT-STGCN -- Toy Example.html#data",
    "href": "연구/서연/ITSTGCN/2022-12-30-(연구&서연) IT-STGCN -- Toy Example.html#data",
    "title": "(연구&서연) IT-STGCN – Toy Example",
    "section": "data",
    "text": "data\n\nfrom torch_geometric_temporal.dataset import WikiMathsDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = WikiMathsDatasetLoader()\n\ndataset = loader.get_dataset(lags=14)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2022-12-30-(연구&서연) IT-STGCN -- Toy Example.html#recurrentgcn",
    "href": "연구/서연/ITSTGCN/2022-12-30-(연구&서연) IT-STGCN -- Toy Example.html#recurrentgcn",
    "title": "(연구&서연) IT-STGCN – Toy Example",
    "section": "RecurrentGCN",
    "text": "RecurrentGCN\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2022-12-30-(연구&서연) IT-STGCN -- Toy Example.html#learn",
    "href": "연구/서연/ITSTGCN/2022-12-30-(연구&서연) IT-STGCN -- Toy Example.html#learn",
    "title": "(연구&서연) IT-STGCN – Toy Example",
    "section": "Learn",
    "text": "Learn\n\n# from tqdm import tqdm\n\n# model = RecurrentGCN(node_features=14, filters=32)\n\n# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\n# model.train()\n\n# for epoch in tqdm(range(50)):\n#     for time, snapshot in enumerate(train_dataset):\n#         y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n#         cost = torch.mean((y_hat-snapshot.y)**2)\n#         cost.backward()\n#         optimizer.step()\n#         optimizer.zero_grad()\n\n\nmodel = RecurrentGCN(node_features=14, filters=32)\nmodel.train()\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(14, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(14, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(14, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)\n\n\n\nfor s in train_dataset:\n    print((s.y-model(s.x,s.edge_index,s.edge_attr)).shape)\n\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2022-12-30-(연구&서연) IT-STGCN -- Toy Example.html#예제의-차원-조사",
    "href": "연구/서연/ITSTGCN/2022-12-30-(연구&서연) IT-STGCN -- Toy Example.html#예제의-차원-조사",
    "title": "(연구&서연) IT-STGCN – Toy Example",
    "section": "예제의 차원 조사",
    "text": "예제의 차원 조사\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([1068, 14])\n\n\n\n1068: number of nodes // 1068개의 노드가 있음\n14: number of features // 하나의 노드에 맵핑된 차원의수\n\n\n_edge_index.shape\n\ntorch.Size([2, 27079])\n\n\n\n_edge_attr.shape\n\ntorch.Size([27079])\n\n\n\n_y.shape\n\ntorch.Size([1068])\n\n\n\n1068: number of nodes\n\n\n_x.shape\n\ntorch.Size([1068, 14])"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2022-12-29-(연구&서연) IT-STGCN -- Tutorial.html",
    "href": "연구/서연/ITSTGCN/2022-12-29-(연구&서연) IT-STGCN -- Tutorial.html",
    "title": "(연구&서연) IT-STGCN – Tutorial",
    "section": "",
    "text": "- 이 문서는 공식홈페이지의 예제와 최서연학생의 블로그 내용을 재구성하여 만듬\n- 이 문서의 목표는 아래와 같다.\n\nSTGCN을 사용할 수 있는 데이터의 형태를 탐구한다.\nSTGCN을 실습할 코드를 확보한다.\n\n- 코랩에서 실습하기 위해서는 아래를 설치해야한다.\n\n!pip install torch-geometric\n!pip install torch-geometric-temporal"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2022-12-29-(연구&서연) IT-STGCN -- Tutorial.html#pyg-의-data-자료형",
    "href": "연구/서연/ITSTGCN/2022-12-29-(연구&서연) IT-STGCN -- Tutorial.html#pyg-의-data-자료형",
    "title": "(연구&서연) IT-STGCN – Tutorial",
    "section": "PyG 의 Data 자료형",
    "text": "PyG 의 Data 자료형\n\nref: https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html#data-handling-of-graphs\n\n- 자료는 PyG의 Data 오브젝트를 기반으로 한다.\n(예제) 아래와 같은 그래프자료를 고려하자.\n\n이러한 자료형은 아래와 같은 형식으로 저장한다.\n\nedge_index = torch.tensor([[0, 1, 1, 2],\n                           [1, 0, 2, 1]], dtype=torch.long)\nx = torch.tensor([[-1], [0], [1]], dtype=torch.float)\ndata = Data(x=x, edge_index=edge_index) # Data는 그래프자료형을 만드는 클래스\n\n\ntype(data)\n\ntorch_geometric.data.data.Data\n\n\n\ndata.x\n\ntensor([[-1.],\n        [ 0.],\n        [ 1.]])\n\n\n\ndata.edge_index\n\ntensor([[0, 1, 1, 2],\n        [1, 0, 2, 1]])"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2022-12-29-(연구&서연) IT-STGCN -- Tutorial.html#pytorch-geometric-temporal-의-자료형",
    "href": "연구/서연/ITSTGCN/2022-12-29-(연구&서연) IT-STGCN -- Tutorial.html#pytorch-geometric-temporal-의-자료형",
    "title": "(연구&서연) IT-STGCN – Tutorial",
    "section": "PyTorch Geometric Temporal 의 자료형",
    "text": "PyTorch Geometric Temporal 의 자료형\n\nref: PyTorch Geometric Temporal Signal\n\n아래의 클래스들중 하나를 이용하여 만든다.\n## Temporal Signal Iterators\ntorch_geometric_temporal.signal.StaticGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphStaticSignal\n## Heterogeneous Temporal Signal Iterators\ntorch_geometric_temporal.signal.StaticHeteroGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicHeteroGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicHeteroGraphStaticSignal\n이중 “Heterogeneous Temporal Signal” 은 우리가 관심이 있는 신호가 아니므로 사실상 아래의 3개만 고려하면 된다.\n\ntorch_geometric_temporal.signal.StaticGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphStaticSignal\n\n여기에서 StaticGraphTemporalSignal 는 시간에 따라서 그래프 구조가 일정한 경우, 즉 \\({\\cal G}_t=\\{{\\cal V},{\\cal E}\\}\\)와 같은 구조를 의미한다.\n(예제1) StaticGraphTemporalSignal 를 이용하여 데이터 셋 만들기\n- json data \\(\\to\\) dict\n\nimport json\nimport urllib\n\n\nurl = \"https://raw.githubusercontent.com/benedekrozemberczki/pytorch_geometric_temporal/master/dataset/chickenpox.json\"\ndata_dict = json.loads(urllib.request.urlopen(url).read())\n# data_dict 출력이 김\n\n\ndata_dict.keys()\n\ndict_keys(['edges', 'node_ids', 'FX'])\n\n\n- 살펴보기\n\nnp.array(data_dict['edges']).T\n\narray([[ 0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  2,  3,\n         3,  3,  3,  3,  3,  4,  4,  5,  5,  5,  5,  6,  6,  6,  6,  6,\n         6,  6,  7,  7,  7,  7,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,\n        10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 12, 12, 12,\n        12, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15,\n        15, 15, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18, 18,\n        18, 18, 19, 19, 19, 19],\n       [10,  6, 13,  1,  0,  5, 16,  0, 16,  1, 14, 10,  8,  2,  5,  8,\n        15, 12,  9, 10,  3,  4, 13,  0, 10,  2,  5,  0, 16,  6, 14, 13,\n        11, 18,  7, 17, 11, 18,  3,  2, 15,  8, 10,  9, 13,  3, 12, 10,\n         5,  9,  8,  3, 10,  2, 13,  0,  6, 11,  7, 13, 18,  3,  9, 13,\n        12, 13,  9,  6,  4, 12,  0, 11, 10, 18, 19,  1, 14,  6, 16,  3,\n        15,  8, 16, 14,  1,  0,  6,  7, 19, 17, 18, 14, 18, 17,  7,  6,\n        19, 11, 18, 14, 19, 17]])\n\n\n\n\\({\\cal E} = \\{(0,10),(0,6), \\dots, (19,17)\\}\\)\n혹은 \\({\\cal E} = \\{(\\tt{BACS},\\tt{JASZ}), ({\\tt BACS},{\\tt FEJER}), \\dots, (\\tt{ZALA},\\tt{VAS})\\}\\)\n\n\ndata_dict['node_ids']\n\n{'BACS': 0,\n 'BARANYA': 1,\n 'BEKES': 2,\n 'BORSOD': 3,\n 'BUDAPEST': 4,\n 'CSONGRAD': 5,\n 'FEJER': 6,\n 'GYOR': 7,\n 'HAJDU': 8,\n 'HEVES': 9,\n 'JASZ': 10,\n 'KOMAROM': 11,\n 'NOGRAD': 12,\n 'PEST': 13,\n 'SOMOGY': 14,\n 'SZABOLCS': 15,\n 'TOLNA': 16,\n 'VAS': 17,\n 'VESZPREM': 18,\n 'ZALA': 19}\n\n\n\n\\({\\cal V}=\\{\\tt{BACS},\\tt{BARANYA} \\dots, \\tt{ZALA}\\}\\)\n\n\nnp.array(data_dict['FX']), np.array(data_dict['FX']).shape\n\n(array([[-1.08135724e-03, -7.11136085e-01, -3.22808515e+00, ...,\n          1.09445310e+00, -7.08747750e-01, -1.82280792e+00],\n        [ 2.85705967e-02, -5.98430173e-01, -2.29097341e-01, ...,\n         -1.59220988e+00, -2.24597623e-01,  7.86330575e-01],\n        [ 3.54742090e-01,  1.90511208e-01,  1.61028185e+00, ...,\n          1.38183225e-01, -7.08747750e-01, -5.61724314e-01],\n        ...,\n        [-4.75512620e-01, -1.19952837e+00, -3.89043358e-01, ...,\n         -1.00023329e+00, -1.71429032e+00,  4.70746677e-02],\n        [-2.08645035e-01,  6.03766218e-01,  1.08216835e-02, ...,\n          4.71099041e-02,  2.45684924e+00, -3.44296107e-01],\n        [ 1.21464875e+00,  7.16472130e-01,  1.29038982e+00, ...,\n          4.56939849e-01,  7.43702632e-01,  1.00375878e+00]]),\n (521, 20))\n\n\n\n\\({\\bf f}=\\begin{bmatrix} {\\bf f}_1\\\\ {\\bf f}_2\\\\ \\dots \\\\ {\\bf f}_{521} \\end{bmatrix}=\\begin{bmatrix} f(t=1,v=\\tt{BACS}) & \\dots & f(t=1,v=\\tt{ZALA}) \\\\ f(t=2,v=\\tt{BACS}) & \\dots & f(t=2,v=\\tt{ZALA}) \\\\ \\dots & \\dots & \\dots \\\\ f(t=521,v=\\tt{BACS}) & \\dots & f(t=521,v=\\tt{ZALA}) \\end{bmatrix}\\)\n\n즉 data_dict는 아래와 같이 구성되어 있음\n\n\n\n\n\n\n\n\n\n\n수학 기호\n코드에 저장된 변수\n자료형\n차원\n설명\n\n\n\n\n\\({\\cal V}\\)\ndata_dict['node_ids']\ndict\n20\n20개의 노드에 대한 설명이 있음\n\n\n\\({\\cal E}\\)\ndata_dict['edges']\nlist (double list)\n(102,2)\n노드들에 대한 102개의 연결을 정의함\n\n\n\\({\\bf f}\\)\ndata_dict['node_ids']\ndict\n(521,20)\n\\(f(t,v)\\) for \\(v \\in {\\cal V}\\) and \\(t = 1,\\dots, T\\)\n\n\n\n- 주어진 자료를 정리하여 그래프신호 \\(\\big(\\{{\\cal V},{\\cal E},{\\bf W}\\},{\\bf f}\\big)\\)를 만들면 아래와 같다.\n\nedges = np.array(data_dict[\"edges\"]).T\nedge_weight = np.ones(edges.shape[1])\nf = np.array(data_dict[\"FX\"])\n\n\n여기에서 edges는 \\({\\cal E}\\)에 대한 정보를\nedges_weight는 \\({\\bf W}\\)에 대한 정보를\nf는 \\({\\bf f}\\)에 대한 정보를 저장한다.\n\n\nNote: 이때 \\({\\bf W}={\\bf E}\\) 로 정의한다. (하지만 꼭 이래야 하는건 아니야)\n\n- data_dict \\(\\to\\) dl\n\nlags = 4\nfeatures = [f[i : i + lags, :].T for i in range(f.shape[0] - lags)]\ntargets = [f[i + lags, :].T for i in range(f.shape[0] - lags)]\n\n\nnp.array(features).shape, np.array(targets).shape\n\n((517, 20, 4), (517, 20))\n\n\n\n\n\n\n\n\n\n설명변수\n반응변수\n\n\n\n\n\\({\\bf X} = {\\tt features} = \\begin{bmatrix} {\\bf f}_1 & {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 \\\\ {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 & {\\bf f}_5 \\\\ \\dots & \\dots & \\dots & \\dots \\\\ {\\bf f}_{517} & {\\bf f}_{518} & {\\bf f}_{519} & {\\bf f}_{520} \\end{bmatrix}\\)\n\\({\\bf y}= {\\tt targets} = \\begin{bmatrix} {\\bf f}_5 \\\\ {\\bf f}_6 \\\\ \\dots \\\\ {\\bf f}_{521} \\end{bmatrix}\\)\n\n\n\n\nAR 느낌으로 표현하면 AR(4) 임\n\n\ndataset = torch_geometric_temporal.signal.StaticGraphTemporalSignal(\n    edge_index= edges,\n    edge_weight = edge_weight,\n    features = features,\n    targets = targets\n)\n\n\ndataset\n\n&lt;torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal at 0x7faad2716a60&gt;\n\n\n- 그런데 이 과정을 아래와 같이 할 수도 있음\n# PyTorch Geometric Temporal 공식홈페이지에 소개된 코드\nloader = torch_geometric_temporal.dataset.ChickenpoxDatasetLoader()\ndataset=loader.get_dataset(lags=4)\n- dataset은 dataset[0], \\(\\dots\\) , dataset[516]과 같은 방식으로 각 시점별 자료에 접근가능\n\ndataset[0]\n\nData(x=[20, 4], edge_index=[2, 102], edge_attr=[102], y=[20])\n\n\n각 시점에 대한 자료형은 아까 살펴보았던 PyG의 Data 자료형과 같음\n\ntype(dataset[0])\n\ntorch_geometric.data.data.Data\n\n\n\ndataset[0].x \n\ntensor([[-1.0814e-03,  2.8571e-02,  3.5474e-01,  2.9544e-01],\n        [-7.1114e-01, -5.9843e-01,  1.9051e-01,  1.0922e+00],\n        [-3.2281e+00, -2.2910e-01,  1.6103e+00, -1.5487e+00],\n        [ 6.4750e-01, -2.2117e+00, -9.6858e-01,  1.1862e+00],\n        [-1.7302e-01, -9.4717e-01,  1.0347e+00, -6.3751e-01],\n        [ 3.6345e-01, -7.5468e-01,  2.9768e-01, -1.6273e-01],\n        [-3.4174e+00,  1.7031e+00, -1.6434e+00,  1.7434e+00],\n        [-1.9641e+00,  5.5208e-01,  1.1811e+00,  6.7002e-01],\n        [-2.2133e+00,  3.0492e+00, -2.3839e+00,  1.8545e+00],\n        [-3.3141e-01,  9.5218e-01, -3.7281e-01, -8.2971e-02],\n        [-1.8380e+00, -5.8728e-01, -3.5514e-02, -7.2298e-02],\n        [-3.4669e-01, -1.9827e-01,  3.9540e-01, -2.4774e-01],\n        [ 1.4219e+00, -1.3266e+00,  5.2338e-01, -1.6374e-01],\n        [-7.7044e-01,  3.2872e-01, -1.0400e+00,  3.4945e-01],\n        [-7.8061e-01, -6.5022e-01,  1.4361e+00, -1.2864e-01],\n        [-1.0993e+00,  1.2732e-01,  5.3621e-01,  1.9023e-01],\n        [ 2.4583e+00, -1.7811e+00,  5.0732e-02, -9.4371e-01],\n        [ 1.0945e+00, -1.5922e+00,  1.3818e-01,  1.1855e+00],\n        [-7.0875e-01, -2.2460e-01, -7.0875e-01,  1.5630e+00],\n        [-1.8228e+00,  7.8633e-01, -5.6172e-01,  1.2647e+00]])\n\n\n\n이 값들은 features[0]의 값들과 같음. 즉 \\([{\\bf f}_1~ {\\bf f}_2~ {\\bf f}_3~ {\\bf f}_4]\\)를 의미함\n\n\ndataset[0].y\n\ntensor([ 0.7106, -0.0725,  2.6099,  1.7870,  0.8024, -0.2614, -0.8370,  1.9674,\n        -0.4212,  0.1655,  1.2519,  2.3743,  0.7877,  0.4531, -0.1721, -0.0614,\n         1.0452,  0.3203, -1.3791,  0.0036])\n\n\n\n이 값들은 targets[0]의 값들과 같음. 즉 \\({\\bf f}_5\\)를 의미함"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2022-12-29-(연구&서연) IT-STGCN -- Tutorial.html#summary-of-data",
    "href": "연구/서연/ITSTGCN/2022-12-29-(연구&서연) IT-STGCN -- Tutorial.html#summary-of-data",
    "title": "(연구&서연) IT-STGCN – Tutorial",
    "section": "summary of data",
    "text": "summary of data\n\n\\(T\\) = 519\n\\(N\\) = 20 # number of nodes\n\\(|{\\cal E}|\\) = 102 # edges\n\\(f(t,v)\\)의 차원? (1,)\n시간에 따라서 Number of nodes가 변하는지? False\n시간에 따라서 Number of nodes가 변하는지? False\n\\({\\bf X}\\): (20,4)\n\\({\\bf y}\\): (20,)\n예제코드적용가능여부: Yes\n\n- Nodes : 20\n\nvertices are counties\n\n-Edges : 102\n\nedges are neighbourhoods\n\n- Time : 519\n\nbetween 2004 and 2014\nper weeks\n\n\nloader = torch_geometric_temporal.dataset.ChickenpoxDatasetLoader()\ndataset = loader.get_dataset(lags=4)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2022-12-29-(연구&서연) IT-STGCN -- Tutorial.html#learn",
    "href": "연구/서연/ITSTGCN/2022-12-29-(연구&서연) IT-STGCN -- Tutorial.html#learn",
    "title": "(연구&서연) IT-STGCN – Tutorial",
    "section": "learn",
    "text": "learn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for t, snapshot in enumerate(train_dataset):\n        yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((yt_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [01:16&lt;00:00,  1.52s/it]\n\n\n\ndataset.features[0].shape\n\n(20, 4)"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2022-12-29-(연구&서연) IT-STGCN -- Tutorial.html#visualization",
    "href": "연구/서연/ITSTGCN/2022-12-29-(연구&서연) IT-STGCN -- Tutorial.html#visualization",
    "title": "(연구&서연) IT-STGCN – Tutorial",
    "section": "visualization",
    "text": "visualization\n\nmodel.eval()\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)\n\n\n\nyhat_train = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in train_dataset]).detach().numpy()\nyhat_test = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in test_dataset]).detach().numpy()\n\n\nV = list(data_dict['node_ids'].keys())\n\n\nfig,ax = plt.subplots(20,1,figsize=(10,50))\nfor k in range(20):\n    ax[k].plot(f[:,k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_train[:,k],label='predicted (tr)')\n    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2022-12-29-(연구&서연) IT-STGCN -- Tutorial.html#footnotes",
    "href": "연구/서연/ITSTGCN/2022-12-29-(연구&서연) IT-STGCN -- Tutorial.html#footnotes",
    "title": "(연구&서연) IT-STGCN – Tutorial",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n일반적인 기하학적 딥러닝을 위한 파이토치 패키지↩︎\nSTGCN을 위한 패키지↩︎"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2023-03-18-(연구&서연) IT-STGCN -- SimualtionPlanner-Tutorial.html",
    "href": "연구/서연/ITSTGCN/2023-03-18-(연구&서연) IT-STGCN -- SimualtionPlanner-Tutorial.html",
    "title": "(연구&서연) IT-STGCN – SimualtionPlanner-Tutorial",
    "section": "",
    "text": "import itstgcn\nimport torch\nimport itstgcn.planner"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2023-03-18-(연구&서연) IT-STGCN -- SimualtionPlanner-Tutorial.html#plnr_stgcn_rand",
    "href": "연구/서연/ITSTGCN/2023-03-18-(연구&서연) IT-STGCN -- SimualtionPlanner-Tutorial.html#plnr_stgcn_rand",
    "title": "(연구&서연) IT-STGCN – SimualtionPlanner-Tutorial",
    "section": "PLNR_STGCN_RAND",
    "text": "PLNR_STGCN_RAND\n\nplans_stgcn_rand = {\n    'max_iteration': 2, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mrate': [0.0, 0.2],\n    'lags': [2, 4], \n    'nof_filters': [4, 8], \n    'inter_method': ['nearest'],\n    'epoch': [3]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader,dataset_name='five_nodes')\n\n\nplnr.simulate()\n\n1/2 is done\n2/2 is done\nAll results are stored in ./simulation_results/2023-03-18_11-56-03.csv"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2023-03-18-(연구&서연) IT-STGCN -- SimualtionPlanner-Tutorial.html#plnr_stgcn_manual",
    "href": "연구/서연/ITSTGCN/2023-03-18-(연구&서연) IT-STGCN -- SimualtionPlanner-Tutorial.html#plnr_stgcn_manual",
    "title": "(연구&서연) IT-STGCN – SimualtionPlanner-Tutorial",
    "section": "PLNR_STGCN_MANUAL",
    "text": "PLNR_STGCN_MANUAL\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\nloader = itstgcn.DatasetLoader(data_dict)\n\n\nmindex= [list(range(10,100)),[],list(range(50,80)),[],[]]\nplans_stgcn_block = {\n    'max_iteration': 3, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex],\n    'lags': [2, 4], \n    'nof_filters': [8,16], \n    'inter_method': ['nearest','linear'],\n    'epoch': [1]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader,dataset_name='five_nodes')\n\n\nplnr.simulate(mindex=mindex,mtype='block')\n\n1/3 is done\n2/3 is done\n3/3 is done\nAll results are stored in ./simulation_results/2023-03-18_11-56-55.csv"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2023-03-18-(연구&서연) IT-STGCN -- SimualtionPlanner-Tutorial.html#plnr_gnar_rand",
    "href": "연구/서연/ITSTGCN/2023-03-18-(연구&서연) IT-STGCN -- SimualtionPlanner-Tutorial.html#plnr_gnar_rand",
    "title": "(연구&서연) IT-STGCN – SimualtionPlanner-Tutorial",
    "section": "PLNR_GNAR_RAND",
    "text": "PLNR_GNAR_RAND\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\nloader = itstgcn.DatasetLoader(data_dict)\n\n\nplans_gnar_rand = {\n    'max_iteration': 3, \n#    'method': ['GNAR'], \n    'mrate': [0.0, 0.2, 0.4],\n    'lags': [2, 4], \n#    'nof_filters': [8,16], \n    'inter_method': ['nearest','linear'],\n#    'epoch': [1]\n}\n\n\nplnr = itstgcn.planner.PLNR_GNAR_RAND(plans_gnar_rand,loader,dataset_name='five_nodes')\nplnr.simulate()\n\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n1/3 is done\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n2/3 is done\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n3/3 is done\nAll results are stored in ./simulation_results/2023-03-18_11-56-56.csv"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2023-03-18-(연구&서연) IT-STGCN -- SimualtionPlanner-Tutorial.html#plnr_gnar_block",
    "href": "연구/서연/ITSTGCN/2023-03-18-(연구&서연) IT-STGCN -- SimualtionPlanner-Tutorial.html#plnr_gnar_block",
    "title": "(연구&서연) IT-STGCN – SimualtionPlanner-Tutorial",
    "section": "PLNR_GNAR_BLOCK",
    "text": "PLNR_GNAR_BLOCK\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\nloader = itstgcn.DatasetLoader(data_dict)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\nplans_gnar_block = {\n    'max_iteration': 3, \n    'method': ['GNAR'], \n    'mindex': [mindex],\n    'lags': [2, 4], \n    'inter_method': ['nearest','linear'],\n}\n\n\nplnr = itstgcn.planner.PLNR_GNAR_MANUAL(plans_gnar_block,loader,dataset_name='five_nodes')\nplnr.simulate(mindex,mtype='block')\n\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n1/3 is done\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n2/3 is done\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n3/3 is done\nAll results are stored in ./simulation_results/2023-03-18_11-56-57.csv"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2023-02-14-(연구&서연) IT-STGCN -- Tables.html",
    "href": "연구/서연/ITSTGCN/2023-02-14-(연구&서연) IT-STGCN -- Tables.html",
    "title": "(연구&서연) IT-STGCN – Tables",
    "section": "",
    "text": "import pandas as pd\n\n- Dataset 5nodes\n\ncol = ['Dataset','iteration', 'method', 'missingrate', 'missingtype', 'lag', 'number_of_filters', 'interpolation','MSE_train', 'MSE_test',]\n\n\ndf = pd.DataFrame(columns=col)\ndf\n\n\n\n\n\n\n\n\nDataset\niteration\nmethod\nmissingrate\nmissingtype\nlag\nnumber_of_filters\ninterpolation\nMSE_train\nMSE_test\n\n\n\n\n\n\n\n\n\n- 실험마다 아래와 같은식으로 추가\n\ndf_row = pd.DataFrame(columns=col)\ndf_row['Dataset'] = 'fivenodes', # ...\ndf_row['iteration'] = 1, # 1,2,3,...,10 \ndf_row['method'] = 'stgcn', # 'stgcn','estgcn','gnar' \ndf_row['missingrate'] = 0.0, # 0.0, 0.2, 0.4, 0.6, 0.8 \ndf_row['missingtype'] = None,  # None, 'randomly' and 'block' \ndf_row['lag'] = 1, # 1,2,3,4 ... \ndf_row['number_of_filters'] = 16, # 16,24,32, ... \ndf_row['interpolation'] = None, # None, 'mean', 'linear'\ndf_row['MSE_train'] = 0.96 \ndf_row['MSE_test'] = 0.55\n\n\ndf = pd.concat([df,df_row])\ndf\n\n\n\n\n\n\n\n\nDataset\niteration\nmethod\nmissingrate\nmissingtype\nlag\nnumber_of_filters\ninterpolation\nMSE_train\nMSE_test\n\n\n\n\n0\nfivenodes\n1\nstgcn\n0.0\nNone\n1\n16\nNone\n0.96\n0.55\n\n\n\n\n\n\n\n\ndf_row = pd.DataFrame(columns=col)\ndf_row['Dataset'] = 'fivenodes', # ...\ndf_row['iteration'] = 1, # 1,2,3,...,10 \ndf_row['method'] = 'stgcn', # 'stgcn','estgcn','gnar' \ndf_row['missingrate'] = 0.2, # 0.0, 0.2, 0.4, 0.6, 0.8 \ndf_row['missingtype'] = 'randomly',  # None, 'randomly' and 'block' \ndf_row['lag'] = 1, # 1,2,3,4 ... \ndf_row['number_of_filters'] = 16, # 16,24,32, ... \ndf_row['interpolation'] = 'mean', # None, 'mean', 'linear'\ndf_row['MSE_train'] = 1.23\ndf_row['MSE_test'] = 0.88\n\n\ndf = pd.concat([df,df_row])\ndf\n\n\n\n\n\n\n\n\nDataset\niteration\nmethod\nmissingrate\nmissingtype\nlag\nnumber_of_filters\ninterpolation\nMSE_train\nMSE_test\n\n\n\n\n0\nfivenodes\n1\nstgcn\n0.0\nNone\n1\n16\nNone\n0.96\n0.55\n\n\n0\nfivenodes\n1\nstgcn\n0.2\nrandomly\n1\n16\nmean\n1.23\n0.88"
  },
  {
    "objectID": "연구/서연/ITSTGCN/2023-03-17-(연구&서연) IT-STGCN -- ITSTGCN-Tutorial.html",
    "href": "연구/서연/ITSTGCN/2023-03-17-(연구&서연) IT-STGCN -- ITSTGCN-Tutorial.html",
    "title": "(연구&서연) IT-STGCN – ITSTGCN-Tutorial",
    "section": "",
    "text": "edit\n\n\nimport\n\nimport itstgcn \nimport torch\n\n\n\n예제1: vanilla STGCN\n- 데이터\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n\n\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \n\n\ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.utils.temporal_signal_split(dataset, train_ratio=0.8)\n\n- 학습\n\nlrnr = itstgcn.StgcnLearner(train_dataset,dataset_name='five_nodes')\n\n/home/csy/Dropbox/blog/posts/GCN/itstgcn/learners.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180588308/work/torch/csrc/utils/tensor_new.cpp:201.)\n  self.lags = torch.tensor(train_dataset.features).shape[-1]\n\n\n\nlrnr.learn(filters=4,epoch=5)\n\n5/5\n\n\n- 적합값\n\n#lrnr(train_dataset) \n#lrnr(test_dataset)\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) \nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\n\n\n\n\n예제2: padding missing values\n- 데이터\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.utils.temporal_signal_split(dataset, train_ratio=0.8)\n\n- 임의로 결측치 발생\n\nmindex = itstgcn.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex=mindex,mtype='rand')\n\n\nfig = itstgcn.plot(torch.tensor(train_dataset_miss.targets),'o')\nfig \n\n\n\n\n\n\n\n\n- 적절한 method로 결측치를 채움 (default 는 linear)\n\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n\nfig = itstgcn.plot(torch.tensor(train_dataset_miss.targets),'o')\nitstgcn.plot_add(fig,torch.tensor(train_dataset_padded.targets),'--x',color='C1',alpha=0.5)\n\n\n\n\n\n\n\n\n다른 method로 결측치를 채울수도 있음. 사용할 수 있는 방법들은 아래에 정리되어 있음\n\nref: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html\n\n\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss,interpolation_method='nearest')\n\n\nfig = itstgcn.plot(torch.tensor(train_dataset_miss.targets),'o')\nitstgcn.plot_add(fig,torch.tensor(train_dataset_padded.targets),'--x',color='C1',alpha=0.5)\n\n\n\n\n\n\n\n\n\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss,interpolation_method='quadratic')\n\n\nfig = itstgcn.plot(torch.tensor(train_dataset_miss.targets),'o')\nitstgcn.plot_add(fig,torch.tensor(train_dataset_padded.targets),'--x',color='C1',alpha=0.5)\n\n\n\n\n\n\n\n\n\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss,interpolation_method='cubic')\n\n\nfig = itstgcn.utils.plot(torch.tensor(train_dataset_miss.targets),'o')\nitstgcn.utils.plot_add(fig,torch.tensor(train_dataset_padded.targets),'--x',color='C1',alpha=0.5)\n\n\n\n\n\n\n\n\n- 블락으로 결측치 발생\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='block')\n\n\nfig = itstgcn.utils.plot(torch.tensor(train_dataset_miss.targets),'o')\nfig \n\n\n\n\n\n\n\n\n\n\n예제3: vanilla STGCN with random missing\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.utils.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = itstgcn.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcn.learners.StgcnLearner(train_dataset_padded)\n\n\nlrnr.learn(filters=4,epoch=5)\n\n5/5\n\n\n- 적합값\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=5,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\n\n\n\n\n예제4: vanilla STGCN with block missing\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.utils.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcn.StgcnLearner(train_dataset_padded)\n\n\nlrnr.learn(filters=4,epoch=5)\n\n5/5\n\n\n- 적합값\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=5,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\n\n\n\n\n예제5: threshold example (random)\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.utils.temporal_signal_split(dataset, train_ratio=0.8)\n\n- 결측치 발생 및 패딩\n\nmindex=itstgcn.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss)\n\n\nf_miss,_ = itstgcn.convert_train_dataset(train_dataset_miss)\nf_padded,_ = itstgcn.convert_train_dataset(train_dataset_padded)\n\n\nfig = itstgcn.utils.plot(f_miss,'o')\nitstgcn.utils.plot_add(fig,f_padded,'--x',alpha=0.5)\n\n\n\n\n\n\n\n\n- update by frequency thresholding\n\nfig = itstgcn.plot(f_miss,'o',alpha=0.5)\nitstgcn.plot_add(fig,f_padded,'--x',alpha=0.5)\nf_updated = itstgcn.update_from_freq_domain(f_padded,train_dataset_padded.mindex)\nitstgcn.plot_add(fig,f_updated,'-')\n\n\n\n\n\n\n\n\n\n\n예제6: threshold example (block)\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n- 결측치 발생 및 패딩\n\nmindex=[list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss)\n\n\nf_miss,_ = itstgcn.convert_train_dataset(train_dataset_miss)\nf_padded,_ = itstgcn.convert_train_dataset(train_dataset_padded)\n\n\nfig = itstgcn.plot(f_miss,'o')\nitstgcn.plot_add(fig,f_padded,'--x',alpha=0.5)\n\n\n\n\n\n\n\n\n- update by frequency thresholding\n\nfig = itstgcn.plot(f_miss,'o',alpha=0.5)\nitstgcn.plot_add(fig,f_padded,'--x',alpha=0.5)\nf_updated = itstgcn.update_from_freq_domain(f_padded,train_dataset_padded.mindex)\nitstgcn.plot_add(fig,f_updated,'-')\n\n\n\n\n\n\n\n\n\n\n예제7: iterative thresholded STGCN (IT-STGCN) with random missing\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = itstgcn.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcn.ITStgcnLearner(train_dataset_padded)\n\n\nlrnr.learn(filters=4,epoch=5)\n\n5/5\n\n\n- 적합값\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)['yhat'].shape\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\n\n\n\n\n예제8: iterative thresholded STGCN (IT-STGCN) with block missing\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcn.ITStgcnLearner(train_dataset_padded)\n\n\nlrnr.learn(filters=4,epoch=5)\n\n5/5\n\n\n- 적합값\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)['yhat'].shape\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\n\n\n\n\n예제9: GNAR (random missing)\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex=itstgcn.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcn.GNARLearner(train_dataset_padded)\n\n\nlrnr.learn()\n\nWARNING: diagonal entries present in original matrix, these will be removed\n\n\n- 적합값\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\n\n\n\n\n예제10: GNAR (block missing)\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex=[list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcn.GNARLearner(train_dataset_padded)\n\n\nlrnr.learn()\n\nWARNING: diagonal entries present in original matrix, these will be removed\n\n\n- 적합값\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "연구/보람/2023-08-22 데이터(8, df02)커널죽음.out.html",
    "href": "연구/보람/2023-08-22 데이터(8, df02)커널죽음.out.html",
    "title": "[FRAUD] 데이터정리 시도(8.25 df02 커널죽음)",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nfrom sklearn import model_selection # split함수이용\n\n- fraudTrain\n\nfraudTrain = pd.read_csv(\"fraudTrain.csv\").iloc[:,1:]\n\n\nfraudTrain = fraudTrain.assign(trans_date_trans_time= list(map(lambda x: pd.to_datetime(x), fraudTrain.trans_date_trans_time)))\nfraudTrain\n\n\n\n\n\n\n\n\ntrans_date_trans_time\ncc_num\nmerchant\ncategory\namt\nfirst\nlast\ngender\nstreet\ncity\n...\nlat\nlong\ncity_pop\njob\ndob\ntrans_num\nunix_time\nmerch_lat\nmerch_long\nis_fraud\n\n\n\n\n0\n2019-01-01 00:00:00\n2.703190e+15\nfraud_Rippin, Kub and Mann\nmisc_net\n4.97\nJennifer\nBanks\nF\n561 Perry Cove\nMoravian Falls\n...\n36.0788\n-81.1781\n3495\nPsychologist, counselling\n1988-03-09\n0b242abb623afc578575680df30655b9\n1325376018\n36.011293\n-82.048315\n0\n\n\n1\n2019-01-01 00:00:00\n6.304230e+11\nfraud_Heller, Gutmann and Zieme\ngrocery_pos\n107.23\nStephanie\nGill\nF\n43039 Riley Greens Suite 393\nOrient\n...\n48.8878\n-118.2105\n149\nSpecial educational needs teacher\n1978-06-21\n1f76529f8574734946361c461b024d99\n1325376044\n49.159047\n-118.186462\n0\n\n\n2\n2019-01-01 00:00:00\n3.885950e+13\nfraud_Lind-Buckridge\nentertainment\n220.11\nEdward\nSanchez\nM\n594 White Dale Suite 530\nMalad City\n...\n42.1808\n-112.2620\n4154\nNature conservation officer\n1962-01-19\na1a22d70485983eac12b5b88dad1cf95\n1325376051\n43.150704\n-112.154481\n0\n\n\n3\n2019-01-01 00:01:00\n3.534090e+15\nfraud_Kutch, Hermiston and Farrell\ngas_transport\n45.00\nJeremy\nWhite\nM\n9443 Cynthia Court Apt. 038\nBoulder\n...\n46.2306\n-112.1138\n1939\nPatent attorney\n1967-01-12\n6b849c168bdad6f867558c3793159a81\n1325376076\n47.034331\n-112.561071\n0\n\n\n4\n2019-01-01 00:03:00\n3.755340e+14\nfraud_Keeling-Crist\nmisc_pos\n41.96\nTyler\nGarcia\nM\n408 Bradley Rest\nDoe Hill\n...\n38.4207\n-79.4629\n99\nDance movement psychotherapist\n1986-03-28\na41d7549acf90789359a9aa5346dcb46\n1325376186\n38.674999\n-78.632459\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1048570\n2020-03-10 16:07:00\n6.011980e+15\nfraud_Fadel Inc\nhealth_fitness\n77.00\nHaley\nWagner\nF\n05561 Farrell Crescent\nAnnapolis\n...\n39.0305\n-76.5515\n92106\nAccountant, chartered certified\n1943-05-28\n45ecd198c65e81e597db22e8d2ef7361\n1362931649\n38.779464\n-76.317042\n0\n\n\n1048571\n2020-03-10 16:07:00\n4.839040e+15\nfraud_Cremin, Hamill and Reichel\nmisc_pos\n116.94\nMeredith\nCampbell\nF\n043 Hanson Turnpike\nHedrick\n...\n41.1826\n-92.3097\n1583\nGeochemist\n1999-06-28\nc00ce51c6ebb7657474a77b9e0b51f34\n1362931670\n41.400318\n-92.726724\n0\n\n\n1048572\n2020-03-10 16:08:00\n5.718440e+11\nfraud_O'Connell, Botsford and Hand\nhome\n21.27\nSusan\nMills\nF\n005 Cody Estates\nLouisville\n...\n38.2507\n-85.7476\n736284\nEngineering geologist\n1952-04-02\n17c9dc8b2a6449ca2473726346e58e6c\n1362931711\n37.293339\n-84.798122\n0\n\n\n1048573\n2020-03-10 16:08:00\n4.646850e+18\nfraud_Thompson-Gleason\nhealth_fitness\n9.52\nJulia\nBell\nF\n576 House Crossroad\nWest Sayville\n...\n40.7320\n-73.1000\n4056\nFilm/video editor\n1990-06-25\n5ca650881b48a6a38754f841c23b77ab\n1362931718\n39.773077\n-72.213209\n0\n\n\n1048574\n2020-03-10 16:08:00\n2.283740e+15\nfraud_Buckridge PLC\nmisc_pos\n6.81\nShannon\nWilliams\nF\n9345 Spencer Junctions Suite 183\nAlpharetta\n...\n34.0770\n-84.3033\n165556\nPrison officer\n1997-12-27\n8d0a575fe635bbde12f1a2bffc126731\n1362931730\n33.601468\n-83.891921\n0\n\n\n\n\n1048575 rows × 22 columns\n\n\n\n- df02\n\n_df1 = fraudTrain[fraudTrain[\"is_fraud\"] == 0].sample(frac=0.20, random_state=42)\n_df2 = fraudTrain[fraudTrain[\"is_fraud\"] == 1]\ndf02 = pd.concat([_df1,_df2])\ndf02 = df02.reset_index()\n\n- df_toy\n\ndf_toy=df02[:5].copy()\ndf_toy.cc_num = pd.Series([1,1,1,2,2])\ndf_toy\n\n\n\n\n\n\n\n\nindex\ntrans_date_trans_time\ncc_num\nmerchant\ncategory\namt\nfirst\nlast\ngender\nstreet\n...\nlat\nlong\ncity_pop\njob\ndob\ntrans_num\nunix_time\nmerch_lat\nmerch_long\nis_fraud\n\n\n\n\n0\n669418\n2019-10-12 18:21:00\n1\nfraud_Haley, Jewess and Bechtelar\nshopping_pos\n7.53\nDebra\nStark\nF\n686 Linda Rest\n...\n32.3836\n-94.8653\n24536\nMultimedia programmer\n1983-10-14\nd313353fa30233e5fab5468e852d22fc\n1350066071\n32.202008\n-94.371865\n0\n\n\n1\n32567\n2019-01-20 13:06:00\n1\nfraud_Turner LLC\ntravel\n3.79\nJudith\nMoss\nF\n46297 Benjamin Plains Suite 703\n...\n39.5370\n-83.4550\n22305\nTelevision floor manager\n1939-03-09\n88c65b4e1585934d578511e627fe3589\n1327064760\n39.156673\n-82.930503\n0\n\n\n2\n156587\n2019-03-24 18:09:00\n1\nfraud_Klein Group\nentertainment\n59.07\nDebbie\nPayne\nF\n204 Ashley Neck Apt. 169\n...\n41.5224\n-71.9934\n4720\nBroadcast presenter\n1977-05-18\n3bd9ede04b5c093143d5e5292940b670\n1332612553\n41.657152\n-72.595751\n0\n\n\n3\n1020243\n2020-02-25 15:12:00\n2\nfraud_Monahan-Morar\npersonal_care\n25.58\nAlan\nParsons\nM\n0547 Russell Ford Suite 574\n...\n39.6171\n-102.4776\n207\nNetwork engineer\n1955-12-04\n19e16ee7a01d229e750359098365e321\n1361805120\n39.080346\n-103.213452\n0\n\n\n4\n116272\n2019-03-06 23:19:00\n2\nfraud_Kozey-Kuhlman\npersonal_care\n84.96\nJill\nFlores\nF\n639 Cruz Islands\n...\n41.9488\n-86.4913\n3104\nHorticulturist, commercial\n1981-03-29\na0c8641ca1f5d6e243ed5a2246e66176\n1331075954\n42.502065\n-86.732664\n0\n\n\n\n\n5 rows × 23 columns\n\n\n\n- df_toy 에서 time_difference 구함\n고객1\n\ndf_toy.iloc[0].trans_date_trans_time.value - df_toy.iloc[1].trans_date_trans_time.value\n\n22914900000000000\n\n\n\ndf_toy.iloc[0].trans_date_trans_time.value - df_toy.iloc[2].trans_date_trans_time.value\n\n17453520000000000\n\n\n\ndf_toy.iloc[1].trans_date_trans_time.value - df_toy.iloc[2].trans_date_trans_time.value\n\n-5461380000000000\n\n\n고객2\n\ndf_toy.iloc[3].trans_date_trans_time.value - df_toy.iloc[4].trans_date_trans_time.value\n\n30729180000000000\n\n\n고객1,2\n\ndef compute_time_difference(group):\n    n = len(group)\n    result = []\n    for i in range(n):\n        for j in range(n):\n            time_difference = abs(group.iloc[i].trans_date_trans_time.value - group.iloc[j].trans_date_trans_time.value)\n            result.append([group.iloc[i].name, group.iloc[j].name, time_difference])\n    return result\n\n\ngroups = df_toy.groupby('cc_num')\nedge_index_list_plus = [compute_time_difference(group) for _, group in groups]\nedge_index_list_plus_flat = [item for sublist in edge_index_list_plus for item in sublist]\nedge_index_list_plus_nparr = np.array(edge_index_list_plus_flat)\nedge_index_list_plus_nparr\n\narray([[                0,                 0,                 0],\n       [                0,                 1, 22914900000000000],\n       [                0,                 2, 17453520000000000],\n       [                1,                 0, 22914900000000000],\n       [                1,                 1,                 0],\n       [                1,                 2,  5461380000000000],\n       [                2,                 0, 17453520000000000],\n       [                2,                 1,  5461380000000000],\n       [                2,                 2,                 0],\n       [                3,                 3,                 0],\n       [                3,                 4, 30729180000000000],\n       [                4,                 3, 30729180000000000],\n       [                4,                 4,                 0]])\n\n\n- df02에서 time_difference 구함\n\nt1 = time.time()\ngroups = df02.groupby('cc_num')\nedge_index_list_plus = [compute_time_difference(group) for _, group in groups]\nedge_index_list_plus_flat = [item for sublist in edge_index_list_plus for item in sublist]\nedge_index_list_plus_nparr = np.array(edge_index_list_plus_flat)\nnp.save('edge_index_list_plus02.npy', edge_index_list_plus_nparr)\nt2 = time.time()\nt2-t1\n\n15537.573440551758\n\n\n\n(t2-t1)/3600\n\n4.3159926223754885"
  }
]