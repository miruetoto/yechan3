[
  {
    "objectID": "2_pl.html",
    "href": "2_pl.html",
    "title": "PyTorch Lightning",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nSep 21, 2022\n\n\n[PL] Lesson1: 단순선형회귀\n\n\n신록예찬\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog\nThis blog was created for my personal research, study and lecture preparation. Therefore, the contents of the blog can be thought of as my practice notes. As a result, sometimes the content of a post may be left unstructured or unfinished. The blog is named after my favorite essay ‘신록예찬’, which is also a nickname I use informally. You can check the written article in the sidebar on the left. It is a great honor for me if these posts can help others to learn and research.\n\nSome links that help me\nblogs\n\nhttps://seoyeonc.github.io/md/\nhttps://seoyeonc.github.io/blog/\nhttps://boram-coco.github.io/coco/\nhttps://pinkocto.github.io/noteda/\nhttps://pinkocto.github.io/Quarto-Blog/\n\nfirst url bunch\n\nchatGPT: https://openai.com/blog/chatgpt/\nmatplotlib: https://matplotlib.org/stable/gallery/index.html\njupyterlab: https://jupyterlab.readthedocs.io/en/stable/index.html\npandas: https://pandas.pydata.org/docs/user_guide/index.html#user-guide\njulia: https://docs.julialang.org/en/v1/\nkeras: https://keras.io/examples/\njulia plots: https://docs.juliaplots.org/stable/\npytorch lightning: https://www.pytorchlightning.ai/\nplotly: https://plotly.com/graphing-libraries/\nquarto: https://quarto.org/\n\nsecond url bunch\n\nlatex: https://editor.codecogs.com/\ntable: https://www.tablesgenerator.com/\npytorch lightning (codes in book): https://github.com/PacktPublishing/Deep-Learning-with-PyTorch-Lightning\nPyG: https://github.com/rusty1s/pytorch_geometric\nrayshader: https://www.rayshader.com/reference/plot_gg.html\nSouth Korea (map): https://github.com/southkorea\nregexp: https://zvon.org/comp/m/regexp.html\nrpy2: https://rpy2.github.io/doc/v3.1.x/html/index.html\npywave: https://pywavelets.readthedocs.io/en/latest/ref/wavelets.html\nPyGSP: https://pygsp.readthedocs.io/en/stable/#\nlatex (neural networks): https://tikz.net/neural_networks/\nplotly overview: https://plotly.com/python/plotly-express/\nfastai (official): https://docs.fast.ai/\nfastai (lecture): https://course.fast.ai/#\nfastai (github codes): https://github.com/fastai/fastai/tree/master/dev_nbs/course\nGML (codes in book): https://github.com/PacktPublishing/Graph-Machine-Learning\nGMLKOR (codes in book): https://github.com/AcornPublishing/graph-ml\nmathNET https://gtribello.github.io/mathNET/index.html\n\nlectures notes\n\nhttp://personal.psu.edu/drh20/asymp/fall2006/lectures/\nhttps://web.ma.utexas.edu/users/gordanz/lecture_notes_page.html"
  },
  {
    "objectID": "3_boram.html",
    "href": "3_boram.html",
    "title": "BORAM",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nMay 19, 2023\n\n\n[BORAM] 신용카드 거래 사기탐지 Try2\n\n\n신록예찬\n\n\n\n\nMay 12, 2023\n\n\n[BORAM] 신용카드 거래 사기탐지 Try1\n\n\n신록예찬\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "2_gml.html",
    "href": "2_gml.html",
    "title": "GML",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap2: 그래프 머신러닝 - Node2Vec, Edge2Vec, Graph2Vec\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap3: 비지도 그래프 학습 - AutoEncoder\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap3: 비지도 그래프 학습 - Graph Neural Network\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap3: 비지도 그래프 학습 - Shallow_Embeddings\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap3: 비지도 그래프 학습 - Structural Deep Network Embedding\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap4: 지도 그래프 학습 - Graph CNN\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap4: 지도 그래프 학습 - 그래프 정규화 방법\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap4: 지도 그래프 학습 - 얕은 임베딩 방법\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap4: 지도 그래프 학습 - 특징 기반 방법\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap5: 응용문제 - 누락된 링크예측\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap5: 응용문제 - 커뮤니티 감지\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap6: 소셜네트워크 그래프\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap7: Graph Neural Network Topic Classifier\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap7: Shallow-Learning Topic Modelling\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap8: 신용카드 거래에 대한 그래프 분석\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap9: Graph Database Connection\n\n\n신록예찬\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2099-01-01-notes2.html",
    "href": "posts/2099-01-01-notes2.html",
    "title": "연습장2",
    "section": "",
    "text": "Nature\n- 마코프체인의 상태는 (1) positive recurrent (2) null recurrent (3) transient 로 나눌 수 있다.\n- 가짜정의: HMC \\(\\{X_t\\}\\)의 어떠한 상태 \\(i\\)가 transient 하다는 의미는 그 상태에 일시적으로 머문다는 의미이다.\n\nChatGPT: “transient”는 한국어로 “일시적인” 또는 “잠깐의”라고 번역할 수 있습니다. 이 단어는 어떤 상태, 현상 또는 조건이 일시적이거나 잠시동안만 지속되는 것을 의미합니다.\n\n\\(\\sum_{t=0}^{\\infty}p_{ii}^{(t)}<\\infty\\)\n- 1D random walk\n\n\\(X_0=0\\)\n\\(p_{i,i+1}=p\\) and \\(p_{i,i-1}=1-p\\)\n\n\\(p_{00}^{(2t+1)}=0\\)\n\nimport numpy as np\n\n\ninit_dist = np.array([0]*500+[1]+[0]*500).reshape(-1,1)\ninit_dist\n\narray([[0],\n       [0],\n       [0],\n       ...,\n       [0],\n       [0],\n       [0]])\n\n\n\np = 0.5\nP = np.zeros(1001*1001).reshape(1001,1001)\nfor i in range(1000):\n    P[i,i+1] = p \nfor i in range(1,1001):\n    P[i,i-1] = 1-p\n\n\nP\n\narray([[0. , 0.5, 0. , ..., 0. , 0. , 0. ],\n       [0.5, 0. , 0.5, ..., 0. , 0. , 0. ],\n       [0. , 0.5, 0. , ..., 0. , 0. , 0. ],\n       ...,\n       [0. , 0. , 0. , ..., 0. , 0.5, 0. ],\n       [0. , 0. , 0. , ..., 0.5, 0. , 0.5],\n       [0. , 0. , 0. , ..., 0. , 0.5, 0. ]])\n\n\n\nP@P@P@P@P@P@P@P\n\narray([[0.0546875, 0.       , 0.109375 , ..., 0.       , 0.       ,\n        0.       ],\n       [0.       , 0.1640625, 0.       , ..., 0.       , 0.       ,\n        0.       ],\n       [0.109375 , 0.       , 0.2421875, ..., 0.       , 0.       ,\n        0.       ],\n       ...,\n       [0.       , 0.       , 0.       , ..., 0.2421875, 0.       ,\n        0.109375 ],\n       [0.       , 0.       , 0.       , ..., 0.       , 0.1640625,\n        0.       ],\n       [0.       , 0.       , 0.       , ..., 0.109375 , 0.       ,\n        0.0546875]])\n\n\n\n0.125*0.5*0.5\n\n0.03125\n\n\n\nT=0\n(4*p*(1-p))**T/np.sqrt(np.pi*T)\n\nRuntimeWarning: divide by zero encountered in scalar divide\n  (4*p*(1-p))**T/np.sqrt(np.pi*T)\n\n\ninf\n\n\n\nnp.linalg.matrix_power(P,T)\n\narray([[0.04101562, 0.        , 0.08789062, ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.12890625, 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.08789062, 0.        , 0.20214844, ..., 0.        , 0.        ,\n        0.        ],\n       ...,\n       [0.        , 0.        , 0.        , ..., 0.20214844, 0.        ,\n        0.08789062],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.12890625,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.08789062, 0.        ,\n        0.04101562]])\n\n\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n\\(N(i) = \\sum_{t=0}^{\\infty}1(X_t=i)= {\\sf sum}({\\bf X} == i)\\)\n\n\nPeriod\n\n\n마코프체인 이론들\n- 정의: PRC, AP인 상태를 에르고딕 상태라고 부른다. [@이외숙2008확률과정론(p63)]\n- 정의: IRR, PRC, AP인 마코프체인을 에르고딕 마코프체인이라고 부른다. [@이외숙2008확률과정론(p69)]\n- 이론: 극한분포가 수렴하고 동일한 row \\({\\bf p}_{\\star}^\\top\\)를 가지는 경우는 \\({\\bf p}_{\\star}^\\top {\\bf 1} =0\\) 이거나 \\({\\bf p}_{\\star}^\\top {\\bf 1} =1\\) 인 경우이다. 여기에서 \\({\\bf p}_{\\star}^\\top {\\bf 1} =0\\)인 경우라면 정상분포 \\({\\boldsymbol \\pi}\\)가 존재하지 않는다. 만약에 \\({\\bf p}_{\\star}^\\top {\\bf 1}=1\\) 인 경우라면 정상분포 \\({\\boldsymbol \\pi}\\)가 존재하고 \\({\\bf p}_{\\star}^\\top ={\\boldsymbol \\pi}^\\top\\)라고 쓸 수 있다.1 [@이외숙2008확률과정론(p69)]\n- 이론: IRR, AP 이면 \\({\\bf P}\\)가 수렴하고 동일한 row를 가진다. [@이외숙2008확률과정론(p69)]\n- 이론: IRR, AP 이면 다음의 두 가지 중 하나가 성립한다.\n\nPRC인 마코프체인이 아니다: 모든상태가 transient 하거나 null recurrent 하다.\nPRC인 마코프체인이다: 모든상태가 positive recurrent 하다.\n\n1의 경우라면 \\(\\sum_{i \\in E}\\pi_i=0\\) 이 되어서 정상분포가 존재하지 않는다. 2의 경우라면 유일한 정상분포를 가진다. [@이외숙2008확률과정론(p69)]\n\n만약에 상태공간이 유한인 상황이라면 항상 IRR, AP인 경우는 항상 PRC이다.\n\n- 이론: IRR, AP, PRC \\(\\Rightarrow\\) (1) \\(\\exists! {\\boldsymbol \\pi}\\) (2) \\({\\boldsymbol \\pi}^\\top={\\bf p}_{\\star}^\\top\\) [@이외숙2008확률과정론(p69)]\n- 이론: IRR, AP, \\(\\exists! {\\boldsymbol \\pi}\\) \\(\\Rightarrow\\) (1) PRC (2) \\({\\boldsymbol \\pi}^\\top = {\\bf p}_{\\star}^\\top\\) [@이외숙2008확률과정론(p69),@durrett2012essentials(Thm1.19)]\n\n[@durrett2012essentials(Thm1.19)] 에서는 PRC임은 빠져있긴함.\n\n- 이론: IRR, RC \\(\\Rightarrow\\) \\(\\exists \\tilde{\\boldsymbol \\pi}\\) [@durrett2012essentials(Thm1.19)]\n- 이론: IRR, \\(\\exists {\\boldsymbol \\pi}\\) \\(\\Rightarrow\\) \\(\\exists! {\\boldsymbol \\pi}\\)\n- 이론: IRR, \\(\\exists {\\boldsymbol \\pi}\\) \\(\\Rightarrow\\)\n\\[\\lim_{T\\to \\infty} \\frac{1}{T}\\sum_{t=0}^{T-1}f(X_t) = \\mathbb{E}_{\\boldsymbol \\pi}[f(X_0)]:=\\sum_{x}f(x)\\pi(x)\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaseNO\n대표예제\nFIN\nIRR\nAP\nNature\n\\(\\exists {\\boldsymbol \\pi}^\\top\\)\n\\(\\exists! {\\boldsymbol \\pi}^\\top\\)\n\\(\\exists! {\\bf p}_{\\star}^\\top\\)\nErgodic THM\nErgodic HMC\n\n\n\n\n1\n\nX\nO\nX\nT\nX\nX\nX\nX\nX\n\n\n2\n\nX\nO\nX\nNR\nX\nX\nX\nX\nX\n\n\n3\n\nX\nO\nX\nPR\nO\nO\nX\nX\nX\n\n\n4\n\nX\nO\nO\nT\nX\nX\nO\nX\nX\n\n\n5\n\nX\nO\nO\nNR\nX\nX\nO\nX\nX\n\n\n6\n\nX\nO\nO\nPR\nO\nO\nO\nO\nO\n\n\n\n- IRR, AP, \\(\\exists {\\boldsymbol \\pi}\\) \\(\\Rightarrow\\) \\(p^n(x,y) \\to \\pi(y)\\) [@durrett2012essentials, Thm, @bremaud2020markov]\n- IRR, RC \\(\\Rightarrow\\) \\(\\frac{N_n(y)}{n} \\to \\frac{1}{E_yT_y}\\)\n- IRR, \\(\\exists {\\boldsymbol \\pi}\\), \\(\\sum_x|f(x)|\\pi(x)<\\infty\\) \\(\\Rightarrow\\) \\(\\frac{1}{n}\\sum_{m=1}^{n}f(X_m) \\to \\sum_xf(x)\\pi(x)\\)\n- IRR, FINITE \\(\\Rightarrow\\) 정상분포가 존재하고 유일하다.\n\n\n\n\n\nFootnotes\n\n\n따라서 정상분포는 유일하게 존재한다.↩︎"
  },
  {
    "objectID": "posts/2099-01-01-notes1.html",
    "href": "posts/2099-01-01-notes1.html",
    "title": "연습장1",
    "section": "",
    "text": "메트로폴리스-헤이스팅스\n\n예제1\n다시 \\(B(2.7,6.3)\\)를 추출하는 예제로 돌아오자.\n\n시도1\n- 우선 우리가 관심이 있는 타겟분포를 그려보자.\n\nf<-function(x){\n    alpha=2.7 \n    beta=6.3\n    gamma(alpha+beta)/gamma(alpha)/gamma(beta) * x^(alpha-1)*(1-x)^(beta-1)\n}\n\n\nplot(1:1000/1000,f(1:1000/1000),type='l')\n\n\n\n\n\nX<-rep(0.1,5000)\n\n\nprint(head(X))\n\n[1] 0.1 0.1 0.1 0.1 0.1 0.1\n\n\n- 현재 \\(X\\)의 값은 모두 0.1이다. 그런데 궁극적으로는 \\(X\\)의 값을 모두 \\(Beta(2.7,6.3)\\)에서 생성된 샘플들로 채우고 싶다.\n\nset.seed(1)\nY<-runif(1)\nprint(Y)\n\n[1] 0.2655087\n\n\n\nplot(1:1000/1000,f(1:1000/1000),type='l')\npoints(Y,0,col=2,cex=2,lwd=5)\npoints(X[1],0,col=4,cex=2,lwd=5)\n\n\n\n\n– 빨간점이 \\(Y\\)이고 파란점은 \\(X\\)이다. 두개의 점중에서 어떤것이 \\(f(x)\\)에서 생성되었다고 믿어지는 점일까?\n- 빨간색 점이 더 가능성이 높아보인다. (pdf값이 더 높음)\n- \\(X[2]\\)의 값은 그냥 빨강으로 결정하자.\n\nX[2]<-Y\n\n\nprint(head(X))\n\n[1] 0.1000000 0.2655087 0.1000000 0.1000000 0.1000000 0.1000000\n\n\n- 다시 \\(Y\\)를 하나 뽑자.\n\nset.seed(2)\nY<-runif(1)\nprint(Y)\n\n[1] 0.1848823\n\n\n- 다시 뽑은 \\(Y\\)는 초록색으로 표현하자.\n\nplot(1:1000/1000,f(1:1000/1000),type='l')\npoints(Y,0,col=3,cex=2,lwd=5)\npoints(X[2],0,col=2,cex=2,lwd=5)\n\n\n\n\n– 둘중에 어떤것이 더 \\(Beta(2.7,6.3)\\)에서 추출한 샘플 같은가?\n- 여전히 빨강이 더 \\(Beta(2.7,6.3)\\)의 분포에서 나온것 같다.\n- 그러면 \\(X[3]\\)의 값도 그냥 빨강으로 한다.\n- 지금까지의 결과를 요약하면 아래와 같다.\n\n\n\n\n\n\n\n\n\n\\(t\\)\n\\(X_t\\)\n\\(Y_t\\)\n설명\n\n\n\n\n\\(1\\)\n\\(0.1\\)\n\\(0.2655087\\)\n\\(Y_1\\)이 \\(X_1\\)보다 더 \\(Beta(2.7,6.3)\\)에서 나온 분포같았음 \\(\\to\\) \\(X_2\\)는 \\(Y_1\\)로 선택\n\n\n\\(2\\)\n\\(0.2655087\\)\n\\(0.1848823\\)\n이번에는 \\(X_2\\)가 \\(Y_2\\)보다 더 \\(Beta(2.7,6.3)\\)에서 나온 분포같음 \\(\\to\\) \\(X_3\\)는 \\(X_2\\)로 선택\n\n\n\\(3\\)\n\\(0.2655087\\)\n\\(-\\)\n-\n\n\n\\(\\dots\\)\n\\(\\dots\\)\n\\(\\dots\\)\n\\(\\dots\\)\n\n\n\n– 이걸 무한대로 반복하면 \\(X_t\\)는 결국 \\(Beta(2.7,6.3)\\)에서 뽑혔을법한 샘플들로 점점 채워진다.\n- 따라서 \\(\\{X_1,X_2,X_3,\\dots,X_{5000}\\}\\)을 모아서 히스토그램을 그리면 적당히 \\(Beta(2.7,6.3)\\)에서 추출한 표본이라 주장할 수 있을것 같다.\n- 앞부분은 내가 임의로 값을 주는것에 따라 다르니까 대충 앞에 100개정도는 버리고 \\(\\{X_{101},X_{102},\\dots,X_{5000}\\}\\)를 모아서 히스토그램을 그리면 좀 더 좋은 그림이 나올것 같다.\n\n\n시도2\n- 시도1의 당연한 우려점은 특정시점 이후에는 \\(X_t\\)는 거의 하나의 값만 나올것 같다는 것이다.\n- 즉 우연히 \\(X_t\\)가 pdf의 최고점에서 찍힌다면, 그 이후에는 거의 \\(X_t\\)는 하나의 값만 나올것\n- 당장 위의 예제만 살펴봐도 \\(X_4, X_5,X_6,\\dots\\) 뽑아보았자 당분간은 \\(X_4=X_5=X_6=..=0.2655087\\) 일것 같다.\n- 히스토그램을 그려봤자 다 \\(0.2655087\\)에만 값이 몰려있을 것이다.\n- 더 그럴듯한 샘플을 선택하는 아이디어는 좋은데, 그런식으로 진행하면 결국 반복할수록 pdf의 최고점을 향해 달려가는 꼴밖에 안된다.\n- 다시 아래의 그림을 관찰해보자.\n\nplot(1:1000/1000,f(1:1000/1000),type='l')\npoints(Y,0,col=3,cex=2,lwd=5)\npoints(X[2],0,col=2,cex=2,lwd=5)\n\n\n\n\n- 초록색점보다 빨간색 점이 더 pdf값이 높으므로 빨간색점이 더 \\(Beta(2.7,6.3)\\)에서 나왔음직한 샘플인것은 맞다.\n- 그런데 \\(100\\%\\) 확신할 수 있는가?\n- 빨간색점 0.2655087 에서의 pdf값은 아래와 같다.\n\nf(0.2655087)\n\n2.64480579727479\n\n\n– 반면 초록색점 0.1848823 에서의 pdf값은 아래와 같다.\n\nf(0.1848823)\n\n2.48267809218198\n\n\n– 사실 초록색점도 가능성 있는 점이다. 만약에 어떤사람이 \\(Beta(2.7,6.3)\\)에서 하나의 확률변수를 생성하고 나머지는 \\(U[0,1]\\)에서 생성했다고 치자. 두 결과를 초록색과 빨간색으로 표시되었다고 할때 어떤색이 \\(Beta(2.7,6.3)\\)에서 생성되었냐고 묻는다면 당신은 빨간색을 고를 것이다.\n- 하지만 빨간색에 전재산을 베팅할 수 있는가?\n\nf(0.2655087) / (f(0.2655087)+f(0.1848823))\n\n0.515809674743804\n\n\n- 빨간색에 \\(51.58\\%\\)의 재산만 베팅한다.\n- 즉 빨간색이 \\(Beta(2.7,6.3)\\)에서 왔다고 믿을 확률이 \\(51.58\\%\\)정도라는 의미이다.\n- 제안하는 알고리즘\n\n\\(X_1\\)에 아무값이나 넣는다.\n균등분포에서 \\(Y_1\\)을 뽑는다.\n\\(\\frac{f(Y_1)}{f(X_1)+f(Y_1)}\\)의 확률로 \\(X_2=Y_1\\)을 선택하고 \\(\\frac{f(X_1)}{f(X_1)+f(Y_1)}\\)의 확률로 \\(X_2=X_1\\)을 선택한다.\n(2)-(3)를 반복한다.\n\n- 실행\n\nX<-rep(0.1,5000)\nfor (i in 2:5000){\n    Y<-runif(1)\n    acceptance_prob<-f(Y)/(f(X[i])+f(Y))\n    U_<-runif(1)\n    X[i]<- Y* (U_< acceptance_prob) +X[i-1] * (U_> acceptance_prob)\n}\n\n\nhist(X[100:5000])\n\n\n\n\n\nplot(X[4900:5000])\n\n\n\n\n– 분명히 \\(X_t\\)와 \\(X_{t-1}\\)는 종속되어있다. 그런데 전체 분포를 그려보니까 \\(Beta(2.7,6.3)\\)의 히스토그램 같다.\n- 이 알고리즘이 왜 성립하는가?\n- 그러고 보니까 이 느낌을 어디서 받았다. (에르고딕, 정상성)\n\n\n시도2의 이론적 근거\n- 주장하고 싶은 것은 아래와 같다. - 타겟분포: \\(X_t\\)의 극한분포는 \\(Beta(2.7,6.3)\\)이다. - 에르고드성: \\(X_{\\infty}\\)의 분포인 \\(Beta(2.7,6.3)\\)의 hist는 \\(X_{100} \\sim X_{\\infty}\\)의 샘플(타임샘플?)을 바탕으로 히스토그램을 그려도된다.\n- \\(X_t\\)는 정상분포를 가지고 그 확률밀도함수가 \\(f(x)\\)임을 보이면 된다.\n- 분포 \\(f\\)가 아래의 조건(detailed balance condition)을 만족시키는지를 체크하면 된다.\n\\[f(x_{t+1})P(x_t|x_{t+1})=f(x_t)P(x_{t+1}|x_t) \\quad \\cdots (\\star\\star)\\]\n– \\(x_{t+1}=x_t\\) 이라면 그냥 성립한다.\n- \\(x_{t+1}\\neq x_t\\) 일때 성립하는지 봐야한다. (\\(x_{t+1}=y_t\\))\n– \\(P(x_{t+1}|x_{t})=\\frac{f(x_{t+1})}{f(x_t)+f(x_{t+1})}\\)\n– \\(x_t\\)와 \\(x_{t+1}\\)의 순서를 바꾸면 \\(P(x_t|x_{t+1})=\\frac{f(x_t)}{f(x_{t})+f(x_{t+1})}\\)\n– \\(P(x_{t+1}|x_t)\\)와 \\(P(x_t|x_{t+1})\\)를 detailed balance condition \\((\\star\\star)\\)에 대입하면 등호가 성립함을 쉽게 체크할 수 있다.\n\n\n시도3\n- 매트로폴리스의 제안을 살펴보자.\n- 매트로폴리스는 누구나 생각할 수 있는 \\(P(x_{t+1}|x_t)=\\frac{f(x_t)}{f(x_t)+f(x_{t+1})}\\) 대신에 좀 더 특별한 것을 생각했다.\n- 매트로폴리스: 나는 \\(P(x_{t+1}|x_t)= \\min\\left (1,\\frac{f(x_{t+1})}{f(x_t)} \\right)\\)를 쓰겠다!\n– 왜??\n- 매트로폴리스의 제안을 곰곰히 살펴보니까 \\(f(x_{t+1})>f(x_t)\\) 이라면 100% 확률로 \\(x_t \\to x_{t+1}\\)로의 전환이 일어난다. 새로운제안이 조금이라도 낫다고 생각되면 무조건 이동하고, 새로운 제안이 약간 안좋아도 높은확률로 이동한다.\n- 다시 아래의 그림을 고려하자.\n\nplot(1:1000/1000,f(1:1000/1000),type='l')\npoints(0.1848823,0,col=3,cex=2,lwd=5)\npoints(0.2655087,0,col=2,cex=2,lwd=5)\n\n\n\n\n- 초록색이 새로운 제안이다.\n- 빨간색에 비하여 부족해 보인다.\n\nprint(f(0.2655087)) ## 빨간색\nprint(f(0.1848823)) ## 초록색 \n\n[1] 2.644806\n[1] 2.482678\n\n\n– 그래도 이동한다.\n\nf(0.1848823)/f(0.2655087)\n\n0.938699580415369\n\n\n- 무려 93%의 확률로 이동한다.\n- 매트로폴리스의 알고리즘은 많은 경우 \\(x_t\\neq x_{t+1}\\)이다. 즉 \\(x_t\\)와 \\(x_{t+1}\\)이 조금 덜 연관되어 보인다.\n- 그런데 매트로폴리스의 제안이 과연 detailed balance condition을 만족할까?\n\\[P(x_{t+1}|x_t)f(x_t)=P(x_t|x_{t+1})f(x_{t+1})\\]\n\n\\(P(x_{t+1}|x_t)= \\min\\left (1,\\frac{f(x_{t+1})}{f(x_t)} \\right):=A\\)\n\\(P(x_{t}|x_{t+1})= \\min\\left (1,\\frac{f(x_{t})}{f(x_{t+1})} \\right):=B\\)\n\n– 그럼 detailed balance condition은 아래와 같다.\n\\[Af(x_t)=Bf(x_{t+1})\\]\n– 경우1: \\(f(x_{t+1})>f(x_t)\\) 라고 가정하자.\n그러면 \\(A=1\\), \\(B=\\frac{f(x_t)}{f(x_{t+1})}\\) 이 된다.\n따라서 detailed balance condition이 성립한다.\n- 경우2: \\(f(x_{t+1})< f(x_t)\\) 라고 가정하자.\n그러면 \\(A=\\frac{f(x_{t+1})}{f(x_t)}, B=1\\)이 된다.\n따라서 detailed balance condition이 성립한다.\n- 경우3: \\(f(x_{t+1})=f(x_t)\\) 이면 그냥 성립.\n(초보단계의) 매트로폴리스-헤이스팅스 알고리즘\n- 메트로폴리스의 알고리즘을 요약하면 아래와 같다.\n\n\\(X_1\\)에 아무값이나 넣는다.\n\\(t=2,3,4,\\dots\\)에 대하여 아래를 반복한다.\n\n\n\\(Y_t\\)를 균등분포에서 뽑고\n\\(\\min\\left(1, \\frac{f(y_t)}{f(x_t)}\\right)\\)의 확률로 \\(X_{t+1}=Y_t\\)를 선택하고 그 외의 확률로 \\(X_{t+1}=X_t\\)를 선택한다.\n\n\nX<-rep(0.1,5000)\nfor (i in 2:5000){\n    Y<-runif(1)\n    acceptance_prob<- min(1,f(Y)/f(X[i]))\n    U_ <- runif(1)\n    X[i]<- Y* (U_<acceptance_prob) + X[i-1]*(U_> acceptance_prob)\n}\n\n\nhist(X)\n\n\n\n\n\nplot(X[4900:5000])\n\n\n\n\n\n\n\n시도4\n- \\(Y\\)를 균등분포가 아닌 다른분포에서 뽑아도 가능할 것 같다.\n- 예를들면 \\(Y \\sim Beta(2,6)\\)에서 추출한다고 해보자.\n\ng<-function(x){\n    alpha=2 \n    beta=6\n    gamma(alpha+beta)/gamma(alpha)/gamma(beta) * x^(alpha-1)*(1-x)^(beta-1)\n}\n\n\nplot(0:99/100,f(0:99/100),type='l',col=4,ylim=c(0,3),main=\"파랑:f(x), 빨강:g(x)\")\nlines(0:99/100,g(0:99/100),col=2)\n\n\n\n\n\nset.seed(1)\nY=rbeta(1,shape1=2,shape2=6)\nY\n\n0.151649741588921\n\n\n\nplot(0:99/100,f(0:99/100),type='l',col=4,ylim=c(0,3),main=\"파랑:f(x), 빨강:g(x)\")\nlines(0:99/100,g(0:99/100),col=2)\npoints(Y,0,cex=2); abline(v=Y,lty=2)\n\n\n\n\n참조분포가 균등분포였으면 \\(Y\\)를 타겟분포의 샘플이라고 믿을 수도 있었음.\n그런데 참조분포가 붉은선의 pdf를 가지므로 \\(Y\\)가 타겟분포의 샘플이라 믿기 어려워 졌음.\n수락확률이 수정되어야 한다.\n\n기존의 수락확률: \\(\\min\\left(1,\\frac{f(Y_t)}{f(x_t)}\\right)\\)\n수정된 수락확률: \\(\\min\\left(1,\\frac{f(Y_t)g(x_t)}{f(x_t)g(Y_t)}\\right)\\)\n\n\nX<-rep(0.1,5000)\nfor (i in 2:5000){\n    Y<-rbeta(1,shape1=2,shape2=6)\n    acceptance_prob<-min(1,f(Y)*g(X[i])/f(X[i])/g(Y))\n    U_<- runif(1)\n    X[i]<- Y* (U_<acceptance_prob) + X[i-1]*(U_> acceptance_prob)\n}\n\n\nhist(X)\n\n\n\n\n\nplot(X[4900:5000])\n\n\n\n\n[수정된 알고리즘]\n\n\\(X_1\\)에 아무값이나 넣는다.\n\\(t=2,3,4,\\dots\\)에 대하여 아래를 반복한다.\n\n\n\\(Y_t\\)를 \\(g\\)에서 뽑고\n\\(\\min\\left(1, \\frac{f(Y_t)g(x_t)}{f(x_t)g(Y_t)}\\right)\\)의 확률로 \\(X_{t+1}=Y_t\\)를 선택하고 그 외의 확률로 \\(X_{t+1}=X_t\\)를 선택한다.\n\n\n\n\n깁스샘플링\n- two-stage 깁스샘플러는 joint distribution에서 아래와 같은 과정을 거쳐 마코프체인을 만든다. 두 확률변수 \\(X\\),\\(Y\\)에 대한 결합확률밀도함수, 조건부확률밀도함수를 각각 \\(f(x,y)\\), \\(f_{Y|X}\\), \\(f_{X|Y}\\)와 같이 선언하자.\nTake \\(X_0=x_0\\)\nFor \\(t=1,2,3,\\dots\\) generate 1. \\(Y_t \\sim f_{Y|X}(\\cdot | x_{t-1})\\) 2. \\(X_t \\sim f_{X|Y}(\\cdot | y_t)\\)\n- 깁스샘플링: conditional의 정보를 알고 있음 \\(\\Rightarrow\\) marginal 과 joint를 샘플링\n- 깁스샘플링으로 2변량 정규분포를 뽑는 방법\n- 깁스샘플링을 이용하면 포스테리어를 샘플링 할 수 있다.\n\n\\(\\theta \\sim {\\cal B}eta(a,b)\\)\n\\(X|\\theta \\sim {\\cal B}in(n,\\theta)\\)\n\n조인트는 아래와 같다.\n\n\\(f(x,\\theta) = \\begin{pmatrix} n \\\\ x \\end{pmatrix}\\frac{\\Gamma(a+b)}{\\Gamma(a)+\\Gamma(b)}\\theta^{x+a-1}(1-\\theta)^{n-x+b-1}\\)\n\n이것을 이용하면 아래를 샘플링 할 수 있다.\n\n\\(\\theta |x \\sim {\\cal B}eta(x+a,n-x+b)\\) <- 이 분포를 명시적으로 몰라도 가능함\n\n- 토필모델\n\n예제1\n- 주사위 2개를 던져서 확률변수 \\(X\\)와 \\(Y\\)를 아래와 같이 정의하자.\n\n\\(X\\): 첫번째 주사위를 던졌을때 나오는 숫자. (\\(X=1,2,3,4,5,6\\))\n\\(Y\\): 두 주사위의 합 (\\(Y=2,3,\\dots,12\\))\n\n– \\(X,Y\\)의 확률질량 함수를 구하면 아래와 같다.\n\n\n\n\\(x\\)\n1\n2\n3\n4\n5\n6\n\n\n\n\n\\(p(x)\\)\n1/6\n1/6\n1/6\n1/6\n1/6\n1/6\n\n\n\n\n\n\n\\(y\\)\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n\n\\(p(x)\\)\n1/36\n2/36\n3/36\n4/36\n5/36\n6/36\n5/36\n4/36\n3/36\n2/36\n1/36\n\n\n\n– 확률변수 \\(X\\)와 \\(Y\\)를 만드는법\n\nX=sample(1:6,size=5000,replace=T)\nprint(head(X))\n\n[1] 3 6 2 6 3 3\n\n\n\nY=X+sample(1:6,size=5000,replace=T)\nprint(head(Y))\n\n[1]  6 11  4  8  8  6\n\n\n\nhist(X,1:7,right=F)\n\n\n\n\n\nhist(Y,2:13,right=F)\n\n\n\n\n– \\(Y=y\\)를 알고 있을떄 \\(X\\)를 쉽게 얻을 수 있을까?\n\n\\(P(X|Y=y)=?\\)\n\n\n\n\ny\nx\n\n\n\n\n2\n1\n\n\n3\n1,2\n\n\n4\n1,2,3\n\n\n5\n1,2,3,4\n\n\n6\n1,2,3,4,5\n\n\n7\n1,2,3,4,5,6\n\n\n8\n2,3,4,5,6\n\n\n9\n3,4,5,6\n\n\n10\n4,5,6\n\n\n11\n5,6\n\n\n12\n6\n\n\n\n– 수식으로 요약하면\n\n\\(y\\leq 7\\): \\(x\\)는 \\(1\\sim (y-1)\\)사이의 숫자를 랜덤으로 뽑는다.\n\\(y>7\\): \\(x\\)는 \\((y-6)\\sim 6\\)사이의 숫자를 랜덤으로 뽑는다.\n\n\nfx_giveny<-function(y){\n    if(y==12){\n        x<-6\n    } else if(y>7){\n        x<-sample((y-6):6,size=1)\n    }else{\n        x<-sample(1:(y-1),size=1)\n    }\n    x\n}\n\n- 그렇다면 아래와 같이 샘플링 할 수도 있지 않을까?\n(\\(random \\sim\\) 주사위)\n\n\\(x_1\\)을 뽑는다. \\(x_1=random\\)\n\\(y_1\\)은 \\(x_1\\)을 이용하여 추출한다. 즉 \\(y_1=x_1+random\\)\n\\(x_2\\)는 \\(y_1\\)을 이용하여 추출한다 즉 \\(x_2 \\sim f(x_2|y_1)\\)\n\\(y_2\\)는 다시 \\(x_2\\)를 이용하여 추출한다. 즉 \\(y_2=x_2+random\\)\n\n…\n\nset.seed(3)\nx<-c()\ny<-c()\nx[1]<-sample(1:6,size=1)\ny[1]<-x[1]+sample(1:6,size=1)\n\n\nx[1]\n\n5\n\n\n\ny[1]\n\n7\n\n\n\nx[2]<-fx_giveny(y[1])\ny[2]<-x[2]+sample(1:6,size=1)\n\n\nprint(x)\n\n[1] 5 4\n\n\n\nprint(y)\n\n[1] 7 8\n\n\n\nx[3]<-fx_giveny(y[2])\ny[3]<-x[3]+sample(1:6,size=1)\n\n\nprint(x)\n\n[1] 5 4 3\n\n\n\nprint(y)\n\n[1] 7 8 6\n\n\n\nx[4]<-fx_giveny(y[3])\ny[4]<-x[4]+sample(1:6,size=1)\n\n\nprint(x)\n\n[1] 5 4 3 4\n\n\n\nprint(y)\n\n[1] 7 8 6 6\n\n\n\nset.seed(3)\nx<-c()\ny<-c()\nx[1]<-sample(1:6,size=1)\nfor(i in 1:5000){\n    y[i]<-x[i]+sample(1:6,size=1)\n    x[i+1]<-fx_giveny(y[i])\n}\n\n\nhist(y,2:13,right=F)\n\n\n\n\n\nhist(x,1:7,right=F)\n\n\n\n\n\n\n깁스샘플링이 가능한 이유\n- \\(X\\) 만 따져보자.\ndetailed balance condition은 아래와 같다.\n\\[transition(x_t \\to x_{t+1})f(x_t)=trainsition(x_{t+1} \\to x_t)f(x_{t+1})\\]\n임을 보이면 된다.\n- 우리의 예제의 경우는 아래를 보이면 된다.\n\n\\(transition(1\\to 1 )\\pi(1)= transition (1\\to 1 )\\pi(1)\\)\n\\(transition(1\\to 2 )\\pi(1)= transition (2\\to 1 )\\pi(2)\\)\n…\n\\(transition(1\\to 6 )\\pi(1)= transition (6\\to 1 )\\pi(6)\\)\n…\n\\(transition(6\\to 6 )\\pi(6)= transition (6\\to 6 )\\pi(6)\\)\n\n노가다를 활용하면 성립함을 알 수 있다.\n- \\(\\{Y_t\\}\\)역시 노다가를 활용하여 staionary process임을 확인 할 수 있다.\n- conditional을 이미 알고 있다고 가정하였고, marginal을 시뮬레이션 할 수 있으므로 joint를 시뮬레이션으로 뽑을 수 있다.\n\n\n깁스샘플링 (알고리즘 )\n\n2차원\n- \\(X_0=x_0\\)를 선택\n- \\(t=1,2,\\dots\\) 에 대하여 아래를 반복하면서 샘플링한다. - \\(Y_t \\sim f_{Y|X}(\\cdot|x_{t-1})\\) - \\(X_t \\sim f_{X|Y}(\\cdot|y_t)\\)\n\n\n다차원\n- \\({\\bf x}^{(t)}=(x_1^{(t)},\\dots, x_p^{(t)})\\)가 주어졌을때 아래를 반복 - \\(X_1^{(t+1)} \\sim f_1(x_1| x_{2}^{(t)},\\dots,x_p^{(t)})\\) - \\(X_2^{(t+1)} \\sim f_2(x_2| x_{1}^{(t+1)}, x_{3}^{(t)}, \\dots, x_p^{(t)})\\) - \\(\\dots\\) - \\(X_p^{(t+1)} \\sim f_p(x_p| x_{1}^{(t+1)},\\dots x_{p-1}^{(t+1)})\\)\n느낌: 나 빼고 다른 \\(p-1\\)의 값이 다 뽑혔으면 그걸 바탕으로 나도 1차원 랜덤변수를 만들 수 있음.\n- 첫 시작은 누가?\n\n\n\n\n토픽모델\n\n예제\n\nlibrary(tidyverse)\n\n\ndocuments = rbind(c('손흥민','골'),\n                  c('골','확률'),\n                  c('확률','데이터과학'))\n\n\nrownames(documents)<-c('doc1','doc2','doc3')\ncolnames(documents)<-c('word1','word2')\ndocuments\n\n\n\nA matrix: 3 × 2 of type chr\n\n    word1word2\n\n\n    doc1손흥민골        \n    doc2골    확률      \n    doc3확률  데이터과학\n\n\n\n\n\ndocument_topics=rbind(c(2,1),c(1,2),c(2,1)) ## 내마음대로 초기화 \nrownames(document_topics)<-c('doc1','doc2','doc3')\ncolnames(document_topics)<-c('word1','word2')\n\n\ndocument_topics\n\n\n\nA matrix: 3 × 2 of type dbl\n\n    word1word2\n\n\n    doc121\n    doc212\n    doc321\n\n\n\n\n문서당 토픽비율 - 문서1:[손흥민,골]=[2,1] - 문서2:[골,확률]=[1,2] - 문서3:[확률,데이터과학]=[2,1]\n토픽별로 자주등장하는 단어 - 토픽1: 골,골,데이터과학 –> 축구? - 토픽2: 손흥민,확률,확률 –> 통계?\n목표: document_topics의 값을 그럴듯한 값으로 채우고 싶다. 예를들면 아래처럼\ndocument_topics=rbind(c(1,1),c(1,2),c(2,2))\ndocument_topics=rbind(c(2,2),c(2,1),c(1,1))\n그러니까 \\(3\\times 2\\) 차원의 랜덤변수를 뽑는 문제이다.\n\n문서1: [손흥민, 골]\n- 임의의 초기값을 넣어서 현재상황은 아래와 같다.\n문서당 토픽비율 - 문서1:[손흥민,골]=[2,1] - 문서2:[골,확률]=[1,2] - 문서3:[확률,데이터과학]=[2,1]\n토픽별로 자주등장하는 단어 - 토픽1: 골,골,데이터과학 –> 축구? - 토픽2: 손흥민,확률,확률 –> 통계?\n- 지금 우리의 관심은 문서1 손흥민 해당하는 토픽으로 토픽=1이라 생각하는 것이 그럴듯한지, 토픽=2라고 생각하는게 그럴듯한지 다시 따져보고 싶다.\n- 깁스샘플링: 현재 관심이 있는 문서1의 첫단어 손흥민에 대한 토픽분류를 제외하고 나머지는 모두 올바른 값이라고 가정하자.\n문서당 토픽비율 - 문서1:[손흥민,골]=[2,1] ==> [?,1] - 문서2:[골,확률]=[1,2] ==> [1,2] - 문서3:[확률,데이터과학]=[2,1] ==> [2,1]\n토픽별로 자주등장하는 단어 - 토픽1: 골,골,데이터과학 ==> 골,골,데이터과학 - 토픽2: 손흥민,확률,확률 ==> ?, 확률, 확률\n- 손흥민이라는 단어가 뽑힐 경우는 아래의 두 경우중 하나이다. - 토픽1에서 뽑혔을 경우 - 토픽2에서 뽑혔을 경우\n- 토픽1에서 뽑혔을 경우는 아래와 같이 계산 할 수 있다. - (문서1에 토픽1이 포함되어 있는 비율) \\(\\times\\) (토픽1에서 손흥민이라는 단어를 뽑을 확률) = 1 \\(\\times\\) 0.001 - p(토픽1|문서1) \\(\\times\\) p(손흥민|토픽1) = 1 \\(\\times\\) 0.001\n- 토픽2에서 뽑혔을 경우는 아래와 같이 계산 할 수 있다. - (문서1에 토픽2이 포함되어 있는 비율) \\(\\times\\) (토픽2에서 손흥민이라는 단어를 뽑을 확률) = 0.001 \\(\\times\\) 0.001 - p(토픽2|문서1) \\(\\times\\) p(손흥민|토픽2) = 0.001 \\(\\times\\) 0.001\n- 손흥민은 토픽1에서 뽑혔다고 보는게 타당함. (왜? 현재단어 손흥민 문서1에 있고, 문서1은 토픽1이 대부분이니까!)\n- 아래와 같이 업데이트 한다.\n문서당 토픽비율 - 문서1:[손흥민,골]=[1,1] - 문서2:[골,확률]=[1,2] - 문서3:[확률,데이터과학]=[2,1]\n토픽별로 자주등장하는 단어 - 토픽1: 손흥민,골,골,데이터과학 - 토픽2: 확률,확률\n문서2: [손흥민, 골]\n- 업데이트 전\n문서당 토픽비율 - 문서1:[손흥민,골]=[1,1] ==> [1,?] - 문서2:[골,확률]=[1,2] ==> [1,2] - 문서3:[확률,데이터과학]=[2,1] ==> [2,1]\n토픽별로 자주등장하는 단어 - 토픽1: 손흥민,?,골,데이터과학 - 토픽2: 확률,확률\n- 샘플링\n\np(토픽1|문서1) \\(\\times\\) p(골|토픽1) = 1 \\(\\times\\) 1/3\n\np(토픽2|문서1) \\(\\times\\) p(골|토픽2) = 0.001 \\(\\times\\) 0.001\n\n결정: 토픽1을 선택 (왜? 현재단어는 문서1에 있는데, 문서1에는 토픽1이 대부분이다, 그리고 현재 단어는 골인데, 골이라는 단어는 토픽1에서 잘나온다.)\n- 업데이트 후 (그대로 유지)\n문서당 토픽비율 - 문서1:[손흥민,골]=[1,1]\n- 문서2:[골,확률]=[1,2] - 문서3:[확률,데이터과학]=[2,1]\n토픽별로 자주등장하는 단어 - 토픽1: 손흥민,골,골,데이터과학 - 토픽2: 확률,확률\n\n- 이런식으로 반복하면 결국 각 단어는 자신의 정체성(토픽1인지 토픽2인지)를 아래와 같은 2가지 기준으로 판단한다. - 나(=단어)는 \\(d\\)-th document에 속해있다. \\(\\to\\) 그런데 이 document의 단어를 쭉 살펴보니 토픽 \\(k\\)가 많다. \\(\\to\\) 나도 토픽 \\(k\\)인가?\n- 나(=단어)와 똑같은 이름을 가진 단어들이 토픽 \\(k'\\)에 많다. \\(\\to\\) 나도 토픽 \\(k'\\)에서 왔을까?\n- 재미있는 점은 각 단어의 선택이 다른 단어에도 영향을 준다는 것이다. (다들 나 빼고는 맞다고 가정하고 있으니까 )\n\n- 구현해보자.\n\ndoclen <- 5 \nword<-c('손흥민','골','골','박지성','패스',\n        '골','확률','패스','손흥민','골',\n        '골','골','확률','패스','골',\n        '골','박지성','통계','확률','골',\n        '확률','통계','박지성','통계','골',\n        '확률','확률','골','통계','AI',\n        '확률','확률','통계','통계','AI',\n        '확률','빅데이터','데이터과학','빅데이터','AI',\n        '확률','데이터과학','AI','데이터과학','데이터과학')\ndoc<-c(rep(1,doclen),rep(2,doclen),rep(3,doclen),\n      rep(4,doclen),rep(5,doclen),rep(6,doclen),\n      rep(7,doclen),rep(8,doclen),rep(9,doclen))\n\ntopic<-c(2,1,1,2,2,\n         1,2,1,2,2,\n         1,2,1,2,2,\n         1,2,1,2,2,\n         1,2,1,2,2,\n         1,2,2,2,2,\n         1,2,1,1,2,\n         1,2,1,1,2,\n         2,1,1,2,2)\ndata<-tibble(word=word,doc=doc,topic=topic)\ndata\n\n\n\nA tibble: 45 × 3\n\n    worddoctopic\n    <chr><dbl><dbl>\n\n\n    손흥민    12\n    골        11\n    골        11\n    박지성    12\n    패스      12\n    골        21\n    확률      22\n    패스      21\n    손흥민    22\n    골        22\n    골        31\n    골        32\n    확률      31\n    패스      32\n    골        32\n    골        41\n    박지성    42\n    통계      41\n    확률      42\n    골        42\n    확률      51\n    통계      52\n    박지성    51\n    통계      52\n    골        52\n    확률      61\n    확률      62\n    골        62\n    통계      62\n    AI        62\n    확률      71\n    확률      72\n    통계      71\n    통계      71\n    AI        72\n    확률      81\n    빅데이터  82\n    데이터과학81\n    빅데이터  81\n    AI        82\n    확률      92\n    데이터과학91\n    AI        91\n    데이터과학92\n    데이터과학92\n\n\n\n\n\ntopic_doc<-function(data,k,d,alpha=0.1){ #k: 토픽의 인덱스, d:doc의 인덱스\n    count_ = dim(filter(data,doc==d,topic==k))[1] + alpha \n    total_ = dim(filter(data,doc==d))[1] + alpha * K # K는 전체 토픽의 수 \n    count_ / total_ \n} \n\n\nword_topic<-function(data,w,k,alpha=0.1){ #k: 토픽의 인덱스, w: word의 인덱스 \n    word_ = filter(data,doc==d)$word[w]\n    count_ = dim(filter(data, topic==k,word==word_))[1] + alpha\n    total_ = dim(filter(data, topic==k))[1] + alpha * W  # W=length(unique(data$word))\n    count_ / total_ \n}\n\n\ntopicprob<-function(data,d,w){\n    rtn<-c()\n    for(k in 1:K){\n        rtn[k]=topic_doc(data,k,d)* word_topic(data,w,k)\n    } \n    rtn/sum(rtn)\n}\n\n\nD<-max(data$doc) # 다큐먼트의 수 \nK<-2 # 토픽의수 \nW<-length(unique(data$word))\nfor(t in 1:2){\n    for(d in 1:D){\n    for(w in 1:doclen){\n    i=(d-1)*doclen+w \n    data[i,]$topic<-(topicprob(data[-i,],d,w)[2] > runif(1)) + 1\n    }\n}\n}\ndata\n\n\n\nA tibble: 45 × 3\n\n    worddoctopic\n    <chr><dbl><dbl>\n\n\n    손흥민    11\n    골        11\n    골        11\n    박지성    11\n    패스      11\n    골        22\n    확률      21\n    패스      21\n    손흥민    21\n    골        21\n    골        31\n    골        31\n    확률      31\n    패스      31\n    골        31\n    골        41\n    박지성    41\n    통계      41\n    확률      41\n    골        41\n    확률      52\n    통계      52\n    박지성    52\n    통계      52\n    골        52\n    확률      62\n    확률      62\n    골        62\n    통계      62\n    AI        62\n    확률      72\n    확률      72\n    통계      72\n    통계      72\n    AI        72\n    확률      82\n    빅데이터  82\n    데이터과학82\n    빅데이터  82\n    AI        82\n    확률      92\n    데이터과학92\n    AI        92\n    데이터과학92\n    데이터과학92"
  },
  {
    "objectID": "posts/2_Studies/CGSP/2023-01-15-Chap-12.4.html",
    "href": "posts/2_Studies/CGSP/2023-01-15-Chap-12.4.html",
    "title": "[CGSP] Chap 12.4: Node Subsampling for PSD Estimation",
    "section": "",
    "text": "using LinearAlgebra, Plots, FFTW, Statistics\n\n\ncolumnwise_kron = \n(C,D) -> hcat([kron(C[:,i],D[:,i]) for i in 1:size(C)[2]]...)\n\n#49 (generic function with 1 method)\n\n\n\n12.4.1 The Sampling Problem\n아래와 같이 길이가 \\(N=10\\) 인 신호 \\({\\bf x}\\)를 고려하자.\n\nx = rand(10)\n\n10-element Vector{Float64}:\n 0.03235208758206609\n 0.5069925854414447\n 0.5795228508497553\n 0.682832351742401\n 0.64422613488741\n 0.24116013388795854\n 0.8439116925218157\n 0.6362602319916778\n 0.386069828675059\n 0.5313655894235898\n\n\n여기에서 1,3,4,5 번째 원소만 추출하여길이가 \\(K=4\\) 인 신호 \\({\\bf y}\\)를 만들고 싶다.\n\ny = x[[1,3,4,5]]\n\n4-element Vector{Float64}:\n 0.03235208758206609\n 0.5795228508497553\n 0.682832351742401\n 0.64422613488741\n\n\n이 과정은 아래와 같이 수행할 수도 있다.\n\nΦ= [1 0 0 0 0 0 0 0 0 0\n    0 0 1 0 0 0 0 0 0 0\n    0 0 0 1 0 0 0 0 0 0\n    0 0 0 0 1 0 0 0 0 0]\n\n4×10 Matrix{Int64}:\n 1  0  0  0  0  0  0  0  0  0\n 0  0  1  0  0  0  0  0  0  0\n 0  0  0  1  0  0  0  0  0  0\n 0  0  0  0  1  0  0  0  0  0\n\n\n\nΦ*x\n\n4-element Vector{Float64}:\n 0.03235208758206609\n 0.5795228508497553\n 0.682832351742401\n 0.64422613488741\n\n\n즉 적당한 \\(K\\times N\\) selection matrix를 선언하여 subsampling을 수행할 수 있다. 이때 매트릭스 \\({\\bf \\Phi}\\)를 subsampling matrix 혹은 sparse sampling matrix 라고 부른다.\n\n\n12.4.2 Compressed LS Estimator\n\nN = 10\nV = [i*j for i in 0:(N-1) for j in 0:(N-1)] |> \n    x -> reshape(x,(N,N)) .|> \n    x -> exp(im * (2π/N) * x) \n\n10×10 Matrix{ComplexF64}:\n 1.0+0.0im        1.0+0.0im          …        1.0+0.0im\n 1.0+0.0im   0.809017+0.587785im         0.809017-0.587785im\n 1.0+0.0im   0.309017+0.951057im         0.309017-0.951057im\n 1.0+0.0im  -0.309017+0.951057im        -0.309017-0.951057im\n 1.0+0.0im  -0.809017+0.587785im        -0.809017-0.587785im\n 1.0+0.0im       -1.0+1.22465e-16im  …       -1.0+1.10218e-15im\n 1.0+0.0im  -0.809017-0.587785im        -0.809017+0.587785im\n 1.0+0.0im  -0.309017-0.951057im        -0.309017+0.951057im\n 1.0+0.0im   0.309017-0.951057im         0.309017+0.951057im\n 1.0+0.0im   0.809017-0.587785im         0.809017+0.587785im\n\n\n\nG = columnwise_kron(conj(V),V)\n\n100×10 Matrix{ComplexF64}:\n 1.0+0.0im        1.0+0.0im          …        1.0+0.0im\n 1.0+0.0im   0.809017+0.587785im         0.809017-0.587785im\n 1.0+0.0im   0.309017+0.951057im         0.309017-0.951057im\n 1.0+0.0im  -0.309017+0.951057im        -0.309017-0.951057im\n 1.0+0.0im  -0.809017+0.587785im        -0.809017-0.587785im\n 1.0+0.0im       -1.0+1.22465e-16im  …       -1.0+1.10218e-15im\n 1.0+0.0im  -0.809017-0.587785im        -0.809017+0.587785im\n 1.0+0.0im  -0.309017-0.951057im        -0.309017+0.951057im\n 1.0+0.0im   0.309017-0.951057im         0.309017+0.951057im\n 1.0+0.0im   0.809017-0.587785im         0.809017+0.587785im\n 1.0+0.0im   0.809017-0.587785im     …   0.809017+0.587785im\n 1.0+0.0im        1.0+0.0im                   1.0+0.0im\n 1.0+0.0im   0.809017+0.587785im         0.809017-0.587785im\n    ⋮                                ⋱  \n 1.0+0.0im        1.0+0.0im                   1.0+0.0im\n 1.0+0.0im   0.809017+0.587785im         0.809017-0.587785im\n 1.0+0.0im   0.809017+0.587785im     …   0.809017-0.587785im\n 1.0+0.0im   0.309017+0.951057im         0.309017-0.951057im\n 1.0+0.0im  -0.309017+0.951057im        -0.309017-0.951057im\n 1.0+0.0im  -0.809017+0.587785im        -0.809017-0.587785im\n 1.0+0.0im       -1.0-1.11022e-16im          -1.0+2.27596e-15im\n 1.0+0.0im  -0.809017-0.587785im     …  -0.809017+0.587785im\n 1.0+0.0im  -0.309017-0.951057im        -0.309017+0.951057im\n 1.0+0.0im   0.309017-0.951057im         0.309017+0.951057im\n 1.0+0.0im   0.809017-0.587785im         0.809017+0.587785im\n 1.0+0.0im        1.0+0.0im                   1.0+0.0im\n\n\n- 방법1\n\nĉx = vec(x*x')\np̂ = inv(G' * G) * G' * ĉx\n\n10-element Vector{ComplexF64}:\n    0.25854107856772546 + 2.245922875954761e-20im\n   0.004743491121735806 - 1.3138893409553828e-18im\n   0.006946482731189413 - 9.791191432641327e-19im\n   0.001721693617954179 - 1.9827974128203887e-18im\n   0.011344167525098774 + 2.6827005818057562e-19im\n 0.00012662617844242917 - 3.748573865136995e-20im\n   0.011344167525098762 + 2.7448152053954017e-18im\n  0.0017216936179541913 - 9.35534609073096e-19im\n   0.006946482731189404 + 1.954408900185458e-18im\n   0.004743491121735756 - 2.561030398375897e-18im\n\n\n- 방법2\n\nĉy = vec(y*y')\np̂ = (kron(Φ,Φ)*G)' * ĉy\n\n10-element Vector{ComplexF64}:\n   3.759462826821233 + 0.0im\n   2.765185174577697 - 2.0816681711721685e-17im\n   1.077337414764992 + 2.7755575615628914e-17im\n 0.11594812606807317 + 2.0816681711721685e-17im\n 0.08838298603932843 + 3.903127820947816e-17im\n 0.32863702713833354 + 4.622231866529366e-33im\n 0.08838298603932859 + 9.540979117872439e-18im\n  0.1159481260680729 - 2.0816681711721685e-17im\n  1.0773374147649915 + 0.0im\n  2.7651851745776965 - 2.0816681711721685e-17im"
  },
  {
    "objectID": "posts/2_Studies/PyTorchLightning/2022-11-29-Lesson1.html",
    "href": "posts/2_Studies/PyTorchLightning/2022-11-29-Lesson1.html",
    "title": "[PL] Lesson1: 단순선형회귀",
    "section": "",
    "text": "import torch\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport pytorch_lightning as pl \n\n\nref\nref: https://guebin.github.io/DL2022/posts/II.%20DNN/2022-09-20-3wk-2.html\n\n\nRegression 1: CPU\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2022/main/posts/II.%20DNN/2022-09-22-regression.csv\")\n\n\nx= torch.tensor(df.x).reshape(-1,1).float()\ny= torch.tensor(df.y).reshape(-1,1).float()\n\n\nds = torch.utils.data.TensorDataset(x,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=100)\n\n\nclass NetLO(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.linr = torch.nn.Linear(1,1)\n        self.loss_fn = torch.nn.MSELoss()\n    def forward(self,x):\n        yhat = self.linr(x)\n        return yhat\n    def configure_optimizers(self):\n        optimizr = torch.optim.SGD(self.parameters(), lr=0.1)\n        return optimizr \n    def training_step(self,batch,batch_idx):\n        x,y = batch\n        yhat = self(x)\n        loss = self.loss_fn(yhat,y) \n        return loss \n\n\nnet = NetLO()\n\n\ntrnr = pl.Trainer(max_epochs=1)\n\nGPU available: True (cuda), used: False\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1767: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n  category=PossibleUserWarning,\n\n\n\nnet.linr.bias.data = torch.tensor([-5.0])\nnet.linr.weight.data = torch.tensor([[10.0]])\n\n\ntrnr.fit(net, train_dataloaders=dl) \n\n\n  | Name    | Type    | Params\n------------------------------------\n0 | linr    | Linear  | 2     \n1 | loss_fn | MSELoss | 0     \n------------------------------------\n2         Trainable params\n0         Non-trainable params\n2         Total params\n0.000     Total estimated model params size (MB)\n\n\n\n\n\n`Trainer.fit` stopped: `max_epochs=1` reached.\n\n\n\nnet.linr.weight, net.linr.bias\n\n(Parameter containing:\n tensor([[8.8111]], requires_grad=True),\n Parameter containing:\n tensor([-3.6577], requires_grad=True))\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\nRegression 2: GPU\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2022/main/posts/II.%20DNN/2022-09-22-regression.csv\")\n\n\nx= torch.tensor(df.x).reshape(-1,1).float()\ny= torch.tensor(df.y).reshape(-1,1).float()\n\n\nds = torch.utils.data.TensorDataset(x,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=100)\n\n\nclass NetLO(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.linr = torch.nn.Linear(1,1)\n        self.loss_fn = torch.nn.MSELoss()\n    def forward(self,x):\n        yhat = self.linr(x)\n        return yhat\n    def configure_optimizers(self):\n        optimizr = torch.optim.SGD(self.parameters(), lr=0.1)\n        return optimizr \n    def training_step(self,batch,batch_idx):\n        x,y = batch\n        yhat = self(x)\n        loss = self.loss_fn(yhat,y) \n        return loss \n\n\nnet = NetLO()\n\n\ntrnr = pl.Trainer(max_epochs=1, accelerator='gpu', devices=1)\n\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\n\n\n\nnet.linr.bias.data = torch.tensor([-5.0])\nnet.linr.weight.data = torch.tensor([[10.0]])\n\n\ntrnr.fit(net, train_dataloaders=dl) \n\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n  | Name    | Type    | Params\n------------------------------------\n0 | linr    | Linear  | 2     \n1 | loss_fn | MSELoss | 0     \n------------------------------------\n2         Trainable params\n0         Non-trainable params\n2         Total params\n0.000     Total estimated model params size (MB)\n\n\n\n\n\n`Trainer.fit` stopped: `max_epochs=1` reached.\n\n\n\nnet.linr.weight, net.linr.bias\n\n(Parameter containing:\n tensor([[8.8111]], requires_grad=True),\n Parameter containing:\n tensor([-3.6577], requires_grad=True))\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter02/01_embedding_examples.html",
    "href": "posts/2_Studies/GML/Chapter02/01_embedding_examples.html",
    "title": "[GML] Chap2: 그래프 머신러닝 - Node2Vec, Edge2Vec, Graph2Vec",
    "section": "",
    "text": "import matplotlib.pyplot as plt\ndef draw_graph(G, pos_nodes, node_names={}, node_size=50, plot_weight=False):\n    nx.draw(G, pos_nodes, with_labels=False, node_size=node_size, edge_color='gray', arrowsize=30)\n    \n    pos_attrs = {}\n    for node, coords in pos_nodes.items():\n        pos_attrs[node] = (coords[0], coords[1] + 0.08)\n        \n    nx.draw_networkx_labels(G, pos_attrs, font_family='serif', font_size=20)\n    \n    \n    if plot_weight:\n        pos_attrs = {}\n        for node, coords in pos_nodes.items():\n            pos_attrs[node] = (coords[0], coords[1] + 0.08)\n        \n        nx.draw_networkx_labels(G, pos_attrs, font_family='serif', font_size=20)\n        edge_labels=dict([((a,b,),d[\"weight\"]) for a,b,d in G.edges(data=True)])\n        nx.draw_networkx_edge_labels(G, pos_nodes, edge_labels=edge_labels)\n    \n    plt.axis('off')\n    axis = plt.gca()\n    axis.set_xlim([1.2*x for x in axis.get_xlim()])\n    axis.set_ylim([1.2*y for y in axis.get_ylim()])"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter02/01_embedding_examples.html#node2vec-example",
    "href": "posts/2_Studies/GML/Chapter02/01_embedding_examples.html#node2vec-example",
    "title": "[GML] Chap2: 그래프 머신러닝 - Node2Vec, Edge2Vec, Graph2Vec",
    "section": "Node2Vec example",
    "text": "Node2Vec example\n\nimport networkx as nx\nfrom node2vec import Node2Vec\n\nG = nx.barbell_graph(m1=7, m2=4)\ndraw_graph(G, nx.spring_layout(G))\n\nnode2vec = Node2Vec(G, dimensions=2)\nmodel = node2vec.fit(window=10)\n\nComputing transition probabilities: 100%|██████████| 18/18 [00:00<00:00, 1941.31it/s]\nGenerating walks (CPU: 1): 100%|██████████| 10/10 [00:00<00:00, 13.25it/s]\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(10,10))\n\nfor x in G.nodes():\n    \n    v = model.wv.get_vector(str(x))\n    ax.scatter(v[0],v[1], s=1000)\n    ax.annotate(str(x), (v[0],v[1]), fontsize=12)"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter02/01_embedding_examples.html#edge2vec-example",
    "href": "posts/2_Studies/GML/Chapter02/01_embedding_examples.html#edge2vec-example",
    "title": "[GML] Chap2: 그래프 머신러닝 - Node2Vec, Edge2Vec, Graph2Vec",
    "section": "Edge2Vec example",
    "text": "Edge2Vec example\n\nfrom node2vec.edges import HadamardEmbedder\nedges_embs = HadamardEmbedder(keyed_vectors=model.wv)\n\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(10,10))\n\nfor x in G.edges():\n    \n    v = edges_embs[(str(x[0]), str(x[1]))]\n    ax.scatter(v[0],v[1], s=1000)\n    ax.annotate(str(x), (v[0],v[1]), fontsize=16)"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter02/01_embedding_examples.html#graph2vec-example",
    "href": "posts/2_Studies/GML/Chapter02/01_embedding_examples.html#graph2vec-example",
    "title": "[GML] Chap2: 그래프 머신러닝 - Node2Vec, Edge2Vec, Graph2Vec",
    "section": "Graph2Vec Example",
    "text": "Graph2Vec Example\n\nimport random\nimport matplotlib.pyplot as plt\nfrom karateclub import Graph2Vec\n\nn_graphs = 20\n\ndef generate_radom():\n    n = random.randint(6, 20)\n    k = random.randint(5, n)\n    p = random.uniform(0, 1)\n    return nx.watts_strogatz_graph(n,k,p), [n,k,p]\n\nGs = [generate_radom() for x in range(n_graphs)]\n\nmodel = Graph2Vec(dimensions=2, wl_iterations=10)\nmodel.fit([x[0] for x in Gs])\nembeddings = model.get_embedding()\n\nfig, ax = plt.subplots(figsize=(10,10))\n\nfor i,vec in enumerate(embeddings):\n    \n    ax.scatter(vec[0],vec[1], s=1000)\n    ax.annotate(str(i), (vec[0],vec[1]), fontsize=40)"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter08/01_Credit_card_edges_classification.html",
    "href": "posts/2_Studies/GML/Chapter08/01_Credit_card_edges_classification.html",
    "title": "[GML] Chap8: 신용카드 거래에 대한 그래프 분석",
    "section": "",
    "text": "import os\nimport math\nimport numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndefault_edge_color = 'gray'\ndefault_node_color = '#407cc9'\nenhanced_node_color = '#f5b042'\nenhanced_edge_color = '#cc2f04'\n\n\n\n\nimport pandas as pd\ndf = pd.read_csv(\"/Users/claudiostamile/Downloads/fraudTrain.csv\")\ndf = df[df[\"is_fraud\"]==0].sample(frac=0.20, random_state=42).append(df[df[\"is_fraud\"] == 1])\ndf\n\n\ndf[\"is_fraud\"].value_counts()\n\n\ndef build_graph_bipartite(df_input, graph_type=nx.Graph()):\n    df = df_input.copy()\n    mapping = {x:node_id for node_id,x in enumerate(set(df[\"cc_num\"].values.tolist() + df[\"merchant\"].values.tolist()))}\n    df[\"from\"] = df[\"cc_num\"].apply(lambda x: mapping[x])\n    df[\"to\"] = df[\"merchant\"].apply(lambda x: mapping[x])\n    df = df[['from', 'to', \"amt\", \"is_fraud\"]].groupby(['from', 'to']).agg({\"is_fraud\": \"sum\", \"amt\": \"sum\"}).reset_index()\n    df[\"is_fraud\"] = df[\"is_fraud\"].apply(lambda x: 1 if x>0 else 0)\n    \n    G = nx.from_edgelist(df[[\"from\", \"to\"]].values, create_using=graph_type)\n    \n    nx.set_node_attributes(G,{x:1 for x in df[\"from\"].unique()}, \"bipartite\")\n    nx.set_node_attributes(G,{x:2 for x in df[\"to\"].unique()}, \"bipartite\")\n    \n    nx.set_edge_attributes(G, \n                       {(int(x[\"from\"]), int(x[\"to\"])):x[\"is_fraud\"] for idx, x in df[[\"from\",\"to\",\"is_fraud\"]].iterrows()}, \n                       \"label\")\n\n    nx.set_edge_attributes(G, \n                       {(int(x[\"from\"]), int(x[\"to\"])):x[\"amt\"] for idx, x in df[[\"from\",\"to\",\"amt\"]].iterrows()}, \n                       \"weight\")\n    return G\n\n\ndef build_graph_tripartite(df_input, graph_type=nx.Graph()):\n    df = df_input.copy()\n    mapping = {x:node_id for node_id,x in enumerate(set(df.index.values.tolist() + \n                                                        df[\"cc_num\"].values.tolist() + \n                                                        df[\"merchant\"].values.tolist()))}\n    df[\"in_node\"] = df[\"cc_num\"].apply(lambda x: mapping[x])\n    df[\"out_node\"] = df[\"merchant\"].apply(lambda x: mapping[x])\n\n    G = nx.from_edgelist([(x[\"in_node\"], mapping[idx]) for idx, x in df.iterrows()] +\n                         [(x[\"out_node\"], mapping[idx]) for idx, x in df.iterrows()], \n                         create_using=graph_type)\n\n    nx.set_node_attributes(G,{x[\"in_node\"]:1 for idx,x in df.iterrows()}, \"bipartite\")\n    nx.set_node_attributes(G,{x[\"out_node\"]:2 for idx,x in df.iterrows()}, \"bipartite\")\n    nx.set_node_attributes(G,{mapping[idx]:3 for idx, x in df.iterrows()}, \"bipartite\")\n\n    nx.set_edge_attributes(G,{(x[\"in_node\"], mapping[idx]):x[\"is_fraud\"] for idx, x in df.iterrows()}, \"label\")\n    nx.set_edge_attributes(G,{(x[\"out_node\"], mapping[idx]):x[\"is_fraud\"] for idx, x in df.iterrows()}, \"label\")\n\n    nx.set_edge_attributes(G,{(x[\"in_node\"], mapping[idx]):x[\"amt\"] for idx, x in df.iterrows()}, \"weight\")\n    nx.set_edge_attributes(G,{(x[\"out_node\"], mapping[idx]):x[\"amt\"] for idx, x in df.iterrows()}, \"weight\")\n    return G\n\n\nG = build_graph_bipartite(df, nx.Graph())\n\n\nfrom networkx.algorithms import bipartite\nbipartite.is_bipartite(G)\n\n\nplt.figure(figsize=(10,10))\ntop = nx.bipartite.sets(G)[0]\npos = nx.bipartite_layout(G, top)\nnx.draw(G, pos=pos, with_labels=False, node_color=default_node_color, edge_color=default_edge_color)\nplt.show()\n\n\nplt.axis(\"off\")\nplt.figure(figsize=(10,10))\n\nnx.draw_networkx(G, pos=spring_pos, node_color=default_node_color, \n                 edges_color=default_edge_color, with_labels=False, node_size=15)\n\n\n\n\n\nprint(nx.info(G))\n\n\nplt.figure(figsize=(10,10))\ndegrees = pd.Series({k: v for k, v in nx.degree(G)})\ndegrees.plot.hist()\nplt.yscale(\"log\")\n\n\nallEdgesWeights = pd.Series({(d[0], d[1]): d[2][\"weight\"] for d in G.edges(data=True)})\nnp.quantile(allEdgesWeights.values,[0.10,0.50,0.70,0.9,1.0])\n\n\nquant_dist = np.quantile(allEdgesWeights.values,[0.10,0.50,0.70,0.9])\nquant_dist\n\n\nallEdgesWeightsFiltered = pd.Series({(d[0], d[1]): d[2][\"weight\"] for d in G.edges(data=True) \n                                     if d[2][\"weight\"] < quant_dist[-1]})\n\n\nplt.figure(figsize=(10,10))\nallEdgesWeightsFiltered.plot.hist(bins=40)\nplt.yscale(\"log\")\n\n\nplt.figure(figsize=(10,10))\nbC = nx.betweenness_centrality(G)\nbc_distr = pd.Series(bC)\nbc_distr.plot.hist()\nplt.yscale(\"log\")\n\n\nnp.mean(list(bC.values()))\n\n\n# degree centrality\nplt.figure(figsize=(10,10))\ndeg_C = nx.degree_centrality(G)\ndegc_distr = pd.Series(deg_C)\ndegc_distr.plot.hist()\n\n\n# closeness centrality\nplt.figure(figsize=(10,10))\nclos_C = nx.closeness_centrality(G)\nclosc_distr = pd.Series(clos_C)\nclosc_distr.plot.hist()\n\n\nnp.mean(list(clos_C.values()))\n\n\n# assortativity\nnx.degree_pearson_correlation_coefficient(G)\n\n\n\n\nimport community\n\nparts = community.best_partition(G, random_state=42, weight='weight')\n\n\ncommunities = pd.Series(parts)\ncommunities.value_counts().sort_values(ascending=False)\n\n\ngraphs = []\nd = {}\nfor x in communities.unique():\n    tmp = nx.subgraph(G, communities[communities==x].index)\n    fraud_edges = sum(nx.get_edge_attributes(tmp, \"label\").values())\n    ratio = 0 if fraud_edges == 0 else (fraud_edges/tmp.number_of_edges())*100\n    d[x] = ratio\n    graphs += [tmp]\n\npd.Series(d).sort_values(ascending=False)\n\n\ngId = 10\nplt.figure(figsize=(10,10))\nspring_pos = nx.spring_layout(graphs[gId])\nplt.axis(\"off\")\nedge_colors = [\"r\" if x == 1 else \"g\" for x in nx.get_edge_attributes(graphs[gId], 'label').values()]\nnx.draw_networkx(graphs[gId], pos=spring_pos, node_color=default_node_color, \n                 edge_color=edge_colors, with_labels=False, node_size=15)\n\n\n\n\n\n\nfrom sklearn.utils import resample\n\ndf_majority = df[df.is_fraud==0]\ndf_minority = df[df.is_fraud==1]\n\ndf_maj_dowsampled = resample(df_majority,\n                             n_samples=len(df_minority),\n                             random_state=42)\n\ndf_downsampled = pd.concat([df_minority, df_maj_dowsampled])\n\nprint(df_downsampled.is_fraud.value_counts())\nG_down = build_graph_bipartite(df_downsampled)\n\n\nfrom sklearn.model_selection import train_test_split\n\n\ntrain_edges, test_edges, train_labels, test_labels = train_test_split(list(range(len(G_down.edges))), \n                                                                      list(nx.get_edge_attributes(G_down, \"label\").values()), \n                                                                      test_size=0.20, \n                                                                      random_state=42)\n\n\nedgs = list(G_down.edges)\ntrain_graph = G_down.edge_subgraph([edgs[x] for x in train_edges]).copy()\ntrain_graph.add_nodes_from(list(set(G_down.nodes) - set(train_graph.nodes)))\n\n\nfrom node2vec import Node2Vec\nfrom node2vec.edges import HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder\n\nnode2vec_train = Node2Vec(train_graph, weight_key='weight')\nmodel_train = node2vec_train.fit(window=10)\n\n\nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn import metrics \n\nclasses = [HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder]\nfor cl in classes:\n    embeddings_train = cl(keyed_vectors=model_train.wv) \n\n    train_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in train_edges]\n    test_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in test_edges]\n    \n    rf = RandomForestClassifier(n_estimators=1000, random_state=42) \n    rf.fit(train_embeddings, train_labels); \n\n    y_pred = rf.predict(test_embeddings)\n    print(cl)\n    print('Precision:', metrics.precision_score(test_labels, y_pred)) \n    print('Recall:', metrics.recall_score(test_labels, y_pred)) \n    print('F1-Score:', metrics.f1_score(test_labels, y_pred)) \n\n\n\n\n\nnod2vec_unsup = Node2Vec(G_down, weight_key='weight')\nunsup_vals = nod2vec_unsup.fit(window=10)\n\n\nfrom sklearn.cluster import KMeans\n\nclasses = [HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder]\ntrue_labels = [x for x in nx.get_edge_attributes(G_down, \"label\").values()]\n\nfor cl in classes:\n    embedding_edge = cl(keyed_vectors=unsup_vals.wv) \n\n    embedding = [embedding_edge[str(x[0]), str(x[1])] for x in G_down.edges()]\n    kmeans = KMeans(2, random_state=42).fit(embedding)\n    \n    \n    nmi = metrics.adjusted_mutual_info_score(true_labels, kmeans.labels_)\n    ho = metrics.homogeneity_score(true_labels, kmeans.labels_)\n    co = metrics.completeness_score(true_labels, kmeans.labels_)\n    vmeasure = metrics.v_measure_score(true_labels, kmeans.labels_)\n    \n    print(cl)\n    print('NMI:', nmi)\n    print('Homogeneity:', ho)\n    print('Completeness:', co)\n    print('V-Measure:', vmeasure)"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter07/02_supervised_classification-embeddings.html",
    "href": "posts/2_Studies/GML/Chapter07/02_supervised_classification-embeddings.html",
    "title": "[GML] Chap7: Shallow-Learning Topic Modelling",
    "section": "",
    "text": "Shallow-Learning Topic Modelling\nIn the following we will show you how to create a topic model, using a shallow-learning approach. Here we will use the results and the embeddings obtained from the document-document projection of the bipartite graph.\nNOTE: This Notebook can only be run after the 01_nlp_graph_creation notebook, as some of the results computed in the first notebook will be here reused.\n\nLoad Dataset\n\nimport pandas as pd\n\n\ncorpus = pd.read_pickle(\"corpus.p\")\n\n\nfrom collections import Counter\ntopics = Counter([label for document_labels in corpus[\"label\"] for label in document_labels]).most_common(10)\n\n\ntopics\n\n[('earn', 3964),\n ('acq', 2369),\n ('money-fx', 717),\n ('grain', 582),\n ('crude', 578),\n ('trade', 485),\n ('interest', 478),\n ('ship', 286),\n ('wheat', 283),\n ('corn', 237)]\n\n\n\ntopicsList = [topic[0] for topic in topics]\ntopicsSet = set(topicsList)\ndataset = corpus[corpus[\"label\"].apply(lambda x: len(topicsSet.intersection(x))>0)]\n\nCreate a class to “simulate” the training of the embeddings\n\nfrom sklearn.base import BaseEstimator\n\nclass EmbeddingsTransformer(BaseEstimator):\n    \n    def __init__(self, embeddings_file):\n        self.embeddings_file = embeddings_file\n        \n    def fit(self, *args, **kwargs):\n        self.embeddings = pd.read_pickle(self.embeddings_file)\n        return self\n        \n    def transform(self, X):\n        return self.embeddings.loc[X.index]\n    \n    def fit_transform(self, X, y):\n        return self.fit().transform(X)\n\n\n\nfrom glob import glob \nfiles = glob(\"./embeddings/*\")\n\n\ngraphEmbeddings = EmbeddingsTransformer(files[0]).fit()\n\nTrain/Test split\n\ndef get_labels(corpus, topicsList=topicsList):\n    return corpus[\"label\"].apply(\n        lambda labels: pd.Series({label: 1 for label in labels}).reindex(topicsList).fillna(0)\n    )[topicsList]\n\n\ndef get_features(corpus):\n    return corpus[\"parsed\"] #graphEmbeddings.transform(corpus[\"parsed\"])\n\n\ndef get_features_and_labels(corpus):\n    return get_features(corpus), get_labels(corpus)\n\n\ndef train_test_split(corpus):\n    graphIndex = [index for index in corpus.index if index in graphEmbeddings.embeddings.index]\n    \n    train_idx = [idx for idx in graphIndex if \"training/\" in idx]\n    test_idx = [idx for idx in graphIndex if \"test/\" in idx]\n    return corpus.loc[train_idx], corpus.loc[test_idx]\n\n\ntrain, test = train_test_split(dataset)\n\nBuild the model and cross-validation\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn.multioutput import MultiOutputClassifier\n\n\nmodel = MultiOutputClassifier(RandomForestClassifier())\n\n\npipeline = Pipeline([\n    (\"embeddings\", graphEmbeddings),\n    (\"model\", model)\n])\n\n\nfrom sklearn.model_selection import GridSearchCV\n\n\nfrom sklearn.model_selection import RandomizedSearchCV\n\n\nfiles\n\n['./bipartiteGraphEmbeddings_20_10.p',\n './bipartiteGraphEmbeddings_10.p',\n './bipartiteGraphEmbeddings_20_30.p',\n './bipartiteGraphEmbeddings_20.p',\n './bipartiteGraphEmbeddings_20_20.p',\n './bipartiteGraphEmbeddings_30.p']\n\n\n\nparam_grid = {\n    \"embeddings__embeddings_file\": files,\n    \"model__estimator__n_estimators\": [50, 100], \n    \"model__estimator__max_features\": [0.2,0.3, \"auto\"], \n    #\"model__estimator__max_depth\": [3, 5]\n}\n\n\nfeatures, labels = get_features_and_labels(train)\n\n\nfrom sklearn.metrics import f1_score \n\n\ngrid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, n_jobs=-1, \n                           scoring=lambda y_true, y_pred: f1_score(y_true, y_pred,average='weighted'))\n\n\nmodel = grid_search.fit(features, labels)\n\n/Users/deusebio/.pyenv/versions/3.7.6/envs/ml-book-7/lib/python3.7/site-packages/sklearn/model_selection/_search.py:921: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n  category=UserWarning\n\n\n\nmodel\n\nGridSearchCV(cv=5,\n             estimator=Pipeline(steps=[('embeddings',\n                                        EmbeddingsTransformer(embeddings_file='bipartiteGraphEmbeddings_20.p')),\n                                       ('model',\n                                        MultiOutputClassifier(estimator=RandomForestClassifier(class_weight='balanced')))]),\n             n_jobs=-1,\n             param_grid={'embeddings__embeddings_file': ['./bipartiteGraphEmbeddings_20_10.p',\n                                                         './bipartiteGraphEmbeddings_10.p',\n                                                         './bipartiteGraphEmbeddings_20_30.p',\n                                                         './bipartiteGraphEmbeddings_20.p',\n                                                         './bipartiteGraphEmbeddings_20_20.p',\n                                                         './bipartiteGraphEmbeddings_30.p'],\n                         'model__estimator__max_features': [0.2, 0.3, 'auto'],\n                         'model__estimator__n_estimators': [50, 100]},\n             scoring=<function <lambda> at 0x14af7ee60>)\n\n\n\nmodel.best_params_\n\n{'embeddings__embeddings_file': './bipartiteGraphEmbeddings_20_10.p',\n 'model__estimator__max_features': 0.2,\n 'model__estimator__n_estimators': 50}\n\n\nEvaluate performance\n\ndef get_predictions(model, features):\n    return pd.DataFrame(\n        model.predict(features), \n        columns=topicsList, \n        index=features.index\n    )\n\n\npreds = get_predictions(model, get_features(test))\nlabels = get_labels(test)\n\n\nerrors = 1 - (labels - preds).abs().sum().sum() / labels.abs().sum().sum()\n\n\nerrors\n\n0.6702547542160029\n\n\n\nfrom sklearn.metrics import classification_report\n\n\nprint(classification_report(labels, preds))\n\n              precision    recall  f1-score   support\n\n           0       0.97      0.94      0.95      1087\n           1       0.93      0.74      0.83       719\n           2       0.79      0.45      0.57       179\n           3       0.96      0.64      0.77       149\n           4       0.95      0.59      0.73       189\n           5       0.95      0.45      0.61       117\n           6       0.87      0.41      0.56       131\n           7       0.83      0.21      0.34        89\n           8       0.69      0.34      0.45        71\n           9       0.61      0.25      0.35        56\n\n   micro avg       0.94      0.72      0.81      2787\n   macro avg       0.85      0.50      0.62      2787\nweighted avg       0.92      0.72      0.79      2787\n samples avg       0.76      0.75      0.75      2787\n\n\n\n/Users/deusebio/.pyenv/versions/3.7.6/envs/ml-book-7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter07/03_supervised_classsification_graphSAGE-TFIDF.html",
    "href": "posts/2_Studies/GML/Chapter07/03_supervised_classsification_graphSAGE-TFIDF.html",
    "title": "[GML] Chap7: Graph Neural Network Topic Classifier",
    "section": "",
    "text": "In the following we will focus on building a model for topic classification based on a Graph Neural Network approach.\nIn particular in the following we will show you how to:\n\nCreate a TF-IDF representation of the corpus, that will be used as node features in the Graph Neural Network model\nBuild, train a Graph Neural Network model and identify the best threshold for classifying documents\nTest the performance of the model in a out-of-sample tests, following a truly inductive approach\n\nNOTE: This Notebook can only be run after the 01_nlp_graph_creation notebook, as some of the results computed in the first notebook will be here reused.\n\n\n\nimport nltk \n\n\nimport numpy as np\nimport pandas as pd\nimport networkx as nx\n\n\ncorpus = pd.read_pickle(\"corpus.p\")\n\n\ncorpus.head()\n\n\n\n\n\n  \n    \n      \n      label\n      clean_text\n      parsed\n      language\n    \n    \n      id\n      \n      \n      \n      \n    \n  \n  \n    \n      test/14826\n      [trade]\n      ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RI...\n      (ASIAN, EXPORTERS, FEAR, DAMAGE, FROM, U.S.-JA...\n      en\n    \n    \n      test/14828\n      [grain]\n      CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STO...\n      (CHINA, DAILY, SAYS, VERMIN, EAT, 7, -, 12, PC...\n      en\n    \n    \n      test/14829\n      [crude, nat-gas]\n      JAPAN TO REVISE LONG-TERM ENERGY DEMAND DOWNWA...\n      (JAPAN, TO, REVISE, LONG, -, TERM, ENERGY, DEM...\n      en\n    \n    \n      test/14832\n      [corn, grain, rice, rubber, sugar, tin, trade]\n      THAI TRADE DEFICIT WIDENS IN FIRST QUARTER  Th...\n      (THAI, TRADE, DEFICIT, WIDENS, IN, FIRST, QUAR...\n      en\n    \n    \n      test/14833\n      [palm-oil, veg-oil]\n      INDONESIA SEES CPO PRICE RISING SHARPLY  Indon...\n      (INDONESIA, SEES, CPO, PRICE, RISING, SHARPLY,...\n      en\n    \n  \n\n\n\n\n\nfrom collections import Counter\ntopics = Counter([label for document_labels in corpus[\"label\"] for label in document_labels]).most_common(10)\n\n\ntopics\n\n[('earn', 3964),\n ('acq', 2369),\n ('money-fx', 717),\n ('grain', 582),\n ('crude', 578),\n ('trade', 485),\n ('interest', 478),\n ('ship', 286),\n ('wheat', 283),\n ('corn', 237)]\n\n\n\ntopicsList = [topic[0] for topic in topics]\ntopicsSet = set(topicsList)\ndataset = corpus[corpus[\"label\"].apply(lambda x: len(topicsSet.intersection(x))>0)]\n\n\ndef get_labels(corpus, topicsList=topicsList):\n    return corpus[\"label\"].apply(\n        lambda labels: pd.Series({label: 1 for label in labels}).reindex(topicsList).fillna(0)\n    )[topicsList]\n\n\nlabels = get_labels(dataset)\n\n\nlabels.head()\n\n\n\n\n\n  \n    \n      \n      earn\n      acq\n      money-fx\n      grain\n      crude\n      trade\n      interest\n      ship\n      wheat\n      corn\n    \n    \n      id\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      test/14826\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      test/14828\n      0.0\n      0.0\n      0.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      test/14829\n      0.0\n      0.0\n      0.0\n      0.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      test/14832\n      0.0\n      0.0\n      0.0\n      1.0\n      0.0\n      1.0\n      0.0\n      0.0\n      0.0\n      1.0\n    \n    \n      test/14839\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      1.0\n      0.0\n      0.0\n    \n  \n\n\n\n\n\ndef get_features(corpus):\n    return corpus[\"parsed\"]\n\n\ndef get_features_and_labels(corpus):\n    return get_features(corpus), get_labels(corpus)\n\n\ndef train_test_split(corpus):\n    train_idx = [idx for idx in corpus.index if \"training/\" in idx]\n    test_idx = [idx for idx in corpus.index if \"test/\" in idx]\n    return corpus.loc[train_idx], corpus.loc[test_idx]\n\n\ntrain, test = train_test_split(dataset)\n\n\ndef my_spacy_tokenizer(pos_filter=[\"NOUN\", \"VERB\", \"PROPN\"]):\n    def tokenizer(doc):\n        return [token.lemma_ for token in doc if (pos_filter is None) or (token.pos_ in pos_filter)] \n    return tokenizer\n\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n\ncntVectorizer = TfidfVectorizer(\n    analyzer=my_spacy_tokenizer(),\n    max_df = 0.25, min_df = 2, max_features = 10000\n)\n\n\ntrainFeatures, _ = get_features_and_labels(train)\ntestFeatures, _ = get_features_and_labels(test)\n\n\ntrainedTransformed = cntVectorizer.fit_transform(trainFeatures)\ntestTransformed = cntVectorizer.transform(testFeatures)\n\n\nfeatures = pd.concat([\n    pd.DataFrame.sparse.from_spmatrix(trainedTransformed, index=trainFeatures.index), \n    pd.DataFrame.sparse.from_spmatrix(testTransformed, index=testFeatures.index)\n])\n\n\nfeatures.shape\n\n(9034, 10000)\n\n\nCreating the Graph\n\nimport stellargraph as sg\nfrom stellargraph import StellarGraph, IndexedArray\nfrom stellargraph.mapper import GraphSAGENodeGenerator\nfrom stellargraph.layer import GraphSAGE\n\nfrom tensorflow.keras import layers, optimizers, losses, metrics, Model\n\n\nedges = pd.read_pickle(\"bipartiteEdges.p\")\n\n\nentityTypes = {entity: ith for ith, entity in enumerate(edges[\"type\"].unique())}\n\n\nentityTypes\n\n{'keywords': 0, 'GPE': 1, 'ORG': 2, 'PERSON': 3}\n\n\n\ndocumentFeatures = features.loc[set(corpus.index).intersection(features.index)] #.assign(document=1, entity=0)\n\n\ndocumentFeatures.head()\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      3\n      4\n      5\n      6\n      7\n      8\n      9\n      ...\n      9990\n      9991\n      9992\n      9993\n      9994\n      9995\n      9996\n      9997\n      9998\n      9999\n    \n    \n      id\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      training/9238\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      test/15296\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      test/15287\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      training/5938\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      test/21465\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n  \n\n5 rows × 10000 columns\n\n\n\n\nentities = edges.groupby([\"target\", \"type\"])[\"source\"].count().groupby(level=0).apply(\n    lambda s: s.droplevel(0).reindex(entityTypes.keys()).fillna(0)\n).unstack(level=1)\n\n\nentityFeatures = (entities.T / entities.sum(axis=1)).T.assign(document=0, entity=1)\n\n\nnodes = {\"entity\": entityFeatures, \n         \"document\": documentFeatures}\n\n\nstellarGraph = StellarGraph(nodes, \n                            edges[edges[\"source\"].isin(documentFeatures.index)], \n                            edge_type_column=\"type\")\n\n\nprint(stellarGraph.info())\n\nStellarGraph: Undirected multigraph\n Nodes: 23998, Edges: 86849\n\n Node types:\n  entity: [14964]\n    Features: float32 vector, length 6\n    Edge types: entity-GPE->document, entity-ORG->document, entity-PERSON->document, entity-keywords->document\n  document: [9034]\n    Features: float32 vector, length 10000\n    Edge types: document-GPE->entity, document-ORG->entity, document-PERSON->entity, document-keywords->entity\n\n Edge types:\n    document-keywords->entity: [78838]\n        Weights: range=[0.0827011, 1], mean=0.258464, std=0.0898612\n        Features: none\n    document-ORG->entity: [4129]\n        Weights: range=[2, 22], mean=3.24122, std=2.30508\n        Features: none\n    document-GPE->entity: [2943]\n        Weights: range=[2, 25], mean=3.25926, std=2.07008\n        Features: none\n    document-PERSON->entity: [939]\n        Weights: range=[2, 14], mean=2.97444, std=1.65956\n        Features: none\n\n\n\nfrom stellargraph.data import EdgeSplitter\n\n\nsplitter = EdgeSplitter(stellarGraph)\n\n\ngraphTest, samplesTest, labelsTest = splitter.train_test_split(p=0.2)\n\n** Sampled 17369 positive and 17369 negative edges. **\n\n\n\nprint(stellarGraph.info())\n\nStellarGraph: Undirected multigraph\n Nodes: 23998, Edges: 86849\n\n Node types:\n  entity: [14964]\n    Features: float32 vector, length 6\n    Edge types: entity-GPE->document, entity-ORG->document, entity-PERSON->document, entity-keywords->document\n  document: [9034]\n    Features: float32 vector, length 10000\n    Edge types: document-GPE->entity, document-ORG->entity, document-PERSON->entity, document-keywords->entity\n\n Edge types:\n    document-keywords->entity: [78838]\n        Weights: range=[0.0827011, 1], mean=0.258464, std=0.0898612\n        Features: none\n    document-ORG->entity: [4129]\n        Weights: range=[2, 22], mean=3.24122, std=2.30508\n        Features: none\n    document-GPE->entity: [2943]\n        Weights: range=[2, 25], mean=3.25926, std=2.07008\n        Features: none\n    document-PERSON->entity: [939]\n        Weights: range=[2, 14], mean=2.97444, std=1.65956\n        Features: none\n\n\n\nprint(graphTest.info())\n\nStellarGraph: Undirected multigraph\n Nodes: 23998, Edges: 69480\n\n Node types:\n  entity: [14964]\n    Features: float32 vector, length 6\n    Edge types: entity-GPE->document, entity-ORG->document, entity-PERSON->document, entity-keywords->document\n  document: [9034]\n    Features: float32 vector, length 10000\n    Edge types: document-GPE->entity, document-ORG->entity, document-PERSON->entity, document-keywords->entity\n\n Edge types:\n    document-keywords->entity: [63057]\n        Weights: range=[0.0827011, 1], mean=0.258427, std=0.0899773\n        Features: none\n    document-ORG->entity: [3296]\n        Weights: range=[2, 22], mean=3.21572, std=2.2592\n        Features: none\n    document-GPE->entity: [2360]\n        Weights: range=[2, 19], mean=3.24237, std=2.01535\n        Features: none\n    document-PERSON->entity: [767]\n        Weights: range=[2, 14], mean=3, std=1.69163\n        Features: none\n\n\n\n\n\nWe start by splitting the data into train, validation and test\n\ntargets = labels.reindex(documentFeatures.index).fillna(0)\n#documentFeatures.drop([\"entity\", \"document\"], axis=1)\n\n\ntargets.head()\n\n\n\n\n\n  \n    \n      \n      earn\n      acq\n      money-fx\n      grain\n      crude\n      trade\n      interest\n      ship\n      wheat\n      corn\n    \n    \n      id\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      test/16678\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      test/15913\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      training/12032\n      0.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      training/8366\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      training/10454\n      0.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n  \n\n\n\n\n\ndef train_test_split(corpus):\n    graphIndex = [index for index in corpus.index]\n    \n    train_idx = [idx for idx in graphIndex if \"training/\" in idx]\n    test_idx = [idx for idx in graphIndex if \"test/\" in idx]\n    return corpus.loc[train_idx], corpus.loc[test_idx]\n\n\nsampled, hold_out = train_test_split(targets)\n\n\nallNeighbors = np.unique([n for node in sampled.index for n in stellarGraph.neighbors(node)])\n\n\nsubgraph = stellarGraph.subgraph(set(sampled.index).union(allNeighbors))\n\n\nprint(subgraph.info())\n\nStellarGraph: Undirected multigraph\n Nodes: 16927, Edges: 62454\n\n Node types:\n  entity: [10438]\n    Features: float32 vector, length 6\n    Edge types: entity-GPE->document, entity-ORG->document, entity-PERSON->document, entity-keywords->document\n  document: [6489]\n    Features: float32 vector, length 10000\n    Edge types: document-GPE->entity, document-ORG->entity, document-PERSON->entity, document-keywords->entity\n\n Edge types:\n    document-keywords->entity: [56647]\n        Weights: range=[0.0918226, 1], mean=0.25739, std=0.0888008\n        Features: none\n    document-ORG->entity: [3032]\n        Weights: range=[2, 22], mean=3.20877, std=2.21143\n        Features: none\n    document-GPE->entity: [2104]\n        Weights: range=[2, 25], mean=3.25808, std=2.08119\n        Features: none\n    document-PERSON->entity: [671]\n        Weights: range=[2, 14], mean=2.97615, std=1.66958\n        Features: none\n\n\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, leftOut = train_test_split(\n    sampled,\n    train_size=0.1,\n    test_size=None,\n    random_state=42,\n)\n\nvalidation, test = train_test_split(\n    leftOut, train_size=0.2, test_size=None, random_state=100,\n)\n\n\nvalidation = validation[validation.sum(axis=1) > 0]\ntest = test[test.sum(axis=1) > 0]\n\n\nprint(f\"Validation: {validation.shape}\")\nprint(f\"Test: {test.shape}\")\n\nValidation: (1168, 10)\nTest: (4673, 10)\n\n\n\n\nWe start by creating the model\n\nbatch_size = 50\nnum_samples = [10, 5]\n\n\nfrom stellargraph.mapper import HinSAGENodeGenerator\n\ngenerator = HinSAGENodeGenerator(subgraph, batch_size, num_samples, head_node_type=\"document\")\n\n\nfrom stellargraph.layer import HinSAGE\n\ngraphsage_model = HinSAGE(\n    layer_sizes=[32, 32], generator=generator, bias=True, dropout=0.5,\n)\n\n\nx_inp, x_out = graphsage_model.in_out_tensors()\nprediction = layers.Dense(units=train.shape[1], activation=\"sigmoid\")(x_out)\n\n\nprediction.shape\n\nTensorShape([None, 10])\n\n\n\nmodel = Model(inputs=x_inp, outputs=prediction)\nmodel.compile(\n    optimizer=optimizers.Adam(lr=0.005),\n    loss=losses.binary_crossentropy,\n    metrics=[\"acc\"],\n)\n\nWe now train the model\n\ntrain_gen = generator.flow(train.index, train, shuffle=True)\n\n\nval_gen = generator.flow(validation.index, validation)\n\n\nhistory = model.fit(\n    train_gen, epochs=50, validation_data=val_gen, verbose=1, shuffle=False\n)\n\nEpoch 1/50\n13/13 [==============================] - 215s 17s/step - loss: 0.6139 - acc: 0.1365 - val_loss: 0.4780 - val_acc: 0.4401\nEpoch 2/50\n13/13 [==============================] - 169s 13s/step - loss: 0.4675 - acc: 0.4323 - val_loss: 0.4001 - val_acc: 0.4401\nEpoch 3/50\n13/13 [==============================] - 162s 13s/step - loss: 0.3973 - acc: 0.4319 - val_loss: 0.3486 - val_acc: 0.4401\nEpoch 4/50\n13/13 [==============================] - 153s 12s/step - loss: 0.3447 - acc: 0.4604 - val_loss: 0.3124 - val_acc: 0.4401\nEpoch 5/50\n13/13 [==============================] - 144s 11s/step - loss: 0.3090 - acc: 0.4997 - val_loss: 0.2853 - val_acc: 0.4932\nEpoch 6/50\n13/13 [==============================] - 159s 13s/step - loss: 0.2886 - acc: 0.5484 - val_loss: 0.2639 - val_acc: 0.6045\nEpoch 7/50\n13/13 [==============================] - 187s 15s/step - loss: 0.2612 - acc: 0.6354 - val_loss: 0.2453 - val_acc: 0.6387\nEpoch 8/50\n13/13 [==============================] - 203s 16s/step - loss: 0.2509 - acc: 0.6294 - val_loss: 0.2307 - val_acc: 0.6404\nEpoch 9/50\n13/13 [==============================] - 178s 14s/step - loss: 0.2370 - acc: 0.6489 - val_loss: 0.2160 - val_acc: 0.6789\nEpoch 10/50\n13/13 [==============================] - 190s 15s/step - loss: 0.2155 - acc: 0.6836 - val_loss: 0.2046 - val_acc: 0.7029\nEpoch 11/50\n13/13 [==============================] - 172s 14s/step - loss: 0.2047 - acc: 0.7310 - val_loss: 0.1938 - val_acc: 0.7260\nEpoch 12/50\n13/13 [==============================] - 145s 12s/step - loss: 0.2009 - acc: 0.7208 - val_loss: 0.1846 - val_acc: 0.7509\nEpoch 13/50\n13/13 [==============================] - 167s 13s/step - loss: 0.1834 - acc: 0.7843 - val_loss: 0.1755 - val_acc: 0.7860\nEpoch 14/50\n13/13 [==============================] - 208s 17s/step - loss: 0.1787 - acc: 0.7943 - val_loss: 0.1679 - val_acc: 0.8005\nEpoch 15/50\n13/13 [==============================] - 216s 17s/step - loss: 0.1718 - acc: 0.8123 - val_loss: 0.1598 - val_acc: 0.8365\nEpoch 16/50\n13/13 [==============================] - 201s 16s/step - loss: 0.1619 - acc: 0.8612 - val_loss: 0.1531 - val_acc: 0.8416\nEpoch 17/50\n13/13 [==============================] - 173s 14s/step - loss: 0.1609 - acc: 0.8378 - val_loss: 0.1470 - val_acc: 0.8502\nEpoch 18/50\n13/13 [==============================] - 157s 12s/step - loss: 0.1496 - acc: 0.8471 - val_loss: 0.1412 - val_acc: 0.8690\nEpoch 19/50\n13/13 [==============================] - 155s 12s/step - loss: 0.1471 - acc: 0.8600 - val_loss: 0.1379 - val_acc: 0.8604\nEpoch 20/50\n13/13 [==============================] - 154s 12s/step - loss: 0.1366 - acc: 0.8801 - val_loss: 0.1318 - val_acc: 0.8767\nEpoch 21/50\n13/13 [==============================] - 155s 12s/step - loss: 0.1362 - acc: 0.8708 - val_loss: 0.1285 - val_acc: 0.8664\nEpoch 22/50\n13/13 [==============================] - 156s 12s/step - loss: 0.1361 - acc: 0.8546 - val_loss: 0.1259 - val_acc: 0.8682\nEpoch 23/50\n13/13 [==============================] - 154s 12s/step - loss: 0.1197 - acc: 0.9104 - val_loss: 0.1231 - val_acc: 0.8733\nEpoch 24/50\n13/13 [==============================] - 146s 11s/step - loss: 0.1240 - acc: 0.8834 - val_loss: 0.1175 - val_acc: 0.8844\nEpoch 25/50\n13/13 [==============================] - 131s 10s/step - loss: 0.1145 - acc: 0.9165 - val_loss: 0.1165 - val_acc: 0.8853\nEpoch 26/50\n13/13 [==============================] - 131s 10s/step - loss: 0.1216 - acc: 0.8844 - val_loss: 0.1155 - val_acc: 0.8784\nEpoch 27/50\n13/13 [==============================] - 132s 11s/step - loss: 0.1084 - acc: 0.9093 - val_loss: 0.1111 - val_acc: 0.8878\nEpoch 28/50\n13/13 [==============================] - 127s 10s/step - loss: 0.1039 - acc: 0.9156 - val_loss: 0.1095 - val_acc: 0.8853\nEpoch 29/50\n13/13 [==============================] - 128s 10s/step - loss: 0.1066 - acc: 0.9175 - val_loss: 0.1095 - val_acc: 0.8818\nEpoch 30/50\n13/13 [==============================] - 194s 16s/step - loss: 0.0987 - acc: 0.9199 - val_loss: 0.1089 - val_acc: 0.8784\nEpoch 31/50\n13/13 [==============================] - 194s 16s/step - loss: 0.0995 - acc: 0.9164 - val_loss: 0.1047 - val_acc: 0.8827\nEpoch 32/50\n13/13 [==============================] - 206s 16s/step - loss: 0.0938 - acc: 0.9322 - val_loss: 0.1030 - val_acc: 0.8818\nEpoch 33/50\n13/13 [==============================] - 199s 16s/step - loss: 0.0907 - acc: 0.9205 - val_loss: 0.1014 - val_acc: 0.8853\nEpoch 34/50\n13/13 [==============================] - 213s 17s/step - loss: 0.0918 - acc: 0.9208 - val_loss: 0.0990 - val_acc: 0.8887\nEpoch 35/50\n13/13 [==============================] - 264s 21s/step - loss: 0.0887 - acc: 0.9342 - val_loss: 0.0978 - val_acc: 0.8878\nEpoch 36/50\n13/13 [==============================] - 378s 30s/step - loss: 0.0875 - acc: 0.9170 - val_loss: 0.0956 - val_acc: 0.8955\nEpoch 37/50\n13/13 [==============================] - 247s 19s/step - loss: 0.0856 - acc: 0.9363 - val_loss: 0.0969 - val_acc: 0.8896\nEpoch 38/50\n13/13 [==============================] - 224s 17s/step - loss: 0.0777 - acc: 0.9312 - val_loss: 0.0938 - val_acc: 0.8921\nEpoch 39/50\n13/13 [==============================] - 201s 16s/step - loss: 0.0837 - acc: 0.9205 - val_loss: 0.0930 - val_acc: 0.8938\nEpoch 40/50\n13/13 [==============================] - 201s 16s/step - loss: 0.0844 - acc: 0.9180 - val_loss: 0.0917 - val_acc: 0.8938\nEpoch 41/50\n13/13 [==============================] - 197s 16s/step - loss: 0.0731 - acc: 0.9353 - val_loss: 0.0917 - val_acc: 0.8938\nEpoch 42/50\n13/13 [==============================] - 210s 17s/step - loss: 0.0732 - acc: 0.9220 - val_loss: 0.0908 - val_acc: 0.8861\nEpoch 43/50\n13/13 [==============================] - 236s 19s/step - loss: 0.0718 - acc: 0.9440 - val_loss: 0.0923 - val_acc: 0.8896\nEpoch 44/50\n13/13 [==============================] - 186s 15s/step - loss: 0.0711 - acc: 0.9581 - val_loss: 0.0912 - val_acc: 0.8861\nEpoch 45/50\n13/13 [==============================] - 169s 13s/step - loss: 0.0704 - acc: 0.9449 - val_loss: 0.0893 - val_acc: 0.8887\nEpoch 46/50\n13/13 [==============================] - 183s 15s/step - loss: 0.0768 - acc: 0.9366 - val_loss: 0.0897 - val_acc: 0.8887\nEpoch 47/50\n13/13 [==============================] - 196s 16s/step - loss: 0.0723 - acc: 0.9305 - val_loss: 0.0861 - val_acc: 0.8990\nEpoch 48/50\n13/13 [==============================] - 154s 12s/step - loss: 0.0733 - acc: 0.9289 - val_loss: 0.0873 - val_acc: 0.8964\nEpoch 49/50\n13/13 [==============================] - 228s 18s/step - loss: 0.0691 - acc: 0.9568 - val_loss: 0.0878 - val_acc: 0.8998\nEpoch 50/50\n13/13 [==============================] - 211s 17s/step - loss: 0.0625 - acc: 0.9409 - val_loss: 0.0864 - val_acc: 0.8896\n\n\n\nsg.utils.plot_history(history)\n\n\n\n\n\nhistory = model.fit(\n    train_gen, epochs=50, validation_data=val_gen, verbose=1, shuffle=False\n)\n\n\nsg.utils.plot_history(history)\n\n\n\n\n\ntest_gen = generator.flow(test.index, test)\n\n\ntest_metrics = model.evaluate(test_gen)\nprint(\"\\nTest Set Metrics:\")\nfor name, val in zip(model.metrics_names, test_metrics):\n    print(\"\\t{}: {:0.4f}\".format(name, val))\n\n94/94 [==============================] - 391s 4s/step - loss: 0.0933 - acc: 0.8795\n\nTest Set Metrics:\n    loss: 0.0933\n    acc: 0.8795\n\n\n\ntest_predictions = pd.DataFrame(model.predict(test_gen), index=test.index, columns=test.columns)\n\n\ntest_results = pd.concat({\n    \"target\": test, \n    \"preds\": test_predictions\n}, axis=1)\n\n\nfrom sklearn.metrics import f1_score, classification_report\n\n\nf1s = {}\n\nfor th in [0.01,0.05,0.1,0.2,0.3,0.4,0.5]:\n    f1s[th] = f1_score(test_results[\"target\"], 1.0*(test_results[\"preds\"]>th), average=\"macro\")\n    \npd.Series(f1s).plot()\n\n<AxesSubplot:>\n\n\n\n\n\nAs it can be seen, with a threshold of about 0.2 we obtain the best performances. We thus use this value for producing the classification report\n\nprint(classification_report(test_results[\"target\"], 1.0*(test_results[\"preds\"]>0.2)))\n\n              precision    recall  f1-score   support\n\n           0       0.92      0.97      0.94      2075\n           1       0.85      0.96      0.90      1200\n           2       0.65      0.90      0.75       364\n           3       0.83      0.95      0.89       305\n           4       0.86      0.68      0.76       296\n           5       0.74      0.56      0.63       269\n           6       0.60      0.80      0.69       245\n           7       0.62      0.10      0.17       150\n           8       0.49      0.95      0.65       149\n           9       0.44      0.88      0.58       129\n\n   micro avg       0.80      0.89      0.84      5182\n   macro avg       0.70      0.78      0.70      5182\nweighted avg       0.82      0.89      0.84      5182\n samples avg       0.83      0.90      0.85      5182\n\n\n\n/Users/deusebio/.pyenv/versions/3.7.6/envs/ml-book-7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n\n\n\n\n\nWe now provide a prediction truly inductive, thus we will be using the full graph and we will also use the threshold of 0.2 we have identified above as the one providing the top f1-score.\n\ngenerator = HinSAGENodeGenerator(stellarGraph, batch_size, num_samples, head_node_type=\"document\")\n\n\nhold_out = hold_out[hold_out.sum(axis=1) > 0]\n\n\nhold_out_gen = generator.flow(hold_out.index, hold_out)\n\n\nhold_out_predictions = model.predict(hold_out_gen)\n\n\npreds = pd.DataFrame(1.0*(hold_out_predictions > 0.2), index=hold_out.index, columns=hold_out.columns)\n\n\nresults = pd.concat({\n    \"target\": hold_out, \n    \"preds\": preds\n}, axis=1)\n\n\nprint(classification_report(results[\"target\"], results[\"preds\"]))\n\n              precision    recall  f1-score   support\n\n           0       0.93      0.99      0.96      1087\n           1       0.90      0.97      0.93       719\n           2       0.64      0.92      0.76       179\n           3       0.82      0.95      0.88       149\n           4       0.85      0.62      0.72       189\n           5       0.74      0.50      0.59       117\n           6       0.60      0.79      0.68       131\n           7       0.43      0.03      0.06        89\n           8       0.50      0.96      0.66        71\n           9       0.39      0.86      0.54        56\n\n   micro avg       0.82      0.89      0.85      2787\n   macro avg       0.68      0.76      0.68      2787\nweighted avg       0.83      0.89      0.84      2787\n samples avg       0.84      0.90      0.86      2787\n\n\n\n/Users/deusebio/.pyenv/versions/3.7.6/envs/ml-book-7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter09/01_Neo4j_bindings.html",
    "href": "posts/2_Studies/GML/Chapter09/01_Neo4j_bindings.html",
    "title": "[GML] Chap9: Graph Database Connection",
    "section": "",
    "text": "Graph Database Connection\nIn the following, we will show you how to connect and query data on Neo4j, using python.\nIMPORTANT NOTE\nThis notebook requires that you have access to a working version of Neo4j. In order to install Neo4j locally, we advise you to refer to the Neo4j webpage (https://neo4j.com/download/) or to use docker (https://hub.docker.com/_/neo4j).\n\nwith open(\"./dataset/movieCreationQuery.txt\", \"rb\") as fid:\n    lines = fid.readlines()\n\n\nquery = \" \".join([line.decode(\"utf-8\").replace(\"\\n\", \"\") for line in lines])\n\n\nfrom neo4j import GraphDatabase\n\n\nuri = \"neo4j://localhost:7687\"\ndriver = GraphDatabase.driver(uri, auth=(\"neo4j\", \"neo5j\"))\n\n\ndef run_query(tx, query):\n    return list(tx.run(query))\n\n\nwith driver.session() as session:\n    session.write_transaction(run_query, query)\n\nQuery\n\nquery = \"MATCH (n) RETURN count(*)\"\n\n\nwith driver.session() as session:\n    result = session.read_transaction(run_query, query)\n[r for r in result]\n\n[<Record count(*)=342>]\n\n\nDelete\n\nwith driver.session() as session:\n    result = session.write_transaction(run_query, \"MATCH (n)-[e]-() DELETE n, e\")"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter04/02_Shallow_embeddings.html",
    "href": "posts/2_Studies/GML/Chapter04/02_Shallow_embeddings.html",
    "title": "[GML] Chap4: 지도 그래프 학습 - 얕은 임베딩 방법",
    "section": "",
    "text": "import matplotlib.pyplot as plt\n\ndef draw_graph(G, node_names={}, nodes_label=[], node_size=900):\n    pos_nodes = nx.spring_layout(G)\n    \n    col = {0:\"steelblue\",1:\"red\",2:\"green\"}\n    \n    colors = [col[x] for x in nodes_label]\n    \n    nx.draw(G, pos_nodes, with_labels=True, node_color=colors, node_size=node_size, edge_color='gray', \n            arrowsize=30)\n    \n    \n    \n    pos_attrs = {}\n    for node, coords in pos_nodes.items():\n        pos_attrs[node] = (coords[0], coords[1] + 0.08)\n        \n    \n    plt.axis('off')\n    axis = plt.gca()\n    axis.set_xlim([1.2*x for x in axis.get_xlim()])\n    axis.set_ylim([1.2*y for y in axis.get_ylim()])\n    plt.show()"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter04/02_Shallow_embeddings.html#degree-matrix",
    "href": "posts/2_Studies/GML/Chapter04/02_Shallow_embeddings.html#degree-matrix",
    "title": "[GML] Chap4: 지도 그래프 학습 - 얕은 임베딩 방법",
    "section": "Degree matrix",
    "text": "Degree matrix\n\nimport numpy as np\nfrom numpy.linalg import inv\n\nD = [G.degree(n) for n in G.nodes()]\nD = np.diag(D)\nD"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter04/02_Shallow_embeddings.html#proximity-matrix",
    "href": "posts/2_Studies/GML/Chapter04/02_Shallow_embeddings.html#proximity-matrix",
    "title": "[GML] Chap4: 지도 그래프 학습 - 얕은 임베딩 방법",
    "section": "Proximity matrix",
    "text": "Proximity matrix\n\nA = inv(D)*nx.to_numpy_matrix(G)\nA"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter04/02_Shallow_embeddings.html#label-propagation-implemenation",
    "href": "posts/2_Studies/GML/Chapter04/02_Shallow_embeddings.html#label-propagation-implemenation",
    "title": "[GML] Chap4: 지도 그래프 학습 - 얕은 임베딩 방법",
    "section": "Label propagation implemenation",
    "text": "Label propagation implemenation\n\nimport numpy as np\nimport networkx as nx\nfrom numpy.linalg import inv\nfrom abc import ABCMeta, abstractmethod\nfrom sklearn.base import BaseEstimator, ClassifierMixin\nfrom sklearn.utils.multiclass import check_classification_targets\nfrom sklearn.utils.validation import check_is_fitted, _deprecate_positional_args\n\nclass GraphLabelPropagation(ClassifierMixin, BaseEstimator, metaclass=ABCMeta):\n    \"\"\"Graph label propagation module.\n    Parameters\n    ----------\n    max_iter : int, default=30\n        Change maximum number of iterations allowed.\n    tol : float, default=1e-3\n        Convergence tolerance: threshold to consider the system at steady\n        state.\n    \"\"\"\n\n    @_deprecate_positional_args\n    def __init__(self, max_iter=30, tol=1e-3):\n\n        self.max_iter = max_iter\n        self.tol = tol\n\n    def predict(self, X):\n        \"\"\"Performs inductive inference across the model.\n        Parameters\n        ----------\n        X : A networkx array.\n            The data matrix.\n        Returns\n        -------\n        y : ndarray of shape (n_samples,)\n            Predictions for input data.\n        \"\"\"\n        probas = self.predict_proba(X)\n        return self.classes_[np.argmax(probas, axis=1)].ravel()\n\n    def predict_proba(self, X):\n        \"\"\"Predict probability for each possible outcome.\n        Compute the probability estimates for each single node in X\n        and each possible outcome seen during training (categorical\n        distribution).\n        Parameters\n        ----------\n        X : A networkx array.\n        Returns\n        -------\n        probabilities : ndarray of shape (n_samples, n_classes)\n            Normalized probability distributions across\n            class labels.\n        \"\"\"\n        check_is_fitted(self)\n        \n        return self.label_distributions_\n    \n    def _validate_data(self, X, y):\n        if not isinstance(X, nx.Graph):\n            raise ValueError(\"Input should be a networkX graph\")\n        if not len(y) == len(X.nodes()):\n            raise ValueError(\"Label data input shape should be equal to the number of nodes in the graph\")\n        return X, y\n    \n    @staticmethod\n    def build_label(x,classes):\n        tmp = np.zeros((classes))\n        tmp[x] = 1\n        return tmp\n    \n    def fit(self, X, y):\n        \"\"\"Fit a semi-supervised label propagation model based\n        on the input graph G and corresponding label matrix y with a dedicated marker value for\n        unlabeled samples.\n        Parameters\n        ----------\n        X : A networkX array.\n        y : array-like of shape (n_samples,)\n            `n_labeled_samples` (unlabeled points are marked as -1)\n            All unlabeled samples will be transductively assigned labels.\n        Returns\n        -------\n        self : object\n        \"\"\"\n        X, y = self._validate_data(X, y)\n        self.X_ = X\n        check_classification_targets(y)\n\n        D = [X.degree(n) for n in X.nodes()]\n        D = np.diag(D)\n        \n        # label construction\n        # construct a categorical distribution for classification only\n        unlabeled_index = np.where(y==-1)[0]\n        labeled_index = np.where(y!=-1)[0]\n        unique_classes = np.unique(y[labeled_index])\n        \n        self.classes_ = unique_classes\n        \n        Y0 = np.array([self.build_label(y[x], len(unique_classes)) \n                                 if x in labeled_index else np.zeros(len(unique_classes)) for x in range(len(y))])\n        \n        A = inv(D)*nx.to_numpy_matrix(G)\n        Y_prev = Y0\n        it = 0\n        c_tool = 10\n        \n        while it < self.max_iter & c_tool > self.tol:\n            Y = A*Y_prev\n            #force labeled nodes\n            Y[labeled_index] = Y0[labeled_index]\n            \n            it +=1\n            c_tol = np.sum(np.abs(Y-Y_prev))\n            \n            Y_prev = Y\n            \n        self.label_distributions_ = Y\n        return self"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter04/02_Shallow_embeddings.html#label-propagation-execution",
    "href": "posts/2_Studies/GML/Chapter04/02_Shallow_embeddings.html#label-propagation-execution",
    "title": "[GML] Chap4: 지도 그래프 학습 - 얕은 임베딩 방법",
    "section": "Label propagation execution",
    "text": "Label propagation execution\n\nglp = GraphLabelPropagation()\ny = np.array([-1 for x in range(len(G.nodes()))])\ny[0] = 1\ny[6] = 0\nglp.fit(G,y)\ntmp = glp.predict(G)\nprint(glp.predict_proba(G))\n\ndraw_graph(G, nodes_label=tmp+1, node_size=1200)"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter04/02_Shallow_embeddings.html#degree-matrix-1",
    "href": "posts/2_Studies/GML/Chapter04/02_Shallow_embeddings.html#degree-matrix-1",
    "title": "[GML] Chap4: 지도 그래프 학습 - 얕은 임베딩 방법",
    "section": "Degree matrix",
    "text": "Degree matrix\n\nimport numpy as np\nfrom numpy.linalg import inv\n\nD = [G.degree(n) for n in G.nodes()]\nD = np.diag(D)\nD"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter04/02_Shallow_embeddings.html#normalized-graph-laplacian-matrix",
    "href": "posts/2_Studies/GML/Chapter04/02_Shallow_embeddings.html#normalized-graph-laplacian-matrix",
    "title": "[GML] Chap4: 지도 그래프 학습 - 얕은 임베딩 방법",
    "section": "Normalized graph Laplacian matrix",
    "text": "Normalized graph Laplacian matrix\n\nfrom scipy.linalg import fractional_matrix_power\nD_inv = fractional_matrix_power(D, -0.5)\nL = D_inv*nx.to_numpy_matrix(G)*D_inv\nL"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter04/02_Shallow_embeddings.html#label-spreading-implementation",
    "href": "posts/2_Studies/GML/Chapter04/02_Shallow_embeddings.html#label-spreading-implementation",
    "title": "[GML] Chap4: 지도 그래프 학습 - 얕은 임베딩 방법",
    "section": "Label spreading implementation",
    "text": "Label spreading implementation\n\nimport numpy as np\nimport networkx as nx\nfrom sklearn.preprocessing import normalize\nfrom scipy.linalg import fractional_matrix_power\nfrom sklearn.utils.multiclass import check_classification_targets\n\nclass GraphLabelSpreading(GraphLabelPropagation):\n    \"\"\"Graph label propagation module.\n    Parameters\n    ----------\n    max_iter : int, default=30\n        Change maximum number of iterations allowed.\n    tol : float, default=1e-3\n        Convergence tolerance: threshold to consider the system at steady\n        state.\n    \"\"\"\n\n    @_deprecate_positional_args\n    def __init__(self, max_iter=30, tol=1e-3, alpha=0.6):\n\n        self.alpha = alpha\n        super().__init__(max_iter, tol)\n    \n    def fit(self, X, y):\n        \"\"\"Fit a semi-supervised label propagation model based\n        on the input graph G and corresponding label matrix y with a dedicated marker value for\n        unlabeled samples.\n        Parameters\n        ----------\n        X : A networkX array.\n        y : array-like of shape (n_samples,)\n            `n_labeled_samples` (unlabeled points are marked as -1)\n            All unlabeled samples will be transductively assigned labels.\n        Returns\n        -------\n        self : object\n        \"\"\"\n        X, y = self._validate_data(X, y)\n        self.X_ = X\n        check_classification_targets(y)\n\n        D = [X.degree(n) for n in X.nodes()]\n        D = np.diag(D)\n        D_inv = np.matrix(fractional_matrix_power(D,-0.5))\n        L = D_inv*nx.to_numpy_matrix(G)*D_inv\n        \n        # label construction\n        # construct a categorical distribution for classification only\n        unlabeled_index = np.where(y==-1)[0]\n        labeled_index = np.where(y!=-1)[0]\n        unique_classes = np.unique(y[labeled_index])\n        \n        self.classes_ = unique_classes\n        \n        Y0 = np.array([self.build_label(y[x], len(unique_classes)) \n                                 if x in labeled_index else np.zeros(len(unique_classes)) for x in range(len(y))])\n        \n        Y_prev = Y0\n        it = 0\n        c_tool = 10\n        \n        while it < self.max_iter & c_tool > self.tol:\n            Y = self.alpha*(L*Y_prev)+((1-self.alpha)*Y0)\n\n            it +=1\n            c_tol = np.sum(np.abs(Y-Y_prev))\n            Y_prev = Y\n        self.label_distributions_ = Y\n        return self"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter04/01_Feature_based_methods.html",
    "href": "posts/2_Studies/GML/Chapter04/01_Feature_based_methods.html",
    "title": "[GML] Chap4: 지도 그래프 학습 - 특징 기반 방법",
    "section": "",
    "text": "Feature based methods\nIn this notebook we will exploring a very naive (yet powerful) approach for solving graph-based supervised machine learning. The idea rely on the classic machine learning approach of handcrafted feature extraction.\nIn Chapter 1 you learned how local and global graph properties can be extracted from graphs. Those properties represent the graph itself and bring important informations which can be useful for classification.\nIn this demo, we will be using the PROTEINS dataset, already integrated in StellarGraph\n\nfrom stellargraph import datasets\nfrom IPython.display import display, HTML\n\ndataset = datasets.PROTEINS()\ndisplay(HTML(dataset.description))\ngraphs, graph_labels = dataset.load()\n\nTo compute the graph metrics, one way is to retrieve the adjacency matrix representation of each graph.\n\n# convert graphs from StellarGraph format to numpy adj matrices\nadjs = [graph.to_adjacency_matrix().A for graph in graphs]\n# convert labes fom Pandas.Series to numpy array\nlabels = graph_labels.to_numpy(dtype=int)\n\n\nimport numpy as np\nimport networkx as nx\n\nmetrics = []\nfor adj in adjs:\n  G = nx.from_numpy_matrix(adj)\n  # basic properties\n  num_edges = G.number_of_edges()\n  # clustering measures\n  cc = nx.average_clustering(G)\n  # measure of efficiency\n  eff = nx.global_efficiency(G)\n\n  metrics.append([num_edges, cc, eff])\n\n\nWe can now exploit scikit-learn utilities to create a train and test set. In our experiments, we will be using 70% of the dataset as training set and the remaining as testset\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(metrics, labels, test_size=0.3, random_state=42)\n\nAs commonly done in many Machine Learning workflows, we preprocess features to have zero mean and unit standard deviation\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaler.fit(X_train)\n\nX_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nIt’s now time for training a proper algorithm. We chose a support vector machine for this task\n\nfrom sklearn import svm\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nclf = svm.SVC()\nclf.fit(X_train_scaled, y_train)\n\ny_pred = clf.predict(X_test_scaled)\n\nprint('Accuracy', accuracy_score(y_test,y_pred))\nprint('Precision', precision_score(y_test,y_pred))\nprint('Recall', recall_score(y_test,y_pred))\nprint('F1-score', f1_score(y_test,y_pred))"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter04/04_Graph_Neural_Networks.html",
    "href": "posts/2_Studies/GML/Chapter04/04_Graph_Neural_Networks.html",
    "title": "[GML] Chap4: 지도 그래프 학습 - Graph CNN",
    "section": "",
    "text": "In this notebook we will exploring a very naive (yet powerful) approach for solving graph-based supervised machine learning. The idea rely on the classic machine learning approach of handcrafted feature extraction.\nIn Chapter 1 you learned how local and global graph properties can be extracted from graphs. Those properties represent the graph itself and bring important informations which can be useful for classification.\n\n!pip install stellargraph\n\nUninstalling stellargraph-1.2.1:\n  Successfully uninstalled stellargraph-1.2.1\n\n\nIn this demo, we will be using the PROTEINS dataset, already integrated in StellarGraph\n\nfrom stellargraph import datasets\nfrom IPython.display import display, HTML\n\ndataset = datasets.PROTEINS()\ndisplay(HTML(dataset.description))\ngraphs, graph_labels = dataset.load()\n\nTo compute the graph metrics, one way is to retrieve the adjacency matrix representation of each graph.\n\n# convert graphs from StellarGraph format to numpy adj matrices\nadjs = [graph.to_adjacency_matrix().A for graph in graphs]\n# convert labes fom Pandas.Series to numpy array\nlabels = graph_labels.to_numpy(dtype=int)\n\n\nimport numpy as np\nimport networkx as nx\n\nmetrics = []\nfor adj in adjs:\n    G = nx.from_numpy_matrix(adj)\n    # basic properties\n    num_edges = G.number_of_edges()\n    # clustering measures\n    cc = nx.average_clustering(G)\n    # measure of efficiency\n    eff = nx.global_efficiency(G)\n\n    metrics.append([num_edges, cc, eff])\n\n\nWe can now exploit scikit-learn utilities to create a train and test set. In our experiments, we will be using 70% of the dataset as training set and the remaining as testset\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(metrics, labels, test_size=0.3, random_state=42)\n\nAs commonly done in many Machine Learning workflows, we preprocess features to have zero mean and unit standard deviation\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaler.fit(X_train)\n\nX_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nIt’s now time for training a proper algorithm. We chose a support vector machine for this task\n\nfrom sklearn import svm\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nclf = svm.SVC()\nclf.fit(X_train_scaled, y_train)\n\ny_pred = clf.predict(X_test_scaled)\n\nprint('Accuracy', accuracy_score(y_test,y_pred))\nprint('Precision', precision_score(y_test,y_pred))\nprint('Recall', recall_score(y_test,y_pred))\nprint('F1-score', f1_score(y_test,y_pred))\n\nAccuracy 0.7455089820359282\nPrecision 0.7709251101321586\nRecall 0.8413461538461539\nF1-score 0.8045977011494253"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter04/04_Graph_Neural_Networks.html#supervised-node-representation-learning-using-graphsage",
    "href": "posts/2_Studies/GML/Chapter04/04_Graph_Neural_Networks.html#supervised-node-representation-learning-using-graphsage",
    "title": "[GML] Chap4: 지도 그래프 학습 - Graph CNN",
    "section": "Supervised node representation learning using GraphSAGE",
    "text": "Supervised node representation learning using GraphSAGE\n\nfrom stellargraph import datasets\nfrom IPython.display import display, HTML\n\ndataset = datasets.Cora()\ndisplay(HTML(dataset.description))\nG, nodes = dataset.load()\n\nThe Cora dataset consists of 2708 scientific publications classified into one of seven classes. The citation network consists of 5429 links. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 1433 unique words.\n\n\nLet’s split the dataset into training and testing set\n\nfrom sklearn.model_selection import train_test_split\ntrain_nodes, test_nodes = train_test_split(\n    nodes, train_size=0.1, test_size=None, stratify=nodes\n)\n\nSince we are performing a categorical classification, it is useful to represent each categorical label in its one-hot encoding\n\nfrom sklearn import preprocessing, feature_extraction, model_selection\nlabel_encoding = preprocessing.LabelBinarizer()\ntrain_labels = label_encoding.fit_transform(train_nodes)\ntest_labels = label_encoding.transform(test_nodes)\n\nIt’s now time for creating the mdoel. It will be composed by two GraphSAGE layers followed by a Dense layer with softmax activation for classification\n\nfrom stellargraph.mapper import GraphSAGENodeGenerator\nbatchsize = 50\nn_samples = [10, 5, 7]\ngenerator = GraphSAGENodeGenerator(G, batchsize, n_samples)\n\n\nfrom stellargraph.layer import GraphSAGE\nfrom tensorflow.keras.layers import Dense\n\ngraphsage_model = GraphSAGE(\n    layer_sizes=[32, 32, 16], generator=generator, bias=True, dropout=0.6,\n)\n\n\ngnn_inp, gnn_out = graphsage_model.in_out_tensors()\noutputs = Dense(units=train_labels.shape[1], activation=\"softmax\")(gnn_out)\n\n\nfrom tensorflow.keras.losses import categorical_crossentropy\nfrom keras.models import Model\nfrom keras.optimizers import Adam\n\nmodel = Model(inputs=gnn_inp, outputs=outputs)\nmodel.compile(optimizer=Adam(lr=0.003), loss=categorical_crossentropy, metrics=[\"acc\"],)\n\nWe will use the flow function of the generator for feeding the model with the train and the test set.\n\ntrain_gen = generator.flow(train_nodes.index, train_labels, shuffle=True)\ntest_gen = generator.flow(test_nodes.index, test_labels)\n\nFinally, let’s train the model!\n\nhistory = model.fit(train_gen, epochs=20, validation_data=test_gen, verbose=2, shuffle=False)"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter04/03_Graph_regularization_graph_neural_training.html",
    "href": "posts/2_Studies/GML/Chapter04/03_Graph_regularization_graph_neural_training.html",
    "title": "[GML] Chap4: 지도 그래프 학습 - 그래프 정규화 방법",
    "section": "",
    "text": "Neural Graph Learning and Graph Regularization\nIn this tutorial, we will be creating a graph regularized version for a topic classification task. The task is to classify paper depending on their content. However in order to do so, we will also use the information encoded in the citation network that relates documents among each other. Of course, we do know that this kind of information is indeed powerful as papers belonging to the same subject tend to reference each other.\n\nLoad Dataset\nFor this tutorial we will be using the Cora dataset available in the stellargraph library\n\nfrom stellargraph import datasets\n\n\ndataset = datasets.Cora()\n\n\n%config Completer.use_jedi = False\n\n\ndataset.download()\n\n\nlabel_index = {\n      'Case_Based': 0,\n      'Genetic_Algorithms': 1,\n      'Neural_Networks': 2,\n      'Probabilistic_Methods': 3,\n      'Reinforcement_Learning': 4,\n      'Rule_Learning': 5,\n      'Theory': 6,\n  }\n\n\nG, labels = dataset.load()\n\nWe now create the Dataset object where we will both include information of the targeted sample (node) and its neighbors. In the following we will also allow to control the number of labelling instances to be used, in order to reproduce and evaluate the classification performance in a semi-supervised setting.\n\nimport numpy as np\nfrom sklearn import preprocessing, feature_extraction, model_selection\n\n\nimport tensorflow as tf\nfrom tensorflow.train import Example, Features, Feature, Int64List, BytesList, FloatList\n\n\nGRAPH_PREFIX=\"NL_nbr\"\n\n\ndef _int64_feature(*value):\n    \"\"\"Returns int64 tf.train.Feature from a bool / enum / int / uint.\"\"\"\n    return Feature(int64_list=Int64List(value=list(value)))\n\ndef _bytes_feature(value):\n    \"\"\"Returns bytes tf.train.Feature from a string.\"\"\"\n    return Feature(\n        bytes_list=BytesList(value=[value.encode('utf-8')])\n    )\n\ndef _float_feature(*value):\n    return Feature(float_list=FloatList(value=list(value)))\n\n\nfrom functools import reduce\nfrom typing import List, Tuple\nimport pandas as pd\nimport six\n\ndef addFeatures(x, y):\n    res = Features()\n    res.CopyFrom(x)\n    res.MergeFrom(y)\n    return res\n\ndef neighborFeatures(features: Features, weight: float, prefix: str):\n    data = {f\"{prefix}_weight\": _float_feature(weight)}\n    for name, feature in six.iteritems(features.feature):\n        data[f\"{prefix}_{name}\"] = feature \n    return Features(feature=data)\n\ndef neighborsFeatures(neighbors: List[Tuple[Features, float]]):\n    return reduce(\n        addFeatures, \n        [neighborFeatures(sample, weight, f\"{GRAPH_PREFIX}_{ith}\") for ith, (sample, weight) in enumerate(neighbors)],\n        Features()\n    )\n\ndef getNeighbors(idx, adjMatrix, topn=5):\n    weights = adjMatrix.loc[idx]\n    return weights[weights>0].sort_values(ascending=False).head(topn).to_dict()\n    \n\ndef semisupervisedDataset(G, labels, ratio=0.2, topn=5):\n    n = int(np.round(len(labels)*ratio))\n    \n    labelled, unlabelled = model_selection.train_test_split(\n        labels, train_size=n, test_size=None, stratify=labels\n    )\n    \n    adjMatrix = pd.DataFrame.sparse.from_spmatrix(G.to_adjacency_matrix(), index=G.nodes(), columns=G.nodes())\n    \n    features = pd.DataFrame(G.node_features(), index=G.nodes())\n    \n    dataset = {\n        index: Features(feature = {\n            #\"id\": _bytes_feature(str(index)), \n            \"id\": _int64_feature(index),\n            \"words\": _float_feature(*[float(x) for x in features.loc[index].values]), \n            \"label\": _int64_feature(label_index[label])\n        })\n        for index, label in pd.concat([labelled, unlabelled]).items()\n    }\n    \n    trainingSet = [\n        Example(features=addFeatures(\n            dataset[exampleId], \n            neighborsFeatures(\n                [(dataset[nodeId], weight) for nodeId, weight in getNeighbors(exampleId, adjMatrix, topn).items()]\n            )\n        ))\n        for exampleId in labelled.index\n    ]\n    \n    testSet = [Example(features=dataset[exampleId]) for exampleId in unlabelled.index]\n\n    serializer = lambda _list: [e.SerializeToString() for e in _list]\n    \n    return serializer(trainingSet), serializer(testSet)\n\nWe split the dataset into a training set and a test set\n\ntrainingSet, testSet = semisupervisedDataset(G, labels)\n\n\nimport tensorflow as tf\n\n\nfrom tensorflow.data import Dataset\n\n\nvocabularySize = 1433\n\n\nneighbors=2\ndefaultWord = tf.constant(0, dtype=tf.float32, shape=[vocabularySize])\n\ndef parseExample(example, training=True):\n    schema = {\n        'words': tf.io.FixedLenFeature([vocabularySize], tf.float32, default_value=defaultWord),\n        'label': tf.io.FixedLenFeature((), tf.int64, default_value=-1)\n    }\n    \n    if training is True:\n        for i in range(neighbors):\n            name = f\"{GRAPH_PREFIX}_{i}\"\n            schema[f\"{name}_weight\"] = tf.io.FixedLenFeature([1], tf.float32, default_value=[0.0])\n            schema[f\"{name}_words\"] = tf.io.FixedLenFeature([vocabularySize], tf.float32, default_value=defaultWord)\n    \n    features = tf.io.parse_single_example(example, schema)\n    \n    label = features.pop(\"label\")\n    return features, label\n\n\ndef sampleGenerator(dataset):\n    def wrapper():\n        for example in dataset:\n            yield example\n    return wrapper\n            \nmyTrain = Dataset \\\n    .from_generator(sampleGenerator(trainingSet), output_types=tf.string, output_shapes=()) \\\n    .map(lambda x: parseExample(x, True))\n\nmyTest = Dataset \\\n    .from_generator(sampleGenerator(testSet), output_types=tf.string, output_shapes=()) \\\n    .map(lambda x: parseExample(x, False))\n\n\nfor features, labels in myTrain.batch(10).take(1):\n    print(features)\n    print(labels)\n\n{'NL_nbr_0_weight': <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\narray([[2.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [2.],\n       [1.],\n       [1.]], dtype=float32)>, 'NL_nbr_0_words': <tf.Tensor: shape=(10, 1433), dtype=float32, numpy=\narray([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, 'NL_nbr_1_weight': <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\narray([[1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.]], dtype=float32)>, 'NL_nbr_1_words': <tf.Tensor: shape=(10, 1433), dtype=float32, numpy=\narray([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, 'words': <tf.Tensor: shape=(10, 1433), dtype=float32, numpy=\narray([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>}\ntf.Tensor([1 1 4 1 0 5 2 1 6 3], shape=(10,), dtype=int64)\n\n\n\nfor features, labels in myTest.batch(10).take(1):\n    print(features)\n    print(labels)\n\n{'words': <tf.Tensor: shape=(10, 1433), dtype=float32, numpy=\narray([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>}\ntf.Tensor([1 1 3 3 2 4 5 3 2 6], shape=(10,), dtype=int64)\n\n\n\n\nCreating the model\nWe now create the model that we will use to classify the documents\n\nlayers = [50, 50]\n\n\n\"\"\"Creates a functional API-based multi-layer perceptron model.\"\"\"\ndef create_model(num_units):\n    inputs = tf.keras.Input(\n          shape=(vocabularySize,), dtype='float32', name='words'\n    )\n\n    # outputs = tf.keras.layers.Dense(len(label_index), activation='softmax')(inputs)\n\n    cur_layer =  inputs\n\n    for num_units in layers:\n        cur_layer = tf.keras.layers.Dense(num_units, activation='relu')(cur_layer)\n        cur_layer = tf.keras.layers.Dropout(0.8)(cur_layer)\n\n    outputs = tf.keras.layers.Dense(len(label_index), activation='softmax')(cur_layer)\n\n    return tf.keras.Model(inputs, outputs=outputs)\n\n\nfrom tensorflow.keras.callbacks import TensorBoard\n\n\nVanilla Model\nWe first train a simple, vanilla version that does not use the citation network information\n\nmodel = create_model([50, 50])\n\nmodel.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy'])\n\n\nmodel.summary()\n\nModel: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nwords (InputLayer)           [(None, 1433)]            0         \n_________________________________________________________________\ndense (Dense)                (None, 50)                71700     \n_________________________________________________________________\ndropout (Dropout)            (None, 50)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 50)                2550      \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 50)                0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 7)                 357       \n=================================================================\nTotal params: 74,607\nTrainable params: 74,607\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\nmodel.fit(myTrain.batch(128), epochs=200, verbose=1, validation_data=myTest.batch(128),\n          callbacks=[TensorBoard(log_dir='/tmp/noRegularization')])\n\nEpoch 1/200\n\n\n/Users/deusebio/.pyenv/versions/3.7.6/envs/ml-book-4/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['NL_nbr_0_weight', 'NL_nbr_0_words', 'NL_nbr_1_weight', 'NL_nbr_1_words'] which did not match any model input. They will be ignored by the model.\n  [n for n in tensors.keys() if n not in ref_input_names])\n\n\n5/5 [==============================] - 2s 323ms/step - loss: 1.9820 - accuracy: 0.1390 - val_loss: 1.9311 - val_accuracy: 0.2022\nEpoch 2/200\n5/5 [==============================] - 0s 114ms/step - loss: 1.9699 - accuracy: 0.1779 - val_loss: 1.9219 - val_accuracy: 0.2373\nEpoch 3/200\n5/5 [==============================] - 0s 117ms/step - loss: 1.9632 - accuracy: 0.1964 - val_loss: 1.9135 - val_accuracy: 0.2742\nEpoch 4/200\n5/5 [==============================] - 0s 106ms/step - loss: 2.0003 - accuracy: 0.1981 - val_loss: 1.9071 - val_accuracy: 0.2886\nEpoch 5/200\n5/5 [==============================] - 1s 117ms/step - loss: 1.9681 - accuracy: 0.1810 - val_loss: 1.9010 - val_accuracy: 0.2941\nEpoch 6/200\n5/5 [==============================] - 0s 117ms/step - loss: 1.8860 - accuracy: 0.2400 - val_loss: 1.8951 - val_accuracy: 0.3010\nEpoch 7/200\n5/5 [==============================] - 1s 124ms/step - loss: 1.8809 - accuracy: 0.2603 - val_loss: 1.8888 - val_accuracy: 0.3052\nEpoch 8/200\n5/5 [==============================] - 0s 111ms/step - loss: 1.8710 - accuracy: 0.2564 - val_loss: 1.8819 - val_accuracy: 0.3038\nEpoch 9/200\n5/5 [==============================] - 1s 130ms/step - loss: 1.8745 - accuracy: 0.2519 - val_loss: 1.8754 - val_accuracy: 0.3015\nEpoch 10/200\n5/5 [==============================] - 0s 111ms/step - loss: 1.8847 - accuracy: 0.2621 - val_loss: 1.8691 - val_accuracy: 0.3024\nEpoch 11/200\n5/5 [==============================] - 1s 117ms/step - loss: 1.8810 - accuracy: 0.2581 - val_loss: 1.8633 - val_accuracy: 0.3029\nEpoch 12/200\n5/5 [==============================] - 1s 124ms/step - loss: 1.8815 - accuracy: 0.2402 - val_loss: 1.8580 - val_accuracy: 0.3024\nEpoch 13/200\n5/5 [==============================] - 0s 109ms/step - loss: 1.8592 - accuracy: 0.2660 - val_loss: 1.8530 - val_accuracy: 0.3024\nEpoch 14/200\n5/5 [==============================] - 0s 106ms/step - loss: 1.8818 - accuracy: 0.2764 - val_loss: 1.8481 - val_accuracy: 0.3024\nEpoch 15/200\n5/5 [==============================] - 0s 112ms/step - loss: 1.8602 - accuracy: 0.2645 - val_loss: 1.8436 - val_accuracy: 0.3029\nEpoch 16/200\n5/5 [==============================] - 0s 110ms/step - loss: 1.8200 - accuracy: 0.2913 - val_loss: 1.8386 - val_accuracy: 0.3024\nEpoch 17/200\n5/5 [==============================] - 0s 105ms/step - loss: 1.7878 - accuracy: 0.2694 - val_loss: 1.8328 - val_accuracy: 0.3024\nEpoch 18/200\n5/5 [==============================] - 0s 104ms/step - loss: 1.8208 - accuracy: 0.2823 - val_loss: 1.8262 - val_accuracy: 0.3019\nEpoch 19/200\n5/5 [==============================] - 0s 116ms/step - loss: 1.8273 - accuracy: 0.2808 - val_loss: 1.8200 - val_accuracy: 0.3019\nEpoch 20/200\n5/5 [==============================] - 1s 122ms/step - loss: 1.8076 - accuracy: 0.2861 - val_loss: 1.8137 - val_accuracy: 0.3019\nEpoch 21/200\n5/5 [==============================] - 0s 112ms/step - loss: 1.7817 - accuracy: 0.2773 - val_loss: 1.8071 - val_accuracy: 0.3019\nEpoch 22/200\n5/5 [==============================] - 1s 148ms/step - loss: 1.7817 - accuracy: 0.2879 - val_loss: 1.7996 - val_accuracy: 0.3019\nEpoch 23/200\n5/5 [==============================] - 0s 106ms/step - loss: 1.8022 - accuracy: 0.2694 - val_loss: 1.7920 - val_accuracy: 0.3019\nEpoch 24/200\n5/5 [==============================] - 0s 113ms/step - loss: 1.7664 - accuracy: 0.2857 - val_loss: 1.7837 - val_accuracy: 0.3019\nEpoch 25/200\n5/5 [==============================] - 1s 118ms/step - loss: 1.7413 - accuracy: 0.3139 - val_loss: 1.7750 - val_accuracy: 0.3019\nEpoch 26/200\n5/5 [==============================] - 0s 111ms/step - loss: 1.7423 - accuracy: 0.2957 - val_loss: 1.7673 - val_accuracy: 0.3019\nEpoch 27/200\n5/5 [==============================] - 0s 104ms/step - loss: 1.7182 - accuracy: 0.3222 - val_loss: 1.7600 - val_accuracy: 0.3019\nEpoch 28/200\n5/5 [==============================] - 0s 109ms/step - loss: 1.7282 - accuracy: 0.3140 - val_loss: 1.7521 - val_accuracy: 0.3019\nEpoch 29/200\n5/5 [==============================] - 1s 132ms/step - loss: 1.7342 - accuracy: 0.2928 - val_loss: 1.7451 - val_accuracy: 0.3019\nEpoch 30/200\n5/5 [==============================] - 0s 116ms/step - loss: 1.6762 - accuracy: 0.3217 - val_loss: 1.7368 - val_accuracy: 0.3019\nEpoch 31/200\n5/5 [==============================] - 0s 106ms/step - loss: 1.7440 - accuracy: 0.2937 - val_loss: 1.7286 - val_accuracy: 0.3019\nEpoch 32/200\n5/5 [==============================] - 1s 119ms/step - loss: 1.7002 - accuracy: 0.2902 - val_loss: 1.7214 - val_accuracy: 0.3024\nEpoch 33/200\n5/5 [==============================] - 0s 106ms/step - loss: 1.6856 - accuracy: 0.3105 - val_loss: 1.7143 - val_accuracy: 0.3029\nEpoch 34/200\n5/5 [==============================] - 1s 120ms/step - loss: 1.6947 - accuracy: 0.2990 - val_loss: 1.7079 - val_accuracy: 0.3033\nEpoch 35/200\n5/5 [==============================] - 0s 107ms/step - loss: 1.6785 - accuracy: 0.3159 - val_loss: 1.7024 - val_accuracy: 0.3038\nEpoch 36/200\n5/5 [==============================] - 0s 117ms/step - loss: 1.6167 - accuracy: 0.3351 - val_loss: 1.6960 - val_accuracy: 0.3052\nEpoch 37/200\n5/5 [==============================] - 0s 114ms/step - loss: 1.6379 - accuracy: 0.3163 - val_loss: 1.6889 - val_accuracy: 0.3056\nEpoch 38/200\n5/5 [==============================] - 0s 117ms/step - loss: 1.6286 - accuracy: 0.3426 - val_loss: 1.6814 - val_accuracy: 0.3066\nEpoch 39/200\n5/5 [==============================] - 1s 118ms/step - loss: 1.6328 - accuracy: 0.3559 - val_loss: 1.6738 - val_accuracy: 0.3084\nEpoch 40/200\n5/5 [==============================] - 1s 118ms/step - loss: 1.6194 - accuracy: 0.3266 - val_loss: 1.6667 - val_accuracy: 0.3126\nEpoch 41/200\n5/5 [==============================] - 1s 117ms/step - loss: 1.5999 - accuracy: 0.3031 - val_loss: 1.6612 - val_accuracy: 0.3181\nEpoch 42/200\n5/5 [==============================] - 0s 111ms/step - loss: 1.6033 - accuracy: 0.3178 - val_loss: 1.6555 - val_accuracy: 0.3246\nEpoch 43/200\n5/5 [==============================] - 0s 111ms/step - loss: 1.6016 - accuracy: 0.3283 - val_loss: 1.6490 - val_accuracy: 0.3338\nEpoch 44/200\n5/5 [==============================] - 0s 107ms/step - loss: 1.5466 - accuracy: 0.3435 - val_loss: 1.6403 - val_accuracy: 0.3430\nEpoch 45/200\n5/5 [==============================] - 0s 107ms/step - loss: 1.5700 - accuracy: 0.3411 - val_loss: 1.6300 - val_accuracy: 0.3500\nEpoch 46/200\n5/5 [==============================] - 1s 152ms/step - loss: 1.5677 - accuracy: 0.3146 - val_loss: 1.6208 - val_accuracy: 0.3587\nEpoch 47/200\n5/5 [==============================] - 1s 163ms/step - loss: 1.5848 - accuracy: 0.3527 - val_loss: 1.6121 - val_accuracy: 0.3652\nEpoch 48/200\n5/5 [==============================] - 1s 159ms/step - loss: 1.5458 - accuracy: 0.3726 - val_loss: 1.6040 - val_accuracy: 0.3703\nEpoch 49/200\n5/5 [==============================] - 1s 128ms/step - loss: 1.5457 - accuracy: 0.3176 - val_loss: 1.5965 - val_accuracy: 0.3758\nEpoch 50/200\n5/5 [==============================] - 1s 143ms/step - loss: 1.5226 - accuracy: 0.3776 - val_loss: 1.5889 - val_accuracy: 0.3804\nEpoch 51/200\n5/5 [==============================] - 0s 113ms/step - loss: 1.5445 - accuracy: 0.3343 - val_loss: 1.5813 - val_accuracy: 0.3869\nEpoch 52/200\n5/5 [==============================] - 1s 127ms/step - loss: 1.5416 - accuracy: 0.3672 - val_loss: 1.5740 - val_accuracy: 0.3938\nEpoch 53/200\n5/5 [==============================] - 0s 113ms/step - loss: 1.4925 - accuracy: 0.3735 - val_loss: 1.5666 - val_accuracy: 0.3984\nEpoch 54/200\n5/5 [==============================] - 1s 120ms/step - loss: 1.4956 - accuracy: 0.3615 - val_loss: 1.5591 - val_accuracy: 0.4035\nEpoch 55/200\n5/5 [==============================] - 0s 108ms/step - loss: 1.5306 - accuracy: 0.3399 - val_loss: 1.5520 - val_accuracy: 0.4090\nEpoch 56/200\n5/5 [==============================] - 0s 115ms/step - loss: 1.4512 - accuracy: 0.3820 - val_loss: 1.5445 - val_accuracy: 0.4155\nEpoch 57/200\n5/5 [==============================] - 1s 131ms/step - loss: 1.4307 - accuracy: 0.3891 - val_loss: 1.5374 - val_accuracy: 0.4183\nEpoch 58/200\n5/5 [==============================] - 1s 120ms/step - loss: 1.4430 - accuracy: 0.3657 - val_loss: 1.5300 - val_accuracy: 0.4247\nEpoch 59/200\n5/5 [==============================] - 1s 143ms/step - loss: 1.4438 - accuracy: 0.3667 - val_loss: 1.5221 - val_accuracy: 0.4280\nEpoch 60/200\n5/5 [==============================] - 0s 112ms/step - loss: 1.4592 - accuracy: 0.3633 - val_loss: 1.5149 - val_accuracy: 0.4326\nEpoch 61/200\n5/5 [==============================] - 1s 182ms/step - loss: 1.4056 - accuracy: 0.3988 - val_loss: 1.5073 - val_accuracy: 0.4367\nEpoch 62/200\n5/5 [==============================] - 1s 125ms/step - loss: 1.4253 - accuracy: 0.3948 - val_loss: 1.5000 - val_accuracy: 0.4414\nEpoch 63/200\n5/5 [==============================] - 1s 149ms/step - loss: 1.3744 - accuracy: 0.4412 - val_loss: 1.4925 - val_accuracy: 0.4460\nEpoch 64/200\n5/5 [==============================] - 1s 133ms/step - loss: 1.3908 - accuracy: 0.4052 - val_loss: 1.4845 - val_accuracy: 0.4478\nEpoch 65/200\n5/5 [==============================] - 1s 119ms/step - loss: 1.3819 - accuracy: 0.4087 - val_loss: 1.4763 - val_accuracy: 0.4538\nEpoch 66/200\n5/5 [==============================] - 1s 130ms/step - loss: 1.3798 - accuracy: 0.4137 - val_loss: 1.4688 - val_accuracy: 0.4566\nEpoch 67/200\n5/5 [==============================] - 1s 125ms/step - loss: 1.3816 - accuracy: 0.4319 - val_loss: 1.4618 - val_accuracy: 0.4580\nEpoch 68/200\n5/5 [==============================] - 1s 122ms/step - loss: 1.3548 - accuracy: 0.4387 - val_loss: 1.4549 - val_accuracy: 0.4594\nEpoch 69/200\n5/5 [==============================] - 1s 144ms/step - loss: 1.3364 - accuracy: 0.4546 - val_loss: 1.4484 - val_accuracy: 0.4608\nEpoch 70/200\n5/5 [==============================] - 1s 137ms/step - loss: 1.3729 - accuracy: 0.4436 - val_loss: 1.4427 - val_accuracy: 0.4612\nEpoch 71/200\n5/5 [==============================] - 1s 142ms/step - loss: 1.3252 - accuracy: 0.4525 - val_loss: 1.4366 - val_accuracy: 0.4658\nEpoch 72/200\n5/5 [==============================] - 1s 125ms/step - loss: 1.3500 - accuracy: 0.4421 - val_loss: 1.4302 - val_accuracy: 0.4695\nEpoch 73/200\n5/5 [==============================] - 1s 121ms/step - loss: 1.2927 - accuracy: 0.4529 - val_loss: 1.4238 - val_accuracy: 0.4718\nEpoch 74/200\n5/5 [==============================] - 1s 129ms/step - loss: 1.2843 - accuracy: 0.4799 - val_loss: 1.4185 - val_accuracy: 0.4760\nEpoch 75/200\n5/5 [==============================] - 1s 140ms/step - loss: 1.2724 - accuracy: 0.5005 - val_loss: 1.4128 - val_accuracy: 0.4829\nEpoch 76/200\n5/5 [==============================] - 1s 119ms/step - loss: 1.3129 - accuracy: 0.4651 - val_loss: 1.4083 - val_accuracy: 0.4848\nEpoch 77/200\n5/5 [==============================] - 1s 121ms/step - loss: 1.2618 - accuracy: 0.4697 - val_loss: 1.4047 - val_accuracy: 0.4861\nEpoch 78/200\n5/5 [==============================] - 1s 140ms/step - loss: 1.2413 - accuracy: 0.5125 - val_loss: 1.4003 - val_accuracy: 0.4885\nEpoch 79/200\n5/5 [==============================] - 1s 118ms/step - loss: 1.2087 - accuracy: 0.5341 - val_loss: 1.3955 - val_accuracy: 0.4903\nEpoch 80/200\n5/5 [==============================] - 0s 117ms/step - loss: 1.2851 - accuracy: 0.4639 - val_loss: 1.3900 - val_accuracy: 0.4935\nEpoch 81/200\n5/5 [==============================] - 1s 155ms/step - loss: 1.2209 - accuracy: 0.5177 - val_loss: 1.3837 - val_accuracy: 0.4986\nEpoch 82/200\n5/5 [==============================] - 1s 165ms/step - loss: 1.1996 - accuracy: 0.5319 - val_loss: 1.3780 - val_accuracy: 0.5005\nEpoch 83/200\n5/5 [==============================] - 1s 136ms/step - loss: 1.2368 - accuracy: 0.4949 - val_loss: 1.3740 - val_accuracy: 0.5046\nEpoch 84/200\n5/5 [==============================] - 1s 128ms/step - loss: 1.2231 - accuracy: 0.5320 - val_loss: 1.3710 - val_accuracy: 0.5069\nEpoch 85/200\n5/5 [==============================] - 1s 124ms/step - loss: 1.2342 - accuracy: 0.5022 - val_loss: 1.3667 - val_accuracy: 0.5106\nEpoch 86/200\n5/5 [==============================] - 1s 121ms/step - loss: 1.2375 - accuracy: 0.4890 - val_loss: 1.3614 - val_accuracy: 0.5125\nEpoch 87/200\n5/5 [==============================] - 1s 126ms/step - loss: 1.2203 - accuracy: 0.5061 - val_loss: 1.3577 - val_accuracy: 0.5162\nEpoch 88/200\n5/5 [==============================] - 1s 120ms/step - loss: 1.2521 - accuracy: 0.5327 - val_loss: 1.3570 - val_accuracy: 0.5185\nEpoch 89/200\n5/5 [==============================] - 0s 117ms/step - loss: 1.1961 - accuracy: 0.5341 - val_loss: 1.3572 - val_accuracy: 0.5194\nEpoch 90/200\n5/5 [==============================] - 1s 123ms/step - loss: 1.1892 - accuracy: 0.5204 - val_loss: 1.3551 - val_accuracy: 0.5226\nEpoch 91/200\n5/5 [==============================] - 1s 137ms/step - loss: 1.1887 - accuracy: 0.5302 - val_loss: 1.3544 - val_accuracy: 0.5268\nEpoch 92/200\n5/5 [==============================] - 1s 125ms/step - loss: 1.1729 - accuracy: 0.5289 - val_loss: 1.3553 - val_accuracy: 0.5254\nEpoch 93/200\n5/5 [==============================] - 1s 129ms/step - loss: 1.1671 - accuracy: 0.5114 - val_loss: 1.3555 - val_accuracy: 0.5277\nEpoch 94/200\n5/5 [==============================] - 1s 121ms/step - loss: 1.1611 - accuracy: 0.5413 - val_loss: 1.3543 - val_accuracy: 0.5277\nEpoch 95/200\n5/5 [==============================] - 1s 156ms/step - loss: 1.1913 - accuracy: 0.5282 - val_loss: 1.3525 - val_accuracy: 0.5259\nEpoch 96/200\n5/5 [==============================] - 1s 168ms/step - loss: 1.1435 - accuracy: 0.5480 - val_loss: 1.3524 - val_accuracy: 0.5263\nEpoch 97/200\n5/5 [==============================] - 1s 130ms/step - loss: 1.1390 - accuracy: 0.5413 - val_loss: 1.3516 - val_accuracy: 0.5295\nEpoch 98/200\n5/5 [==============================] - 1s 120ms/step - loss: 1.1598 - accuracy: 0.5492 - val_loss: 1.3472 - val_accuracy: 0.5328\nEpoch 99/200\n5/5 [==============================] - 1s 122ms/step - loss: 1.1754 - accuracy: 0.4923 - val_loss: 1.3409 - val_accuracy: 0.5360\nEpoch 100/200\n5/5 [==============================] - 1s 126ms/step - loss: 1.1441 - accuracy: 0.5521 - val_loss: 1.3364 - val_accuracy: 0.5397\nEpoch 101/200\n5/5 [==============================] - 1s 140ms/step - loss: 1.1213 - accuracy: 0.5697 - val_loss: 1.3323 - val_accuracy: 0.5416\nEpoch 102/200\n5/5 [==============================] - 1s 125ms/step - loss: 1.1414 - accuracy: 0.5274 - val_loss: 1.3311 - val_accuracy: 0.5420\nEpoch 103/200\n5/5 [==============================] - 1s 151ms/step - loss: 1.0863 - accuracy: 0.5567 - val_loss: 1.3315 - val_accuracy: 0.5439\nEpoch 104/200\n5/5 [==============================] - 1s 132ms/step - loss: 1.0917 - accuracy: 0.5921 - val_loss: 1.3338 - val_accuracy: 0.5439\nEpoch 105/200\n5/5 [==============================] - 1s 130ms/step - loss: 1.1084 - accuracy: 0.5622 - val_loss: 1.3379 - val_accuracy: 0.5416\nEpoch 106/200\n5/5 [==============================] - 1s 130ms/step - loss: 1.0470 - accuracy: 0.5800 - val_loss: 1.3419 - val_accuracy: 0.5425\nEpoch 107/200\n5/5 [==============================] - 1s 124ms/step - loss: 1.0953 - accuracy: 0.5640 - val_loss: 1.3420 - val_accuracy: 0.5429\nEpoch 108/200\n5/5 [==============================] - 1s 133ms/step - loss: 1.0905 - accuracy: 0.5702 - val_loss: 1.3417 - val_accuracy: 0.5434\nEpoch 109/200\n5/5 [==============================] - 1s 140ms/step - loss: 1.1185 - accuracy: 0.5661 - val_loss: 1.3425 - val_accuracy: 0.5457\nEpoch 110/200\n5/5 [==============================] - 1s 129ms/step - loss: 1.0886 - accuracy: 0.5817 - val_loss: 1.3417 - val_accuracy: 0.5466\nEpoch 111/200\n5/5 [==============================] - 1s 132ms/step - loss: 1.0223 - accuracy: 0.6096 - val_loss: 1.3427 - val_accuracy: 0.5476\nEpoch 112/200\n5/5 [==============================] - 1s 130ms/step - loss: 1.0619 - accuracy: 0.5801 - val_loss: 1.3440 - val_accuracy: 0.5485\nEpoch 113/200\n5/5 [==============================] - 1s 125ms/step - loss: 1.0970 - accuracy: 0.5693 - val_loss: 1.3435 - val_accuracy: 0.5489\nEpoch 114/200\n5/5 [==============================] - 1s 122ms/step - loss: 1.0307 - accuracy: 0.5842 - val_loss: 1.3434 - val_accuracy: 0.5503\nEpoch 115/200\n5/5 [==============================] - 1s 128ms/step - loss: 1.0729 - accuracy: 0.5749 - val_loss: 1.3409 - val_accuracy: 0.5512\nEpoch 116/200\n5/5 [==============================] - 1s 132ms/step - loss: 1.0652 - accuracy: 0.5892 - val_loss: 1.3405 - val_accuracy: 0.5526\nEpoch 117/200\n5/5 [==============================] - 1s 146ms/step - loss: 1.0331 - accuracy: 0.5950 - val_loss: 1.3448 - val_accuracy: 0.5531\nEpoch 118/200\n5/5 [==============================] - 1s 137ms/step - loss: 1.0661 - accuracy: 0.6041 - val_loss: 1.3518 - val_accuracy: 0.5536\nEpoch 119/200\n5/5 [==============================] - 1s 127ms/step - loss: 1.0243 - accuracy: 0.6106 - val_loss: 1.3588 - val_accuracy: 0.5512\nEpoch 120/200\n5/5 [==============================] - 1s 129ms/step - loss: 0.9959 - accuracy: 0.6434 - val_loss: 1.3643 - val_accuracy: 0.5508\nEpoch 121/200\n5/5 [==============================] - 1s 127ms/step - loss: 1.0377 - accuracy: 0.6012 - val_loss: 1.3699 - val_accuracy: 0.5503\nEpoch 122/200\n5/5 [==============================] - 1s 129ms/step - loss: 1.0587 - accuracy: 0.5726 - val_loss: 1.3722 - val_accuracy: 0.5512\nEpoch 123/200\n5/5 [==============================] - 1s 137ms/step - loss: 1.0212 - accuracy: 0.5867 - val_loss: 1.3694 - val_accuracy: 0.5536\nEpoch 124/200\n5/5 [==============================] - 1s 189ms/step - loss: 1.0011 - accuracy: 0.6239 - val_loss: 1.3711 - val_accuracy: 0.5522\nEpoch 125/200\n5/5 [==============================] - 1s 141ms/step - loss: 0.9889 - accuracy: 0.6348 - val_loss: 1.3728 - val_accuracy: 0.5536\nEpoch 126/200\n5/5 [==============================] - 1s 181ms/step - loss: 1.0428 - accuracy: 0.5786 - val_loss: 1.3751 - val_accuracy: 0.5522\nEpoch 127/200\n5/5 [==============================] - 1s 135ms/step - loss: 0.9908 - accuracy: 0.6201 - val_loss: 1.3732 - val_accuracy: 0.5545\nEpoch 128/200\n5/5 [==============================] - 1s 181ms/step - loss: 1.0277 - accuracy: 0.5775 - val_loss: 1.3710 - val_accuracy: 0.5572\nEpoch 129/200\n5/5 [==============================] - 1s 165ms/step - loss: 0.9862 - accuracy: 0.6151 - val_loss: 1.3746 - val_accuracy: 0.5568\nEpoch 130/200\n5/5 [==============================] - 1s 167ms/step - loss: 0.9637 - accuracy: 0.6345 - val_loss: 1.3762 - val_accuracy: 0.5572\nEpoch 131/200\n5/5 [==============================] - 1s 140ms/step - loss: 0.9107 - accuracy: 0.6454 - val_loss: 1.3763 - val_accuracy: 0.5591\nEpoch 132/200\n5/5 [==============================] - 1s 137ms/step - loss: 1.0057 - accuracy: 0.6081 - val_loss: 1.3782 - val_accuracy: 0.5605\nEpoch 133/200\n5/5 [==============================] - 1s 128ms/step - loss: 0.9786 - accuracy: 0.6209 - val_loss: 1.3788 - val_accuracy: 0.5623\nEpoch 134/200\n5/5 [==============================] - 1s 123ms/step - loss: 1.0011 - accuracy: 0.5990 - val_loss: 1.3778 - val_accuracy: 0.5651\nEpoch 135/200\n5/5 [==============================] - 1s 125ms/step - loss: 0.9755 - accuracy: 0.6250 - val_loss: 1.3808 - val_accuracy: 0.5660\nEpoch 136/200\n5/5 [==============================] - 1s 126ms/step - loss: 0.9770 - accuracy: 0.6175 - val_loss: 1.3842 - val_accuracy: 0.5660\nEpoch 137/200\n5/5 [==============================] - 1s 127ms/step - loss: 0.9876 - accuracy: 0.6137 - val_loss: 1.3843 - val_accuracy: 0.5679\nEpoch 138/200\n5/5 [==============================] - 1s 136ms/step - loss: 0.9466 - accuracy: 0.6355 - val_loss: 1.3863 - val_accuracy: 0.5683\nEpoch 139/200\n5/5 [==============================] - 1s 130ms/step - loss: 0.9569 - accuracy: 0.6377 - val_loss: 1.3873 - val_accuracy: 0.5679\nEpoch 140/200\n5/5 [==============================] - 1s 129ms/step - loss: 0.9659 - accuracy: 0.6065 - val_loss: 1.3893 - val_accuracy: 0.5693\nEpoch 141/200\n5/5 [==============================] - 1s 139ms/step - loss: 0.9756 - accuracy: 0.6249 - val_loss: 1.3956 - val_accuracy: 0.5674\nEpoch 142/200\n5/5 [==============================] - 1s 131ms/step - loss: 0.9219 - accuracy: 0.6481 - val_loss: 1.4022 - val_accuracy: 0.5674\nEpoch 143/200\n5/5 [==============================] - 1s 130ms/step - loss: 0.9725 - accuracy: 0.6032 - val_loss: 1.4084 - val_accuracy: 0.5683\nEpoch 144/200\n5/5 [==============================] - 1s 138ms/step - loss: 0.9968 - accuracy: 0.6080 - val_loss: 1.4106 - val_accuracy: 0.5693\nEpoch 145/200\n5/5 [==============================] - 1s 129ms/step - loss: 0.9467 - accuracy: 0.6306 - val_loss: 1.4139 - val_accuracy: 0.5688\nEpoch 146/200\n5/5 [==============================] - 1s 130ms/step - loss: 0.9845 - accuracy: 0.5994 - val_loss: 1.4185 - val_accuracy: 0.5683\nEpoch 147/200\n5/5 [==============================] - 1s 127ms/step - loss: 0.9523 - accuracy: 0.6219 - val_loss: 1.4186 - val_accuracy: 0.5702\nEpoch 148/200\n5/5 [==============================] - 1s 129ms/step - loss: 0.8707 - accuracy: 0.6598 - val_loss: 1.4205 - val_accuracy: 0.5716\nEpoch 149/200\n5/5 [==============================] - 1s 123ms/step - loss: 0.8485 - accuracy: 0.6838 - val_loss: 1.4247 - val_accuracy: 0.5716\nEpoch 150/200\n5/5 [==============================] - 1s 135ms/step - loss: 0.9404 - accuracy: 0.6376 - val_loss: 1.4308 - val_accuracy: 0.5702\nEpoch 151/200\n5/5 [==============================] - 1s 128ms/step - loss: 0.9460 - accuracy: 0.6284 - val_loss: 1.4369 - val_accuracy: 0.5697\nEpoch 152/200\n5/5 [==============================] - 1s 132ms/step - loss: 0.9460 - accuracy: 0.6174 - val_loss: 1.4409 - val_accuracy: 0.5725\nEpoch 153/200\n5/5 [==============================] - 1s 128ms/step - loss: 0.9012 - accuracy: 0.6378 - val_loss: 1.4443 - val_accuracy: 0.5716\nEpoch 154/200\n5/5 [==============================] - 1s 128ms/step - loss: 0.9226 - accuracy: 0.6226 - val_loss: 1.4550 - val_accuracy: 0.5720\nEpoch 155/200\n5/5 [==============================] - 1s 130ms/step - loss: 0.9105 - accuracy: 0.6375 - val_loss: 1.4706 - val_accuracy: 0.5697\nEpoch 156/200\n5/5 [==============================] - 1s 157ms/step - loss: 0.8782 - accuracy: 0.6690 - val_loss: 1.4826 - val_accuracy: 0.5683\nEpoch 157/200\n5/5 [==============================] - 1s 129ms/step - loss: 0.9039 - accuracy: 0.6218 - val_loss: 1.4903 - val_accuracy: 0.5674\nEpoch 158/200\n5/5 [==============================] - 1s 135ms/step - loss: 0.9291 - accuracy: 0.6337 - val_loss: 1.4911 - val_accuracy: 0.5697\nEpoch 159/200\n5/5 [==============================] - 1s 122ms/step - loss: 0.9176 - accuracy: 0.6366 - val_loss: 1.4898 - val_accuracy: 0.5693\nEpoch 160/200\n5/5 [==============================] - 1s 134ms/step - loss: 0.8564 - accuracy: 0.6516 - val_loss: 1.4861 - val_accuracy: 0.5706\nEpoch 161/200\n5/5 [==============================] - 1s 127ms/step - loss: 0.8857 - accuracy: 0.6542 - val_loss: 1.4837 - val_accuracy: 0.5739\nEpoch 162/200\n5/5 [==============================] - 1s 128ms/step - loss: 0.8963 - accuracy: 0.6515 - val_loss: 1.4879 - val_accuracy: 0.5748\nEpoch 163/200\n5/5 [==============================] - 1s 125ms/step - loss: 0.8920 - accuracy: 0.6548 - val_loss: 1.4925 - val_accuracy: 0.5753\nEpoch 164/200\n5/5 [==============================] - 1s 123ms/step - loss: 0.8300 - accuracy: 0.6915 - val_loss: 1.5003 - val_accuracy: 0.5753\nEpoch 165/200\n5/5 [==============================] - 1s 133ms/step - loss: 0.9243 - accuracy: 0.6382 - val_loss: 1.5114 - val_accuracy: 0.5720\nEpoch 166/200\n5/5 [==============================] - 1s 122ms/step - loss: 0.8374 - accuracy: 0.6702 - val_loss: 1.5212 - val_accuracy: 0.5716\nEpoch 167/200\n5/5 [==============================] - 1s 127ms/step - loss: 0.8366 - accuracy: 0.6680 - val_loss: 1.5251 - val_accuracy: 0.5702\nEpoch 168/200\n5/5 [==============================] - 1s 130ms/step - loss: 0.8265 - accuracy: 0.6612 - val_loss: 1.5247 - val_accuracy: 0.5734\nEpoch 169/200\n5/5 [==============================] - 1s 138ms/step - loss: 0.8960 - accuracy: 0.6386 - val_loss: 1.5208 - val_accuracy: 0.5757\nEpoch 170/200\n5/5 [==============================] - 1s 144ms/step - loss: 0.8747 - accuracy: 0.6373 - val_loss: 1.5191 - val_accuracy: 0.5771\nEpoch 171/200\n5/5 [==============================] - 1s 214ms/step - loss: 0.8566 - accuracy: 0.6471 - val_loss: 1.5159 - val_accuracy: 0.5803\nEpoch 172/200\n5/5 [==============================] - 1s 143ms/step - loss: 0.8520 - accuracy: 0.6547 - val_loss: 1.5122 - val_accuracy: 0.5799\nEpoch 173/200\n5/5 [==============================] - 1s 241ms/step - loss: 0.8766 - accuracy: 0.6567 - val_loss: 1.5082 - val_accuracy: 0.5822\nEpoch 174/200\n5/5 [==============================] - 1s 219ms/step - loss: 0.7819 - accuracy: 0.7044 - val_loss: 1.5063 - val_accuracy: 0.5822\nEpoch 175/200\n5/5 [==============================] - 1s 184ms/step - loss: 0.8579 - accuracy: 0.6566 - val_loss: 1.5071 - val_accuracy: 0.5822\nEpoch 176/200\n5/5 [==============================] - 1s 186ms/step - loss: 0.8649 - accuracy: 0.6656 - val_loss: 1.5106 - val_accuracy: 0.5813\nEpoch 177/200\n5/5 [==============================] - 1s 193ms/step - loss: 0.8462 - accuracy: 0.6377 - val_loss: 1.5143 - val_accuracy: 0.5826\nEpoch 178/200\n5/5 [==============================] - 1s 175ms/step - loss: 0.8405 - accuracy: 0.6676 - val_loss: 1.5171 - val_accuracy: 0.5845\nEpoch 179/200\n5/5 [==============================] - 1s 183ms/step - loss: 0.8065 - accuracy: 0.6713 - val_loss: 1.5199 - val_accuracy: 0.5831\nEpoch 180/200\n5/5 [==============================] - 1s 162ms/step - loss: 0.8850 - accuracy: 0.6369 - val_loss: 1.5232 - val_accuracy: 0.5831\nEpoch 181/200\n5/5 [==============================] - 1s 216ms/step - loss: 0.8796 - accuracy: 0.6546 - val_loss: 1.5259 - val_accuracy: 0.5826\nEpoch 182/200\n5/5 [==============================] - 1s 162ms/step - loss: 0.7898 - accuracy: 0.6730 - val_loss: 1.5311 - val_accuracy: 0.5826\nEpoch 183/200\n5/5 [==============================] - 1s 159ms/step - loss: 0.7982 - accuracy: 0.6828 - val_loss: 1.5380 - val_accuracy: 0.5836\nEpoch 184/200\n5/5 [==============================] - 1s 156ms/step - loss: 0.8291 - accuracy: 0.6792 - val_loss: 1.5468 - val_accuracy: 0.5836\nEpoch 185/200\n5/5 [==============================] - 1s 144ms/step - loss: 0.8375 - accuracy: 0.6788 - val_loss: 1.5529 - val_accuracy: 0.5840\nEpoch 186/200\n5/5 [==============================] - 1s 143ms/step - loss: 0.8144 - accuracy: 0.6788 - val_loss: 1.5538 - val_accuracy: 0.5840\nEpoch 187/200\n5/5 [==============================] - 1s 130ms/step - loss: 0.8369 - accuracy: 0.6873 - val_loss: 1.5555 - val_accuracy: 0.5836\nEpoch 188/200\n5/5 [==============================] - 1s 130ms/step - loss: 0.8426 - accuracy: 0.6679 - val_loss: 1.5574 - val_accuracy: 0.5849\nEpoch 189/200\n5/5 [==============================] - 1s 144ms/step - loss: 0.7954 - accuracy: 0.6879 - val_loss: 1.5557 - val_accuracy: 0.5863\nEpoch 190/200\n5/5 [==============================] - 1s 131ms/step - loss: 0.7880 - accuracy: 0.6742 - val_loss: 1.5611 - val_accuracy: 0.5854\nEpoch 191/200\n5/5 [==============================] - 1s 172ms/step - loss: 0.8489 - accuracy: 0.6390 - val_loss: 1.5656 - val_accuracy: 0.5863\nEpoch 192/200\n5/5 [==============================] - 1s 175ms/step - loss: 0.8292 - accuracy: 0.6736 - val_loss: 1.5664 - val_accuracy: 0.5854\nEpoch 193/200\n5/5 [==============================] - 1s 151ms/step - loss: 0.7881 - accuracy: 0.6958 - val_loss: 1.5735 - val_accuracy: 0.5854\nEpoch 194/200\n5/5 [==============================] - 1s 145ms/step - loss: 0.8304 - accuracy: 0.6515 - val_loss: 1.5778 - val_accuracy: 0.5845\nEpoch 195/200\n5/5 [==============================] - 1s 217ms/step - loss: 0.7969 - accuracy: 0.6696 - val_loss: 1.5797 - val_accuracy: 0.5840\nEpoch 196/200\n5/5 [==============================] - 1s 183ms/step - loss: 0.7856 - accuracy: 0.6726 - val_loss: 1.5763 - val_accuracy: 0.5854\nEpoch 197/200\n5/5 [==============================] - 1s 170ms/step - loss: 0.7966 - accuracy: 0.6883 - val_loss: 1.5783 - val_accuracy: 0.5859\nEpoch 198/200\n5/5 [==============================] - 1s 147ms/step - loss: 0.8072 - accuracy: 0.6626 - val_loss: 1.5819 - val_accuracy: 0.5854\nEpoch 199/200\n5/5 [==============================] - 1s 135ms/step - loss: 0.7893 - accuracy: 0.6858 - val_loss: 1.5884 - val_accuracy: 0.5849\nEpoch 200/200\n5/5 [==============================] - 1s 154ms/step - loss: 0.7798 - accuracy: 0.6795 - val_loss: 1.5948 - val_accuracy: 0.5873\n\n\n<tensorflow.python.keras.callbacks.History at 0x14e4a9290>\n\n\n\n\nGraph Regularized Version\nWe now create the graph-regularized version that uses the citation network information\n\nbase_model = create_model([50, 50])\n\n\nimport neural_structured_learning as nsl\n\n\ngraph_reg_config = nsl.configs.make_graph_reg_config(\n    max_neighbors=2,\n    multiplier=0.1,\n    distance_type=nsl.configs.DistanceType.L2,\n    sum_over_axis=-1)\ngraph_reg_model = nsl.keras.GraphRegularization(base_model,\n                                                graph_reg_config)\ngraph_reg_model.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy'])\n#graph_reg_model.fit(train_dataset, epochs=200, verbose=1)\n\n\ngraph_reg_model.fit(myTrain.batch(128), epochs=200, verbose=1, validation_data=myTest.batch(128),\n          callbacks=[TensorBoard(log_dir='/tmp/regularization')])\n\nEpoch 1/200\n\n\n/Users/deusebio/.pyenv/versions/3.7.6/envs/ml-book-4/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape:0\", shape=(None, 7), dtype=float32), dense_shape=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n  \"shape. This may consume a large amount of memory.\" % value)\n\n\n5/5 [==============================] - 4s 328ms/step - loss: 2.1052 - accuracy: 0.1049 - scaled_graph_loss: 0.0056 - val_loss: 1.9455 - val_accuracy: 0.1440\nEpoch 2/200\n5/5 [==============================] - 1s 179ms/step - loss: 2.0342 - accuracy: 0.1722 - scaled_graph_loss: 0.0047 - val_loss: 1.9367 - val_accuracy: 0.1934\nEpoch 3/200\n5/5 [==============================] - 1s 156ms/step - loss: 1.9881 - accuracy: 0.1603 - scaled_graph_loss: 0.0039 - val_loss: 1.9293 - val_accuracy: 0.2355\nEpoch 4/200\n5/5 [==============================] - 1s 178ms/step - loss: 1.9918 - accuracy: 0.1816 - scaled_graph_loss: 0.0035 - val_loss: 1.9224 - val_accuracy: 0.2770\nEpoch 5/200\n5/5 [==============================] - 1s 162ms/step - loss: 1.9551 - accuracy: 0.1983 - scaled_graph_loss: 0.0029 - val_loss: 1.9165 - val_accuracy: 0.2978\nEpoch 6/200\n5/5 [==============================] - 1s 156ms/step - loss: 1.9745 - accuracy: 0.1918 - scaled_graph_loss: 0.0028 - val_loss: 1.9113 - val_accuracy: 0.3033\nEpoch 7/200\n5/5 [==============================] - 1s 170ms/step - loss: 1.9490 - accuracy: 0.1762 - scaled_graph_loss: 0.0023 - val_loss: 1.9068 - val_accuracy: 0.3075\nEpoch 8/200\n5/5 [==============================] - 1s 218ms/step - loss: 1.9262 - accuracy: 0.2016 - scaled_graph_loss: 0.0025 - val_loss: 1.9025 - val_accuracy: 0.3112\nEpoch 9/200\n5/5 [==============================] - 1s 208ms/step - loss: 1.9413 - accuracy: 0.2383 - scaled_graph_loss: 0.0023 - val_loss: 1.8983 - val_accuracy: 0.3066\nEpoch 10/200\n5/5 [==============================] - 1s 170ms/step - loss: 1.9136 - accuracy: 0.2278 - scaled_graph_loss: 0.0022 - val_loss: 1.8942 - val_accuracy: 0.3061\nEpoch 11/200\n5/5 [==============================] - 1s 154ms/step - loss: 1.9232 - accuracy: 0.2413 - scaled_graph_loss: 0.0022 - val_loss: 1.8900 - val_accuracy: 0.3066\nEpoch 12/200\n5/5 [==============================] - 1s 157ms/step - loss: 1.8885 - accuracy: 0.2682 - scaled_graph_loss: 0.0022 - val_loss: 1.8857 - val_accuracy: 0.3052\nEpoch 13/200\n5/5 [==============================] - 1s 192ms/step - loss: 1.8657 - accuracy: 0.2789 - scaled_graph_loss: 0.0021 - val_loss: 1.8813 - val_accuracy: 0.3052\nEpoch 14/200\n5/5 [==============================] - 1s 178ms/step - loss: 1.9115 - accuracy: 0.2158 - scaled_graph_loss: 0.0022 - val_loss: 1.8771 - val_accuracy: 0.3033\nEpoch 15/200\n5/5 [==============================] - 1s 174ms/step - loss: 1.8700 - accuracy: 0.2652 - scaled_graph_loss: 0.0020 - val_loss: 1.8725 - val_accuracy: 0.3029\nEpoch 16/200\n5/5 [==============================] - 1s 154ms/step - loss: 1.8883 - accuracy: 0.2607 - scaled_graph_loss: 0.0026 - val_loss: 1.8676 - val_accuracy: 0.3024\nEpoch 17/200\n5/5 [==============================] - 1s 141ms/step - loss: 1.8588 - accuracy: 0.2631 - scaled_graph_loss: 0.0025 - val_loss: 1.8625 - val_accuracy: 0.3019\nEpoch 18/200\n5/5 [==============================] - 1s 152ms/step - loss: 1.8774 - accuracy: 0.2593 - scaled_graph_loss: 0.0026 - val_loss: 1.8577 - val_accuracy: 0.3019\nEpoch 19/200\n5/5 [==============================] - 1s 187ms/step - loss: 1.8376 - accuracy: 0.2726 - scaled_graph_loss: 0.0028 - val_loss: 1.8530 - val_accuracy: 0.3019\nEpoch 20/200\n5/5 [==============================] - 1s 146ms/step - loss: 1.8590 - accuracy: 0.3045 - scaled_graph_loss: 0.0030 - val_loss: 1.8485 - val_accuracy: 0.3019\nEpoch 21/200\n5/5 [==============================] - 1s 204ms/step - loss: 1.8240 - accuracy: 0.2647 - scaled_graph_loss: 0.0028 - val_loss: 1.8439 - val_accuracy: 0.3019\nEpoch 22/200\n5/5 [==============================] - 1s 159ms/step - loss: 1.8541 - accuracy: 0.2940 - scaled_graph_loss: 0.0032 - val_loss: 1.8397 - val_accuracy: 0.3019\nEpoch 23/200\n5/5 [==============================] - 1s 208ms/step - loss: 1.8121 - accuracy: 0.3230 - scaled_graph_loss: 0.0034 - val_loss: 1.8350 - val_accuracy: 0.3019\nEpoch 24/200\n5/5 [==============================] - 1s 189ms/step - loss: 1.8325 - accuracy: 0.2986 - scaled_graph_loss: 0.0032 - val_loss: 1.8304 - val_accuracy: 0.3019\nEpoch 25/200\n5/5 [==============================] - 1s 170ms/step - loss: 1.8066 - accuracy: 0.2818 - scaled_graph_loss: 0.0032 - val_loss: 1.8254 - val_accuracy: 0.3019\nEpoch 26/200\n5/5 [==============================] - 1s 204ms/step - loss: 1.8389 - accuracy: 0.2880 - scaled_graph_loss: 0.0036 - val_loss: 1.8211 - val_accuracy: 0.3019\nEpoch 27/200\n5/5 [==============================] - 1s 208ms/step - loss: 1.8070 - accuracy: 0.3068 - scaled_graph_loss: 0.0034 - val_loss: 1.8168 - val_accuracy: 0.3024\nEpoch 28/200\n5/5 [==============================] - 1s 171ms/step - loss: 1.8070 - accuracy: 0.2909 - scaled_graph_loss: 0.0038 - val_loss: 1.8122 - val_accuracy: 0.3024\nEpoch 29/200\n5/5 [==============================] - 1s 167ms/step - loss: 1.7793 - accuracy: 0.2947 - scaled_graph_loss: 0.0046 - val_loss: 1.8069 - val_accuracy: 0.3024\nEpoch 30/200\n5/5 [==============================] - 1s 168ms/step - loss: 1.7738 - accuracy: 0.2886 - scaled_graph_loss: 0.0048 - val_loss: 1.8016 - val_accuracy: 0.3024\nEpoch 31/200\n5/5 [==============================] - 1s 156ms/step - loss: 1.7596 - accuracy: 0.3011 - scaled_graph_loss: 0.0043 - val_loss: 1.7957 - val_accuracy: 0.3024\nEpoch 32/200\n5/5 [==============================] - 1s 261ms/step - loss: 1.7768 - accuracy: 0.3165 - scaled_graph_loss: 0.0053 - val_loss: 1.7900 - val_accuracy: 0.3024\nEpoch 33/200\n5/5 [==============================] - 1s 196ms/step - loss: 1.7419 - accuracy: 0.3019 - scaled_graph_loss: 0.0052 - val_loss: 1.7840 - val_accuracy: 0.3024\nEpoch 34/200\n5/5 [==============================] - 1s 177ms/step - loss: 1.7615 - accuracy: 0.2834 - scaled_graph_loss: 0.0060 - val_loss: 1.7783 - val_accuracy: 0.3024\nEpoch 35/200\n5/5 [==============================] - 1s 168ms/step - loss: 1.7419 - accuracy: 0.3210 - scaled_graph_loss: 0.0057 - val_loss: 1.7730 - val_accuracy: 0.3024\nEpoch 36/200\n5/5 [==============================] - 1s 179ms/step - loss: 1.7253 - accuracy: 0.3277 - scaled_graph_loss: 0.0061 - val_loss: 1.7670 - val_accuracy: 0.3024\nEpoch 37/200\n5/5 [==============================] - 1s 212ms/step - loss: 1.7170 - accuracy: 0.3362 - scaled_graph_loss: 0.0061 - val_loss: 1.7608 - val_accuracy: 0.3024\nEpoch 38/200\n5/5 [==============================] - 1s 212ms/step - loss: 1.7038 - accuracy: 0.3185 - scaled_graph_loss: 0.0064 - val_loss: 1.7548 - val_accuracy: 0.3024\nEpoch 39/200\n5/5 [==============================] - 1s 207ms/step - loss: 1.7044 - accuracy: 0.3301 - scaled_graph_loss: 0.0065 - val_loss: 1.7491 - val_accuracy: 0.3024\nEpoch 40/200\n5/5 [==============================] - 1s 152ms/step - loss: 1.7011 - accuracy: 0.3390 - scaled_graph_loss: 0.0069 - val_loss: 1.7428 - val_accuracy: 0.3029\nEpoch 41/200\n5/5 [==============================] - 1s 192ms/step - loss: 1.6931 - accuracy: 0.3415 - scaled_graph_loss: 0.0075 - val_loss: 1.7368 - val_accuracy: 0.3042\nEpoch 42/200\n5/5 [==============================] - 1s 159ms/step - loss: 1.7035 - accuracy: 0.3211 - scaled_graph_loss: 0.0074 - val_loss: 1.7310 - val_accuracy: 0.3038\nEpoch 43/200\n5/5 [==============================] - 1s 151ms/step - loss: 1.6884 - accuracy: 0.3293 - scaled_graph_loss: 0.0075 - val_loss: 1.7258 - val_accuracy: 0.3047\nEpoch 44/200\n5/5 [==============================] - 1s 148ms/step - loss: 1.7046 - accuracy: 0.3319 - scaled_graph_loss: 0.0079 - val_loss: 1.7206 - val_accuracy: 0.3047\nEpoch 45/200\n5/5 [==============================] - 1s 151ms/step - loss: 1.6325 - accuracy: 0.3369 - scaled_graph_loss: 0.0082 - val_loss: 1.7141 - val_accuracy: 0.3052\nEpoch 46/200\n5/5 [==============================] - 1s 167ms/step - loss: 1.6682 - accuracy: 0.3413 - scaled_graph_loss: 0.0082 - val_loss: 1.7070 - val_accuracy: 0.3061\nEpoch 47/200\n5/5 [==============================] - 1s 164ms/step - loss: 1.5976 - accuracy: 0.3434 - scaled_graph_loss: 0.0094 - val_loss: 1.6997 - val_accuracy: 0.3066\nEpoch 48/200\n5/5 [==============================] - 1s 183ms/step - loss: 1.6572 - accuracy: 0.3536 - scaled_graph_loss: 0.0093 - val_loss: 1.6933 - val_accuracy: 0.3084\nEpoch 49/200\n5/5 [==============================] - 1s 159ms/step - loss: 1.6508 - accuracy: 0.3540 - scaled_graph_loss: 0.0098 - val_loss: 1.6861 - val_accuracy: 0.3112\nEpoch 50/200\n5/5 [==============================] - 1s 148ms/step - loss: 1.6408 - accuracy: 0.3250 - scaled_graph_loss: 0.0097 - val_loss: 1.6793 - val_accuracy: 0.3149\nEpoch 51/200\n5/5 [==============================] - 1s 181ms/step - loss: 1.6336 - accuracy: 0.3462 - scaled_graph_loss: 0.0092 - val_loss: 1.6736 - val_accuracy: 0.3190\nEpoch 52/200\n5/5 [==============================] - 1s 227ms/step - loss: 1.6309 - accuracy: 0.3321 - scaled_graph_loss: 0.0103 - val_loss: 1.6677 - val_accuracy: 0.3236\nEpoch 53/200\n5/5 [==============================] - 1s 271ms/step - loss: 1.6388 - accuracy: 0.3596 - scaled_graph_loss: 0.0111 - val_loss: 1.6628 - val_accuracy: 0.3287\nEpoch 54/200\n5/5 [==============================] - 1s 178ms/step - loss: 1.5818 - accuracy: 0.3541 - scaled_graph_loss: 0.0103 - val_loss: 1.6570 - val_accuracy: 0.3338\nEpoch 55/200\n5/5 [==============================] - 1s 272ms/step - loss: 1.5723 - accuracy: 0.3685 - scaled_graph_loss: 0.0109 - val_loss: 1.6503 - val_accuracy: 0.3398\nEpoch 56/200\n5/5 [==============================] - 1s 220ms/step - loss: 1.5742 - accuracy: 0.3803 - scaled_graph_loss: 0.0103 - val_loss: 1.6434 - val_accuracy: 0.3467\nEpoch 57/200\n5/5 [==============================] - 1s 200ms/step - loss: 1.5509 - accuracy: 0.3862 - scaled_graph_loss: 0.0114 - val_loss: 1.6370 - val_accuracy: 0.3578\nEpoch 58/200\n5/5 [==============================] - 1s 168ms/step - loss: 1.5821 - accuracy: 0.3674 - scaled_graph_loss: 0.0117 - val_loss: 1.6305 - val_accuracy: 0.3638\nEpoch 59/200\n5/5 [==============================] - 1s 151ms/step - loss: 1.5852 - accuracy: 0.3616 - scaled_graph_loss: 0.0118 - val_loss: 1.6237 - val_accuracy: 0.3698\nEpoch 60/200\n5/5 [==============================] - 1s 140ms/step - loss: 1.5499 - accuracy: 0.3611 - scaled_graph_loss: 0.0115 - val_loss: 1.6169 - val_accuracy: 0.3726\nEpoch 61/200\n5/5 [==============================] - 1s 156ms/step - loss: 1.5457 - accuracy: 0.3744 - scaled_graph_loss: 0.0142 - val_loss: 1.6107 - val_accuracy: 0.3795\nEpoch 62/200\n5/5 [==============================] - 1s 132ms/step - loss: 1.5397 - accuracy: 0.3819 - scaled_graph_loss: 0.0127 - val_loss: 1.6045 - val_accuracy: 0.3892\nEpoch 63/200\n5/5 [==============================] - 1s 153ms/step - loss: 1.5438 - accuracy: 0.4087 - scaled_graph_loss: 0.0136 - val_loss: 1.5984 - val_accuracy: 0.3947\nEpoch 64/200\n5/5 [==============================] - 1s 162ms/step - loss: 1.5161 - accuracy: 0.3815 - scaled_graph_loss: 0.0135 - val_loss: 1.5919 - val_accuracy: 0.4017\nEpoch 65/200\n5/5 [==============================] - 1s 143ms/step - loss: 1.5581 - accuracy: 0.3713 - scaled_graph_loss: 0.0134 - val_loss: 1.5854 - val_accuracy: 0.4086\nEpoch 66/200\n5/5 [==============================] - 1s 138ms/step - loss: 1.5347 - accuracy: 0.3858 - scaled_graph_loss: 0.0122 - val_loss: 1.5794 - val_accuracy: 0.4197\nEpoch 67/200\n5/5 [==============================] - 1s 204ms/step - loss: 1.4917 - accuracy: 0.4024 - scaled_graph_loss: 0.0141 - val_loss: 1.5733 - val_accuracy: 0.4326\nEpoch 68/200\n5/5 [==============================] - 1s 223ms/step - loss: 1.4804 - accuracy: 0.3927 - scaled_graph_loss: 0.0129 - val_loss: 1.5658 - val_accuracy: 0.4483\nEpoch 69/200\n5/5 [==============================] - 1s 252ms/step - loss: 1.4751 - accuracy: 0.4093 - scaled_graph_loss: 0.0138 - val_loss: 1.5586 - val_accuracy: 0.4575\nEpoch 70/200\n5/5 [==============================] - 1s 192ms/step - loss: 1.4870 - accuracy: 0.4230 - scaled_graph_loss: 0.0140 - val_loss: 1.5514 - val_accuracy: 0.4645\nEpoch 71/200\n5/5 [==============================] - 1s 213ms/step - loss: 1.4541 - accuracy: 0.4380 - scaled_graph_loss: 0.0146 - val_loss: 1.5447 - val_accuracy: 0.4686\nEpoch 72/200\n5/5 [==============================] - 1s 264ms/step - loss: 1.4528 - accuracy: 0.4193 - scaled_graph_loss: 0.0141 - val_loss: 1.5373 - val_accuracy: 0.4765\nEpoch 73/200\n5/5 [==============================] - 1s 199ms/step - loss: 1.4318 - accuracy: 0.4144 - scaled_graph_loss: 0.0177 - val_loss: 1.5302 - val_accuracy: 0.4820\nEpoch 74/200\n5/5 [==============================] - 1s 210ms/step - loss: 1.4495 - accuracy: 0.4282 - scaled_graph_loss: 0.0161 - val_loss: 1.5239 - val_accuracy: 0.4926\nEpoch 75/200\n5/5 [==============================] - 1s 164ms/step - loss: 1.4085 - accuracy: 0.4447 - scaled_graph_loss: 0.0161 - val_loss: 1.5170 - val_accuracy: 0.4958\nEpoch 76/200\n5/5 [==============================] - 1s 171ms/step - loss: 1.3982 - accuracy: 0.4639 - scaled_graph_loss: 0.0155 - val_loss: 1.5103 - val_accuracy: 0.5000\nEpoch 77/200\n5/5 [==============================] - 1s 186ms/step - loss: 1.3995 - accuracy: 0.4773 - scaled_graph_loss: 0.0168 - val_loss: 1.5037 - val_accuracy: 0.5037\nEpoch 78/200\n5/5 [==============================] - 1s 179ms/step - loss: 1.4244 - accuracy: 0.4426 - scaled_graph_loss: 0.0185 - val_loss: 1.4985 - val_accuracy: 0.5074\nEpoch 79/200\n5/5 [==============================] - 1s 194ms/step - loss: 1.4186 - accuracy: 0.4440 - scaled_graph_loss: 0.0163 - val_loss: 1.4933 - val_accuracy: 0.5102\nEpoch 80/200\n5/5 [==============================] - 1s 212ms/step - loss: 1.3805 - accuracy: 0.4560 - scaled_graph_loss: 0.0170 - val_loss: 1.4872 - val_accuracy: 0.5115\nEpoch 81/200\n5/5 [==============================] - 1s 204ms/step - loss: 1.3641 - accuracy: 0.4687 - scaled_graph_loss: 0.0173 - val_loss: 1.4800 - val_accuracy: 0.5166\nEpoch 82/200\n5/5 [==============================] - 1s 207ms/step - loss: 1.3796 - accuracy: 0.4717 - scaled_graph_loss: 0.0164 - val_loss: 1.4728 - val_accuracy: 0.5249\nEpoch 83/200\n5/5 [==============================] - 1s 203ms/step - loss: 1.4130 - accuracy: 0.4492 - scaled_graph_loss: 0.0177 - val_loss: 1.4667 - val_accuracy: 0.5314\nEpoch 84/200\n5/5 [==============================] - 1s 222ms/step - loss: 1.3239 - accuracy: 0.4916 - scaled_graph_loss: 0.0197 - val_loss: 1.4608 - val_accuracy: 0.5369\nEpoch 85/200\n5/5 [==============================] - 1s 220ms/step - loss: 1.3893 - accuracy: 0.4488 - scaled_graph_loss: 0.0186 - val_loss: 1.4551 - val_accuracy: 0.5434\nEpoch 86/200\n5/5 [==============================] - 1s 236ms/step - loss: 1.3161 - accuracy: 0.4909 - scaled_graph_loss: 0.0204 - val_loss: 1.4490 - val_accuracy: 0.5466\nEpoch 87/200\n5/5 [==============================] - 1s 179ms/step - loss: 1.3434 - accuracy: 0.4966 - scaled_graph_loss: 0.0200 - val_loss: 1.4419 - val_accuracy: 0.5476\nEpoch 88/200\n5/5 [==============================] - 1s 250ms/step - loss: 1.3027 - accuracy: 0.5098 - scaled_graph_loss: 0.0196 - val_loss: 1.4357 - val_accuracy: 0.5489\nEpoch 89/200\n5/5 [==============================] - 1s 230ms/step - loss: 1.3019 - accuracy: 0.4970 - scaled_graph_loss: 0.0201 - val_loss: 1.4293 - val_accuracy: 0.5526\nEpoch 90/200\n5/5 [==============================] - 1s 248ms/step - loss: 1.2992 - accuracy: 0.4944 - scaled_graph_loss: 0.0205 - val_loss: 1.4230 - val_accuracy: 0.5559\nEpoch 91/200\n5/5 [==============================] - 1s 231ms/step - loss: 1.3239 - accuracy: 0.4901 - scaled_graph_loss: 0.0179 - val_loss: 1.4171 - val_accuracy: 0.5619\nEpoch 92/200\n5/5 [==============================] - 1s 221ms/step - loss: 1.3136 - accuracy: 0.5136 - scaled_graph_loss: 0.0196 - val_loss: 1.4112 - val_accuracy: 0.5669\nEpoch 93/200\n5/5 [==============================] - 1s 183ms/step - loss: 1.2639 - accuracy: 0.5288 - scaled_graph_loss: 0.0209 - val_loss: 1.4053 - val_accuracy: 0.5665\nEpoch 94/200\n5/5 [==============================] - 1s 205ms/step - loss: 1.2763 - accuracy: 0.5047 - scaled_graph_loss: 0.0209 - val_loss: 1.3995 - val_accuracy: 0.5665\nEpoch 95/200\n5/5 [==============================] - 1s 238ms/step - loss: 1.2617 - accuracy: 0.5052 - scaled_graph_loss: 0.0207 - val_loss: 1.3948 - val_accuracy: 0.5656\nEpoch 96/200\n5/5 [==============================] - 1s 218ms/step - loss: 1.2874 - accuracy: 0.5022 - scaled_graph_loss: 0.0226 - val_loss: 1.3906 - val_accuracy: 0.5697\nEpoch 97/200\n5/5 [==============================] - 1s 256ms/step - loss: 1.2262 - accuracy: 0.5307 - scaled_graph_loss: 0.0216 - val_loss: 1.3858 - val_accuracy: 0.5702\nEpoch 98/200\n5/5 [==============================] - 1s 197ms/step - loss: 1.2362 - accuracy: 0.5532 - scaled_graph_loss: 0.0216 - val_loss: 1.3793 - val_accuracy: 0.5725\nEpoch 99/200\n5/5 [==============================] - 1s 262ms/step - loss: 1.2081 - accuracy: 0.5314 - scaled_graph_loss: 0.0236 - val_loss: 1.3731 - val_accuracy: 0.5748\nEpoch 100/200\n5/5 [==============================] - 1s 160ms/step - loss: 1.2115 - accuracy: 0.5213 - scaled_graph_loss: 0.0224 - val_loss: 1.3678 - val_accuracy: 0.5780\nEpoch 101/200\n5/5 [==============================] - 1s 153ms/step - loss: 1.1994 - accuracy: 0.5480 - scaled_graph_loss: 0.0230 - val_loss: 1.3620 - val_accuracy: 0.5785\nEpoch 102/200\n5/5 [==============================] - 1s 144ms/step - loss: 1.1956 - accuracy: 0.5351 - scaled_graph_loss: 0.0240 - val_loss: 1.3569 - val_accuracy: 0.5799\nEpoch 103/200\n5/5 [==============================] - 1s 154ms/step - loss: 1.2904 - accuracy: 0.4833 - scaled_graph_loss: 0.0225 - val_loss: 1.3529 - val_accuracy: 0.5803\nEpoch 104/200\n5/5 [==============================] - 1s 210ms/step - loss: 1.1866 - accuracy: 0.5519 - scaled_graph_loss: 0.0241 - val_loss: 1.3486 - val_accuracy: 0.5799\nEpoch 105/200\n5/5 [==============================] - 1s 184ms/step - loss: 1.2259 - accuracy: 0.5028 - scaled_graph_loss: 0.0225 - val_loss: 1.3449 - val_accuracy: 0.5822\nEpoch 106/200\n5/5 [==============================] - 1s 218ms/step - loss: 1.2135 - accuracy: 0.5383 - scaled_graph_loss: 0.0246 - val_loss: 1.3409 - val_accuracy: 0.5826\nEpoch 107/200\n5/5 [==============================] - 1s 215ms/step - loss: 1.1978 - accuracy: 0.5241 - scaled_graph_loss: 0.0244 - val_loss: 1.3366 - val_accuracy: 0.5831\nEpoch 108/200\n5/5 [==============================] - 1s 214ms/step - loss: 1.1885 - accuracy: 0.5566 - scaled_graph_loss: 0.0250 - val_loss: 1.3322 - val_accuracy: 0.5845\nEpoch 109/200\n5/5 [==============================] - 1s 168ms/step - loss: 1.1876 - accuracy: 0.5501 - scaled_graph_loss: 0.0258 - val_loss: 1.3270 - val_accuracy: 0.5877\nEpoch 110/200\n5/5 [==============================] - 1s 172ms/step - loss: 1.1515 - accuracy: 0.5736 - scaled_graph_loss: 0.0251 - val_loss: 1.3238 - val_accuracy: 0.5896\nEpoch 111/200\n5/5 [==============================] - 1s 166ms/step - loss: 1.1388 - accuracy: 0.5336 - scaled_graph_loss: 0.0248 - val_loss: 1.3204 - val_accuracy: 0.5910\nEpoch 112/200\n5/5 [==============================] - 1s 176ms/step - loss: 1.1100 - accuracy: 0.5436 - scaled_graph_loss: 0.0266 - val_loss: 1.3165 - val_accuracy: 0.5928\nEpoch 113/200\n5/5 [==============================] - 1s 158ms/step - loss: 1.1504 - accuracy: 0.5861 - scaled_graph_loss: 0.0254 - val_loss: 1.3145 - val_accuracy: 0.5910\nEpoch 114/200\n5/5 [==============================] - 1s 214ms/step - loss: 1.1706 - accuracy: 0.5344 - scaled_graph_loss: 0.0262 - val_loss: 1.3123 - val_accuracy: 0.5905\nEpoch 115/200\n5/5 [==============================] - 1s 164ms/step - loss: 1.1645 - accuracy: 0.5694 - scaled_graph_loss: 0.0257 - val_loss: 1.3099 - val_accuracy: 0.5905\nEpoch 116/200\n5/5 [==============================] - 1s 227ms/step - loss: 1.1480 - accuracy: 0.5713 - scaled_graph_loss: 0.0249 - val_loss: 1.3066 - val_accuracy: 0.5919\nEpoch 117/200\n5/5 [==============================] - 1s 194ms/step - loss: 1.1302 - accuracy: 0.5679 - scaled_graph_loss: 0.0253 - val_loss: 1.3026 - val_accuracy: 0.5937\nEpoch 118/200\n5/5 [==============================] - 1s 137ms/step - loss: 1.1127 - accuracy: 0.5759 - scaled_graph_loss: 0.0240 - val_loss: 1.3002 - val_accuracy: 0.5942\nEpoch 119/200\n5/5 [==============================] - 1s 209ms/step - loss: 1.1154 - accuracy: 0.5697 - scaled_graph_loss: 0.0271 - val_loss: 1.2991 - val_accuracy: 0.5942\nEpoch 120/200\n5/5 [==============================] - 1s 187ms/step - loss: 1.0834 - accuracy: 0.5843 - scaled_graph_loss: 0.0245 - val_loss: 1.2963 - val_accuracy: 0.5951\nEpoch 121/200\n5/5 [==============================] - 1s 156ms/step - loss: 1.1061 - accuracy: 0.5903 - scaled_graph_loss: 0.0258 - val_loss: 1.2935 - val_accuracy: 0.5965\nEpoch 122/200\n5/5 [==============================] - 1s 167ms/step - loss: 1.0833 - accuracy: 0.5821 - scaled_graph_loss: 0.0254 - val_loss: 1.2900 - val_accuracy: 0.5970\nEpoch 123/200\n5/5 [==============================] - 1s 175ms/step - loss: 1.1348 - accuracy: 0.5637 - scaled_graph_loss: 0.0248 - val_loss: 1.2858 - val_accuracy: 0.5988\nEpoch 124/200\n5/5 [==============================] - 1s 170ms/step - loss: 1.0713 - accuracy: 0.5912 - scaled_graph_loss: 0.0252 - val_loss: 1.2819 - val_accuracy: 0.5997\nEpoch 125/200\n5/5 [==============================] - 1s 176ms/step - loss: 1.0583 - accuracy: 0.5960 - scaled_graph_loss: 0.0277 - val_loss: 1.2799 - val_accuracy: 0.6006\nEpoch 126/200\n5/5 [==============================] - 1s 179ms/step - loss: 1.0950 - accuracy: 0.6009 - scaled_graph_loss: 0.0253 - val_loss: 1.2770 - val_accuracy: 0.5993\nEpoch 127/200\n5/5 [==============================] - 1s 163ms/step - loss: 1.1018 - accuracy: 0.5771 - scaled_graph_loss: 0.0259 - val_loss: 1.2736 - val_accuracy: 0.6020\nEpoch 128/200\n5/5 [==============================] - 1s 147ms/step - loss: 1.1109 - accuracy: 0.5796 - scaled_graph_loss: 0.0273 - val_loss: 1.2704 - val_accuracy: 0.6016\nEpoch 129/200\n5/5 [==============================] - 1s 142ms/step - loss: 1.0983 - accuracy: 0.5808 - scaled_graph_loss: 0.0266 - val_loss: 1.2668 - val_accuracy: 0.6034\nEpoch 130/200\n5/5 [==============================] - 1s 135ms/step - loss: 1.1054 - accuracy: 0.5490 - scaled_graph_loss: 0.0296 - val_loss: 1.2626 - val_accuracy: 0.6066\nEpoch 131/200\n5/5 [==============================] - 1s 136ms/step - loss: 1.0896 - accuracy: 0.6092 - scaled_graph_loss: 0.0295 - val_loss: 1.2595 - val_accuracy: 0.6080\nEpoch 132/200\n5/5 [==============================] - 1s 148ms/step - loss: 1.0911 - accuracy: 0.5874 - scaled_graph_loss: 0.0292 - val_loss: 1.2571 - val_accuracy: 0.6076\nEpoch 133/200\n5/5 [==============================] - 1s 149ms/step - loss: 1.1144 - accuracy: 0.5697 - scaled_graph_loss: 0.0279 - val_loss: 1.2532 - val_accuracy: 0.6094\nEpoch 134/200\n5/5 [==============================] - 1s 140ms/step - loss: 1.0619 - accuracy: 0.5921 - scaled_graph_loss: 0.0314 - val_loss: 1.2494 - val_accuracy: 0.6103\nEpoch 135/200\n5/5 [==============================] - 1s 152ms/step - loss: 1.0882 - accuracy: 0.5957 - scaled_graph_loss: 0.0283 - val_loss: 1.2506 - val_accuracy: 0.6094\nEpoch 136/200\n5/5 [==============================] - 1s 181ms/step - loss: 1.0127 - accuracy: 0.6250 - scaled_graph_loss: 0.0296 - val_loss: 1.2510 - val_accuracy: 0.6090\nEpoch 137/200\n5/5 [==============================] - 1s 157ms/step - loss: 1.0254 - accuracy: 0.6049 - scaled_graph_loss: 0.0278 - val_loss: 1.2501 - val_accuracy: 0.6103\nEpoch 138/200\n5/5 [==============================] - 1s 145ms/step - loss: 1.0017 - accuracy: 0.6117 - scaled_graph_loss: 0.0298 - val_loss: 1.2472 - val_accuracy: 0.6108\nEpoch 139/200\n5/5 [==============================] - 1s 155ms/step - loss: 1.0102 - accuracy: 0.6226 - scaled_graph_loss: 0.0277 - val_loss: 1.2472 - val_accuracy: 0.6117\nEpoch 140/200\n5/5 [==============================] - 1s 187ms/step - loss: 1.0174 - accuracy: 0.6061 - scaled_graph_loss: 0.0314 - val_loss: 1.2470 - val_accuracy: 0.6127\nEpoch 141/200\n5/5 [==============================] - 1s 175ms/step - loss: 1.0487 - accuracy: 0.6027 - scaled_graph_loss: 0.0279 - val_loss: 1.2464 - val_accuracy: 0.6131\nEpoch 142/200\n5/5 [==============================] - 1s 164ms/step - loss: 1.0059 - accuracy: 0.5976 - scaled_graph_loss: 0.0290 - val_loss: 1.2446 - val_accuracy: 0.6131\nEpoch 143/200\n5/5 [==============================] - 1s 209ms/step - loss: 0.9457 - accuracy: 0.6522 - scaled_graph_loss: 0.0272 - val_loss: 1.2440 - val_accuracy: 0.6131\nEpoch 144/200\n5/5 [==============================] - 1s 176ms/step - loss: 1.0196 - accuracy: 0.6143 - scaled_graph_loss: 0.0281 - val_loss: 1.2449 - val_accuracy: 0.6136\nEpoch 145/200\n5/5 [==============================] - 1s 222ms/step - loss: 1.0264 - accuracy: 0.6045 - scaled_graph_loss: 0.0281 - val_loss: 1.2458 - val_accuracy: 0.6136\nEpoch 146/200\n5/5 [==============================] - 1s 181ms/step - loss: 0.9464 - accuracy: 0.6266 - scaled_graph_loss: 0.0315 - val_loss: 1.2463 - val_accuracy: 0.6136\nEpoch 147/200\n5/5 [==============================] - 1s 191ms/step - loss: 1.0403 - accuracy: 0.5913 - scaled_graph_loss: 0.0275 - val_loss: 1.2475 - val_accuracy: 0.6127\nEpoch 148/200\n5/5 [==============================] - 1s 231ms/step - loss: 1.0299 - accuracy: 0.6055 - scaled_graph_loss: 0.0302 - val_loss: 1.2493 - val_accuracy: 0.6127\nEpoch 149/200\n5/5 [==============================] - 1s 174ms/step - loss: 1.0777 - accuracy: 0.5722 - scaled_graph_loss: 0.0313 - val_loss: 1.2508 - val_accuracy: 0.6127\nEpoch 150/200\n5/5 [==============================] - 1s 265ms/step - loss: 1.0012 - accuracy: 0.6296 - scaled_graph_loss: 0.0288 - val_loss: 1.2516 - val_accuracy: 0.6131\nEpoch 151/200\n5/5 [==============================] - 1s 256ms/step - loss: 0.9506 - accuracy: 0.6113 - scaled_graph_loss: 0.0292 - val_loss: 1.2499 - val_accuracy: 0.6136\nEpoch 152/200\n5/5 [==============================] - 1s 250ms/step - loss: 1.0039 - accuracy: 0.6003 - scaled_graph_loss: 0.0286 - val_loss: 1.2448 - val_accuracy: 0.6145\nEpoch 153/200\n5/5 [==============================] - 1s 239ms/step - loss: 0.9514 - accuracy: 0.6343 - scaled_graph_loss: 0.0299 - val_loss: 1.2397 - val_accuracy: 0.6154\nEpoch 154/200\n5/5 [==============================] - 1s 199ms/step - loss: 0.9848 - accuracy: 0.6177 - scaled_graph_loss: 0.0309 - val_loss: 1.2356 - val_accuracy: 0.6177\nEpoch 155/200\n5/5 [==============================] - 1s 163ms/step - loss: 0.9157 - accuracy: 0.6665 - scaled_graph_loss: 0.0314 - val_loss: 1.2342 - val_accuracy: 0.6177\nEpoch 156/200\n5/5 [==============================] - 1s 160ms/step - loss: 0.9497 - accuracy: 0.6200 - scaled_graph_loss: 0.0301 - val_loss: 1.2320 - val_accuracy: 0.6177\nEpoch 157/200\n5/5 [==============================] - 1s 172ms/step - loss: 0.9808 - accuracy: 0.6151 - scaled_graph_loss: 0.0309 - val_loss: 1.2295 - val_accuracy: 0.6200\nEpoch 158/200\n5/5 [==============================] - 1s 181ms/step - loss: 0.9169 - accuracy: 0.6518 - scaled_graph_loss: 0.0283 - val_loss: 1.2264 - val_accuracy: 0.6219\nEpoch 159/200\n5/5 [==============================] - 1s 168ms/step - loss: 1.0104 - accuracy: 0.6188 - scaled_graph_loss: 0.0289 - val_loss: 1.2250 - val_accuracy: 0.6228\nEpoch 160/200\n5/5 [==============================] - 1s 180ms/step - loss: 0.9568 - accuracy: 0.5875 - scaled_graph_loss: 0.0311 - val_loss: 1.2251 - val_accuracy: 0.6219\nEpoch 161/200\n5/5 [==============================] - 1s 162ms/step - loss: 0.9131 - accuracy: 0.6352 - scaled_graph_loss: 0.0303 - val_loss: 1.2244 - val_accuracy: 0.6219\nEpoch 162/200\n5/5 [==============================] - 1s 168ms/step - loss: 0.9322 - accuracy: 0.6390 - scaled_graph_loss: 0.0308 - val_loss: 1.2250 - val_accuracy: 0.6223\nEpoch 163/200\n5/5 [==============================] - 1s 191ms/step - loss: 0.9138 - accuracy: 0.6420 - scaled_graph_loss: 0.0309 - val_loss: 1.2265 - val_accuracy: 0.6223\nEpoch 164/200\n5/5 [==============================] - 1s 161ms/step - loss: 0.9189 - accuracy: 0.6483 - scaled_graph_loss: 0.0310 - val_loss: 1.2288 - val_accuracy: 0.6214\nEpoch 165/200\n5/5 [==============================] - 1s 167ms/step - loss: 0.9210 - accuracy: 0.6330 - scaled_graph_loss: 0.0331 - val_loss: 1.2299 - val_accuracy: 0.6228\nEpoch 166/200\n5/5 [==============================] - 1s 201ms/step - loss: 0.9685 - accuracy: 0.6292 - scaled_graph_loss: 0.0329 - val_loss: 1.2324 - val_accuracy: 0.6251\nEpoch 167/200\n5/5 [==============================] - 1s 260ms/step - loss: 0.9593 - accuracy: 0.6231 - scaled_graph_loss: 0.0320 - val_loss: 1.2372 - val_accuracy: 0.6251\nEpoch 168/200\n5/5 [==============================] - 1s 186ms/step - loss: 0.9453 - accuracy: 0.6082 - scaled_graph_loss: 0.0301 - val_loss: 1.2409 - val_accuracy: 0.6260\nEpoch 169/200\n5/5 [==============================] - 1s 174ms/step - loss: 1.0013 - accuracy: 0.6015 - scaled_graph_loss: 0.0313 - val_loss: 1.2456 - val_accuracy: 0.6247\nEpoch 170/200\n5/5 [==============================] - 1s 225ms/step - loss: 0.9140 - accuracy: 0.6605 - scaled_graph_loss: 0.0311 - val_loss: 1.2488 - val_accuracy: 0.6228\nEpoch 171/200\n5/5 [==============================] - 1s 184ms/step - loss: 0.8999 - accuracy: 0.6485 - scaled_graph_loss: 0.0295 - val_loss: 1.2475 - val_accuracy: 0.6237\nEpoch 172/200\n5/5 [==============================] - 1s 163ms/step - loss: 0.9913 - accuracy: 0.6180 - scaled_graph_loss: 0.0299 - val_loss: 1.2500 - val_accuracy: 0.6242\nEpoch 173/200\n5/5 [==============================] - 1s 229ms/step - loss: 0.9542 - accuracy: 0.6138 - scaled_graph_loss: 0.0290 - val_loss: 1.2513 - val_accuracy: 0.6237\nEpoch 174/200\n5/5 [==============================] - 1s 283ms/step - loss: 0.9251 - accuracy: 0.6392 - scaled_graph_loss: 0.0309 - val_loss: 1.2524 - val_accuracy: 0.6247\nEpoch 175/200\n5/5 [==============================] - 1s 277ms/step - loss: 0.9016 - accuracy: 0.6572 - scaled_graph_loss: 0.0321 - val_loss: 1.2525 - val_accuracy: 0.6260\nEpoch 176/200\n5/5 [==============================] - 1s 271ms/step - loss: 0.9267 - accuracy: 0.6182 - scaled_graph_loss: 0.0311 - val_loss: 1.2514 - val_accuracy: 0.6260\nEpoch 177/200\n5/5 [==============================] - 1s 231ms/step - loss: 0.8702 - accuracy: 0.6715 - scaled_graph_loss: 0.0307 - val_loss: 1.2500 - val_accuracy: 0.6265\nEpoch 178/200\n5/5 [==============================] - 1s 179ms/step - loss: 0.8859 - accuracy: 0.6498 - scaled_graph_loss: 0.0300 - val_loss: 1.2444 - val_accuracy: 0.6260\nEpoch 179/200\n5/5 [==============================] - 1s 232ms/step - loss: 0.9165 - accuracy: 0.6484 - scaled_graph_loss: 0.0306 - val_loss: 1.2410 - val_accuracy: 0.6265\nEpoch 180/200\n5/5 [==============================] - 1s 269ms/step - loss: 0.8989 - accuracy: 0.6480 - scaled_graph_loss: 0.0308 - val_loss: 1.2395 - val_accuracy: 0.6260\nEpoch 181/200\n5/5 [==============================] - 1s 280ms/step - loss: 0.9084 - accuracy: 0.6570 - scaled_graph_loss: 0.0303 - val_loss: 1.2380 - val_accuracy: 0.6270\nEpoch 182/200\n5/5 [==============================] - 1s 184ms/step - loss: 0.8927 - accuracy: 0.6529 - scaled_graph_loss: 0.0321 - val_loss: 1.2398 - val_accuracy: 0.6293\nEpoch 183/200\n5/5 [==============================] - 1s 269ms/step - loss: 0.9331 - accuracy: 0.6413 - scaled_graph_loss: 0.0324 - val_loss: 1.2425 - val_accuracy: 0.6274\nEpoch 184/200\n5/5 [==============================] - 1s 232ms/step - loss: 0.8546 - accuracy: 0.6809 - scaled_graph_loss: 0.0297 - val_loss: 1.2477 - val_accuracy: 0.6283\nEpoch 185/200\n5/5 [==============================] - 1s 195ms/step - loss: 0.8826 - accuracy: 0.6345 - scaled_graph_loss: 0.0327 - val_loss: 1.2524 - val_accuracy: 0.6274\nEpoch 186/200\n5/5 [==============================] - 1s 234ms/step - loss: 0.8374 - accuracy: 0.6524 - scaled_graph_loss: 0.0321 - val_loss: 1.2602 - val_accuracy: 0.6288\nEpoch 187/200\n5/5 [==============================] - 1s 240ms/step - loss: 0.9199 - accuracy: 0.6291 - scaled_graph_loss: 0.0331 - val_loss: 1.2633 - val_accuracy: 0.6279\nEpoch 188/200\n5/5 [==============================] - 1s 198ms/step - loss: 0.8474 - accuracy: 0.6932 - scaled_graph_loss: 0.0315 - val_loss: 1.2667 - val_accuracy: 0.6270\nEpoch 189/200\n5/5 [==============================] - 1s 162ms/step - loss: 0.8857 - accuracy: 0.6527 - scaled_graph_loss: 0.0326 - val_loss: 1.2682 - val_accuracy: 0.6251\nEpoch 190/200\n5/5 [==============================] - 1s 167ms/step - loss: 0.8189 - accuracy: 0.6870 - scaled_graph_loss: 0.0335 - val_loss: 1.2717 - val_accuracy: 0.6251\nEpoch 191/200\n5/5 [==============================] - 1s 157ms/step - loss: 0.9053 - accuracy: 0.6332 - scaled_graph_loss: 0.0321 - val_loss: 1.2757 - val_accuracy: 0.6233\nEpoch 192/200\n5/5 [==============================] - 1s 156ms/step - loss: 0.9003 - accuracy: 0.6519 - scaled_graph_loss: 0.0333 - val_loss: 1.2747 - val_accuracy: 0.6256\nEpoch 193/200\n5/5 [==============================] - 1s 165ms/step - loss: 0.8634 - accuracy: 0.6420 - scaled_graph_loss: 0.0301 - val_loss: 1.2704 - val_accuracy: 0.6270\nEpoch 194/200\n5/5 [==============================] - 1s 164ms/step - loss: 0.8267 - accuracy: 0.6727 - scaled_graph_loss: 0.0314 - val_loss: 1.2641 - val_accuracy: 0.6274\nEpoch 195/200\n5/5 [==============================] - 1s 172ms/step - loss: 0.8430 - accuracy: 0.6941 - scaled_graph_loss: 0.0338 - val_loss: 1.2606 - val_accuracy: 0.6283\nEpoch 196/200\n5/5 [==============================] - 1s 177ms/step - loss: 0.8967 - accuracy: 0.6375 - scaled_graph_loss: 0.0320 - val_loss: 1.2575 - val_accuracy: 0.6316\nEpoch 197/200\n5/5 [==============================] - 1s 164ms/step - loss: 0.8748 - accuracy: 0.6446 - scaled_graph_loss: 0.0315 - val_loss: 1.2558 - val_accuracy: 0.6320\nEpoch 198/200\n5/5 [==============================] - 1s 190ms/step - loss: 0.9019 - accuracy: 0.6390 - scaled_graph_loss: 0.0323 - val_loss: 1.2531 - val_accuracy: 0.6316\nEpoch 199/200\n5/5 [==============================] - 1s 139ms/step - loss: 0.7997 - accuracy: 0.6777 - scaled_graph_loss: 0.0342 - val_loss: 1.2514 - val_accuracy: 0.6325\nEpoch 200/200\n5/5 [==============================] - 1s 247ms/step - loss: 0.9136 - accuracy: 0.6405 - scaled_graph_loss: 0.0328 - val_loss: 1.2526 - val_accuracy: 0.6320\n\n\n<tensorflow.python.keras.callbacks.History at 0x14fe35610>"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter06/01_Social_network_analysis.html",
    "href": "posts/2_Studies/GML/Chapter06/01_Social_network_analysis.html",
    "title": "[GML] Chap6: 소셜네트워크 그래프",
    "section": "",
    "text": "import os\nimport math\nimport numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndefault_edge_color = 'gray'\ndefault_node_color = '#407cc9'\nenhanced_node_color = '#f5b042'\nenhanced_edge_color = '#cc2f04'\n\nIn this chapter we will focus on using the techniques outlined in previous chapters to analyze the most-common example of nowadays graphs: Social Networks. In particular we will apply the techniques outlined in previous chapters to investigate the topological properties of the networks, such as 1. identifying relevant communities as well as 2. identifying particularly important nodes in the network.\nWe will then use node embeddings to leverage on the power of topological information for different tasks, such as link prediction (as a potential recommendation engine for new friends)\n\n\nFirst, we need to download the dataset. We will be using the SNAP Facebook social graph. The dataset was created by collection Facebook user information from survey participants. More in detail, 10 ego-networks were created from ten users. Each user was asked to identify all the circles (list of friends) to which their friends belong. Then, all the “ego-network” were combined in a single graph.\n\n!wget http://snap.stanford.edu/data/facebook_combined.txt.gz\n!wget http://snap.stanford.edu/data/facebook.tar.gz\n!gzip -d facebook_combined.txt.gz\n!tar -xf facebook.tar.gz\n\n\n\n\nThe code above downloads two main files: * a text file containing the edge list of the graph. The graph is actually created * an archive containing a folder (“facebook”) with all the information related to each ego-network\n\n# check the downloaded content\n!ls\n\n\n# take a look at the first lines of the edge list\n!head facebook_combined.txt\n\nWe can now proceed loading the combined network using networkx. We will also load the nodeId of the 10 “ego-user”\n\nG = nx.read_edgelist(\"facebook_combined.txt\", create_using=nx.Graph(), nodetype=int)\n\n\nprint(nx.info(G))\n\n\n# Each file in the \"facebook\" directory is named as nodeId.format\n# where nodeId is the id of an ego-user and format is the format of the file\nego_nodes = set([int(name.split('.')[0]) for name in os.listdir(\"facebook/\")])\n\nLet’s visualize the network for a deeper understanding\n\n#Create network layout for visualizations\nspring_pos = nx.spring_layout(G)\n\n\nplt.axis(\"off\")\nnx.draw_networkx(G, pos=spring_pos, node_color=default_node_color, edge_color=default_edge_color, with_labels=False, node_size=35)\n\n\n\n\n\ndef draw_metric(G, dct, spring_pos):\n  \"\"\" draw the graph G using the layout spring_pos.\n      The top 10 nodes w.r.t. values in the dictionary dct\n      are enhanced in the visualization \"\"\"\n  top = 10\n  max_nodes =  sorted(dct.items(), key = lambda v: -v[1])[:top]\n  \n  max_keys = [key for key,_ in max_nodes]\n  max_vals = [val*300 for _, val in max_nodes]\n\n  plt.axis(\"off\")\n  \n  nx.draw_networkx(G, \n                   pos=spring_pos, \n                   cmap='Blues', \n                   edge_color=default_edge_color,\n                   node_color=default_node_color, \n                   node_size=3,\n                   alpha=0.4, \n                   with_labels=False)\n  \n  nx.draw_networkx_nodes(G, \n                         pos=spring_pos, \n                         nodelist=max_keys, \n                         node_color=enhanced_edge_color,\n                         node_size=max_vals)\n\n\n# betweenness centrality\nbC = nx.betweenness_centrality(G)\nnp.mean(list(bC.values()))\n\n\ndraw_metric(G,bC,spring_pos)\n\n\n# global efficiency\ngE = nx.global_efficiency(G)\nprint(gE)\n\n\n# average clustering\naC = nx.average_clustering(G)\nprint(aC)\n\n\n# degree centrality\ndeg_C = nx.degree_centrality(G)\nnp.mean(list(deg_C.values()))\n\n\ndraw_metric(G,deg_C,spring_pos)\n\n\n# closeness centrality\nclos_C = nx.closeness_centrality(G)\nnp.mean(list(clos_C.values()))\n\n\ndraw_metric(G,clos_C,spring_pos)\n\n\n# assortativity\nassortativity = nx.degree_pearson_correlation_coefficient(G)\nassortativity\n\n\nt = nx.transitivity(G)\nt\n\n\n#import networkx.algorithms.community as nx_comm\n#nx_comm.modularity(G, nx_comm.label_propagation_communities(G))\n\n\n\nIn the following cells we will automatically detect communities using infromation from the network topology\n\nimport community\n\nparts = community.best_partition(G)\nvalues = [parts.get(node) for node in G.nodes()]\n\nfor node in ego_nodes:\n  print(node, \"is in community number\", parts.get(node))\n  \nn_sizes = [5]*len(G.nodes())\nfor node in ego_nodes:\n  n_sizes[node] = 250\n\nplt.axis(\"off\")\nnx.draw_networkx(G, pos=spring_pos, cmap=plt.get_cmap(\"Blues\"), edge_color=default_edge_color, node_color=values, node_size=n_sizes, with_labels=False)\n\n# enhance color and size of the ego-nodes\nnodes = nx.draw_networkx_nodes(G,spring_pos,ego_nodes,node_color=[parts.get(node) for node in ego_nodes])\nnodes.set_edgecolor(enhanced_node_color)\n\n\n\n\n\nSince the combined network we are analyzing is actually composed by 10 sub-networks (ego-networks), it’s interesting to inspect all those subnetwork. In the following cells we will analyze the subnetwork of the ego-user “0”.\n\nG0 = nx.read_edgelist(\"facebook/0.edges\", create_using=nx.Graph(), nodetype=int)\nfor node in G0.copy():\n  G0.add_edge(0,node)\n\nplt.axis(\"off\")\npos_G0 = nx.spring_layout(G0)\nnx.draw_networkx(G0, pos=pos_G0, with_labels=False, node_size=35, edge_color=default_edge_color)\n\nNodes belonging to each subnetwork are stored in the “facebook” folder under the name nodeId.circles\n\nimport pandas as pd\ncircles = {}\n\nwith open(\"facebook/0.circles\") as f_in:\n  line = f_in.readline().rstrip().split(\"\\t\")\n  while line and not '' in line:\n    circles[line[0]] = [int(v) for v in line[1:]]\n    line = f_in.readline().rstrip().split(\"\\t\")\n\n\nnode_colors = [0] * G0.number_of_nodes()\ncount = 0\nfor key in circles:\n  circle = circles[key]\n  for node in circle:\n    if node < G0.number_of_nodes():\n      node_colors[node] = count\n  count += 1\n\nnx.draw_networkx(G0, pos=pos_G0, with_labels=False, node_size=35, node_color=node_colors, edge_color=default_edge_color)\n\n\nparts = community.best_partition(G0)\nvalues = [parts.get(node) for node in G0.nodes()]\n\nplt.axis(\"off\")\nnx.draw_networkx(G0, pos=pos_G0, cmap=plt.get_cmap(\"Blues\"), edge_color=default_edge_color, node_color=values, node_size=35, with_labels=False)\n\n\n# community found does not reflect the circles\nset(parts.values())\nlen(circles)\n\n\n# a node can be present in more than one list??\nfor i in circles:\n  for j in circles:\n    if i != j:\n      for n1 in circles[i]:\n        for n2 in circles[j]:\n          if n1 == n2:\n            print(n1, 'present in ',i,'found in', j)\n            assert(False)\n\n\n#@title  \nnx.average_shortest_path_length(G0)\nnx.global_efficiency(G0)\nnx.average_clustering(G0)\n\nnp.mean(list(nx.betweenness_centrality(G0).values()))\nnp.mean(list(nx.closeness_centrality(G0).values()))\nnp.mean(list(nx.degree_centrality(G0).values()))\nnx.degree_pearson_correlation_coefficient(G)\nnx.transitivity(G)\n\nimport networkx.algorithms.community as nx_comm\nnx_comm.modularity(G, nx_comm.label_propagation_communities(G))\n\n\n\n\nWe will now proceed with the actual machine learning task. In particular, we will perform an edge prediction task for the Facebook social graph.\n\n\nAs first, let’s load all the features describing each node. This is not a straightforward process and requires a bit of codes, since each subnetwork contains it’s own set of features, whose names and values are stored in different files.\n\n# Adapted from https://github.com/jcatw/snap-facebook\n\nfeat_file_name = \"feature_map.txt\"\nfeature_index = {}  #numeric index to name\ninverted_feature_index = {} #name to numeric index\nnetwork = nx.Graph()\n\ndef parse_featname_line(line):\n  \"\"\" used to parse each line of the files containing feature names \"\"\"\n  line = line[(line.find(' '))+1:]  # chop first field\n  split = line.split(';')\n  name = ';'.join(split[:-1]) # feature name\n  index = int(split[-1].split(\" \")[-1]) #feature index\n  return index, name\n\ndef load_features():\n  \"\"\" \n  parse each ego-network and creates two dictionaries:\n      - feature_index: maps numeric indices to names\n      - inverted_feature_index: maps names to numeric indices\n  \"\"\"\n  import glob\n  feat_file_name = 'tmp.txt'\n  # may need to build the index first\n  if not os.path.exists(feat_file_name):\n      feat_index = {}\n      # build the index from data/*.featnames files\n      featname_files = glob.iglob(\"facebook/*.featnames\")\n      for featname_file_name in featname_files:\n          featname_file = open(featname_file_name, 'r')\n          for line in featname_file:\n              # example line:\n              # 0 birthday;anonymized feature 376\n              index, name = parse_featname_line(line)\n              feat_index[index] = name\n          featname_file.close()\n      keys = feat_index.keys()\n      keys = sorted(keys)\n      out = open(feat_file_name,'w')\n      for key in keys:\n          out.write(\"%d %s\\n\" % (key, feat_index[key]))\n      out.close()\n\n  index_file = open(feat_file_name,'r')\n  for line in index_file:\n      split = line.strip().split(' ')\n      key = int(split[0])\n      val = split[1]\n      feature_index[key] = val\n  index_file.close()\n\n  for key in feature_index.keys():\n      val = feature_index[key]\n      inverted_feature_index[val] = key\n\ndef parse_nodes(network, ego_nodes):\n  \"\"\"\n  for each nodes in the network assign the corresponding features \n  previously loaded using the load_features function\n  \"\"\"\n  # parse each node\n  for node_id in ego_nodes:\n      featname_file = open(f'facebook/{node_id}.featnames','r')\n      feat_file     = open(f'facebook/{node_id}.feat','r')\n      egofeat_file  = open(f'facebook/{node_id}.egofeat','r')\n      edge_file     = open(f'facebook/{node_id}.edges','r')\n\n      ego_features = [int(x) for x in egofeat_file.readline().split(' ')]\n\n      # Add ego node features\n      network.nodes[node_id]['features'] = np.zeros(len(feature_index))\n      \n      # parse ego node\n      i = 0\n      for line in featname_file:\n          key, val = parse_featname_line(line)\n          # Update feature value if necessary\n          if ego_features[i] + 1 > network.nodes[node_id]['features'][key]:\n              network.nodes[node_id]['features'][key] = ego_features[i] + 1\n          i += 1\n\n      # parse neighboring nodes\n      for line in feat_file:\n          featname_file.seek(0)\n          split = [int(x) for x in line.split(' ')]\n          node_id = split[0]\n          features = split[1:]\n\n          # Add node features\n          network.nodes[node_id]['features'] = np.zeros(len(feature_index))\n\n          i = 0\n          for line in featname_file:\n              key, val = parse_featname_line(line)\n              # Update feature value if necessary\n              if features[i] + 1 > network.nodes[node_id]['features'][key]:\n                  network.nodes[node_id]['features'][key] = features[i] + 1\n              i += 1\n          \n      featname_file.close()\n      feat_file.close()\n      egofeat_file.close()\n      edge_file.close()\n\n\n# parse edge features and add them to the networkx nodes\nload_features()\nparse_nodes(G, ego_nodes)\n\n\n# check features has been correctly assigned\nG.nodes[0]\n\n\n\n\n\nIt’s now time for machine learning. As first, we will be using stellargraph utility function to define a train and test set. More in detail, TODO\n\n!pip install stellargraph\n!pip install node2vec==0.3.3\n!pip install git+https://github.com/palash1992/GEM.git\n\n\nfrom sklearn.model_selection import train_test_split\nfrom stellargraph.data import EdgeSplitter\nfrom stellargraph import StellarGraph\n\nedgeSplitter = EdgeSplitter(G) \ngraph_test, samples_test, labels_test = edgeSplitter.train_test_split(p=0.1, method=\"global\", seed=24)\n\nedgeSplitter = EdgeSplitter(graph_test, G) \ngraph_train, samples_train, labels_train = edgeSplitter.train_test_split(p=0.1, method=\"global\", seed=24)\n\nWe will be comparing three different methods for predicting missing edges: - Method1: node2vec will be used to learn a node embedding. Such embeddings will be used to train a Random Forest classifier in a supervised manner - Method2: graphSAGE (with and without features) will be used for link prediction - Method3: hand-crafted features will be extracted and used to train a Random Forest classifier\n\n\n\nfrom node2vec import Node2Vec\nfrom node2vec.edges import HadamardEmbedder \nfrom stellargraph.data import EdgeSplitter \n\nnode2vec = Node2Vec(graph_train) \nmodel = node2vec.fit() \nedges_embs = HadamardEmbedder(keyed_vectors=model.wv) \ntrain_embeddings = [edges_embs[str(x[0]),str(x[1])] for x in samples_train]\n\nedges_embs = HadamardEmbedder(keyed_vectors=model.wv) \ntest_embeddings = [edges_embs[str(x[0]),str(x[1])] for x in samples_test]\n\n\nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn import metrics \n\nrf = RandomForestClassifier(n_estimators=10) \nrf.fit(train_embeddings, labels_train); \n \ny_pred = rf.predict(test_embeddings) \nprint('Precision:', metrics.precision_score(labels_test, y_pred)) \nprint('Recall:', metrics.recall_score(labels_test, y_pred)) \nprint('F1-Score:', metrics.f1_score(labels_test, y_pred)) \n\n\n\n\n\n# graphSAGE no feats\n\n\neye = np.eye(graph_train.number_of_nodes())\nfake_features = {n:eye[n] for n in G.nodes()}\nnx.set_node_attributes(graph_train, fake_features, \"fake\")\n\neye = np.eye(graph_test.number_of_nodes())\nfake_features = {n:eye[n] for n in G.nodes()}\nnx.set_node_attributes(graph_test, fake_features, \"fake\")\n\n\ngraph_train.nodes[0]\n\n\nfrom stellargraph.mapper import GraphSAGELinkGenerator\n\nbatch_size = 64\nnum_samples = [4, 4]\n\nsg_graph_train = StellarGraph.from_networkx(graph_train, node_features=\"fake\")\nsg_graph_test = StellarGraph.from_networkx(graph_test, node_features=\"fake\")\n\ntrain_gen = GraphSAGELinkGenerator(sg_graph_train, batch_size, num_samples)\ntrain_flow = train_gen.flow(samples_train, labels_train, shuffle=True, seed=24)\n\ntest_gen = GraphSAGELinkGenerator(sg_graph_test, batch_size, num_samples)\ntest_flow = test_gen.flow(samples_test, labels_test, seed=24)\n\n\nfrom stellargraph.layer import GraphSAGE, link_classification\nfrom tensorflow import keras\n\nlayer_sizes = [20, 20]\ngraphsage = GraphSAGE(\n    layer_sizes=layer_sizes, generator=train_gen, bias=True, dropout=0.3\n)\n\nx_inp, x_out = graphsage.in_out_tensors()\n\nprediction = link_classification(\n    output_dim=1, output_act=\"sigmoid\", edge_embedding_method=\"ip\"\n)(x_out)\n\nmodel = keras.Model(inputs=x_inp, outputs=prediction)\n\nmodel.compile(\n    optimizer=keras.optimizers.Adam(lr=1e-3),\n    loss=keras.losses.mse,\n    metrics=[\"acc\"],\n)\n\n\nepochs = 10\nhistory = model.fit(train_flow, epochs=epochs, validation_data=test_flow)\n\n\nfrom sklearn import metrics \ny_pred = np.round(model.predict(train_flow)).flatten()\nprint('Precision:', metrics.precision_score(labels_train, y_pred)) \nprint('Recall:', metrics.recall_score(labels_train, y_pred)) \nprint('F1-Score:', metrics.f1_score(labels_train, y_pred)) \n\n\ny_pred = np.round(model.predict(test_flow)).flatten()\nprint('Precision:', metrics.precision_score(labels_test, y_pred)) \nprint('Recall:', metrics.recall_score(labels_test, y_pred)) \nprint('F1-Score:', metrics.f1_score(labels_test, y_pred)) \n\n\n# graphSAGE + feats\n\n\nsg_graph_train = StellarGraph.from_networkx(graph_train, node_features=\"features\")\nsg_graph_test = StellarGraph.from_networkx(graph_test, node_features=\"features\")\n\ntrain_gen = GraphSAGELinkGenerator(sg_graph_train, batch_size, num_samples)\ntrain_flow = train_gen.flow(samples_train, labels_train, shuffle=True, seed=24)\n\ntest_gen = GraphSAGELinkGenerator(sg_graph_test, batch_size, num_samples)\ntest_flow = test_gen.flow(samples_test, labels_test, seed=24)\n\n\nlayer_sizes = [20, 20]\ngraphsage = GraphSAGE(\n    layer_sizes=layer_sizes, generator=train_gen, bias=True, dropout=0.3\n)\n\nx_inp, x_out = graphsage.in_out_tensors()\n\nprediction = link_classification(\n    output_dim=1, output_act=\"sigmoid\", edge_embedding_method=\"ip\"\n)(x_out)\n\nmodel = keras.Model(inputs=x_inp, outputs=prediction)\n\nmodel.compile(\n    optimizer=keras.optimizers.Adam(lr=1e-3),\n    loss=keras.losses.mse,\n    metrics=[\"acc\"],\n)\n\nepochs = 10\nhistory = model.fit(train_flow, epochs=epochs, validation_data=test_flow)\n\n\nfrom sklearn import metrics \ny_pred = np.round(model.predict(train_flow)).flatten()\nprint('Precision:', metrics.precision_score(labels_train, y_pred)) \nprint('Recall:', metrics.recall_score(labels_train, y_pred)) \nprint('F1-Score:', metrics.f1_score(labels_train, y_pred)) \n\n\ny_pred = np.round(model.predict(test_flow)).flatten()\nprint('Precision:', metrics.precision_score(labels_test, y_pred)) \nprint('Recall:', metrics.recall_score(labels_test, y_pred)) \nprint('F1-Score:', metrics.f1_score(labels_test, y_pred)) \n\n\n\n\n\nimport community\n\ndef get_shortest_path(G,u,v):\n  \"\"\" return the shortest path length between u,v \n      in the graph without the edge (u,v) \"\"\"\n  removed = False\n  if G.has_edge(u,v):\n    removed = True\n    G.remove_edge(u,v) # temporary remove edge\n  \n  try:\n    sp = len(nx.shortest_path(G, u, v))\n  except:\n    sp = 0\n\n  if removed:\n    G.add_edge(u,v) # add back the edge if it was removed\n\n  return sp\n\ndef get_hc_features(G, samples_edges, labels):\n  # precompute metrics\n  centralities = nx.degree_centrality(G)\n  parts = community.best_partition(G)\n  \n  feats = []\n  for (u,v),l in zip(samples_edges, labels):\n    shortest_path = get_shortest_path(G, u, v)\n    j_coefficient = next(nx.jaccard_coefficient(G, ebunch=[(u, v)]))[-1]\n    u_centrality = centralities[u]\n    v_centrality = centralities[v]\n    u_community = parts.get(u)\n    v_community = parts.get(v)\n    # add the feature vector\n    feats += [[shortest_path, j_coefficient, u_centrality, v_centrality]]\n  return feats\n\nfeat_train = get_hc_features(graph_train, samples_train, labels_train)\nfeat_test = get_hc_features(graph_test, samples_test, labels_test)\n\n\nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn import metrics \n\nrf = RandomForestClassifier(n_estimators=10) \nrf.fit(feat_train, labels_train); \n \ny_pred = rf.predict(feat_test) \nprint('Precision:', metrics.precision_score(labels_test, y_pred)) \nprint('Recall:', metrics.recall_score(labels_test, y_pred)) \nprint('F1-Score:', metrics.f1_score(labels_test, y_pred))"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter05/01_link_prediction.html",
    "href": "posts/2_Studies/GML/Chapter05/01_link_prediction.html",
    "title": "[GML] Chap5: 응용문제 - 누락된 링크예측",
    "section": "",
    "text": "import networkx as nx\nedges = [[1,3],[2,3],[2,4],[4,5],[5,6],[5,7]]\nG = nx.from_edgelist(edges)\npreds = nx.resource_allocation_index(G,[(1,2),(2,5),(3,4)])\nprint(list(preds))\ndraw_graph(G)\n\n[(1, 2, 0.5), (2, 5, 0.5), (3, 4, 0.5)]\n\n\n\n\n\n\n\n\n\nimport networkx as nx\nedges = [[1,3],[2,3],[2,4],[4,5],[5,6],[5,7]]\nG = nx.from_edgelist(edges)\npreds = nx.jaccard_coefficient(G,[(1,2),(2,5),(3,4)])\nprint(list(preds))\ndraw_graph(G)\n\n[(1, 2, 0.5), (2, 5, 0.25), (3, 4, 0.3333333333333333)]\n\n\n\n\n\n\n\n\n\n\n\n\nimport networkx as nx\nedges = [[1,3],[2,3],[2,4],[4,5],[5,6],[5,7]]\nG = nx.from_edgelist(edges)\n\nG.nodes[1][\"community\"] = 0\nG.nodes[2][\"community\"] = 0\nG.nodes[3][\"community\"] = 0\n\nG.nodes[4][\"community\"] = 1\nG.nodes[5][\"community\"] = 1\nG.nodes[6][\"community\"] = 1\nG.nodes[7][\"community\"] = 1\npreds = nx.cn_soundarajan_hopcroft(G,[(1,2),(2,5),(3,4)])\nprint(list(preds))\ndraw_graph(G)\n\n[(1, 2, 2), (2, 5, 1), (3, 4, 1)]\n\n\n\n\n\n\n\n\n\nimport networkx as nx\nedges = [[1,3],[2,3],[2,4],[4,5],[5,6],[5,7]]\nG = nx.from_edgelist(edges)\n\nG.nodes[1][\"community\"] = 0\nG.nodes[2][\"community\"] = 0\nG.nodes[3][\"community\"] = 0\n\nG.nodes[4][\"community\"] = 1\nG.nodes[5][\"community\"] = 1\nG.nodes[6][\"community\"] = 1\nG.nodes[7][\"community\"] = 1\npreds = nx.ra_index_soundarajan_hopcroft(G,[(1,2),(2,5),(3,4)])\nprint(list(preds))\ndraw_graph(G)\n\n[(1, 2, 0.5), (2, 5, 0), (3, 4, 0)]\n\n\n\n\n\n\n\n\n\n\nimport networkx as nx\nimport pandas as pd\n\nedgelist = pd.read_csv(\"cora.cites\", sep='\\t', header=None, names=[\"target\", \"source\"])\nG = nx.from_pandas_edgelist(edgelist)\ndraw_graph(G)\n\n\n\n\n\nfrom stellargraph.data import EdgeSplitter\n\nedgeSplitter = EdgeSplitter(G)\ngraph_test, samples_test, labels_test = edgeSplitter.train_test_split(\n    p=0.1, method=\"global\"\n)\n\n** Sampled 527 positive and 527 negative edges. **\n\n\n\nedgeSplitter = EdgeSplitter(graph_test, G)\ngraph_train, samples_train, labels_train = edgeSplitter.train_test_split(\n    p=0.1, method=\"global\"\n)\n\n** Sampled 475 positive and 475 negative edges. **\n\n\n\nfrom node2vec import Node2Vec\nfrom node2vec.edges import HadamardEmbedder\n\nnode2vec = Node2Vec(graph_train)\nmodel = node2vec.fit()\nedges_embs = HadamardEmbedder(keyed_vectors=model.wv)\ntrain_embeddings = [edges_embs[str(x[0]),str(x[1])] for x in samples_train]\n\nComputing transition probabilities: 100%|██████████| 2708/2708 [00:00<00:00, 4284.35it/s]\nGenerating walks (CPU: 1): 100%|██████████| 10/10 [01:24<00:00,  8.43s/it]\n\n\n\ntest_embeddings = [edges_embs[str(x[0]),str(x[1])] for x in samples_test]\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=1000)\nrf.fit(train_embeddings, labels_train);\n\n\nfrom sklearn import metrics\n\ny_pred = rf.predict(test_embeddings)\n\nprint('Precision:', metrics.precision_score(labels_test, y_pred))\nprint('Recall:', metrics.recall_score(labels_test, y_pred))\nprint('F1-Score:', metrics.f1_score(labels_test, y_pred))\n\nPrecision: 0.8557114228456913\nRecall: 0.8102466793168881\nF1-Score: 0.8323586744639375\n\n\n\nimport matplotlib.pyplot as plt\n\ndef draw_graph(G, node_names={}, node_size=500):\n    pos_nodes = nx.spring_layout(G)\n    nx.draw(G, pos_nodes, with_labels=True, node_size=node_size, edge_color='gray', arrowsize=30)\n    \n    pos_attrs = {}\n    for node, coords in pos_nodes.items():\n        pos_attrs[node] = (coords[0], coords[1] + 0.08)\n        \n    #nx.draw_networkx_labels(G, pos_attrs, font_family='serif', font_size=20)\n    \n    plt.axis('off')\n    axis = plt.gca()\n    axis.set_xlim([1.2*x for x in axis.get_xlim()])\n    axis.set_ylim([1.2*y for y in axis.get_ylim()])\n    plt.show()"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter05/02_community_detection_algorithms.html",
    "href": "posts/2_Studies/GML/Chapter05/02_community_detection_algorithms.html",
    "title": "[GML] Chap5: 응용문제 - 커뮤니티 감지",
    "section": "",
    "text": "Network Communities Detection\nIn this notebook, we will explore some methods to perform a community detection using several algortihms. Before testing the algorithms, let us create a simple benchmark graph.\n\n%matplotlib inline\nfrom matplotlib import pyplot as plt\n\n\nimport numpy as np\nimport pandas as pd\n\n\nimport networkx as nx \nG = nx.barbell_graph(m1=10, m2=4) \n\n\nMatrix Factorization\nWe start by using some matrix factorization technique to extract the embeddings, which are visualized and then clustered traditional clustering algorithms.\n\nfrom gem.embedding.hope import HOPE \ngf = HOPE(d=4, beta=0.01) \ngf.learn_embedding(G) \nembeddings = gf.get_embedding() \n\nSVD error (low rank): 0.052092\n\n\n\nfrom sklearn.manifold import TSNE\n\n\ntsne = TSNE(n_components=2) \n\nemb2d = tsne.fit_transform(embeddings)\n\n\nplt.plot(embeddings[:, 0], embeddings[:, 1], 'o', linewidth=0)\n\n\n\n\nWe start by using a GaussianMixture model to perform the clustering\n\nfrom sklearn.mixture import GaussianMixture\n\n\ngm = GaussianMixture(n_components=3, random_state=0) #.(embeddings)\n\n\nlabels = gm.fit_predict(embeddings)\n\n\ncolors = [\"blue\", \"green\", \"red\"]\n\n\nnx.draw_spring(G, node_color=[colors[label] for label in labels])\n\n\n\n\n\n\nSpectral Clustering\nWe now perform a spectral clustering based on the adjacency matrix of the graph. It is worth noting that this clustering is not a mutually exclusive clustering and nodes may belong to more than one community\n\nadj=np.array(nx.adjacency_matrix(G).todense())\n\n\nfrom communities.algorithms import spectral_clustering\n\ncommunities = spectral_clustering(adj, k=3)\n\nIn the next plot we highlight the nodes that belong to a community using the red color. The blue nodes do not belong to the given community\n\nplt.figure(figsize=(20, 5))\n\nfor ith, community in enumerate(communities):\n    cols = [\"red\" if node in community else \"blue\" for node in G.nodes]\n    plt.subplot(1,3,ith+1)\n    plt.title(f\"Community {ith}\")\n    nx.draw_spring(G, node_color=cols)\n\n\n\n\nThe next command shows the node ids belonging to the different communities\n\ncommunities\n\n[{14, 15, 16, 17, 18, 19, 20, 21, 22, 23},\n {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11},\n {12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23}]\n\n\n\n\nNon Negative Matrix Factorization\nHere, we again use matrix factorization, but now using the Non-Negative Matrix Factorization, and associating the clusters with the latent dimensions.\n\nfrom sklearn.decomposition import NMF\n\n\nnmf = NMF(n_components=2)\n\n\nemb = nmf.fit_transform(adj)\n\n/Users/deusebio/.pyenv/versions/3.8.6/envs/ml-book-5/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n  warnings.warn((\"The 'init' value, when 'init=None' and \"\n\n\n\nplt.plot(emb[:, 0], emb[:, 1], 'o', linewidth=0)\n\n\n\n\nBy setting a threshold value of 0.01, we determine which nodes belong to the given community.\n\ncommunities = [set(np.where(emb[:,ith]>0.01)[0]) for ith in range(2)]\n\n\nplt.figure(figsize=(20, 5))\n\nfor ith, community in enumerate(communities):\n    cols = [\"red\" if node in community else \"blue\" for node in G.nodes]\n    plt.subplot(1,3,ith+1)\n    plt.title(f\"Community {ith}\")\n    nx.draw_spring(G, node_color=cols)\n\n\n\n\nAlthough the example above does not show this, in general also this clustering method may be non-mutually exclusive, and nodes may belong to more than one community\n\n\nLouvain and Modularity Optimization\nHere, we use the Louvain method, which is one of the most popular methods for performing community detection, even on fairly large graphs. As described in the chapter, the Louvain method basically optimize the partitioning (it is a mutually exclusing community detection algorithm), identifying the one that maximize the modularity score, meaning that nodes belonging to the same community are very well connected among themself, and weakly connected to the other communities.\nLouvain, unlike other community detection algorithms, does not require to specity the number of communities in advance and find the best, optimal number of communities.\n\nfrom communities.algorithms import louvain_method\ncommunities = louvain_method(adj)\n\n\nc = pd.Series({node: colors[ith] for ith, nodes in enumerate(communities) for node in nodes}).values\nnx.draw_spring(G, node_color=c)\n\n\n\n\n\ncommunities\n\n\n\nGirvan Newman\nThe Girvan–Newman algorithm detects communities by progressively removing edges from the original graph. The algorithm removes the “most valuable” edge, traditionally the edge with the highest betweenness centrality, at each step. As the graph breaks down into pieces, the tightly knit community structure is exposed and the result can be depicted as a dendrogram.\nBE AWARE that because of the betweeness centrality computation, this method may not scale well on large graphs\n\nfrom communities.algorithms import girvan_newman\ncommunities = girvan_newman(adj, n=2)\n\n\nc = pd.Series({node: colors[ith] for ith, nodes in enumerate(communities) for node in nodes}).values\nnx.draw_spring(G, node_color=c)\n\n\ncommunities"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter03/04_Graph_Neural_Network.html",
    "href": "posts/2_Studies/GML/Chapter03/04_Graph_Neural_Network.html",
    "title": "[GML] Chap3: 비지도 그래프 학습 - Graph Neural Network",
    "section": "",
    "text": "In this notebook we will be performing unsupervised graph representation learning using Graph ConvNet as encoder.\nThe model embeds a graph by using stacked Graph ConvNet layers\n\n#from networkx import karate_club_graph, to_numpy_matrix\nimport numpy as np\nimport networkx as nx\nfrom scipy.linalg import sqrtm\nimport matplotlib.pyplot as plt\n\nG = nx.barbell_graph(m1=10, m2=4)\n\norder = np.arange(G.number_of_nodes())\nA = nx.to_numpy_matrix(G, nodelist=order)\nI = np.eye(G.number_of_nodes())\n\n\nnp.random.seed(7)\n\nA_hat = A + np.eye(G.number_of_nodes()) # add self-connections\n\nD_hat = np.array(np.sum(A_hat, axis=0))[0]\nD_hat = np.array(np.diag(D_hat))\nD_hat = np.linalg.inv(sqrtm(D_hat))\n\nA_hat = D_hat @ A_hat @ D_hat\n\ndef glorot_init(nin, nout):\n  sd = np.sqrt(6.0 / (nin + nout))\n  return np.random.uniform(-sd, sd, size=(nin, nout))\n\nclass GCNLayer():\n  def __init__(self, n_inputs, n_outputs):\n      self.n_inputs = n_inputs\n      self.n_outputs = n_outputs\n      self.W = glorot_init(self.n_outputs, self.n_inputs)\n      self.activation = np.tanh\n      \n  def forward(self, A, X):\n      self._X = (A @ X).T # (N,N)*(N,n_outputs) ==> (n_outputs,N)\n      H = self.W @ self._X # (N, D)*(D, n_outputs) => (N, n_outputs)\n      H = self.activation(H)\n      return H.T # (n_outputs, N)\n\ngcn1 = GCNLayer(G.number_of_nodes(), 8)\ngcn2 = GCNLayer(8, 4)\ngcn3 = GCNLayer(4, 2)\n\nH1 = gcn1.forward(A_hat, I)\nH2 = gcn2.forward(A_hat, H1)\nH3 = gcn3.forward(A_hat, H2)\n\nembeddings = H3\n\n\ndef draw_graph(G, filename=None, node_size=50):\n  pos_nodes = nx.spring_layout(G)\n  nx.draw(G, pos_nodes, with_labels=False, node_size=node_size, edge_color='gray')\n  \n  pos_attrs = {}\n  for node, coords in pos_nodes.items():\n    pos_attrs[node] = (coords[0], coords[1] + 0.08)\n\n  plt.axis('off')\n  axis = plt.gca()\n  axis.set_xlim([1.2*x for x in axis.get_xlim()])\n  axis.set_ylim([1.2*y for y in axis.get_ylim()])\n\nembeddings = np.array(embeddings)\ndraw_graph(G)\n\n\n\n\n\nplt.scatter(embeddings[:, 0], embeddings[:, 1])\nplt.savefig('embedding_gcn.png',dpi=300)\n\n\n\n\n\n\nFor the next example, we need to install StellarGraph, the python library we will be using to build the model\n\n# install StellarGraph\n!pip install -q stellargraph[demos]==1.2.1\n\nzsh:1: no matches found: stellargraph[demos]==1.2.1\n\n\n\nimport pandas as pd\nimport numpy as np\nimport networkx as nx\nimport os\n\nimport stellargraph as sg\nfrom stellargraph.mapper import FullBatchNodeGenerator\nfrom stellargraph.layer import GCN\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, optimizers, losses, metrics, Model\nfrom sklearn import preprocessing, model_selection\nfrom IPython.display import display, HTML\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nIn this demo, we will be using the PROTEINS dataset, already integrated in StellarGraph\n\ndataset = sg.datasets.PROTEINS()\ndisplay(HTML(dataset.description))\ngraphs, graph_labels = dataset.load()\n\nEach graph represents a protein and graph labels represent whether they are are enzymes or non-enzymes. The dataset includes 1113 graphs with 39 nodes and 73 edges on average for each graph. Graph nodes have 4 attributes (including a one-hot encoding of their label), and each graph is labelled as belonging to 1 of 2 classes.\n\n\n\n# let's print some info to better understand the dataset\nprint(graphs[0].info())\ngraph_labels.value_counts().to_frame()\n\nStellarGraph: Undirected multigraph\n Nodes: 42, Edges: 162\n\n Node types:\n  default: [42]\n    Features: float32 vector, length 4\n    Edge types: default-default->default\n\n Edge types:\n    default-default->default: [162]\n        Weights: all 1 (default)\n        Features: none\n\n\n\n\n\n\n  \n    \n      \n      label\n    \n  \n  \n    \n      1\n      663\n    \n    \n      2\n      450\n    \n  \n\n\n\n\n\n\nIt’s now time to build-up the model. StellarGraph offers several utility function to load and process the dataset, as well as define the GNN model and train.\n\n# TODO\ngenerator = sg.mapper.PaddedGraphGenerator(graphs)\n\n\n# define a GCN model containing 2 layers of size 64 and 32, respectively. \n# ReLU activation function is used to add non-linearity between layers\ngc_model = sg.layer.GCNSupervisedGraphClassification(\n    [64, 32], [\"relu\", \"relu\"], generator, pool_all_layers=True\n)\n\n\ninp1, out1 = gc_model.in_out_tensors()\ninp2, out2 = gc_model.in_out_tensors()\n\nvec_distance = tf.norm(out1 - out2, axis=1)\n\n\npair_model = Model(inp1 + inp2, vec_distance)\nembedding_model = Model(inp1, out1)\n\n\ndef graph_distance(graph1, graph2):\n    spec1 = nx.laplacian_spectrum(graph1.to_networkx(feature_attr=None))\n    spec2 = nx.laplacian_spectrum(graph2.to_networkx(feature_attr=None))\n    k = min(len(spec1), len(spec2))\n    return np.linalg.norm(spec1[:k] - spec2[:k])\n\n\ngraph_idx = np.random.RandomState(0).randint(len(graphs), size=(100, 2))\ntargets = [graph_distance(graphs[left], graphs[right]) for left, right in graph_idx]\ntrain_gen = generator.flow(graph_idx, batch_size=10, targets=targets)\n\n\npair_model.compile(optimizers.Adam(1e-2), loss=\"mse\")\n\n\nhistory = pair_model.fit(train_gen, epochs=500, verbose=0)\nsg.utils.plot_history(history)\n\n\n\n\n\nembeddings = embedding_model.predict(generator.flow(graphs))\n\n\nfrom sklearn.manifold import TSNE\n\ntsne = TSNE(2)\ntwo_d = tsne.fit_transform(embeddings)\n\n\nplt.scatter(two_d[:, 0], two_d[:, 1], c=graph_labels.cat.codes, cmap=\"jet\", alpha=0.4)\nplt.savefig('embedding_TSNE.png',dpi=300)"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter03/02_Autoencoders.html",
    "href": "posts/2_Studies/GML/Chapter03/02_Autoencoders.html",
    "title": "[GML] Chap3: 비지도 그래프 학습 - AutoEncoder",
    "section": "",
    "text": "AutoEncoder\nIn the following we will show you how to create, train and use a simple autoencoder. We will then show you how to make an auto-encoder more robust against noise.\n\nLoad Dataset\n\nimport tensorflow as tf\n\n\nfrom tensorflow.keras.datasets import fashion_mnist\n\n\n(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n\nprint (x_train.shape)\nprint (x_test.shape)\n\n\nfrom matplotlib import pyplot as plt\n\n\nclasses = {\n    0:\"T-shirt/top\",\n    1: \"Trouser\",\n    2: \"Pullover\",\n    3: \"Dress\",\n    4: \"Coat\",\n    5: \"Sandal\",\n    6: \"Shirt\",\n    7: \"Sneaker\",\n    8: \"Bag\",\n    9: \"Ankle boot\", \n}\n\n\nn = 6\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    # display original\n    ax = plt.subplot(1, n, i + 1)\n    plt.imshow(x_test[i])\n    plt.title(classes[y_test[i]])\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\nplt.show()\n# plt.savefig(\"TrainingSet.png\")\n\n\n\nCreate Autoencoder\n\nfrom tensorflow.keras.layers import Flatten, Conv2D, Dropout, MaxPooling2D, UpSampling2D, Input\n\n\nfrom tensorflow.keras import Model\n\n\ninput_img = Input(shape=(28, 28, 1))\n\nx = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nencoded = MaxPooling2D((2, 2), padding='same')(x)\n\n# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(16, (3, 3), activation='relu')(x)\nx = UpSampling2D((2, 2))(x)\ndecoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n\nautoencoder = Model(input_img, decoded)\n\n\nModel(input_img, encoded).summary()\n\n\nautoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n\n\nfrom tensorflow.keras.callbacks import TensorBoard\n\n\nautoencoder.fit(x_train, x_train,\n                epochs=50,\n                batch_size=128,\n                shuffle=True,\n                validation_data=(x_test, x_test),\n                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])\n\n\nautoencoder.save(\"./data/Batch50.p\")\n\n\nfrom tensorflow.keras.models import load_model\n\n\nautoencoder_first = load_model(\"./data/Batch50.p\")\n\n\ndecoded_imgs = autoencoder_first.predict(x_test)\n\nn = 6\nplt.figure(figsize=(20, 7))\nfor i in range(1, n + 1):\n    # Display original\n    ax = plt.subplot(2, n, i)\n    plt.imshow(x_test[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # Display reconstruction\n    ax = plt.subplot(2, n, i + n)\n    plt.imshow(decoded_imgs[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()\n\n\nfrom tensorflow.keras.optimizers import Adam\n\n\nautoencoder.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy')\n\n\nautoencoder.fit(x_train, x_train,\n                epochs=50,\n                batch_size=128,\n                shuffle=True,\n                validation_data=(x_test, x_test),\n                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])\n\n\nautoencoder.save(\"./data/Batch100.p\")\n\n\ndecoded_imgs = autoencoder.predict(x_test)\n\nn = 10\nplt.figure(figsize=(20, 4))\nfor i in range(1, n + 1):\n    # Display original\n    ax = plt.subplot(2, n, i)\n    plt.imshow(x_test[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # Display reconstruction\n    ax = plt.subplot(2, n, i + n)\n    plt.imshow(decoded_imgs[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\nplt.show()\n\n\n\nEmbeddings\nWe use the trained layers in order to get the core representation in the middle layer of the autoencoder, and we represent them with the TSNE\n\nembeddings = Model(input_img, Flatten()(encoded)).predict(x_test)\n\n\nfrom sklearn.manifold import TSNE\nimport numpy as np\n\n\ntsne = TSNE(n_components=2)\n\n\nemb2d = tsne.fit_transform(embeddings)\n\n\nx,y = np.squeeze(emb2d[:, 0]), np.squeeze(emb2d[:, 1])\n\n\nimport pandas as pd\n\n\nfrom matplotlib.cm import tab10\n\n\nsummary =  pd.DataFrame({\"x\": x, \"y\": y, \"target\": y_test, \"size\": 10})\n\nplt.figure(figsize=(10,8))\n\nfor key, sel in summary.groupby(\"target\"):\n    plt.scatter(sel[\"x\"], sel[\"y\"], s=10, color=tab10.colors[key], label=classes[key])\n    \nplt.legend()\nplt.axis(\"off\")\n\n\n\nDenoising\nIntroducing noise in order to train more robust auto-encoders\n\nfrom tensorflow.keras.layers import GaussianNoise\n\n\ninput_img = Input(shape=(28, 28, 1))\n\nnoisy_input = GaussianNoise(0.1)(input_img)\n\nx = Conv2D(16, (3, 3), activation='relu', padding='same')(noisy_input)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nencoded = MaxPooling2D((2, 2), padding='same')(x)\n\n# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(16, (3, 3), activation='relu')(x)\nx = UpSampling2D((2, 2))(x)\ndecoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n\nnoisy_autoencoder = Model(input_img, decoded)\n\n\nnoisy_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n\n\nnoisy_autoencoder.fit(x_train, x_train,\n                epochs=50,\n                batch_size=128,\n                shuffle=True,\n                validation_data=(x_test, x_test),\n                callbacks=[TensorBoard(log_dir='/tmp/noisy_autoencoder')])\n\n\nautoencoder.save(\"./data/DenoisingAutoencoder.p\")\n\n\nnoise_factor = 0.1\nx_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \nx_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n\nx_train_noisy = np.clip(x_train_noisy, 0., 1.)\nx_test_noisy = np.clip(x_test_noisy, 0., 1.)\n\n\ndecoded_imgs = autoencoder.predict(x_test_noisy)\n\ndecoded_imgs_denoised = noisy_autoencoder.predict(x_test_noisy)\n\nn = 6\nplt.figure(figsize=(20, 10))\nfor i in range(1, n + 1):\n    # Display original\n    ax = plt.subplot(3, n, i)\n    plt.imshow(x_test_noisy[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    if i==0:\n        plt.ylabel(\"Original\")\n    else:\n        ax.get_yaxis().set_visible(False)\n        \n    # Display reconstruction\n    ax = plt.subplot(3, n, i + n)\n    plt.imshow(decoded_imgs[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    if i==0:\n        plt.ylabel(\"Vanilla Autoencoder\")\n    else:\n        ax.get_yaxis().set_visible(False)\n     \n    ax = plt.subplot(3, n, i + 2*n)\n    plt.imshow(decoded_imgs_denoised[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    if i==0:\n        plt.ylabel(\"Denoising Autoencoder\")\n    else:\n        ax.get_yaxis().set_visible(False)\n    \n        \nplt.show()\n\n\ndecoded_imgs = noisy_autoencoder.predict(x_test_noisy)\n\nn = 10\nplt.figure(figsize=(20, 4))\nfor i in range(1, n + 1):\n    # Display original\n    ax = plt.subplot(2, n, i)\n    plt.imshow(x_test_noisy[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # Display reconstruction\n    ax = plt.subplot(2, n, i + n)\n    plt.imshow(decoded_imgs[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter03/01_Shallow_Embeddings.html",
    "href": "posts/2_Studies/GML/Chapter03/01_Shallow_Embeddings.html",
    "title": "[GML] Chap3: 비지도 그래프 학습 - Shallow_Embeddings",
    "section": "",
    "text": "import matplotlib.pyplot as plt\n\ndef draw_graph(G, node_names={}, node_size=500):\n    pos_nodes = nx.spring_layout(G)\n    nx.draw(G, pos_nodes, with_labels=True, node_size=node_size, edge_color='gray', arrowsize=30)\n    \n    pos_attrs = {}\n    for node, coords in pos_nodes.items():\n        pos_attrs[node] = (coords[0], coords[1] + 0.08)\n        \n    #nx.draw_networkx_labels(G, pos_attrs, font_family='serif', font_size=20)\n    \n    plt.axis('off')\n    axis = plt.gca()\n    axis.set_xlim([1.2*x for x in axis.get_xlim()])\n    axis.set_ylim([1.2*y for y in axis.get_ylim()])\n    plt.show()"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter03/01_Shallow_Embeddings.html#graph-factorization",
    "href": "posts/2_Studies/GML/Chapter03/01_Shallow_Embeddings.html#graph-factorization",
    "title": "[GML] Chap3: 비지도 그래프 학습 - Shallow_Embeddings",
    "section": "Graph Factorization",
    "text": "Graph Factorization\n\nimport networkx as nx\n\nG = nx.barbell_graph(m1=3, m2=2)\ndraw_graph(G)\n\n\nfrom pathlib import Path\nPath(\"gem/intermediate\").mkdir(parents=True, exist_ok=True)\n\n\nfrom gem.embedding.gf import GraphFactorization\n\nG = nx.barbell_graph(m1=10, m2=4)\ndraw_graph(G)\n\ngf = GraphFactorization(d=2,  data_set=None,max_iter=10000, eta=1*10**-4, regu=1.0)\ngf.learn_embedding(G)\n\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(10,10))\n\nfor x in G.nodes():\n    \n    v = gf.get_embedding()[x]\n    ax.scatter(v[0],v[1], s=1000)\n    ax.annotate(str(x), (v[0],v[1]), fontsize=12)"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter03/01_Shallow_Embeddings.html#graphrep",
    "href": "posts/2_Studies/GML/Chapter03/01_Shallow_Embeddings.html#graphrep",
    "title": "[GML] Chap3: 비지도 그래프 학습 - Shallow_Embeddings",
    "section": "GraphRep",
    "text": "GraphRep\n\nimport networkx as nx\nfrom karateclub.node_embedding.neighbourhood.grarep import GraRep\n\nG = nx.barbell_graph(m1=10, m2=4)\ndraw_graph(G)\n\ngr = GraRep(dimensions=2,order=3)\ngr.fit(G)\n\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(10,10))\n\nida = 4\nidb = 5\nfor x in G.nodes():\n    \n    v = gr.get_embedding()[x]\n    ax.scatter(v[ida],v[idb], s=1000)\n    ax.annotate(str(x), (v[ida],v[idb]), fontsize=12)"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter03/01_Shallow_Embeddings.html#hope",
    "href": "posts/2_Studies/GML/Chapter03/01_Shallow_Embeddings.html#hope",
    "title": "[GML] Chap3: 비지도 그래프 학습 - Shallow_Embeddings",
    "section": "HOPE",
    "text": "HOPE\n\nimport networkx as nx\nfrom gem.embedding.hope import HOPE\n\nG = nx.barbell_graph(m1=10, m2=4)\ndraw_graph(G)\n\nhp = HOPE(d=4, beta=0.01)\nhp.learn_embedding(G)\n\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(10,10))\n\nfor x in G.nodes():\n    \n    v = hp.get_embedding()[x,2:]\n    ax.scatter(v[0],v[1], s=1000)\n    ax.annotate(str(x), (v[0],v[1]), fontsize=20)"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter03/01_Shallow_Embeddings.html#deepwalk",
    "href": "posts/2_Studies/GML/Chapter03/01_Shallow_Embeddings.html#deepwalk",
    "title": "[GML] Chap3: 비지도 그래프 학습 - Shallow_Embeddings",
    "section": "DeepWalk",
    "text": "DeepWalk\n\nimport networkx as nx\nfrom karateclub.node_embedding.neighbourhood.deepwalk import DeepWalk\n\nG = nx.barbell_graph(m1=10, m2=4)\ndraw_graph(G)\n\ndw = DeepWalk(dimensions=2)\ndw.fit(G)\n\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(10,10))\n\nfor x in G.nodes():\n    \n    v = dw.get_embedding()[x]\n    ax.scatter(v[0],v[1], s=1000)\n    ax.annotate(str(x), (v[0],v[1]), fontsize=12)"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter03/01_Shallow_Embeddings.html#node2vec",
    "href": "posts/2_Studies/GML/Chapter03/01_Shallow_Embeddings.html#node2vec",
    "title": "[GML] Chap3: 비지도 그래프 학습 - Shallow_Embeddings",
    "section": "Node2Vec",
    "text": "Node2Vec\n\nimport networkx as nx\nfrom node2vec import Node2Vec\n\nG = nx.barbell_graph(m1=10, m2=4)\ndraw_graph(G)\n\nnode2vec = Node2Vec(G, dimensions=2)\nmodel = node2vec.fit(window=10)\nembeddings = model.wv\n\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(10,10))\n\nfor x in G.nodes():\n    \n    v = model.wv[str(x)]\n    ax.scatter(v[0],v[1], s=1000)\n    ax.annotate(str(x), (v[0],v[1]), fontsize=16)\n\nplt.show()"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter03/01_Shallow_Embeddings.html#edge2vec",
    "href": "posts/2_Studies/GML/Chapter03/01_Shallow_Embeddings.html#edge2vec",
    "title": "[GML] Chap3: 비지도 그래프 학습 - Shallow_Embeddings",
    "section": "Edge2Vec",
    "text": "Edge2Vec\n\nfrom node2vec.edges import HadamardEmbedder\nedges_embs = HadamardEmbedder(keyed_vectors=model.wv)\n\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(10,10))\n\nfor x in G.edges():\n    \n    v = edges_embs[(str(x[0]), str(x[1]))]\n    ax.scatter(v[0],v[1], s=1000)\n    ax.annotate(str(x), (v[0],v[1]), fontsize=16)\n\nplt.show()"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter03/01_Shallow_Embeddings.html#graph2vec",
    "href": "posts/2_Studies/GML/Chapter03/01_Shallow_Embeddings.html#graph2vec",
    "title": "[GML] Chap3: 비지도 그래프 학습 - Shallow_Embeddings",
    "section": "Graph2Vec",
    "text": "Graph2Vec\n\nimport random\nimport matplotlib.pyplot as plt\nfrom karateclub import Graph2Vec\n\nn_graphs = 20\n\ndef generate_radom():\n    n = random.randint(6, 20)\n    k = random.randint(5, n)\n    p = random.uniform(0, 1)\n    return nx.watts_strogatz_graph(n,k,p), [n,k,p]\n\nGs = [generate_radom() for x in range(n_graphs)]\n\nmodel = Graph2Vec(dimensions=2, wl_iterations=10)\nmodel.fit([x[0] for x in Gs])\nembeddings = model.get_embedding()\n\nfig, ax = plt.subplots(figsize=(10,10))\n\nfor i,vec in enumerate(embeddings):\n    \n    ax.scatter(vec[0],vec[1], s=1000)\n    ax.annotate(str(i), (vec[0],vec[1]), fontsize=40)"
  },
  {
    "objectID": "posts/2_Studies/GML/Chapter03/03_Structural_deep_neural_embeddings.html",
    "href": "posts/2_Studies/GML/Chapter03/03_Structural_deep_neural_embeddings.html",
    "title": "[GML] Chap3: 비지도 그래프 학습 - Structural Deep Network Embedding",
    "section": "",
    "text": "Structural Deep Network Embedding\nimport tensorflow as tf\n\nfrom gem.embedding.sdne import SDNE\n\n\nimport networkx as nx\n\n\ngraph = nx.karate_club_graph()\n\n\nm1 = SDNE(d=2, beta=5, alpha=1e-5, nu1=1e-6, nu2=1e-6, K=3,n_units=[50, 15,], rho=0.3, n_iter=10, \n          xeta=0.01,n_batch=50,\n          modelfile=['enc_model.json', 'dec_model.json'],\n          weightfile=['enc_weights.hdf5', 'dec_weights.hdf5'])\n\n\nm1 = SDNE(d=2, beta=5, alpha=1e-5, nu1=1e-6, nu2=1e-6, K=3,n_units=[50, 15,], rho=0.3, n_iter=50, \n          xeta=0.01,n_batch=100,\n          modelfile=['enc_model.json', 'dec_model.json'],\n          weightfile=['enc_weights.hdf5', 'dec_weights.hdf5'])\n\n\nm1.learn_embedding(graph)\n\n\nx, y = list(zip(*m1.get_embedding()))\n\n\nfrom matplotlib import pyplot as plt\n\n\nplt.plot(x, y, 'o',linewidth=None)"
  },
  {
    "objectID": "posts/4_Notes/2000-01-01-우분투 포맷 및 개발용 서버 셋팅.html",
    "href": "posts/4_Notes/2000-01-01-우분투 포맷 및 개발용 서버 셋팅.html",
    "title": "[Note] 우분투 포맷 및 개발용 서버 셋팅",
    "section": "",
    "text": "About this doc\n- 우분투에서 여러가지 개발환경을 설정하는 방법을 포스팅 하겠다.\n- 이 포스트는 우분투를 메인OS(사무용+연구용)로 사용하고 싶은 사람, 우분투를 활용하여 개발용 서버를 구축하고 싶은 사람에게 모두 유용한다.\n- 이 포스트는 2080 이상의 GPU를 활용한 학습을 원하는 사람에게 유용하다.\n- 이 포스트는 R과 파이썬을 동시에 쓰는 사람에게 유용하다.\n- 이 포스트는 Rstudio, Jupyter Lab을 동시에 쓰는 사람에게 유용하다.\n- 매년 조금씩 셋팅방법이 다른것 같다.\n- 가장 최근에는 2023년 3월8일에 이 블로그 내용으로 셋팅해보았음.\n\n\n우분투설치\n- 22.04부터는 파티션 나누지 않고 그냥 설치해도 잘 되는것 같다.\n\n\n네트워크 설정\n- ?표시있는 아이콘 \\(\\to\\) Wired Connected \\(\\to\\) Wired Settings \\(\\to\\) Connection의 설정 \\(\\to\\) IPv4 \\(\\to\\) Manual \\(\\to\\) Address, Netmask, Gateway, DNS 설정 \\(\\to\\) 네트워크 토글\n\n\n한글설정 (개발용 서버일 경우 생략 가능)\n- 아래와 같이 커맨드에 친다.\nibus-setup\n이걸 치면 IBus Preferences 라는 창이 나오는데 여기에서 (1) Input Method 탭 클릭 (2) Add 버튼 클릭 (3) Korean 선택 (4) Hangul 선택을 한다.\n- 위의 단계에서 Korean이 안보이면 Language Support로 가서 한국어팩을 설치하고 리부팅 하면 된다. (보통 실행하자마자 알아서 설치되더라.. 설치가 안되면 Install / Remove Languages... 이라는 탭을 클릭해서 설치하자) 리부팅을 꼭 해야한다는 것에 주의하자.\n- 이제 Region & Language로 가서 설정하면 된다.\n\n\n그래픽카드 드라이버설치\n- 전체적인 내용은 여기를 참고하자.\n- 준비작업\nsudo apt update \nsudo apt install gcc\nsudo apt install build-essential\n- 우선 gedit를 열고 아래를 복사해서 붙여넣는다.\nblacklist nouveau\noptions nouveau modeset=0\n파일이름을 blacklist-nouveau.conf로 home에 저장\n- 루트권한획득\nsudo -i\n아이디와 비밀번호를 입력하고 루트권한을 얻는다.\n- 아래를 입력한다.\nsudo cp /home/cgb2/blacklist-nouveau.conf /etc/modprobe.d\nsudo update-initramfs -u\nsudo reboot \n- 그래픽카드 다운로드: 드라이버 설치파일을 다운받는다. 앤비디아공식홈페이지에서 다운받자. OS를 리눅스 64-bit으로 선택하고 검색을 누르면 다운받아진다.\n- 그래픽키다 설치: 다운받은뒤에는 파일이 있는 폴더로 이동하여\nchmod +x NVIDIA-Linux-x86_64-410.78.run\n를 실행하자. 보통 NVI까지치고 적당히 탭을 누르면 알아서 뒷부분이 완성된다. 이 과정은 추후에 드라이버를 실행할수 있도록 권한을 풀어두는 것이다. 그리고 아래를 실행한다.\nsudo ./NVIDIA-Linux-x86_64-410.78.run\n그 다음 드라이버가 잘 설치되었는지 확인한다.\nnvidia-smi\n\n\n아나콘다\n- (아나콘다 설치) 아나콘다를 다운받은 폴더로 가서 아래와 같이 실행한다.\nbash Anaconda3-2019.03-Linux-x86_64.sh\n대충 bash Ana 정도까지만 치고 tab을 누르면 알아서 완성된다.\n- (환경만들기) 커맨드를 키고 아래를 실행한다.\n(base) conda create -n py38r40 python=3.8\n(base) conda create --name py38r40 python=3.8\n둘 중 아무거나 실행해도 된다. 파이썬 환경이 너무 높으면 나중에 conda tensorflow-gpu가 먹히지 않으니 환경을 만들때 파이썬버전을 3.8.x로 하자. (현시점 2021년 2월25일기준 3.9.x이면 conda tensorflow-gpu 가 동작하지 않음.)\n\n\nssh연결\n- 처음에 ssh를 연결하기위해서는 연결당하는 컴퓨터에 가서 아래를 실행해야 한다.\nsudo apt install openssh-server\n22번포트 우회하기\n- step1: /etc/ssh/sshd_config 파일을 연다.\nsudo vi /etc/ssh/sshd_config \n- step2: Port 22 라고 된 부분의 주석을 풀고 원하는 포트번호 설정\n...\n\n#Port 22\n#AddressFamily any\n#ListenAddress 0.0.0.0\n#ListenAddress ::\n\n...\n- step3: 수정내용을 적용\nsudo systemctl restart ssh.service\n- step4: 수정한 포트로 ssh접속\n\n\n주피터랩 원격제어\n- 1단계: 주피터랩설치\n(py38) conda install -c conda-forge jupyterlab\n\nNote: 사실 위에서 주피터랩을 따로 설치안해도 주피터랩이 잘만 실행된다. 하지만 이렇게하니까 나중에 R커널을 만들기위해 IRkernel::installspec()을 실행할때 에러가 난다.\n\n- 2단계: 패스워드 설정\n(py38) jupyter lab --generate-config\n(py38) jupyter lab password\n- 3단계: jupyter lab 환경설정\nnano /home/cgb/.jupyter/jupyter_lab_config.py \n아래를 변경\nc.ServerApp.ip = '192.168.0.4'\nc.ServerApp.port = 1306\nc.ServerApp.open_browser = False\n여기에서 192.168.0.4 는 내부아이피다. 고정아피이가 있다면 고정아이피 주소를 쓰면 된다.\n\n\n주피터노트북 원격제어\n- 1단계: 주피터노트북 설치 (보통 lab을 설치하면 이미 설치되어있음)\n(py38) conda install -c conda-forge notebook \n- 2단계: 패스워드 설정\nfrom notebook.auth import passwd\npasswd()\nEnter password: \nVerify password: \n생성된값 (argon 어쩌고..)을 복사\n- 3단계: 환경설정\njupyter notebook --generate-config\nnano /home/cgb/.jupyter/jupyter_notebook_config.py\n아이피주소와 패스워드를 바꾼다. (port는 선택, browser도 선택 )\nc.NotebookApp.open_browser = False\nc.NotebookApp.ip = '192.168.0.4'\nc.NotebookApp.port = 1307\nc.NotebookApp.password = ''\n여기에서 192.168.0.4 는 내부아이피다. 고정아피이가 있다면 고정아이피 주소를 쓰면 된다.\n\nTip: 주피터노트북과 랩을 양쪽으로 셋팅후 주피터 노트북으로 실행하면 2개를 모두 쓸 수 있음\n\n\n\nR설치ver1: (base)에 설치\n- 설치전: 기존의 R 삭제\nconda remove r-base -y \nsudo apt-get remove r-base-core \nsudo apt purge r-base* r-recommended r-cran-*\nsudo apt autoremove\n- R설치전 준비작업: 나노에디터를 키고 /etc/apt/sources.list를 연다.\nsudo nano /etc/apt/sources.list\n화살표로 이동하여 맨아래로 간뒤에 아래중 하나를 추가한다. (나는 focal-cran40으로 추가함)\ndeb https://cloud.r-project.org/bin/linux/ubuntu impish-cran40/\ndeb https://cloud.r-project.org/bin/linux/ubuntu hirsute-cran40/\ndeb https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/\ndeb https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/\ndeb https://cloud.r-project.org/bin/linux/ubuntu xenial-cran40/\n저장후 나노에디터 종료. 그리고 아래를 실행.\nsudo apt-get update\n경우에 따라서 아래와 같은 에러메시지가 뜰 수 있다.\n...\nW: GPG error: https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9 \n...\n공개키가 없어서 생기는 에러이므로 아래와 같이 가져온다.\nwget -qO- https://cloud.r-project.org/bin/linux/ubuntu/marutter_pubkey.asc | sudo tee -a /etc/apt/trusted.gpg.d/cran_ubuntu_key.asc\nsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9\n#sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 51716619E084DAB9\n그리고 다시 아래를 실행\nsudo apt-get update\n에러가 없이 뭔가 마무리 되어야한다.\n(base) cgb3@cgb3:~$ sudo apt-get update\nIgn:1 http://linux.dropbox.com/ubuntu disco InRelease\nHit:2 http://security.ubuntu.com/ubuntu focal-security InRelease  \nHit:3 http://kr.archive.ubuntu.com/ubuntu focal InRelease                                 \nHit:4 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease                \nHit:5 http://linux.dropbox.com/ubuntu disco Release                 \nGet:6 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\nHit:8 http://kr.archive.ubuntu.com/ubuntu focal-updates InRelease\nGet:9 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ Packages [46.4 kB]\nHit:10 http://kr.archive.ubuntu.com/ubuntu focal-backports InRelease\nFetched 50.0 kB in 1s (36.5 kB/s)                   \nReading package lists... Done\n- R설치\nwget http://security.ubuntu.com/ubuntu/pool/main/i/icu/libicu66_66.1-2ubuntu2_amd64.deb\nsudo dpkg -i libicu66_66.1-2ubuntu2_amd64.deb\nsudo apt-get install r-base\n- tidyverse 설치 (R studio 설치전에 tidyverse 설치해야함)\n- Rstudio 설치: https://www.rstudio.com/products/rstudio/download-server/debian-ubuntu/\n\n우분투22로 설정할것!!\n\nsudo apt remove rstudio-server\nsudo apt-get install gdebi-core\nwget https://download2.rstudio.org/server/jammy/amd64/rstudio-server-2022.12.0-353-amd64.deb\nsudo gdebi rstudio-server-2022.12.0-353-amd64.deb\n- Rstudio를 설치하면 ~/R/x86_64-conda-linux-gnu-library/4.1이 새로 생성된다.\n\nRstudio에서 설치한 패키지는 이 폴더에 저장된다.\n\n- 주피터와 R커널 연결\nR # sudo R \ninstall.packages(\"IRkernel\")\nIRkernel::installspec()\n\n\nR설치ver2: (py38r40)에 설치\n- R설치\n(py38r40) conda install -c conda-forge r-essentials=4.0\n이러면 콘다환경에는 R이 깔리고 base에는 R이 깔리지 않는다.\n- 커널연결\n콘다환경에서 R을 실행한다. Rstudio가 아니라 커맨드에서 R을 실행해야한다. 그리고 아래를 실행하면 주피터랩과 R환경이 연결된다.\nIRkernel::installspec()\n이제 주피터랩에서 R kernel을 사용할 수 있다.\n\n\n가상환경에서 Rstudio server 설치 (어려움)\n- 이제 Rstudio server를 설치하는 방법을 다룬다.\n- 먼저 Rstudio를 설치한다. 참고로 Rstudio server 설치하는법은 여기를 참고하라. 요약하면 터미널에서 아래3줄을 입력하기만 하면된다.\n(py38r40) sudo apt-get install gdebi-core\n(py38r40) wget https://download2.rstudio.org/server/bionic/amd64/rstudio-server-1.2.5033-amd64.deb\n(py38r40) sudo gdebi rstudio-server-1.2.5033-amd64.deb\n\nWarning: Rstudio 1.3x 이상을 설치하지말고 1.2x를 설치해야 한다. 이상하게 1.3x이상은 후에 서술할 Gregor Strurm가 그의 깃허브에서 제안하는 방식이 잘 동작하지 않았다. 이는 알려진 문제였고 이를 해결하는 해결책을 서술한 스레드가 있어보이긴 했지만 나는 그냥 Rstudio 1.2x를 설치하고 쓰는 것을 선택했다.\n\n\nNote: 이미 rstudio server 가 다른버전으로 깔려있다면 sudo apt remove rstudio-server 를 통하여 삭제하고 설치하자.\n\n- 이제 Rstudio 설치가 끝났다. 설치된 Rstudio를 아나콘다 가상환경에 설치된 R과 연결해보자. 우선 아래를 실행한다.\n(py38r40) sudo apt install uuid\n(py38r40) sudo apt install git\n(py38r40) git clone https://github.com/grst/rstudio-server-conda.git\n위에 두줄은 Gregor Sturm이 만든 어떤 프로그램을 쓰기 위한 사전준비작업이다. 마지막줄을 실행하면 Gregor Sturm이 만든 프로그램이 다운받아진다. 이게 프로그램 설치가 완료된것이다. 이제 컴퓨터 껐다 킬때마다 아래를 실행한다.\n(py38r40) ./rstudio-server-conda/local/start_rstudio_server.sh 8787 # use any free port number here. \n이제 192.168.0.4:8787 따위의 주소로 접속하면 Rstudio를 쓸 수 있다. 참고로 system-wide Rstudio server를 죽여야 할 때가 있다. 그럴땐 아래 명령을 치면 된다.\n(py38r40) sudo systemctl disable rstudio-server.service\n(py38r40) sudo systemctl stop rstudio-server.service\n\n\n자주 설치하는 패키지 리스트\n- 아래를 미리 깔아두자..\n# conda install -c conda-forge jupyterlab \nconda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch\npip install fastai\npip install plotly \npip install ipywidgets\npip install jupyter-dash\npip install dash \npip install plotnine\npip install seaborn\npip install opencv-python\npip install folium\npip install pandas_datareader\nconda install -c conda-forge r-essentials=4 \npip install rpy2\nconda install -c conda-forge python-graphviz\n- tensorflow-gpu 는 현재(2022-03-06) python=3.10 에서 동작함\nconda create -n py310 python=3.10 \nconda activate py310 \nconda install -c conda-forge tensorflow-gpu \n- 아래를 설치하면 좋음\nsudo apt install mc \n\n\n터미널 예쁘게 만들기\n- zsh 설치 + oh my zsh 설치\nsudo install zsh \nsh -c \"$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\"\n- 테마변경\n\n.zshrc 파일 열기\n\nnano ~/.zshrc \n\n아래의 내용 수정\n\n...\nZSH_THEME=\"agnoster\"\n...\n- 색상변경\n\n아래의 파일 열기\n\ncd ~/.oh-my-zsh/themes/\nnano agnoster.zsh-theme  \n\n내용수정\n\n...\nprompt_dir() {\n  prompt_segment 39d $CURRENT_FG '%~'\n}\n...\n\n\nsublime text and TeX (개발용 서버일 경우 생략 가능)\n- ‘Ubuntu Software’에 가서 ’sublime Text’를 치면 다운받을 수 있다. 다운받은뒤에 ’file’ -> ’open folder’를 활용하여 깃허브의 로칼저장소를 열어두면 편리하다.\n- 아래를 실행하여 TeX을 깐다.\nsudo apt install texlive-full\n- 이제 sublime과 latex을 연결하여보자. 여기를 참고하자. (1) sublime을 키고 ‘컨트롤+쉬프트+p’를 눌러 ’Install Package Control’ 선택 (2) 다시 ‘컨트롤+쉬프트+p’ 를 눌러 ‘Package Control: Install Package’를 실행 (3) 그러면 바로 검색창이 나오는데 거기서 ’LaTeXTools’를 입력해서 실행 (4) 다시 ’컨트롤+쉬프트+p’를 누르고 ’LaTeXTools: Check system’ 선택. 모두 ’available’이 나오면 잘 설치된 것이다.\n- *.tex파일을 열고 ’컨트롤+b’를 누르자. 처음이면 어떤 메뉴들이 보일텐데 그냥 ’Latex’을 선택하자. 그러면 코딩결과가 pdf로 나온다.\n- (수식미리보기) ‘Perferences’ > ‘Packages Setting’ > ‘LaTeXTools’ > ‘Settings-User’를 선택한다. ’93번째라인’에 ’preview_math_mode’를 “all”로 바꾼다. 그러면 수식들이 미리 출력된다. 그외에도 자유롭게 셋팅을 조정할 수 있다. 원래셋팅은 ’Perferences’ > ‘Packages Setting’ > ‘LaTeXTools’ > ‘Settings-Defaults’ 에 있다."
  },
  {
    "objectID": "posts/4_Notes/2000-01-06-주피터랩- 설정 및 몇가지 팁.html",
    "href": "posts/4_Notes/2000-01-06-주피터랩- 설정 및 몇가지 팁.html",
    "title": "[Note] 주피터랩: 설정 및 몇가지 팁",
    "section": "",
    "text": "주피터에 R커널을 연결할 경우 그림크기 조정\noptions(repr.plot.width=10, repr.plot.height=3,repr.plot.res=300)\n\n\n깃허브에서 *.py파일 불러오기\nimport requests\nexec(requests.get('http://miruetoto.github.io/my_code/datahandling.py').text)\n\n\nrpy2 magic\nimport rpy2\n%load_ext rpy2.ipython\n\n\n깃허브에서 *.R파일 불러오기\nimport rpy2\n%load_ext rpy2.ipython\n%R library(devtools)\n%R source_url(\"http://miruetoto.github.io/my_code/datahandling.r\")\n\n\nmatplotlib 그림크기조정\nimport matplotlib as mpl \nimport matplotlib.pyplot as plt \nIpython_default=plt.rcParams.copy() # save initial value \nfrom matplotlib import cycler\nplt.rc('figure',dpi=150) # default value 4 figure.dpi is 72.0 \n# plt.rcParams.update(Ipython_default) # load initial value \n\n\nGPU 사용여부 체크\nfrom keras import backend as K\nprint('GPU check 4 Keras: '+ str(K.tensorflow_backend._get_available_gpus()))\nimport torch\nprint('GPU check 4 Pytorch: '+ str(torch.cuda.get_device_name(0)))\n\n\n깃랩관련 (회사아니면 필요없음)\n- load *.py from gitlab\nimport gitlab\ngl = gitlab.Gitlab('http://10.178.145.54:9000', private_token='RkZz465zdyyEChamLKy8')\ngl.auth()\nproject = gl.projects.get(2)\n\n# (1) load RF.py, RF_withGIT.py, RF_withR.py\nRF_py = project.files.get(file_path='modeling/RF.py', ref='fridge').decode()\nRF_GIT_py = project.files.get(file_path='utils/RF_withGIT.py', ref='fridge').decode()\nRF_R_py = project.files.get(file_path='utils/RF_withR.py', ref='fridge').decode()\nexec(str(RF_py, 'utf-8'))\nexec(str(RF_GIT_py, 'utf-8'))\nexec(str(RF_R_py, 'utf-8'))\n- load *.R in gitlab\nimport gitlab\ngl = gitlab.Gitlab('http://10.178.145.54:9000', private_token='RkZz465zdyyEChamLKy8')\ngl.auth()\nproject = gl.projects.get(2)\nRF_R_rcode = project.files.get(file_path='utils/RF_Rfunctions.r', ref='fridge').decode()\n# tricks for source('Rfunctions.r')\nfile1 = open(\"RF_Rfunctions.r\",\"w\") \nfile1.write(str(RF_R_rcode, 'utf-8'))\nfile1.close() \nro.r(\"source('RF_Rfunctions.r')\")\nimport os\nos.remove('RF_Rfunctions.r')\n\n\n& 옵션으로 주피터 실행\n- 서버에 접속한다.\nssh lgcgb@10.178.144.65\n아래와 같이 끝에 &을 붙이면 된다.\nconda activate py20190129\njupyter lab &\n실행하고 난뒤에는 엔터를 쳐서 빠져나온다. 이렇게 하면 서버자체에 모니터를 연결하고 커널창을 띄운것과 같은 효과를 준다. 즉 서버에 접속한 컴퓨터를 끄는것과 상관없이 서버에서는 항상 주피터가 열려 있게 된다.\n\n\n& 옵션으로 실행한 주피터프로세스 죽이기\n- 서버에 접속한다.\nssh lgcgb@10.178.144.65\n실행된 프로세스를 찾기위해 아래를 실행한다.\nps aux | grep jupyter-lab\n결과는 아래와 같이 나온다.\nlgcgb    26888  0.2  0.1 326760 86724 ?        Sl   10:14   0:12 /home/lgcgb/anaconda3/envs/py20190129/bin/python3.7 /home/lgcgb/anaconda3/envs/py20190129/bin/jupyter-lab\nlgcgb    27146  0.0  0.0  15720  1008 pts/3    S+   11:56   0:00 grep --color=auto jupyter-lab\n26888에 해당하는 것이 주피터를 띄운 커널이다. 이 번호를 기억했다가 프로세스를 아래와 같은 명령으로 죽인다.\nkill 26888\n\n\n패스워드 없이 주피터 실행\n- 아래와 같이 하면 외부에서 접속할때 패스워드를 입력하지 않음.\njupyter lab --LabApp.token='' --LabApp.password=''\njupyter notebook --NotebookApp.token='' --NotebookApp.password=''"
  },
  {
    "objectID": "posts/4_Notes/2000-01-07-줄리아 설치 및 실행.html",
    "href": "posts/4_Notes/2000-01-07-줄리아 설치 및 실행.html",
    "title": "[Note] 줄리아 설치 및 실행",
    "section": "",
    "text": "설치\n- 여기에 접속한다. 스크롤링하여 ’Generic Linux Binaries for x86 / 64-bit(GPG)’를 찾는다. 그리고 ’64-bit’를 클릭해서 다운받는다. (참고로 왼쪽에 ’help’를 누르면 설치페이지 설명서가 나온다.) 그러면 아래와 같은 파일이 나온다.\njulia-1.3.1-linux-x86_64.tar.gz\n이 파일을 더블클릭해서 압축을 풀어준다. 압축을 풀면 julia-1.3.1라는 폴더가 생긴다. 이 폴더를 원하는 위치로 (줄리아가 설치되기를 원하는 위치) 이동시킨다. 나는 home에 이동시켰다.\n- 아래를 실행하면 줄리아가 실행된다. (둘중 아무거나)\n/home/cgb/julia-1.3.1/bin/julia\n~/julia-1.3.1/bin/julia\n\n\n주피터와 연결\n- 아래중 하나를 실행하여 줄리아를 킨다.\n/home/cgb/julia-1.3.1/bin/julia\n~/julia-1.3.1/bin/julia\n- 줄리아를 실행한뒤에 아래를 입력하면 주피터노트북에 연결된다.\nusing Pkg\nPkg.add(\"IJulia\")\n- 한 가지 의문점이 있다. 나같은 경우는 ’(base)’에서 줄리아를 실행하고 연결하였다. 그런데 혹시 몰라서 (py38r40)에서도 줄리아를 실행해봤는데 잘 실행되었다. 줄리아를 실행시키고 위의 명령 Pkg.add(\"IJulia\")를 다시쳤는데, 이미 연결되어서 더이상 변화시킨게 없다는 메시지가 떴다. 이러면 (base)에 설치된 줄리아가 (py38r40)에서도 실행된 줄리아와 동일하다는 의미일까? \\(\\Longrightarrow\\) 그렇다. 왜냐하면 줄리아는 anaconda내의 폴더에 설치한 것이 아니기 때문에. home에 보통 설치하니깐.\n\n\n환경변수 조정\n- 참고로 어디서든 줄리아를 실행시키고 싶다면 환경변수를 조작하면 된다. 아래를 실행해서 나노에디터를 킨다.\nsudo nano /etc/environment\n맨끝에 다음과 같이 되어있을 것이다.\n~~ usr/local/games\"\n마지막에 /home/cgb/julia-1.3.1/bin/julia를 추가한다. 즉 아래와 같이 만든다.\n~~ usr/local/games:/home/cgb/julia-1.3.1/bin/julia\"\n세이브하고 나온다. (그런데 이 과정을 안거쳐도 되는것 같음.) 이제 커맨드에서 아래를 실행한다.\nexport PATH=$PATH:/home/cgb/julia-1.3.1/bin\n이렇게하면 이제 단순히 julia라고만 쳐도 julia가 실행된다.\n\n\n플루토에서 강의영상 넣는 방법\n- 아래를 삽입\nhtml\"\"\"\n<div style=\"display: flex; justify-content: center;\">\n<div  notthestyle=\"position: relative; right: 0; top: 0; z-index: 300;\">\n<iframe src=\n\"\nhttps://www.youtube.com/embed/\n\"\nwidth=600 height=375  frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\"\"\"\n\n\n플루토를 이용한 홈페이지 만드는 방법\n- 단계1: https://github.com/JuliaPluto/static-export-template 에 가서 Clone\n- 단계2: Setting -> GitHub Pages -> Source -> gh-pages / root\n\n\n플루토 키는 방법\nimport Pluto\nPluto.run(host=\"0.0.0.0\",port=1234,launch_browser=false,require_secret_for_open_links=false,require_secret_for_access=false,threads=\"8\")"
  },
  {
    "objectID": "posts/4_Notes/2000-01-08-깃(Git).html",
    "href": "posts/4_Notes/2000-01-08-깃(Git).html",
    "title": "[Note] 깃(Git)",
    "section": "",
    "text": "clone\ngithub repository \\(\\to\\) code \\(\\to\\) clone tab, ssh를 복사 (git@github.com:miruetoto/yechan.git처럼 생김)\n터미널에서 아래를 입력\ngit clone git@github.com:miruetoto/yechan.git 01_yechan\n\n\npull\n- 깃이 설치된 가장 상위폴더(Documents/Github/miruetoto.github.io)에 가서 아래를 입력한다.\ngit pull\n\n\nbranch\n- 서버에 이미 guebin이라는 브랜치가 있다면 아래와 같이 동기화 시킨다.\ngit chechout guebin\ngit push -u origin guebin\n여기에서 git push -u origin guebin을 안해도 동기화가 잘될때도 있는데 아닐때도 있다.\n\n\nremote\n- 깃이 설치된 가장 상위폴더(Documents/Github/miruetoto.github.io)에 가서 아래를 입력하면 깃허브의 url 주소를 확인할 수 있다.\n(base) lgcgb2@lgcgb2:~/Documents/GitHub/miruetoto.github.io$ git remote -v\norigin https://github.com/miruetoto/miruetoto.github.io.git (fetch)\norigin https://github.com/miruetoto/miruetoto.github.io.git (push)\nupstream https://github.com/daattali/beautiful-jekyll.git (fetch)\nupstream https://github.com/daattali/beautiful-jekyll.git (push)\n\n\nconfig\n- 설정보기\ngit config —list \n- 설정삭제\ngit config --unset user.name\ngit config --unser user.email\n- 전역설정삭제\ngit config --unset --global user.name\ngit config --unset --global user.email\n- 중복값 설정삭제\ngit config --unset-all user.name\ngit config --unset-all user.email\n- 중복값 전역으로 설정삭제\ngit config --unset-all --global user.name\ngit config --unset-all --global user.email\n- 비번안치고 푸쉬하는법?\ngit config credential.helper store\n입력이후에 git push\n\n\nGit token\nhttps://github.com/settings/tokens 에서 확인가능\n\nAppendix\n\n리눅스에서 github desktop 설치\n\n여기로 간다.\n한 챕터의 (2.3.1 Linux RC1 와 같이 되어있음) 아래쪽에 보면 ▶ Assets 라고 되어있는데 이걸 클릭하면 다운받을 수 있는 파일들이 나온다. 확장자가 .deb로 끝나는걸 골라서 다운받은뒤에 실행한다."
  },
  {
    "objectID": "posts/4_Notes/2000-01-04-우분투 익히기.html",
    "href": "posts/4_Notes/2000-01-04-우분투 익히기.html",
    "title": "[Note] 우분투 익히기",
    "section": "",
    "text": "날짜, 달력\ndate \ncal \n\n\n파일시스템\n- 작업경로, 디렉토리 이동, 파일확인\npwd \ncd cgb2 \ncd ~cgb2 ## 어디서든 실행가능\ncd ## cgb2로 로그인 되어있을 경우 cd ~cgb2와 동일 \ncd ~cgb2/Dropbox\nls \nls -a \nls -l # 자세히\nls -lt # 자세히+파일수정시간에 따른 정렬\nls -lt --reverse # 자세히+파일수정시간의 역순으로 정렬 \n- 엄밀하게는 cd cgb2 는 cd ./cgb2로 써야한다. 하지만 ./는 생략가능하므로 그냥 cd cgb2라고 쓰는것\n- 뭐하는 파일인지 알고싶다면?\nfile picture.jpg\n- 카피, 이동, 새폴더, 삭제, 바로가기\ncp file1 file2 # file1을 복사하여 file2를 새로 만듬. file2가 이미 있다면 file1의 내용을 덮어씀 \ncp file1 file2 -i # 위와 동일한데 덮어쓰기 여부에 대한 확인메시지 생성\ncp file1 file2 --interactive # 위와 동일\ncp -r dir1 dir2 # dir1의 모든파일을 복사하여 dir2로 이동한뒤 붙어넣음. dir2가 없다면 새로 만듬. 기존의 dir2에 있던 파일이 삭제되는건 아님 \ncp --recursive dir1 dir2 # 위와 동일 \nmv # 카피사용방법과 동일 \nmkdir temp\nmkdir temp1, temp2, temp3 \nrm file1 # file1삭제 \nrm -r file1 dir1 # file1삭제 dir1폴더삭제 \nrm -rf file1 dir1 # 위와 동일한데 file1이나 dir1이 존재하지 않더라고 rm이 실행\nln ## 바로 가기 만드는건데 쓸줄모름 배우기 싫어\n- -v(verbose)를 쓰면 친절한 느낌이 든다.\n(base) cgb2@cgb2-desktop:~/Dropbox$ cp *.txt temppp -v\n'colab.txt' -> 'temppp/colab.txt'\n\n\necho\n- echo 기본기능\ncgb2@cgb2-desktop:~/Dropbox/temppp$ echo test\ntest\n- echo + * : *가 현재 디렉토리에 있는 모든 파일이름으로 확장된이후에 echo가 동작함.\n(base) cgb2@cgb2-desktop:~/Dropbox/temppp$ ls\ncolab.txt  sample.txt\n(base) cgb2@cgb2-desktop:~/Dropbox/temppp$ echo *\ncolab.txt sample.txt\n- 응용\n(base) cgb2@cgb2-desktop:~$ echo D*\nDesktop Documents Downloads Dropbox\n- 응용2\n(base) cgb2@cgb2-desktop:~$ echo /usr/*\n/usr/bin /usr/games /usr/include /usr/lib /usr/lib32 /usr/lib64 /usr/libexec /usr/libx32 /usr/local /usr/sbin /usr/share /usr/src\n- 응용3\n(base) cgb2@cgb2-desktop:~$ echo ~\n/home/cgb2\n- 응용4\n(base) cgb2@cgb2-desktop:~/Dropbox$ echo $((2+2))\n4\n\n\n기본디렉토리 설명\n/bin 시스템 부팅과 실행에 필요한 바이너리(프로그램)들을 포함\n/etc 시스템 전반의 환경설정. 이 디렉터리의 모든 파일은 텍스트형식임.\n\n/etc/password 사용자 계정정보\n\n/lib 시스템 프로그램에서 사용하는 공유 라이브러리가 저장. 윈도우즈의 DLL과 비슷한 것.\n/usr 사용자가 사용하는 모든 프로그램과 지원파일들 (Program files + 프로그램들의 설정값)\n\n/usr/bin 리눅스 배포판이 설치한 실행 프로그램들이 있다. (여기에 R이 깔린다!!)\n\nhp-align, hp-check, hp-config_usb-printer …\nX11\nvi\ngcc\nsu, sudo\nsar\nssh, ssh-agent, ssh-keygen, ….\nnvidia-smi\n\n/usr/lib 여기에는 /usr/bin에 있는 프로그램들을 위한 공유라이브러리가 저장된다. (여기에 R folder가 있다)\n\n여기에 R폴더가 있다. 그런데 R패키지가 여기에 깔리진 않음\n\n/usr/local/bin 소스코드로 컴파일된 파일, 보통 비어있음\n/usr/local/lib/R/site-library R패키지가 설치되어있음, 예를들면 tidyverse\n\n\n\nvim\n- 파일여는법/만드는법 (sudo는 읽기전용 파일을 만들수있음)\nsudo vim /etc/apt/sources.list\n- 에디터에서 사용법\ni \nESC \n:w \n:q\n:wq\n/keyword  \ndd # 현재행삭제 \n\n\nwget\nwget https://download2.rstudio.org/server/bionic/amd64/rstudio-server-1.2.5033-amd64.deb\n\n\ngdebi\nsudo gdebi rstudio-server-1.2.5033-amd64.deb\n\n\napt\nsudo apt-get remove r-base-core\nsudo apt purge r-base* r-recommended r-cran-*\nsudo apt autoremove\nsudo apt list \nsudo apt update\nsudo apt install openssh-server \nsudo apt-get install gdebi-core\n- sudo apt-get과 sudo apt 차이? 별 차이 없는듯 - https://askubuntu.com/questions/445384/what-is-the-difference-between-apt-and-apt-get\n\nThey are very similar command line tools available in Trusty (14.04) and later. apt-get and apt-cache’s most commonly used commands are available in apt. apt-get may be considered as lower-level and “back-end”, and support other APT-based tools. apt is designed for end-users (human) and its output may be changed between versions.\n\n\n\nconda\nconda \nconda env -h \nconda install -h \nconda remove -h  \nconda update -h \nconda env list\nconda create -n py38r40 python=3.8\nconda env remove -n py38r40 \nconda install -c conda-forge jupyterlab \nconda remove jupyterlab \nconda remove r-base -y \nconda remove -n py38r40 jupyterlab \nconda update scipy\nconda update -n py38r40 scipy\nconda list \n\n\npip\npip\npip list\npip list > list.txt\npip freeze # 좀 더 자세히 나온다 \npip freeze > list.txt \npip show matplotlib # 설치된패키지 정보가 나옴. 좋음.\npip install rpy2\npip install -r list.txt \npip install dash==1.13.3\npip install jupyterlab \"ipywidgets>=7.5\"\npip install -U numpy\npip install --upgrade pip\npip install --upgrade tensorflow\npip uninstall matplotlib\n\n\n리소스 모니터링\ndf # disk \nfree # memory \nnvidia-smi \nwatch -n 5 nvidia-smi -a --display=utilization\ntop\nsar -1 r \n\n# 나노에디터\n\n`-` 파일열기\n\n```default\nsudo nano /etc/apt/sources.list\n- 읽기전용 파일만들기: 파일을 만드는것도 파일 여는방법과 동일함. 즉 아래와 같이 하면 exam.txt가 현재 폴더에 있다면 열고아니면 (읽기전용으로) 만든다.\nsudo nano /home/cgb/Desktop/exam.txt\n- 읽기전용이 아닌 일반파일 만들기\nnano /home/cgb/Desktop/exam.txt\n- 나노에디터종료: 컨트롤+X\n- 파일저장: 컨트롤+O\n- 찾기: 컨트롤+W\n- 되돌리기: 알트+U\n\n\nssh\n- 처음에 ssh를 연결하기위해서는 연결당하는 컴퓨터에 가서 아래를 실행해야 한다.\nsudo apt install openssh-server\n\n22번포트 우회하기\n- step1: /etc/ssh/sshd_config 파일을 연다.\nsudo vi /etc/ssh/sshd_config \n- step2: Port 22 라고 된 부분의 주석을 풀고 원하는 포트번호 설정\n...\n\n#Port 22\n#AddressFamily any\n#ListenAddress 0.0.0.0\n#ListenAddress ::\n\n...\n- step3: 수정내용을 적용\nsudo systemctl restart ssh.service\n- step4: 수정한 포트로 ssh접속\n\n\n\nsublime\n- 찾아바꾸기: 컨트롤+h\n- 화면분할: 옵션+커맨드+2,3,4 …\n\n\n파일생성, 파일삭제\ncat > sample.txt \nrm -r folderName \nrm -rf .local/share/Trash/files/* # 휴지통삭제 \n\n\ndeb\ndpkg -i quarto-1.2.335-linux-amd64.deb # 설치\ndpkg -r quarto # 삭제"
  },
  {
    "objectID": "posts/3_Researches/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html",
    "href": "posts/3_Researches/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html",
    "title": "[IT-STGCN] SimualtionPlanner-Tutorial",
    "section": "",
    "text": "import itstgcn\nimport torch\nimport itstgcn.planner"
  },
  {
    "objectID": "posts/3_Researches/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_stgcn_rand",
    "href": "posts/3_Researches/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_stgcn_rand",
    "title": "[IT-STGCN] SimualtionPlanner-Tutorial",
    "section": "PLNR_STGCN_RAND",
    "text": "PLNR_STGCN_RAND\n\nplans_stgcn_rand = {\n    'max_iteration': 2, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mrate': [0.0, 0.2],\n    'lags': [2, 4], \n    'nof_filters': [4, 8], \n    'inter_method': ['nearest'],\n    'epoch': [3]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader,dataset_name='five_nodes')\n\n\nplnr.simulate()\n\n1/2 is done\n2/2 is done\nAll results are stored in ./simulation_results/2023-03-18_11-56-03.csv"
  },
  {
    "objectID": "posts/3_Researches/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_stgcn_manual",
    "href": "posts/3_Researches/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_stgcn_manual",
    "title": "[IT-STGCN] SimualtionPlanner-Tutorial",
    "section": "PLNR_STGCN_MANUAL",
    "text": "PLNR_STGCN_MANUAL\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\nloader = itstgcn.DatasetLoader(data_dict)\n\n\nmindex= [list(range(10,100)),[],list(range(50,80)),[],[]]\nplans_stgcn_block = {\n    'max_iteration': 3, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex],\n    'lags': [2, 4], \n    'nof_filters': [8,16], \n    'inter_method': ['nearest','linear'],\n    'epoch': [1]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader,dataset_name='five_nodes')\n\n\nplnr.simulate(mindex=mindex,mtype='block')\n\n1/3 is done\n2/3 is done\n3/3 is done\nAll results are stored in ./simulation_results/2023-03-18_11-56-55.csv"
  },
  {
    "objectID": "posts/3_Researches/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_rand",
    "href": "posts/3_Researches/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_rand",
    "title": "[IT-STGCN] SimualtionPlanner-Tutorial",
    "section": "PLNR_GNAR_RAND",
    "text": "PLNR_GNAR_RAND\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\nloader = itstgcn.DatasetLoader(data_dict)\n\n\nplans_gnar_rand = {\n    'max_iteration': 3, \n#    'method': ['GNAR'], \n    'mrate': [0.0, 0.2, 0.4],\n    'lags': [2, 4], \n#    'nof_filters': [8,16], \n    'inter_method': ['nearest','linear'],\n#    'epoch': [1]\n}\n\n\nplnr = itstgcn.planner.PLNR_GNAR_RAND(plans_gnar_rand,loader,dataset_name='five_nodes')\nplnr.simulate()\n\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n1/3 is done\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n2/3 is done\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n3/3 is done\nAll results are stored in ./simulation_results/2023-03-18_11-56-56.csv"
  },
  {
    "objectID": "posts/3_Researches/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_block",
    "href": "posts/3_Researches/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_block",
    "title": "[IT-STGCN] SimualtionPlanner-Tutorial",
    "section": "PLNR_GNAR_BLOCK",
    "text": "PLNR_GNAR_BLOCK\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\nloader = itstgcn.DatasetLoader(data_dict)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\nplans_gnar_block = {\n    'max_iteration': 3, \n    'method': ['GNAR'], \n    'mindex': [mindex],\n    'lags': [2, 4], \n    'inter_method': ['nearest','linear'],\n}\n\n\nplnr = itstgcn.planner.PLNR_GNAR_MANUAL(plans_gnar_block,loader,dataset_name='five_nodes')\nplnr.simulate(mindex,mtype='block')\n\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n1/3 is done\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n2/3 is done\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n3/3 is done\nAll results are stored in ./simulation_results/2023-03-18_11-56-57.csv"
  },
  {
    "objectID": "posts/3_Researches/ITSTGCN/2022-12-30-STGCN-Toy Example.html",
    "href": "posts/3_Researches/ITSTGCN/2022-12-30-STGCN-Toy Example.html",
    "title": "[IT-STGCN] STGCN: Toy Example",
    "section": "",
    "text": "import networkx as nx\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport torch"
  },
  {
    "objectID": "posts/3_Researches/ITSTGCN/2022-12-30-STGCN-Toy Example.html#data",
    "href": "posts/3_Researches/ITSTGCN/2022-12-30-STGCN-Toy Example.html#data",
    "title": "[IT-STGCN] STGCN: Toy Example",
    "section": "data",
    "text": "data\n\nfrom torch_geometric_temporal.dataset import WikiMathsDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = WikiMathsDatasetLoader()\n\ndataset = loader.get_dataset(lags=14)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)"
  },
  {
    "objectID": "posts/3_Researches/ITSTGCN/2022-12-30-STGCN-Toy Example.html#recurrentgcn",
    "href": "posts/3_Researches/ITSTGCN/2022-12-30-STGCN-Toy Example.html#recurrentgcn",
    "title": "[IT-STGCN] STGCN: Toy Example",
    "section": "RecurrentGCN",
    "text": "RecurrentGCN\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h"
  },
  {
    "objectID": "posts/3_Researches/ITSTGCN/2022-12-30-STGCN-Toy Example.html#learn",
    "href": "posts/3_Researches/ITSTGCN/2022-12-30-STGCN-Toy Example.html#learn",
    "title": "[IT-STGCN] STGCN: Toy Example",
    "section": "Learn",
    "text": "Learn\n\n# from tqdm import tqdm\n\n# model = RecurrentGCN(node_features=14, filters=32)\n\n# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\n# model.train()\n\n# for epoch in tqdm(range(50)):\n#     for time, snapshot in enumerate(train_dataset):\n#         y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n#         cost = torch.mean((y_hat-snapshot.y)**2)\n#         cost.backward()\n#         optimizer.step()\n#         optimizer.zero_grad()\n\n\nmodel = RecurrentGCN(node_features=14, filters=32)\nmodel.train()\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(14, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(14, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(14, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)\n\n\n\nfor s in train_dataset:\n    print((s.y-model(s.x,s.edge_index,s.edge_attr)).shape)\n\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])"
  },
  {
    "objectID": "posts/3_Researches/ITSTGCN/2022-12-30-STGCN-Toy Example.html#예제의-차원-조사",
    "href": "posts/3_Researches/ITSTGCN/2022-12-30-STGCN-Toy Example.html#예제의-차원-조사",
    "title": "[IT-STGCN] STGCN: Toy Example",
    "section": "예제의 차원 조사",
    "text": "예제의 차원 조사\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([1068, 14])\n\n\n\n1068: number of nodes // 1068개의 노드가 있음\n14: number of features // 하나의 노드에 맵핑된 차원의수\n\n\n_edge_index.shape\n\ntorch.Size([2, 27079])\n\n\n\n_edge_attr.shape\n\ntorch.Size([27079])\n\n\n\n_y.shape\n\ntorch.Size([1068])\n\n\n\n1068: number of nodes\n\n\n_x.shape\n\ntorch.Size([1068, 14])"
  },
  {
    "objectID": "posts/3_Researches/ITSTGCN/2023-02-14-Tables.html",
    "href": "posts/3_Researches/ITSTGCN/2023-02-14-Tables.html",
    "title": "[IT-STGCN] Tables",
    "section": "",
    "text": "import pandas as pd\n\n- Dataset 5nodes\n\ncol = ['Dataset','iteration', 'method', 'missingrate', 'missingtype', 'lag', 'number_of_filters', 'interpolation','MSE_train', 'MSE_test',]\n\n\ndf = pd.DataFrame(columns=col)\ndf\n\n\n\n\n\n  \n    \n      \n      Dataset\n      iteration\n      method\n      missingrate\n      missingtype\n      lag\n      number_of_filters\n      interpolation\n      MSE_train\n      MSE_test\n    \n  \n  \n  \n\n\n\n\n- 실험마다 아래와 같은식으로 추가\n\ndf_row = pd.DataFrame(columns=col)\ndf_row['Dataset'] = 'fivenodes', # ...\ndf_row['iteration'] = 1, # 1,2,3,...,10 \ndf_row['method'] = 'stgcn', # 'stgcn','estgcn','gnar' \ndf_row['missingrate'] = 0.0, # 0.0, 0.2, 0.4, 0.6, 0.8 \ndf_row['missingtype'] = None,  # None, 'randomly' and 'block' \ndf_row['lag'] = 1, # 1,2,3,4 ... \ndf_row['number_of_filters'] = 16, # 16,24,32, ... \ndf_row['interpolation'] = None, # None, 'mean', 'linear'\ndf_row['MSE_train'] = 0.96 \ndf_row['MSE_test'] = 0.55\n\n\ndf = pd.concat([df,df_row])\ndf\n\n\n\n\n\n  \n    \n      \n      Dataset\n      iteration\n      method\n      missingrate\n      missingtype\n      lag\n      number_of_filters\n      interpolation\n      MSE_train\n      MSE_test\n    \n  \n  \n    \n      0\n      fivenodes\n      1\n      stgcn\n      0.0\n      None\n      1\n      16\n      None\n      0.96\n      0.55\n    \n  \n\n\n\n\n\ndf_row = pd.DataFrame(columns=col)\ndf_row['Dataset'] = 'fivenodes', # ...\ndf_row['iteration'] = 1, # 1,2,3,...,10 \ndf_row['method'] = 'stgcn', # 'stgcn','estgcn','gnar' \ndf_row['missingrate'] = 0.2, # 0.0, 0.2, 0.4, 0.6, 0.8 \ndf_row['missingtype'] = 'randomly',  # None, 'randomly' and 'block' \ndf_row['lag'] = 1, # 1,2,3,4 ... \ndf_row['number_of_filters'] = 16, # 16,24,32, ... \ndf_row['interpolation'] = 'mean', # None, 'mean', 'linear'\ndf_row['MSE_train'] = 1.23\ndf_row['MSE_test'] = 0.88\n\n\ndf = pd.concat([df,df_row])\ndf\n\n\n\n\n\n  \n    \n      \n      Dataset\n      iteration\n      method\n      missingrate\n      missingtype\n      lag\n      number_of_filters\n      interpolation\n      MSE_train\n      MSE_test\n    \n  \n  \n    \n      0\n      fivenodes\n      1\n      stgcn\n      0.0\n      None\n      1\n      16\n      None\n      0.96\n      0.55\n    \n    \n      0\n      fivenodes\n      1\n      stgcn\n      0.2\n      randomly\n      1\n      16\n      mean\n      1.23\n      0.88"
  },
  {
    "objectID": "posts/3_Researches/HST/2023-01-23-CommunityDetection.html",
    "href": "posts/3_Researches/HST/2023-01-23-CommunityDetection.html",
    "title": "[HST] CommunityDetection",
    "section": "",
    "text": "ref\n- Roddenberry et al. (2020)\n\nhttps://arxiv.org/pdf/2001.10944.pdf\nintro에 그래프는 single correct한 structure를 알 수 없다는 이야기가 있는데 이를 이용해야함.\n\n\n\n\n\n\n\n\n\n방법론\n\nRoddenberry, T Mitchell, Michael T Schaub, Hoi-To Wai, and Santiago Segarra. 2020. “Exact Blind Community Detection from Signals on Multiple Graphs.” IEEE Transactions on Signal Processing 68: 5016–30."
  },
  {
    "objectID": "posts/3_Researches/BORAM/2023-05-12-try1.html",
    "href": "posts/3_Researches/BORAM/2023-05-12-try1.html",
    "title": "[BORAM] 신용카드 거래 사기탐지 Try1",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport networkx as nx\nimport sklearn\n\n# sklearn\nfrom sklearn import model_selection # split함수이용\nfrom sklearn import ensemble # RF \nfrom sklearn import metrics \n\n# embedding \nfrom node2vec import Node2Vec\nfrom node2vec.edges import HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder\n\n/home/cgb2/anaconda3/envs/py38/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\n\ndef build_graph_bipartite(df_input, graph_type=nx.Graph()):\n    df=df_input.copy()\n    mapping={x:node_id for node_id, x in enumerate(set(df[\"cc_num\"].values.tolist()+\\\n                                                      df[\"merchant\"].values.tolist()))}\n    \n    df[\"from\"]=df[\"cc_num\"].apply(lambda x:mapping[x])  #엣지의 출발점\n    df[\"to\"]=df[\"merchant\"].apply(lambda x:mapping[x])  #엣지의 도착점\n    \n    df = df[['from', 'to', \"amt\", \"is_fraud\"]].groupby(['from','to']).agg({\"is_fraud\":\"sum\",\"amt\":\"sum\"}).reset_index()\n    df[\"is_fraud\"]=df[\"is_fraud\"].apply(lambda x:1 if x>0 else 0)\n    \n    G=nx.from_edgelist(df[[\"from\",\"to\"]].values, create_using=graph_type)\n    \n    nx.set_edge_attributes(G,{(int(x[\"from\"]),int(x[\"to\"])):x[\"is_fraud\"] for idx, x in df[[\"from\",\"to\",\"is_fraud\"]].iterrows()}, \"label\")  #엣지 속성 설정,각 속성의 사기 여부부     \n    nx.set_edge_attributes(G,{(int(x[\"from\"]),int(x[\"to\"])):x[\"amt\"] for idx,x in df[[\"from\",\"to\",\"amt\"]].iterrows()}, \"weight\") # 엣지 속성 설정, 각 엣지의 거래 금액\n\n    return G\n\n\ndef build_graph_tripartite(df_input, graph_type=nx.Graph()):\n    df=df_input.copy()\n    mapping={x:node_id for node_id, x in enumerate(set(df.index.values.tolist() + \n                                                       df[\"cc_num\"].values.tolist() +\n                                                       df[\"merchant\"].values.tolist()))}\n    df[\"in_node\"]= df[\"cc_num\"].apply(lambda x: mapping[x])\n    df[\"out_node\"]=df[\"merchant\"].apply(lambda x:mapping[x])\n    \n        \n    G=nx.from_edgelist([(x[\"in_node\"], mapping[idx]) for idx, x in df.iterrows()] +\\\n                        [(x[\"out_node\"], mapping[idx]) for idx, x in df.iterrows()], create_using=graph_type)\n    \n    nx.set_edge_attributes(G,{(x[\"in_node\"], mapping[idx]):x[\"is_fraud\"] for idx, x in df.iterrows()}, \"label\")     \n    nx.set_edge_attributes(G,{(x[\"out_node\"], mapping[idx]):x[\"is_fraud\"] for idx, x in df.iterrows()}, \"label\")   \n    nx.set_edge_attributes(G,{(x[\"in_node\"], mapping[idx]):x[\"amt\"] for idx, x in df.iterrows()}, \"weight\")  \n    nx.set_edge_attributes(G,{(x[\"out_node\"], mapping[idx]):x[\"amt\"] for idx, x in df.iterrows()}, \"weight\")\n\n    return G\n    \n    \ndef down_sample_textbook(df):\n    df_majority = df[df.is_fraud==0].copy()\n    df_minority = df[df.is_fraud==1].copy()\n    df_maj_dowsampled = sklearn.utils.resample(df_majority, n_samples=len(df_minority), replace=False, random_state=42)\n    df_downsampled = pd.concat([df_minority, df_maj_dowsampled])\n    return df_downsampled\n\ndef embedding(Graph):\n    # Graph -> X (feature)\n    _edgs = list(Graph.edges)\n    subGraph = Graph.edge_subgraph([_edgs[x] for x in range(len(Graph.edges))]).copy()\n    subGraph.add_nodes_from(list(set(Graph.nodes) - set(subGraph.nodes)))    \n    embedded = AverageEmbedder(Node2Vec(subGraph, weight_key='weight').fit(window=10).wv)\n    X = [embedded[str(_edgs[x][0]), str(_edgs[x][1])] for x in range(len(Graph.edges))]\n    # Graph -> y (label)\n    y = np.array(list(nx.get_edge_attributes(Graph, \"label\").values()))\n    return X,y \n\ndef anal(df):\n    Graph = build_graph_bipartite(df)\n    X,XX,y,yy = embedding(Graph)\n    lrnr = RandomForestClassifier(n_estimators=100, random_state=42) \n    lrnr.fit(X,y)\n    yyhat = lrnr.predict(XX)\n    df = pd.DataFrame({\n        'acc':[sklearn.metrics.accuracy_score(yy,yyhat)], \n        'pre':[sklearn.metrics.precision_score(yy,yyhat)], \n        'rec':[sklearn.metrics.recall_score(yy,yyhat)],\n        'f1':[sklearn.metrics.f1_score(yy,yyhat)]}\n    )    \n    return df\n\ndef our_sampling1(df):\n    cus_list = set(df.query('is_fraud==1').cc_num.tolist())\n    return df.query(\"cc_num in @ cus_list\")"
  },
  {
    "objectID": "posts/3_Researches/BORAM/2023-05-12-try1.html#데이터-종류",
    "href": "posts/3_Researches/BORAM/2023-05-12-try1.html#데이터-종류",
    "title": "[BORAM] 신용카드 거래 사기탐지 Try1",
    "section": "데이터 종류",
    "text": "데이터 종류\n\nfraudTrain.csv: (1048575, 23), 기본데이터\ndf02: (214520, 23), is_fraud==0 에서는 20퍼의 샘플만, is_fraud==1 에서는 모든 샘플을 뽑아서 정리한 새로운 자료\ndf50 = (12012, 23), df20에서 is_fraud==0 와 is_fraud==1 의 비율을 맞추어서 샘플을 뽑은 것\n\n\n\n\n\n\n\n\n\n\n데이터\nshape\n사기거래빈도\n설명\n\n\n\n\nfraudTrain\n(1048575, 22)\n0.00573\n원래자료\n\n\ndf02\n(214520, 22)\n0.028\nis_fraud==0 에서는 20퍼의 샘플만, is_fraud==1 에서는 모든 샘플을 뽑아서 정리한 새로운 자료\n\n\ndf50\n(12012, 22)\n0.5\ndf02에서 사기비율을 50퍼로 맞추어 샘플링한 자료\n\n\ndf50_tr\n(9009, 22)\n0.49828\ndf50에서 랜덤으로 train/test를 분리하여 얻은 train dataset\n\n\ndf50_test\n(3003, 22)\n0.50516\ndf50에서 랜덤으로 train/test를 분리하여 얻은 test dataset\n\n\ndf02_tr\n(211517, 22)\n0.02122\ndf02에서 df50_test에 해당하는 인덱스를 제외\n\n\nfraudTrain_tr\n(1045572, 22)\n0.00429\nfraudTrain에서 df50_test에 해당하는 인덱스를 제외\n\n\n\n- fraudTrain\n\nfraudTrain = pd.read_csv(\"fraudTrain.csv\").iloc[:,1:]\nfraudTrain.shape\n\n(1048575, 22)\n\n\n\nfraudTrain.is_fraud.mean().round(5)\n\n0.00573\n\n\n- df20\n\n_df1 = fraudTrain[fraudTrain[\"is_fraud\"] == 0].sample(frac=0.20, random_state=42)\n_df2 = fraudTrain[fraudTrain[\"is_fraud\"] == 1]\ndf02 = pd.concat([_df1,_df2])\ndf02.shape\n\n(214520, 22)\n\n\n\ndf02.is_fraud.mean().round(5)\n\n0.028\n\n\n- df50\n\ndf50 = down_sample_textbook(df02)\ndf50.shape\n\n(12012, 22)\n\n\n\ndf50\n\n\n\n\n\n  \n    \n      \n      trans_date_trans_time\n      cc_num\n      merchant\n      category\n      amt\n      first\n      last\n      gender\n      street\n      city\n      ...\n      lat\n      long\n      city_pop\n      job\n      dob\n      trans_num\n      unix_time\n      merch_lat\n      merch_long\n      is_fraud\n    \n  \n  \n    \n      2449\n      2019-01-02 1:06\n      4.613310e+12\n      fraud_Rutherford-Mertz\n      grocery_pos\n      281.06\n      Jason\n      Murphy\n      M\n      542 Steve Curve Suite 011\n      Collettsville\n      ...\n      35.9946\n      -81.7266\n      885\n      Soil scientist\n      1988-09-15\n      e8a81877ae9a0a7f883e15cb39dc4022\n      1325466397\n      36.430124\n      -81.179483\n      1\n    \n    \n      2472\n      2019-01-02 1:47\n      3.401870e+14\n      fraud_Jenkins, Hauck and Friesen\n      gas_transport\n      11.52\n      Misty\n      Hart\n      F\n      27954 Hall Mill Suite 575\n      San Antonio\n      ...\n      29.4400\n      -98.4590\n      1595797\n      Horticultural consultant\n      1960-10-28\n      bc7d41c41103877b03232f03f1f8d3f5\n      1325468849\n      29.819364\n      -99.142791\n      1\n    \n    \n      2523\n      2019-01-02 3:05\n      3.401870e+14\n      fraud_Goodwin-Nitzsche\n      grocery_pos\n      276.31\n      Misty\n      Hart\n      F\n      27954 Hall Mill Suite 575\n      San Antonio\n      ...\n      29.4400\n      -98.4590\n      1595797\n      Horticultural consultant\n      1960-10-28\n      b98f12f4168391b2203238813df5aa8c\n      1325473523\n      29.273085\n      -98.836360\n      1\n    \n    \n      2546\n      2019-01-02 3:38\n      4.613310e+12\n      fraud_Erdman-Kertzmann\n      gas_transport\n      7.03\n      Jason\n      Murphy\n      M\n      542 Steve Curve Suite 011\n      Collettsville\n      ...\n      35.9946\n      -81.7266\n      885\n      Soil scientist\n      1988-09-15\n      397894a5c4c02e3c61c784001f0f14e4\n      1325475483\n      35.909292\n      -82.091010\n      1\n    \n    \n      2553\n      2019-01-02 3:55\n      3.401870e+14\n      fraud_Koepp-Parker\n      grocery_pos\n      275.73\n      Misty\n      Hart\n      F\n      27954 Hall Mill Suite 575\n      San Antonio\n      ...\n      29.4400\n      -98.4590\n      1595797\n      Horticultural consultant\n      1960-10-28\n      7863235a750d73a244c07f1fb7f0185a\n      1325476547\n      29.786426\n      -98.683410\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      363827\n      2019-06-17 19:30\n      2.475090e+15\n      fraud_Frami Group\n      entertainment\n      81.13\n      John\n      Miller\n      M\n      153 Mccullough Springs Apt. 857\n      Lamberton\n      ...\n      44.2378\n      -95.2739\n      1507\n      Land/geomatics surveyor\n      1993-10-12\n      c66cb411019c7dfd4d89f42a1ba4765f\n      1339961448\n      44.212695\n      -95.661879\n      0\n    \n    \n      140154\n      2019-03-17 14:33\n      2.131550e+14\n      fraud_Bahringer-Streich\n      food_dining\n      55.00\n      Christopher\n      Sheppard\n      M\n      39218 Baker Shoals\n      Bristow\n      ...\n      38.1981\n      -86.6821\n      965\n      Horticultural therapist\n      1982-02-10\n      316b9d25b9fa7d08a6831b7dab6634cd\n      1331994839\n      38.394240\n      -86.413557\n      0\n    \n    \n      860597\n      2019-12-17 12:31\n      2.280870e+15\n      fraud_Lubowitz-Walter\n      kids_pets\n      8.12\n      Katherine\n      Cooper\n      F\n      3854 Lauren Springs Suite 648\n      Oakford\n      ...\n      40.0994\n      -89.9601\n      530\n      Transport planner\n      1967-09-23\n      d92e9e63d9b24c3ccb92d05cba4cac54\n      1355747517\n      39.695248\n      -89.853063\n      0\n    \n    \n      29341\n      2019-01-18 9:20\n      4.878360e+15\n      fraud_Denesik and Sons\n      shopping_pos\n      3.52\n      Tina\n      Alvarez\n      F\n      1976 Tyler Underpass\n      Early\n      ...\n      42.4483\n      -95.1726\n      885\n      Pilot, airline\n      1949-08-14\n      8390ce51cfb8482b618ebc4ac370bcf7\n      1326878457\n      42.633204\n      -95.598143\n      0\n    \n    \n      529797\n      2019-08-16 13:17\n      4.450830e+15\n      fraud_Beier and Sons\n      home\n      84.15\n      Donna\n      Davis\n      F\n      6760 Donovan Lakes\n      Clayton\n      ...\n      34.5906\n      -95.3800\n      1760\n      Occupational psychologist\n      1972-01-20\n      04e1be9bcb18ea8b96048659bd02177b\n      1345123058\n      33.885236\n      -95.885110\n      0\n    \n  \n\n12012 rows × 22 columns\n\n\n\n\ndf50.is_fraud.mean().round(5)\n\n0.5\n\n\n- df50_tr, df50_test\n\ndf50_tr,df50_test = sklearn.model_selection.train_test_split(df50, random_state=42)\n\n\ndf50_tr.is_fraud.mean().round(5), df50_test.is_fraud.mean().round(5)\n\n(0.49828, 0.50516)\n\n\n- df02_tr, fraudTrain_tr\n\ndf02_tr = df02.loc[[i not in df50_test.index for i in df02.index],:].copy()\nfraudTrain_tr = fraudTrain.loc[[i not in df50_test.index for i in fraudTrain.index],:].copy()\n\n\ndf02_tr.shape, fraudTrain_tr.shape\n\n((211517, 22), (1045572, 22))\n\n\n\ndf02_tr.is_fraud.mean().round(5), fraudTrain_tr.is_fraud.mean().round(5)\n\n(0.02122, 0.00429)"
  },
  {
    "objectID": "posts/3_Researches/BORAM/2023-05-19-try2.html",
    "href": "posts/3_Researches/BORAM/2023-05-19-try2.html",
    "title": "[BORAM] 신용카드 거래 사기탐지 Try2",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport networkx as nx\nimport sklearn\n\n# sklearn\nfrom sklearn import model_selection # split함수이용\nfrom sklearn import ensemble # RF,GBM\nfrom sklearn import metrics \n\n# embedding \nfrom node2vec import Node2Vec\nfrom node2vec.edges import HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder\n\n\ndef build_graph_bipartite(df_input, graph_type=nx.Graph()):\n    df=df_input.copy()\n    mapping={x:node_id for node_id, x in enumerate(set(df[\"cc_num\"].values.tolist()+\\\n                                                      df[\"merchant\"].values.tolist()))}\n    \n    df[\"from\"]=df[\"cc_num\"].apply(lambda x:mapping[x])  #엣지의 출발점\n    df[\"to\"]=df[\"merchant\"].apply(lambda x:mapping[x])  #엣지의 도착점\n    \n    df = df[['from', 'to', \"amt\", \"is_fraud\"]].groupby(['from','to']).agg({\"is_fraud\":\"sum\",\"amt\":\"sum\"}).reset_index()\n    df[\"is_fraud\"]=df[\"is_fraud\"].apply(lambda x:1 if x>0 else 0)\n    \n    G=nx.from_edgelist(df[[\"from\",\"to\"]].values, create_using=graph_type)\n    \n    nx.set_edge_attributes(G,{(int(x[\"from\"]),int(x[\"to\"])):x[\"is_fraud\"] for idx, x in df[[\"from\",\"to\",\"is_fraud\"]].iterrows()}, \"label\")  #엣지 속성 설정,각 속성의 사기 여부부     \n    nx.set_edge_attributes(G,{(int(x[\"from\"]),int(x[\"to\"])):x[\"amt\"] for idx,x in df[[\"from\",\"to\",\"amt\"]].iterrows()}, \"weight\") # 엣지 속성 설정, 각 엣지의 거래 금액\n\n    return G\n\n\ndef build_graph_tripartite(df_input, graph_type=nx.Graph()):\n    df=df_input.copy()\n    mapping={x:node_id for node_id, x in enumerate(set(df.index.values.tolist() + \n                                                       df[\"cc_num\"].values.tolist() +\n                                                       df[\"merchant\"].values.tolist()))}\n    df[\"in_node\"]= df[\"cc_num\"].apply(lambda x: mapping[x])\n    df[\"out_node\"]=df[\"merchant\"].apply(lambda x:mapping[x])\n    \n        \n    G=nx.from_edgelist([(x[\"in_node\"], mapping[idx]) for idx, x in df.iterrows()] +\\\n                        [(x[\"out_node\"], mapping[idx]) for idx, x in df.iterrows()], create_using=graph_type)\n    \n    nx.set_edge_attributes(G,{(x[\"in_node\"], mapping[idx]):x[\"is_fraud\"] for idx, x in df.iterrows()}, \"label\")     \n    nx.set_edge_attributes(G,{(x[\"out_node\"], mapping[idx]):x[\"is_fraud\"] for idx, x in df.iterrows()}, \"label\")   \n    nx.set_edge_attributes(G,{(x[\"in_node\"], mapping[idx]):x[\"amt\"] for idx, x in df.iterrows()}, \"weight\")  \n    nx.set_edge_attributes(G,{(x[\"out_node\"], mapping[idx]):x[\"amt\"] for idx, x in df.iterrows()}, \"weight\")\n\n    return G\n    \n    \ndef down_sample_textbook(df):\n    df_majority = df[df.is_fraud==0].copy()\n    df_minority = df[df.is_fraud==1].copy()\n    df_maj_dowsampled = sklearn.utils.resample(df_majority, n_samples=len(df_minority), replace=False, random_state=42)\n    df_downsampled = pd.concat([df_minority, df_maj_dowsampled])\n    return df_downsampled\n\ndef embedding(Graph):\n    # Graph -> X (feature)\n    _edgs = list(Graph.edges)\n    subGraph = Graph.edge_subgraph([_edgs[x] for x in range(len(Graph.edges))]).copy()\n    subGraph.add_nodes_from(list(set(Graph.nodes) - set(subGraph.nodes)))    \n    embedded = AverageEmbedder(Node2Vec(subGraph, weight_key='weight').fit(window=10).wv)\n    X = [embedded[str(_edgs[x][0]), str(_edgs[x][1])] for x in range(len(Graph.edges))]\n    # Graph -> y (label)\n    y = np.array(list(nx.get_edge_attributes(Graph, \"label\").values()))\n    return X,y \n\ndef anal(df):\n    Graph = build_graph_bipartite(df)\n    X,XX,y,yy = embedding(Graph)\n    lrnr = RandomForestClassifier(n_estimators=100, random_state=42) \n    lrnr.fit(X,y)\n    yyhat = lrnr.predict(XX)\n    df = pd.DataFrame({\n        'acc':[sklearn.metrics.accuracy_score(yy,yyhat)], \n        'pre':[sklearn.metrics.precision_score(yy,yyhat)], \n        'rec':[sklearn.metrics.recall_score(yy,yyhat)],\n        'f1':[sklearn.metrics.f1_score(yy,yyhat)]}\n    )    \n    return df\n\ndef our_sampling1(df):\n    cus_list = set(df.query('is_fraud==1').cc_num.tolist())\n    return df.query(\"cc_num in @ cus_list\")\n\n\ndef amtano1(df_train):\n    df = df_train.copy()\n    df = df.assign(amtano=0)\n    normalize = lambda arr: (arr-np.median(arr))/np.std(arr) if np.std(arr)!=0 else arr*0 \n    for cc_num, sub_df in df.groupby('cc_num'):\n        df.loc[df.cc_num == cc_num,['amtano']] = normalize(sub_df.amt).cumsum()\n    return df"
  },
  {
    "objectID": "posts/3_Researches/BORAM/2023-05-19-try2.html#데이터-종류",
    "href": "posts/3_Researches/BORAM/2023-05-19-try2.html#데이터-종류",
    "title": "[BORAM] 신용카드 거래 사기탐지 Try2",
    "section": "데이터 종류",
    "text": "데이터 종류\n\nfraudTrain.csv: (1048575, 23), 기본데이터\ndf02: (214520, 23), is_fraud==0 에서는 20퍼의 샘플만, is_fraud==1 에서는 모든 샘플을 뽑아서 정리한 새로운 자료\ndf50 = (12012, 23), df20에서 is_fraud==0 와 is_fraud==1 의 비율을 맞추어서 샘플을 뽑은 것\n\n\n\n\n\n\n\n\n\n\n데이터\nshape\n사기거래빈도\n설명\n\n\n\n\nfraudTrain\n(1048575, 22)\n0.00573\n원래자료\n\n\ndf02\n(214520, 22)\n0.028\nis_fraud==0 에서는 20퍼의 샘플만, is_fraud==1 에서는 모든 샘플을 뽑아서 정리한 새로운 자료\n\n\ndf50\n(12012, 22)\n0.5\ndf02에서 사기비율을 50퍼로 맞추어 샘플링한 자료\n\n\ndf50_tr\n(9009, 22)\n0.49828\ndf50에서 랜덤으로 train/test를 분리하여 얻은 train dataset\n\n\ndf50_test\n(3003, 22)\n0.50516\ndf50에서 랜덤으로 train/test를 분리하여 얻은 test dataset\n\n\ndf02_tr\n(211517, 22)\n0.02122\ndf02에서 df50_test에 해당하는 인덱스를 제외\n\n\nfraudTrain_tr\n(1045572, 22)\n0.00429\nfraudTrain에서 df50_test에 해당하는 인덱스를 제외\n\n\n\n- fraudTrain\n\nfraudTrain = pd.read_csv(\"fraudTrain.csv\").iloc[:,1:]\nfraudTrain.shape\n\n(1048575, 22)\n\n\n\nfraudTrain.is_fraud.mean().round(5)\n\n0.00573\n\n\n- df20\n\n_df1 = fraudTrain[fraudTrain[\"is_fraud\"] == 0].sample(frac=0.20, random_state=42)\n_df2 = fraudTrain[fraudTrain[\"is_fraud\"] == 1]\ndf02 = pd.concat([_df1,_df2])\ndf02.shape\n\n(214520, 22)\n\n\n\ndf02.is_fraud.mean().round(5)\n\n0.028\n\n\n- df50\n\ndf50 = down_sample_textbook(df02)\ndf50.shape\n\n(12012, 22)\n\n\n\ndf50\n\n\n\n\n\n  \n    \n      \n      trans_date_trans_time\n      cc_num\n      merchant\n      category\n      amt\n      first\n      last\n      gender\n      street\n      city\n      ...\n      lat\n      long\n      city_pop\n      job\n      dob\n      trans_num\n      unix_time\n      merch_lat\n      merch_long\n      is_fraud\n    \n  \n  \n    \n      2449\n      2019-01-02 1:06\n      4.613310e+12\n      fraud_Rutherford-Mertz\n      grocery_pos\n      281.06\n      Jason\n      Murphy\n      M\n      542 Steve Curve Suite 011\n      Collettsville\n      ...\n      35.9946\n      -81.7266\n      885\n      Soil scientist\n      1988-09-15\n      e8a81877ae9a0a7f883e15cb39dc4022\n      1325466397\n      36.430124\n      -81.179483\n      1\n    \n    \n      2472\n      2019-01-02 1:47\n      3.401870e+14\n      fraud_Jenkins, Hauck and Friesen\n      gas_transport\n      11.52\n      Misty\n      Hart\n      F\n      27954 Hall Mill Suite 575\n      San Antonio\n      ...\n      29.4400\n      -98.4590\n      1595797\n      Horticultural consultant\n      1960-10-28\n      bc7d41c41103877b03232f03f1f8d3f5\n      1325468849\n      29.819364\n      -99.142791\n      1\n    \n    \n      2523\n      2019-01-02 3:05\n      3.401870e+14\n      fraud_Goodwin-Nitzsche\n      grocery_pos\n      276.31\n      Misty\n      Hart\n      F\n      27954 Hall Mill Suite 575\n      San Antonio\n      ...\n      29.4400\n      -98.4590\n      1595797\n      Horticultural consultant\n      1960-10-28\n      b98f12f4168391b2203238813df5aa8c\n      1325473523\n      29.273085\n      -98.836360\n      1\n    \n    \n      2546\n      2019-01-02 3:38\n      4.613310e+12\n      fraud_Erdman-Kertzmann\n      gas_transport\n      7.03\n      Jason\n      Murphy\n      M\n      542 Steve Curve Suite 011\n      Collettsville\n      ...\n      35.9946\n      -81.7266\n      885\n      Soil scientist\n      1988-09-15\n      397894a5c4c02e3c61c784001f0f14e4\n      1325475483\n      35.909292\n      -82.091010\n      1\n    \n    \n      2553\n      2019-01-02 3:55\n      3.401870e+14\n      fraud_Koepp-Parker\n      grocery_pos\n      275.73\n      Misty\n      Hart\n      F\n      27954 Hall Mill Suite 575\n      San Antonio\n      ...\n      29.4400\n      -98.4590\n      1595797\n      Horticultural consultant\n      1960-10-28\n      7863235a750d73a244c07f1fb7f0185a\n      1325476547\n      29.786426\n      -98.683410\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      363827\n      2019-06-17 19:30\n      2.475090e+15\n      fraud_Frami Group\n      entertainment\n      81.13\n      John\n      Miller\n      M\n      153 Mccullough Springs Apt. 857\n      Lamberton\n      ...\n      44.2378\n      -95.2739\n      1507\n      Land/geomatics surveyor\n      1993-10-12\n      c66cb411019c7dfd4d89f42a1ba4765f\n      1339961448\n      44.212695\n      -95.661879\n      0\n    \n    \n      140154\n      2019-03-17 14:33\n      2.131550e+14\n      fraud_Bahringer-Streich\n      food_dining\n      55.00\n      Christopher\n      Sheppard\n      M\n      39218 Baker Shoals\n      Bristow\n      ...\n      38.1981\n      -86.6821\n      965\n      Horticultural therapist\n      1982-02-10\n      316b9d25b9fa7d08a6831b7dab6634cd\n      1331994839\n      38.394240\n      -86.413557\n      0\n    \n    \n      860597\n      2019-12-17 12:31\n      2.280870e+15\n      fraud_Lubowitz-Walter\n      kids_pets\n      8.12\n      Katherine\n      Cooper\n      F\n      3854 Lauren Springs Suite 648\n      Oakford\n      ...\n      40.0994\n      -89.9601\n      530\n      Transport planner\n      1967-09-23\n      d92e9e63d9b24c3ccb92d05cba4cac54\n      1355747517\n      39.695248\n      -89.853063\n      0\n    \n    \n      29341\n      2019-01-18 9:20\n      4.878360e+15\n      fraud_Denesik and Sons\n      shopping_pos\n      3.52\n      Tina\n      Alvarez\n      F\n      1976 Tyler Underpass\n      Early\n      ...\n      42.4483\n      -95.1726\n      885\n      Pilot, airline\n      1949-08-14\n      8390ce51cfb8482b618ebc4ac370bcf7\n      1326878457\n      42.633204\n      -95.598143\n      0\n    \n    \n      529797\n      2019-08-16 13:17\n      4.450830e+15\n      fraud_Beier and Sons\n      home\n      84.15\n      Donna\n      Davis\n      F\n      6760 Donovan Lakes\n      Clayton\n      ...\n      34.5906\n      -95.3800\n      1760\n      Occupational psychologist\n      1972-01-20\n      04e1be9bcb18ea8b96048659bd02177b\n      1345123058\n      33.885236\n      -95.885110\n      0\n    \n  \n\n12012 rows × 22 columns\n\n\n\n\ndf50.is_fraud.mean().round(5)\n\n0.5\n\n\n- df50_tr, df50_test\n\ndf50_tr,df50_test = sklearn.model_selection.train_test_split(df50, random_state=42)\n\n\ndf50_tr.is_fraud.mean().round(5), df50_test.is_fraud.mean().round(5)\n\n(0.49828, 0.50516)\n\n\n- df02_tr, fraudTrain_tr\n\ndf02_tr = df02.loc[[i not in df50_test.index for i in df02.index],:].copy()\nfraudTrain_tr = fraudTrain.loc[[i not in df50_test.index for i in fraudTrain.index],:].copy()\n\n\ndf02_tr.shape, fraudTrain_tr.shape\n\n((211517, 22), (1045572, 22))\n\n\n\ndf02_tr.is_fraud.mean().round(5), fraudTrain_tr.is_fraud.mean().round(5)\n\n(0.02122, 0.00429)"
  },
  {
    "objectID": "posts/3_Researches/SOLAR/2023-04-03-일사량.html",
    "href": "posts/3_Researches/SOLAR/2023-04-03-일사량.html",
    "title": "[SOLAR] 일사량자료정리",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport itertools\n\n\ndf0 = pd.read_csv('https://raw.githubusercontent.com/pinkocto/noteda/main/posts/data/OBS_ASOS_TIM_data0.csv', encoding='cp949') # 2021-01-01 ~ 2021-12-31\ndf1 = pd.read_csv('https://raw.githubusercontent.com/pinkocto/noteda/main/posts/data/OBS_ASOS_TIM_data1.csv') # 2022-01-01 ~ 2023-12-31\ndf2 = pd.read_csv('https://raw.githubusercontent.com/pinkocto/noteda/main/posts/data/test_raw.csv', encoding='cp949') # 2023-01-01 ~ 2023-01-15\n\n- df_raw\n\ndf_raw = pd.concat([df0, df1])\ndf_raw\n\n\n\n\n\n  \n    \n      \n      지점\n      지점명\n      일시\n      일사(MJ/m2)\n    \n  \n  \n    \n      0\n      93\n      북춘천\n      2021-01-01 08:00\n      0.00\n    \n    \n      1\n      93\n      북춘천\n      2021-01-01 09:00\n      0.37\n    \n    \n      2\n      93\n      북춘천\n      2021-01-01 10:00\n      0.96\n    \n    \n      3\n      93\n      북춘천\n      2021-01-01 11:00\n      1.40\n    \n    \n      4\n      93\n      북춘천\n      2021-01-01 12:00\n      1.72\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      229672\n      283\n      경주시\n      2022-12-31 14:00:00\n      1.82\n    \n    \n      229673\n      283\n      경주시\n      2022-12-31 15:00:00\n      1.52\n    \n    \n      229674\n      283\n      경주시\n      2022-12-31 16:00:00\n      0.96\n    \n    \n      229675\n      283\n      경주시\n      2022-12-31 17:00:00\n      0.35\n    \n    \n      229676\n      283\n      경주시\n      2022-12-31 18:00:00\n      0.01\n    \n  \n\n444720 rows × 4 columns\n\n\n\n- 지점칼럼 삭제 // 일시 \\(\\to\\) 날짜,시간 으로 분리\n\ndf_temp = df_raw.assign(날짜= list(map(lambda x: x[:10],df_raw['일시'])))\\\n.assign(시간= list(map(lambda x: x[11:16],df_raw['일시'])))\\\n.drop(['일시','지점'],axis=1).rename({'일사(MJ/m2)':'일사'},axis=1).reset_index(drop=True)\ndf_temp\n\n\n\n\n\n  \n    \n      \n      지점명\n      일사\n      날짜\n      시간\n    \n  \n  \n    \n      0\n      북춘천\n      0.00\n      2021-01-01\n      08:00\n    \n    \n      1\n      북춘천\n      0.37\n      2021-01-01\n      09:00\n    \n    \n      2\n      북춘천\n      0.96\n      2021-01-01\n      10:00\n    \n    \n      3\n      북춘천\n      1.40\n      2021-01-01\n      11:00\n    \n    \n      4\n      북춘천\n      1.72\n      2021-01-01\n      12:00\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      444715\n      경주시\n      1.82\n      2022-12-31\n      14:00\n    \n    \n      444716\n      경주시\n      1.52\n      2022-12-31\n      15:00\n    \n    \n      444717\n      경주시\n      0.96\n      2022-12-31\n      16:00\n    \n    \n      444718\n      경주시\n      0.35\n      2022-12-31\n      17:00\n    \n    \n      444719\n      경주시\n      0.01\n      2022-12-31\n      18:00\n    \n  \n\n444720 rows × 4 columns\n\n\n\n- 파주,상주,동두천,충주,제천은 삭제\n\ndf_temp = df_temp.query(\"지점명 not in ['파주','상주','동두천','충주','제천']\").reset_index(drop=True)\ndf_temp\n\n\n\n\n\n  \n    \n      \n      지점명\n      일사\n      날짜\n      시간\n    \n  \n  \n    \n      0\n      북춘천\n      0.00\n      2021-01-01\n      08:00\n    \n    \n      1\n      북춘천\n      0.37\n      2021-01-01\n      09:00\n    \n    \n      2\n      북춘천\n      0.96\n      2021-01-01\n      10:00\n    \n    \n      3\n      북춘천\n      1.40\n      2021-01-01\n      11:00\n    \n    \n      4\n      북춘천\n      1.72\n      2021-01-01\n      12:00\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      420955\n      경주시\n      1.82\n      2022-12-31\n      14:00\n    \n    \n      420956\n      경주시\n      1.52\n      2022-12-31\n      15:00\n    \n    \n      420957\n      경주시\n      0.96\n      2022-12-31\n      16:00\n    \n    \n      420958\n      경주시\n      0.35\n      2022-12-31\n      17:00\n    \n    \n      420959\n      경주시\n      0.01\n      2022-12-31\n      18:00\n    \n  \n\n420960 rows × 4 columns\n\n\n\n- 시간이 비어있지 않도록..\n\nreg = df_temp['지점명'].unique().tolist() \nday = df_temp['날짜'].unique().tolist() \ntime = list(df_temp['시간'].unique())\ntime = ['0{}:00'.format(i) for i in range(0,8)] + time\n\n\ndf_temp2 = pd.DataFrame(itertools.product(reg,day,time)).rename({0:'지점명',1:'날짜',2:'시간'},axis=1).merge(df_temp,how='left').fillna(0)\ndf_temp2\n\n\n\n\n\n  \n    \n      \n      지점명\n      날짜\n      시간\n      일사\n    \n  \n  \n    \n      0\n      북춘천\n      2021-01-01\n      00:00\n      0.0\n    \n    \n      1\n      북춘천\n      2021-01-01\n      01:00\n      0.0\n    \n    \n      2\n      북춘천\n      2021-01-01\n      02:00\n      0.0\n    \n    \n      3\n      북춘천\n      2021-01-01\n      03:00\n      0.0\n    \n    \n      4\n      북춘천\n      2021-01-01\n      04:00\n      0.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      802995\n      경주시\n      2022-12-31\n      07:00\n      0.0\n    \n    \n      802996\n      경주시\n      2022-12-31\n      20:00\n      0.0\n    \n    \n      802997\n      경주시\n      2022-12-31\n      06:00\n      0.0\n    \n    \n      802998\n      경주시\n      2022-12-31\n      21:00\n      0.0\n    \n    \n      802999\n      경주시\n      2022-12-31\n      05:00\n      0.0\n    \n  \n\n803000 rows × 4 columns\n\n\n\n\ndf_temp2[:20]\n\n\n\n\n\n  \n    \n      \n      지점명\n      날짜\n      시간\n      일사\n    \n  \n  \n    \n      0\n      북춘천\n      2021-01-01\n      00:00\n      0.00\n    \n    \n      1\n      북춘천\n      2021-01-01\n      01:00\n      0.00\n    \n    \n      2\n      북춘천\n      2021-01-01\n      02:00\n      0.00\n    \n    \n      3\n      북춘천\n      2021-01-01\n      03:00\n      0.00\n    \n    \n      4\n      북춘천\n      2021-01-01\n      04:00\n      0.00\n    \n    \n      5\n      북춘천\n      2021-01-01\n      05:00\n      0.00\n    \n    \n      6\n      북춘천\n      2021-01-01\n      06:00\n      0.00\n    \n    \n      7\n      북춘천\n      2021-01-01\n      07:00\n      0.00\n    \n    \n      8\n      북춘천\n      2021-01-01\n      08:00\n      0.00\n    \n    \n      9\n      북춘천\n      2021-01-01\n      09:00\n      0.37\n    \n    \n      10\n      북춘천\n      2021-01-01\n      10:00\n      0.96\n    \n    \n      11\n      북춘천\n      2021-01-01\n      11:00\n      1.40\n    \n    \n      12\n      북춘천\n      2021-01-01\n      12:00\n      1.72\n    \n    \n      13\n      북춘천\n      2021-01-01\n      13:00\n      1.84\n    \n    \n      14\n      북춘천\n      2021-01-01\n      14:00\n      1.74\n    \n    \n      15\n      북춘천\n      2021-01-01\n      15:00\n      1.30\n    \n    \n      16\n      북춘천\n      2021-01-01\n      16:00\n      0.93\n    \n    \n      17\n      북춘천\n      2021-01-01\n      17:00\n      0.29\n    \n    \n      18\n      북춘천\n      2021-01-01\n      18:00\n      0.01\n    \n    \n      19\n      북춘천\n      2021-01-01\n      19:00\n      0.00\n    \n  \n\n\n\n\n\ndf_temp2[-20:]\n\n\n\n\n\n  \n    \n      \n      지점명\n      날짜\n      시간\n      일사\n    \n  \n  \n    \n      802980\n      경주시\n      2022-12-31\n      05:00\n      0.00\n    \n    \n      802981\n      경주시\n      2022-12-31\n      06:00\n      0.00\n    \n    \n      802982\n      경주시\n      2022-12-31\n      07:00\n      0.00\n    \n    \n      802983\n      경주시\n      2022-12-31\n      08:00\n      0.02\n    \n    \n      802984\n      경주시\n      2022-12-31\n      09:00\n      0.41\n    \n    \n      802985\n      경주시\n      2022-12-31\n      10:00\n      1.05\n    \n    \n      802986\n      경주시\n      2022-12-31\n      11:00\n      1.52\n    \n    \n      802987\n      경주시\n      2022-12-31\n      12:00\n      1.86\n    \n    \n      802988\n      경주시\n      2022-12-31\n      13:00\n      1.93\n    \n    \n      802989\n      경주시\n      2022-12-31\n      14:00\n      1.82\n    \n    \n      802990\n      경주시\n      2022-12-31\n      15:00\n      1.52\n    \n    \n      802991\n      경주시\n      2022-12-31\n      16:00\n      0.96\n    \n    \n      802992\n      경주시\n      2022-12-31\n      17:00\n      0.35\n    \n    \n      802993\n      경주시\n      2022-12-31\n      18:00\n      0.01\n    \n    \n      802994\n      경주시\n      2022-12-31\n      19:00\n      0.00\n    \n    \n      802995\n      경주시\n      2022-12-31\n      07:00\n      0.00\n    \n    \n      802996\n      경주시\n      2022-12-31\n      20:00\n      0.00\n    \n    \n      802997\n      경주시\n      2022-12-31\n      06:00\n      0.00\n    \n    \n      802998\n      경주시\n      2022-12-31\n      21:00\n      0.00\n    \n    \n      802999\n      경주시\n      2022-12-31\n      05:00\n      0.00\n    \n  \n\n\n\n\n\ndf_temp2\n\n\n\n\n\n  \n    \n      \n      지점명\n      날짜\n      시간\n      일사\n    \n  \n  \n    \n      0\n      북춘천\n      2021-01-01\n      00:00\n      0.0\n    \n    \n      1\n      북춘천\n      2021-01-01\n      01:00\n      0.0\n    \n    \n      2\n      북춘천\n      2021-01-01\n      02:00\n      0.0\n    \n    \n      3\n      북춘천\n      2021-01-01\n      03:00\n      0.0\n    \n    \n      4\n      북춘천\n      2021-01-01\n      04:00\n      0.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      802995\n      경주시\n      2022-12-31\n      07:00\n      0.0\n    \n    \n      802996\n      경주시\n      2022-12-31\n      20:00\n      0.0\n    \n    \n      802997\n      경주시\n      2022-12-31\n      06:00\n      0.0\n    \n    \n      802998\n      경주시\n      2022-12-31\n      21:00\n      0.0\n    \n    \n      802999\n      경주시\n      2022-12-31\n      05:00\n      0.0\n    \n  \n\n803000 rows × 4 columns\n\n\n\n- 시간,날짜 \\(\\to\\) 일시\n\ndf_temp3=df_temp2.assign(일시 = list(map(lambda x,y: x+'-'+y,df_temp2['날짜'],df_temp2['시간'])))\\\n.drop(['날짜','시간'],axis=1)\ndf_temp3\n\n\n\n\n\n  \n    \n      \n      지점명\n      일사\n      일시\n    \n  \n  \n    \n      0\n      북춘천\n      0.0\n      2021-01-01-00:00\n    \n    \n      1\n      북춘천\n      0.0\n      2021-01-01-01:00\n    \n    \n      2\n      북춘천\n      0.0\n      2021-01-01-02:00\n    \n    \n      3\n      북춘천\n      0.0\n      2021-01-01-03:00\n    \n    \n      4\n      북춘천\n      0.0\n      2021-01-01-04:00\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      802995\n      경주시\n      0.0\n      2022-12-31-07:00\n    \n    \n      802996\n      경주시\n      0.0\n      2022-12-31-20:00\n    \n    \n      802997\n      경주시\n      0.0\n      2022-12-31-06:00\n    \n    \n      802998\n      경주시\n      0.0\n      2022-12-31-21:00\n    \n    \n      802999\n      경주시\n      0.0\n      2022-12-31-05:00\n    \n  \n\n803000 rows × 3 columns\n\n\n\n- 저장\n\ndf_temp3.rename({'지점명':'region','일사':'solar_radiation','일시':'date'},axis=1)\n\n\n\n\n\n  \n    \n      \n      region\n      solar_radiation\n      date\n    \n  \n  \n    \n      0\n      북춘천\n      0.0\n      2021-01-01-00:00\n    \n    \n      1\n      북춘천\n      0.0\n      2021-01-01-01:00\n    \n    \n      2\n      북춘천\n      0.0\n      2021-01-01-02:00\n    \n    \n      3\n      북춘천\n      0.0\n      2021-01-01-03:00\n    \n    \n      4\n      북춘천\n      0.0\n      2021-01-01-04:00\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      802995\n      경주시\n      0.0\n      2022-12-31-07:00\n    \n    \n      802996\n      경주시\n      0.0\n      2022-12-31-20:00\n    \n    \n      802997\n      경주시\n      0.0\n      2022-12-31-06:00\n    \n    \n      802998\n      경주시\n      0.0\n      2022-12-31-21:00\n    \n    \n      802999\n      경주시\n      0.0\n      2022-12-31-05:00\n    \n  \n\n803000 rows × 3 columns\n\n\n\n\ndf = df_temp3.rename({'지점명':'region','일사':'solar_radiation','일시':'date'},axis=1)\ndf.to_csv(\"solar_radiation.csv\",index=False)\n!git add .\n!git commit -m .\n!git push \n\n[main 299d058] .\n 3 files changed, 806273 insertions(+)\n create mode 100644 \"posts/3_Researches/SOLAR/.ipynb_checkpoints/2023-04-03-\\354\\235\\274\\354\\202\\254\\353\\237\\211-checkpoint.ipynb\"\n create mode 100644 \"posts/3_Researches/SOLAR/2023-04-03-\\354\\235\\274\\354\\202\\254\\353\\237\\211.ipynb\"\n create mode 100644 posts/3_Researches/SOLAR/solar_radiation.csv\nEnumerating objects: 10, done.\nCounting objects: 100% (10/10), done.\nDelta compression using up to 16 threads\nCompressing objects: 100% (7/7), done.\nWriting objects: 100% (7/7), 8.74 KiB | 8.74 MiB/s, done.\nTotal 7 (delta 2), reused 0 (delta 0)\nremote: Resolving deltas: 100% (2/2), completed with 2 local objects.\nTo https://github.com/miruetoto/yechan3.git\n   495d9ce..299d058  main -> main\n\n\n- 불러오기\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/miruetoto/yechan3/main/posts/3_Researches/SOLAR/solar_radiation.csv\")\ndf\n\n\n\n\n\n  \n    \n      \n      region\n      solar_radiation\n      date\n    \n  \n  \n    \n      0\n      북춘천\n      0.0\n      2021-01-01-00:00\n    \n    \n      1\n      북춘천\n      0.0\n      2021-01-01-01:00\n    \n    \n      2\n      북춘천\n      0.0\n      2021-01-01-02:00\n    \n    \n      3\n      북춘천\n      0.0\n      2021-01-01-03:00\n    \n    \n      4\n      북춘천\n      0.0\n      2021-01-01-04:00\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      802995\n      경주시\n      0.0\n      2022-12-31-07:00\n    \n    \n      802996\n      경주시\n      0.0\n      2022-12-31-20:00\n    \n    \n      802997\n      경주시\n      0.0\n      2022-12-31-06:00\n    \n    \n      802998\n      경주시\n      0.0\n      2022-12-31-21:00\n    \n    \n      802999\n      경주시\n      0.0\n      2022-12-31-05:00\n    \n  \n\n803000 rows × 3 columns\n\n\n\n- 다운로드\n!wget https://raw.githubusercontent.com/miruetoto/yechan3/main/posts/3_Researches/SOLAR/solar_radiation.csv"
  },
  {
    "objectID": "posts/1_Essays/2019-04-26-퓨리에 변환.html",
    "href": "posts/1_Essays/2019-04-26-퓨리에 변환.html",
    "title": "[Essays] 퓨리에 변환",
    "section": "",
    "text": "About this doc\n- 이번에는 퓨리에 표현들을 정리하도록 하겠다. 내생각엔 퓨리에 표현들도 벡터의 미분만큼 복잡한 것 같다. 정의가 너무 많고 그게 그거 같아서 그렇다. 이번기회에 깔끔하게 정리하도록 하자. 참고한 문헌은 아래와 같다.\n\nHaykin, S., & Van Veen, B. (2007). Signals and systems. John Wiley & Sons.\n\n\n\n들어가며\n- 우선 신호와 하나의 신호값을 구분하는 notation을 생각하자. 우리가 다루는 신호 즉 데이터는 값들의 집합이다. 우리가 시계열자료를 다룬다면 데이터는 아래와 같이 표현한다.\n\n\\(\\{x_i: i \\in \\mathbb{Z}\\}\\)\n\n이와 유시하게 우리가 다루는 자료가 \\(t \\in \\mathbb{R}\\)인 연속신호라면 아래와 같이 표현한다.\n\n\\(\\{x(t): t \\in \\mathbb{R}\\}\\)\n\n우리가 모든 \\(i \\in \\mathbb{Z}\\) 혹은 모든 \\(t \\in \\mathbb{R}\\)에서 신호를 다룰 생각이 없다면 아래와 같은 표현도 얼마든지 가능하다.\n\n\\(\\{x_i: i=0,1,\\dots, \\xi-1 \\}\\)\n\\(\\{x(t):t \\in (0,\\zeta) \\}\\)\n\n- 위와 같이 집합의 표현 없이 단독으로 \\(x_i\\), \\(x(t)\\)와 같이 쓰면 하나의 고정된 값 \\(i,t\\)에 대한 \\(x_i\\), \\(x(t)\\)로 이해하자. 솔직히 이렇게 꼭 신호를 엄밀하게 집합으로 정의하는게 유별나 보일수도 있다. 일반적으로 사람들은 \\(\\{x(t): ~t \\in \\mathbb{R} \\}\\) 대신에 보통 \\(x(t)\\)로 간단하게 줄여서 쓰곤한다.1 하지만 이 포스팅에 한정하여 위와 같이 집합의 형태로 엄밀하게 구분해 쓰도록 하자. 처음에는 익숙하지 않지만 나중에는 편리하다.\n\n\n퓨리에표현들\n- 지금부터 우리가 고려하는 모든 신호들은 기본적으로 (1) infinity range에서 정의된 신호라고 가정한다. 즉 연속신호이면 \\(\\mathbb{R}\\)에서 정의된다고 가정하고 이산신호면 \\(\\mathbb{Z}\\)에서 정의된다고 가정한다. 또한 우리가 분석하고자 하는 신호는 (2) integrable 하다고 가정한다. 이건 퓨리에표현들이 적분 혹은 무한합의 형태로 표현된다는 것을 상기하면 타당하여 보인다.\n- 즉 우리가 고려하는 신호는 인피니티-레인지에서 정의되며 인피니티-레인지에서 적분값이 유한한 연속신호 혹은 이산신호 임을 알 수 있다. 이러한 신호는 구체적으로는 아래와 같이 쓸 수 있다.\n\n\\(\\left\\{x(t): \\int_{-\\infty}^{\\infty} |x(t)| dt <\\infty,~ t \\in \\mathbb{R} \\right\\}\\)\n\\(\\left\\{x_i: \\sum_{i=-\\infty}^{\\infty} |x_i| <\\infty,~ i \\in \\mathbb{Z} \\right\\}\\)\n\n- 그런데 integrable 한 함수들만을 고려하다 보면 우리가 다룰 수 있는 신호의 범위가 확 줄어들게 된다. 가령 예를 들어서 아래와 같은 신호는 적분을 하면 무한대가 나오기 때문에 intergrable 하지 않다.\n\n\\(\\left\\{x(t): x(t)=\\sin(t)+1 ,~ t \\in \\mathbb{R} \\right\\}\\)\n\n이것은 좀 불합리해 보이는데 위의 신호는 주기신호라서 한 주기의 패턴만 분석하면 될것 같이 보이기 때문이다. 위의 신호는 intergrable 하지않지만 아래의 신호는 intergrable 하다.\n\n\\(\\left\\{x(t): x(t)=\\sin(t)+1 ,~ t \\in (0,2\\pi) \\right\\}\\)\n\n우리는 이런신호까지 분석하기로 한다. 이런신호를 분석할 수 있는 이유는 해석학 교재를 참고하면 된다.2\n- 아무튼 우리는 (1) 인피니티-레인지에서 정의되는 가지는 신호 (2) 인피니티-레인지에서 적분값이 잘 정의되는 신호, 혹은 한 주기만 적분해 보았을때 그 값이 잘 정의되는 주기신호 를 타겟팅해 분석한다. 즉 분석하는 신호는 구체적으로 아래의 4가지이다.\ncase 1: 연속-비주기\n\n\\(\\left\\{x(t): \\int_{-\\infty}^{\\infty} |x(t)| dt <\\infty,~ t \\in \\mathbb{R} \\right\\}.\\)\n\ncase 2: 연속-주기\n\n\\(\\left\\{x(t): \\int_{0}^{\\zeta} |x(t)| dt <\\infty, ~ , x(t)=x(t+\\zeta), ~ t \\in \\mathbb{R}, \\right\\}.\\)\n\ncase 3: 이산-비주기\n\n\\(\\left\\{x_i: \\sum_{i=-\\infty}^{\\infty} |x_i| <\\infty,~ i \\in \\mathbb{Z} \\right\\}.\\)\n\ncase 4: 이산-주기\n\n\\(\\left\\{x_i: \\sum_{i=0}^{\\xi-1} |x_i| <\\infty,~ i, x_i=x_{i+\\xi},~ i \\in \\mathbb{Z} \\right\\}.\\)\n\n- 표현들을 정리하기에 앞서서 몇 가지 알아두어야 할 사항이 있다. (1) 시간축에서 연속인 신호는 주파수측에서는 비주기신호가 나온다. (2) 시간축에서 디스크릿한 신호는 주파수측에서는 주기신호이다. (3) 시간축에서 주기인 신호는 주파수에서는 디스크릿하다. (4) 시간축에서 비주기신호는 주파수에서 연속이다. 이 사실들을 종합하면 각각의 경우에 해당하는 퓨리에 표현들은 아래와 같은 특징을 가지고 있음을 알 수 있다.\ncase 1: 연속-비주기\n\n\\(\\left\\{x(t): \\int_{-\\infty}^{\\infty} |x(t)| dt <\\infty,~ t \\in \\mathbb{R} \\right\\} \\\\ \\overset{FT}{\\Longleftrightarrow} \\left\\{\\hat x(\\omega): \\int_{-\\infty}^{\\infty} |\\hat x(\\omega)| d\\omega <\\infty,~ \\omega \\in \\mathbb{R} \\right\\}\\)\n\ncase 2: 연속-주기\n\n\\(\\left\\{x(t): \\int_{0}^{\\zeta} |x(t)| dt <\\infty,~ x(t)=x(t+\\zeta),~ t \\in \\mathbb{R} \\right\\} \\\\ \\overset{FS}{\\Longleftrightarrow} \\left\\{\\hat x_k: \\sum_{k=-\\infty}^{\\infty} |\\hat x_k| <\\infty,~ k \\in \\mathbb{Z} \\right\\}\\)\n\ncase 3: 이산-비주기\n\n\\(\\left\\{x_i: \\sum_{i=-\\infty}^{\\infty} |x_i| <\\infty,~ i \\in \\mathbb{Z} \\right\\} \\\\ \\overset{DTFT}{\\Longleftrightarrow} \\left\\{\\hat x(\\omega): \\int_{0}^{2\\pi} |\\hat x(\\omega)| d\\omega <\\infty,~ \\hat x(\\omega)=\\hat x(\\omega+2\\pi),~ \\omega \\in \\mathbb{R} \\right\\}.\\)\n\ncase 4: 이산-주기\n\n\\(\\left\\{x_i: \\sum_{i=0}^{\\xi-1} |x_i| <\\infty,~ x_i=x_{i+\\xi},~ i \\in \\mathbb{R} \\right\\} \\\\ \\overset{DTFS}{\\Longleftrightarrow} \\left\\{\\hat x_k: \\sum_{k=0}^{\\xi-1} |\\hat x_k| <\\infty,~\\hat x_k = \\hat x_{k+\\xi} ,~ k \\in \\mathbb{Z} \\right\\}.\\)\n\n- 여기에서 \\(\\zeta\\)는 (시간축에서) 연속신호의 주기라고 정의하고 \\(\\xi\\)는 (시간축에서) 이산신호의 주기라고 약속하자. 주파수영역이 디스크릿하게 나오면 FS라고 부르고 주파수영역이 컨티뉴어스하게 나오면 FT라고 부른다. 특이한점은 비주기-이산신호에 대한 FS \\(\\hat x(\\omega)\\)는 주파수 영역에서 주기가 \\(2\\pi\\)임을 파악할 수 있다. 이유는 궁금해하지말자. (내생각에 그냥 \\(\\omega\\)를 적당히 스케일링하여 주기를 \\(2\\pi\\)로 맞췄을 거다.)\n- 이제 짜증나는 적분가능조건따위는 버리도록 하자. 대신에 각 경우에 퓨리에변환(혹은series)과 그 역이 어떻게 정의되는지 알아보자. 그리고 외우자. 각 신호가 어떠한 도메인에서 정의되는지만 잘 파악하면 의외로 외우기 쉽다.\ncase 1. 연속-비주기\n\n\\(\\left\\{x(t): x(t)=\\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} \\hat x(\\omega)e^{j\\omega t} d\\omega,~ t \\in \\mathbb{R} \\right\\} \\\\ \\overset{FT}{\\Longleftrightarrow} \\left\\{\\hat x(\\omega): \\hat x(\\omega)=\\int_{-\\infty}^{\\infty} x(t)e^{-j\\omega t} dt,~ \\omega \\in \\mathbb{R} \\right\\}.\\)\n\ncase 2. 연속-주기\n\n\\(\\left\\{x(t): x(t)= \\sum_{k=-\\infty}^{\\infty} \\hat x_k e^{j \\frac{2\\pi}{\\zeta} t} ,~ t \\in \\mathbb{R} \\right\\} \\\\ \\overset{FS}{\\Longleftrightarrow} \\left\\{\\hat x_k: \\hat x_k= \\frac{1}{\\zeta}\\int_{0}^{\\zeta}x(t)e^{-j \\frac{2\\pi k}{\\zeta}t}dt,~ k \\in \\mathbb{Z} \\right\\}.\\)\n\ncase 3. 이산-비주기\n\n\\(\\left\\{x_i: x_i=\\frac{1}{2\\pi}\\int_{0}^{2\\pi}\\hat x(\\omega)e^{j \\omega i}d\\omega, ~ i \\in \\mathbb{Z} \\right\\} \\\\ \\overset{DTFT}{\\Longleftrightarrow} \\left\\{\\hat x(\\omega): \\hat x(\\omega)=\\sum_{i=-\\infty}^{\\infty}x_ie^{-j\\omega i}, ~\\omega \\in \\mathbb{R} \\right\\}.\\)\n\ncase 4. 이산-주기\n\n\\(\\left\\{x_i: x_i=\\sum_{k=0}^{\\xi-1} \\hat x_k e^{-j\\frac{2\\pi k}{\\xi}i},~ i \\in \\mathbb{Z} \\right\\} \\\\ \\overset{DTFS}{\\Longleftrightarrow} \\left\\{\\hat x_k: \\hat x_k= \\frac{1}{\\xi}\\sum_{i=0}^{\\xi-1} x_i e^{-j\\frac{2\\pi k}{\\xi}i},~ k \\in \\mathbb{Z} \\right\\}.\\)\n\n- 주기함수는 (그것이 이산이든 연속이든) 주파수영역에서의 값이 디스크릿하다. 즉 위에서 case2와 case4인 경우는 주파수영역에서 값이 디스크릿하다. 이것을 연속함수인것처럼 바꿔보면 아래와 같이 쓸 수 있다.\ncase 2. 연속-주기\n\n\\(\\left\\{x(t): x(t)= \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} \\hat x(\\omega)e^{j\\omega t} d\\omega,~ t \\in \\mathbb{R} \\right\\} \\\\ \\overset{FT}{\\Longleftrightarrow} \\left\\{\\hat x(\\omega): 2\\pi\\sum_{k=-\\infty}^{\\infty}\\left[\\frac{1}{\\zeta}\\int_{0}^{\\zeta}x(t)e^{-j \\frac{2\\pi k}{\\zeta}t}dt\\right]\\delta\\left(\\omega-\\frac{2\\pi k}{\\zeta}\\right), ~ k \\in \\mathbb{Z} \\right\\}.\\)\n\ncase 4. 이산-주기\n\n\\(\\left\\{x_i: x_i=\\frac{1}{2\\pi}\\int_{0}^{2\\pi}\\hat x(\\omega)e^{j \\omega i}d\\omega,,~ i \\in \\mathbb{Z} \\right\\} \\\\ \\overset{DTFT}{\\Longleftrightarrow} \\left\\{\\hat x(\\omega): 2\\pi\\sum_{k=-\\infty}^{\\infty}\\left[\\frac{1}{\\xi}\\sum_{i=0}^{\\xi-1} x_i e^{-j\\frac{2\\pi k}{\\xi}i}\\right]\\delta\\left(\\omega-\\frac{2\\pi k}{\\xi}\\right),~ k \\in \\mathbb{Z} \\right\\}.\\)\n\n- 주목할것은 주기가 \\(\\zeta\\) 혹은 \\(\\xi\\) 인 함수의 주파수 응답은 오로지\n\n\\(\\omega \\in \\left\\{\\frac{2 \\pi k}{\\zeta}, k \\in \\mathbb{Z}\\right\\}\\)\n\n혹은\n\n\\(\\omega \\in \\left\\{\\frac{2 \\pi k}{\\xi}, k \\in \\mathbb{Z}\\right\\}\\)\n\n에서만 존재한다는 점이다. 또한 이산신호의 경우 \\(x_i\\)의 주기가 \\(\\xi\\) 이면 \\(\\hat{x}(\\omega)\\)의 주기역시 \\(\\xi\\) 라는점 역시 주목할만한 부분이다.\n- 주파수영역에서 디스크릿한 함수를 연속인것처럼 표현했듯이 시간영역에서 디스크릿한 함수 역시 연속인것처럼 표현할 수 있다. 예를들면 \\(\\{x_i: x_i=x(iT),~i \\in \\mathbb{Z}\\}\\) 와 같은 관계가 있는 경우 아래와 같이 표현 가능하다.\n\\[x_{\\delta}(t)=\\sum_{i=-\\infty}^{\\infty}x_i\\delta(t-iT).\\]\n이거 엄청 중요하다.\n\n\n\n\n\nFootnotes\n\n\n나도 그렇다.↩︎\n사실 나도 잘 모름 (뭐 quotient group이런거 알아야 하는데 공부하려면 꽤 걸릴듯)↩︎"
  },
  {
    "objectID": "posts/1_Essays/2023-01-07-해석학(1).html",
    "href": "posts/1_Essays/2023-01-07-해석학(1).html",
    "title": "[Essays] 해석학(1)",
    "section": "",
    "text": "이걸 증명하려면 자연수를 정의하는 페아노공리를 알아야함.\n그리고 그 공리로부터 유도되는 여러가지 자연수 성질중 하나인 자연수 집합은 위로 유계가 아니라는 사실을 알아야함.\n아르키메데스성질: For all \\(x \\in \\mathbb{R}\\) there exists \\(N \\in \\mathbb{N}\\) such that \\(x<N\\).\n\n아무 실수나 잡으면 그 숫자보다 큰 자연수가 존재한다는 의미\n아르키메데스 성질은 완비성공리로부터 증명가능함.\n\n아르키메데스 성질을 이용하면 임의의 \\(\\epsilon\\)보다 작은 \\(\\frac{1}{N}\\)을 항상 잡을수 있다. 즉 모든 \\(\\epsilon>0\\) 에 대하여 \\(0\\leq \\frac{1}{N} < \\epsilon\\) 을 만족하는 \\(N\\)이 항상 존재함을 알 수 있다.\n(예제) 아래를 증명하라.\n\\[\\lim_{n\\to \\infty}\\frac{4n}{2n+1}=2\\]\n(풀이) 모든 \\(\\epsilon>0\\)에 대하여 아래가 항상 성립함을 보이면 된다.\n\\[\\exists N \\in \\mathbb{N} \\quad \\text{such that} \\quad n \\geq N \\Rightarrow 0\\leq \\left |\\frac{4n}{2n+1}-2 \\right|<\\epsilon\\]\n그런데 \\(|\\frac{4n}{2n+1}-2|\\leq \\frac{1}{n}\\) 이므로 우리는 모든 \\(\\epsilon >0\\)에 대하여 아래가 성립함을 보이면 된다.\n\\[\\exists N \\in \\mathbb{N} \\quad \\text{such that} \\quad n \\geq N \\Rightarrow 0\\leq \\frac{1}{n} <\\epsilon\\]\n그런데 \\(n\\geq N\\)이라는 조건하에서는 \\(\\frac{1}{n} \\leq \\frac{1}{N}\\) 이므로 우리는 다시 모든 \\(\\epsilon>0\\)에 대하여 아래가 성립함을 보이면 된다.\n\\[\\exists N \\in \\mathbb{N} \\quad \\text{such that} \\quad 0 \\leq \\frac{1}{N} <\\epsilon\\]\n이러한 \\(N\\)은 아르키메데스의 성질에 의하여 항상 존재한다."
  },
  {
    "objectID": "posts/1_Essays/2023-01-07-해석학(1).html#체-공리",
    "href": "posts/1_Essays/2023-01-07-해석학(1).html#체-공리",
    "title": "[Essays] 해석학(1)",
    "section": "체 공리",
    "text": "체 공리\n- 실수는 더하기와 곱셈이라는 연산이 합리적으로 정리되는 집합이라는 의미"
  },
  {
    "objectID": "posts/1_Essays/2023-01-07-해석학(1).html#순서-공리",
    "href": "posts/1_Essays/2023-01-07-해석학(1).html#순서-공리",
    "title": "[Essays] 해석학(1)",
    "section": "순서 공리",
    "text": "순서 공리\n- 순서공리에 의하여 부등식이 정의됨\n- 3분성질"
  },
  {
    "objectID": "posts/1_Essays/2023-01-07-해석학(1).html#디리클레함수",
    "href": "posts/1_Essays/2023-01-07-해석학(1).html#디리클레함수",
    "title": "[Essays] 해석학(1)",
    "section": "디리클레함수",
    "text": "디리클레함수\n모든 점에서 불연속인 함수임"
  },
  {
    "objectID": "posts/1_Essays/2023-01-07-해석학(1).html#thomae-함수",
    "href": "posts/1_Essays/2023-01-07-해석학(1).html#thomae-함수",
    "title": "[Essays] 해석학(1)",
    "section": "Thomae 함수",
    "text": "Thomae 함수\n유리수에서는 불연속, 무리수에서는 연속"
  },
  {
    "objectID": "posts/1_Essays/2023-01-07-해석학(1).html#합성함수의-연속",
    "href": "posts/1_Essays/2023-01-07-해석학(1).html#합성함수의-연속",
    "title": "[Essays] 해석학(1)",
    "section": "합성함수의 연속",
    "text": "합성함수의 연속\n함수 \\(f(x)\\)와 \\(g(x)\\)가 모두 \\(x=c\\)에서 연속이면 함수 \\((f\\circ g)(x)\\) 혹은 \\((g \\circ f)(x)\\)도 \\(x=c\\)에서 연속이다."
  },
  {
    "objectID": "posts/1_Essays/2023-01-07-해석학(1).html#중간값정리-leftrightarrow-완비성공리",
    "href": "posts/1_Essays/2023-01-07-해석학(1).html#중간값정리-leftrightarrow-완비성공리",
    "title": "[Essays] 해석학(1)",
    "section": "중간값정리 \\(\\Leftrightarrow\\) 완비성공리",
    "text": "중간값정리 \\(\\Leftrightarrow\\) 완비성공리"
  },
  {
    "objectID": "posts/1_Essays/2023-01-07-해석학(1).html#균등연속임을-판단하는-방법",
    "href": "posts/1_Essays/2023-01-07-해석학(1).html#균등연속임을-판단하는-방법",
    "title": "[Essays] 해석학(1)",
    "section": "균등연속임을 판단하는 방법",
    "text": "균등연속임을 판단하는 방법\n\n립쉬츠조건: 어떠한 함수 \\(f\\)가 \\(|f(x)-f(u)|\\leq K|x-u|\\)를 만족하면 이러한 함수는 균등연속이다. \\(\\delta=\\frac{\\epsilon}{K}\\) 로만 선택하면 되므로\n\\(f(x)\\)가 연속이라고하자. \\(f(x)\\)의 정의역이 유계폐구간이면 함수 \\(f\\)는 균등연속이라 주장할 수 있다. 만약에 \\(f(x)\\)의 정의역이 개구간이면 구간의 양 끝점에서의 극한이 존재할때 \\(f\\)를 균등연속이라고 주장할 수 있다.\n\\(f(x)\\)가 개구간에서 정의된 경우"
  },
  {
    "objectID": "posts/1_Essays/2023-01-07-해석학(1).html#균등연속이-아님을-판단하는-방법",
    "href": "posts/1_Essays/2023-01-07-해석학(1).html#균등연속이-아님을-판단하는-방법",
    "title": "[Essays] 해석학(1)",
    "section": "균등연속이 아님을 판단하는 방법",
    "text": "균등연속이 아님을 판단하는 방법\n\n어떠한 \\(\\epsilon_0>0\\)가 존재하여, 내가 \\(\\delta\\)를 어떻게 잡든 \\(|x-u|<\\delta\\) and \\(|f(x)-f(u)|\\geq\\epsilon_0\\) 를 만족하는 \\(x\\)와 \\(u\\)가 존재하면 균등연속이 아니다.\n\\(\\lim_{n\\to\\infty}(x_n-u_n)=0\\) 이지만 \\(|f(x_n)-f(u_n)| \\geq \\epsilon_0\\) 임을 확인하면 균등연속이 아니다. 즉 \\(x\\)축에서는 수렴하는 두개의 수열이 함수를 태우면 수렴하지 않는 경우"
  },
  {
    "objectID": "posts/1_Essays/2023-01-07-해석학(1).html#균등연속의-특징",
    "href": "posts/1_Essays/2023-01-07-해석학(1).html#균등연속의-특징",
    "title": "[Essays] 해석학(1)",
    "section": "균등연속의 특징",
    "text": "균등연속의 특징\n코시수열을 보존한다. 즉 \\(x_n\\)이 코시수열이고 함수 \\(f\\)가 균등연속이면 \\(f(x_n)\\)역시 코시수열이다.\n연속확장정리: 개구간에서의 균등연속을 사용하고 싶음. \\(f(x)\\)가 개구간 \\((a,b)\\)에서 연속이고 양 끝점, 즉 \\(a\\), \\(b\\)에서의 극한이 존재하면 \\(f(x)\\)는 균등연속이다.\n균등연속의 아이디어: x축에서 수렴하던 어떤애가 y축에서도 수렴했으면 좋겠음. (이게 원래 안되는 건데요, 균등연속일때는 가능합니다)"
  },
  {
    "objectID": "posts/1_Essays/2023-01-07-해석학(1).html#모티브",
    "href": "posts/1_Essays/2023-01-07-해석학(1).html#모티브",
    "title": "[Essays] 해석학(1)",
    "section": "모티브",
    "text": "모티브\n아래와 같은 합성함수의 미분을 생각하여 보자.4\n\\[(f\\circ g)'(c) = \\lim_{x\\to c}\\frac{f(g(x))-f(g(c))}{x-c}\\]\n(풀이1)\n고등학교 수준에서는 이것을 아래와 같이 쓸 수 있다.\n\\[\\lim_{x\\to c}\\frac{f(g(x))-f(g(c))}{x-c}=\\lim_{x\\to c}\\left(\\frac{f(g(x))-f(g(c))}{g(x)-g(c)}\\frac{g(x)-g(c)}{x-c}\\right)=f'\\big(g(c)\\big)\\cdot g'(c)\\]\n(아쉬움)\n이 증명의 단점은 \\(g(x)-g(c)\\neq 0\\)이라는 조건이 필요하다는 것이다. 이 조건을 제외할 수는 없을까? 그리스 수학자인 카라테오도리(Caratheodory)는 아래와 같은 명제를 발견하였다.\n(명제) \\(f(x)\\) 가 \\(x=c\\) 에서 미분가능하다 \\(\\Longleftrightarrow\\) 적당한 연속함수 \\(\\varphi(x)\\) 가 존재하여 (i) \\(\\varphi(x)\\) 는 \\(x=c\\) 에서 미분가능하고 (ii) \\(f(x)-f(c)=\\varphi(c)(x-c)\\) 이다.\n이것을 이용하면 합성함수의 미분을 다시 풀어보자.\n(풀이2)\n먼저 \\(g(x)\\) 는 \\(x=c\\) 에서 미분가능하다라는 조건은 아래와 같이 표현할 수 있다.\n\n\\(g(x)\\) 가 \\(x=c\\) 에서 미분가능하다 \\(\\Leftrightarrow\\) \\(g(x)-g(c)=\\varphi(c)(x-c)\\)\n\n또한 \\((f\\circ g)(x)=f(g(x))\\) 는 \\(x=g(c)\\) 에서 미분가능하다라는 조건은 아래와 같이 표현할 수 있다.\n\n\\((f\\circ g)(x)\\) 가 \\(x=g(c)\\) 에서 미분가능하다 \\(\\Leftrightarrow\\) \\(f(g(x))-f(g(c))=\\psi(g(c))(g(x)-g(c))\\)\n\n\n#"
  },
  {
    "objectID": "posts/1_Essays/2023-02-05-시계열의 주파수영역 분석.html",
    "href": "posts/1_Essays/2023-02-05-시계열의 주파수영역 분석.html",
    "title": "[Essays] 시계열의 주파수영역 분석",
    "section": "",
    "text": "이 포스트는 Wei (2006) 의 CHAPTER 12 Spectral Theory of Stationary Processes 를 요약한 것이다\n\n\\(Z_t\\)를 real-valued stationary process 라고 하자. 그리고 \\(\\gamma_k\\)를 \\(Z_t\\)의 autocovariance sequence 라고 하자. 만약에 \\(\\gamma_k\\) 가 absolutely summable 하다면1 아래와 같은 표현이 존재한다.\n\\[\nf(\\omega)=\\frac{1}{2\\pi}\\sum_{k=-\\infty}^{\\infty}\\gamma_k e^{-i\\omega k}=\\frac{1}{2\\pi}\\gamma_0 + \\frac{1}{\\pi}\\sum_{k=1}^{\\infty}\\gamma_k\\cos(\\omega k)\n\\]\n첫 등호에서 두번째 등호로 넘어갈때 아래의 성질들이 이용되었다.\n\n\\(e^{i\\theta} = \\cos \\theta + i \\sin\\theta\\)\n\\(\\gamma_k = \\gamma_{-k}\\)\n\\(\\sin \\omega(-k) = - \\sin \\omega k\\)\n\\(\\cos \\omega(-k) = \\cos \\omega k\\)\n\n여기에서 \\(f(\\omega)\\)는 \\(\\gamma_k\\)를 퓨리에변환한 결과이다. \\(f(\\omega)\\)를 역 퓨리에변환하면 다시 \\(\\gamma_k\\)를 얻을 수 있는데 이를 수식으로 표현하면 아래와 같다.\n\\[\\gamma_k = \\int_{-\\pi}^{\\pi}f(\\omega) e^{i\\omega k}d\\omega\\]\n만약에 \\(\\gamma_k\\)가 absolutely summable 하지 않으면 \\(f(\\omega)\\)의 존재성을 장담할 수 없다. 따라서 위와 같은 표현은 불가능하다. 대신 아래와 같이 Fourier-Stieltjes integral 의 형으로는 표현가능하다.\n\\[\\gamma_k = \\int_{-\\pi}^{\\pi}e^{i\\omega k}dF(\\omega)\\]\n여기에서 \\(F(\\omega)\\)는 spectral distribution function 이라고 한다. \\(F(\\omega)\\)는 nondecreasing function 이다. \\(F(\\omega)\\)는 아래와 같은 3가지 컴포넌트의 합으로 표현할 수 있다.\n\n유한개의 jump만을 가지는 step function\nabsolutely continuous function\nsigular function\n\n여기에서 3은 대부분의 응용분야에서 중요하지 않으므로 결국 \\(F(\\omega)\\)는 아래와 같이 표현할 수 있다.\n\\[F(\\omega) \\approx F_s(\\omega) + F_c(\\omega)\\]\n여기에서 \\(F_s(\\omega)\\)는 유한개의 jump를 가지는 step function 이고 \\(F_c(\\omega)\\)는 absolutely continuous 한 함수이다.\n만약에 시계열이 absolutely summable 하다면 \\(F(\\omega) = F_c(\\omega)\\) 이며 이경우에는 \\(dF(\\omega) = f(\\omega)d\\omega\\) 로 표현할 수 있다.\n여기에서 step spectral distribution function에 대하여 설명하기 위하여 아래와 같은 모형2를 고려하자.\n\\[Z_t = \\sum_{i=1}^{M}A_i \\sin(\\omega_i t + \\Theta_i)\\]\n여기에서 \\(A_i\\)는 constant 이며 \\(\\Theta_i \\sim U(-\\pi,\\pi)\\) 이다.\n여기에서 \\(Z_t\\)는 stationary process 이다.\n일반적으로 stationary process는 아래와 같이 표현할 수 있다.\n\\[Z_t = A \\sin\\left(\\frac{2\\pi t}{12}+\\lambda \\right)+\\left[\\frac{\\theta(B)}{\\phi(B)}\\right]a_t\\]\n여기에서 \\(A\\)는 상수이며 \\(\\lambda\\)는 uniform \\([-\\pi,\\pi]\\)을 따르는 랜덤변수이다.\nWold (1938)는 임의의 covariance stationary process 는 아래와 같이 표현 할 수 있다는 것을 알아냈다.\n\\[Z_t = Z_t^{(d)} + Z_t^{(n)}\\]\n여기에서 \\(Z_t^{(d)}\\)는 purely deterministic component 이고 \\(Z_t^{(n)}\\)는 purely nondeterministic component 이다.\n이 분해는 아래의 수식에서 다룬 바 있던 spectral distribution function 의 decomposition 과 유사하다.\n\\[F(\\omega) \\approx F_s(\\omega) + F_c(\\omega)\\]\n왜냐하면 \\(Z_t^{(d)}\\)는 step spectral distribution 을 가지고 \\(Z_t^{(n)}\\)은 absolutely continuous spectral distribution 을 가진다. 따라서 \\(Z_t^{(d)}\\)를\n\n\n\n\n\nReferences\n\nWei, William WS. 2006. “Time Series Analysis: Univariate and Multivariate.” Methods. Boston, MA: Pearson Addison Wesley.\n\nFootnotes\n\n\n\\(\\sum_{k=-\\infty}^{\\infty}|\\gamma_k| <\\infty\\) 이라는 의미↩︎\ngeneral linear cyclical model 이라고 하는듯↩︎"
  },
  {
    "objectID": "posts/1_Essays/2023-01-11-여러가지 부등식.html",
    "href": "posts/1_Essays/2023-01-11-여러가지 부등식.html",
    "title": "[Essays] 여러가지 부등식",
    "section": "",
    "text": "여러가지 부등식 I\n\n(베르누이 부등식) \\(\\forall n \\in N, h>-1 \\Rightarrow (1+h)^n \\geq 1+nh\\)"
  },
  {
    "objectID": "posts/1_Essays/2023-01-20-추정.html",
    "href": "posts/1_Essays/2023-01-20-추정.html",
    "title": "[Essays] 추정",
    "section": "",
    "text": "using Distributions, Plots"
  },
  {
    "objectID": "posts/1_Essays/2023-01-20-추정.html#mle의-일치성에-대한-구체적인-논의",
    "href": "posts/1_Essays/2023-01-20-추정.html#mle의-일치성에-대한-구체적인-논의",
    "title": "[Essays] 추정",
    "section": "MLE의 일치성에 대한 구체적인 논의",
    "text": "MLE의 일치성에 대한 구체적인 논의\n\\(X_1,\\dots,X_{10} \\overset{i.i.d.}{\\sim} Ber(\\theta)\\) 이라고 하자.\n\nx = rand(Bernoulli(0.3),10)\nx\n\n10-element Vector{Bool}:\n 0\n 0\n 1\n 1\n 1\n 1\n 0\n 0\n 0\n 0\n\n\n여기에서 \\(\\theta\\)는 추정해야할 미지의 모수이지만 우리는 시뮬레이션의 편의상 \\(\\theta\\)의 참값을 \\(\\theta_0=\\frac{1}{3}\\)로 알고 있다고 하자. MLE를 논의함에 있어 핵심적인 역할을 하는 것은 \\(Y_1=\\log f(X_1;\\theta)\\)이다. 아래는 \\(Y_1\\)에 대한 몇가지 코멘트이다.\n(1) \\(Y_1\\)은 \\(X_1\\)와 \\(\\theta\\)의 함수이다.\n\n우선 \\(X_1\\)의 함수이므로 \\(Y_1\\)역시 확률변수이다. 따라서 \\(Y_1\\)에 대하여 평균등을 취할 수 있으며 LLN을 쓸 수 있다.\n\\(Y_1\\)은 \\(\\theta\\)에 대한 함수이므로 \\(\\theta\\)에 대하여 미분할 수 있다.\n\n(베르누이 예제)\n우리의 베르누이 예제에서 \\(Y_1\\)은 아래와 같이 계산된다.\n\\[Y_1 = \\log f(X_1;\\theta)= X_1 \\log \\theta + (1-X_1)\\log(1-\\theta)\\]\n보는 것 처럼 \\(Y_1\\)은 \\(X_1\\)와 \\(\\theta\\)의 함수임\n(2) \\(\\mathbb{E}_{\\theta_0}(Y_1)\\)은 \\(\\theta\\) 만의 함수이다. 적당한 조건4이 만족된다면 \\(\\mathbb{E}_{\\theta_0}(Y_1)\\)은 \\(\\theta_0\\) 에서 최대화 된다.\n(베르누이 예제)\n\\(\\mathbb{E}_{\\theta_0}(Y_1) = \\mathbb{E}_{\\theta_0}(X_1)\\log\\theta + (1-\\mathbb{E}_{\\theta_0}(X_1))\\log(1-\\theta) = \\frac{1}{3} \\log\\theta + (1-\\frac{1}{3})\\log(1-\\theta)\\)\n\n일반적인 상황에서는 참모수를 모르지만 우리는 시뮬레이션을 \\(\\theta=1/3\\)에서 하였으므로 참모수 \\(\\theta_0=\\mathbb{E}_{\\theta_0}(X_1)=\\frac{1}{3}\\)을 알고 있다고 가정한다.\n\n\nplot(θ -> (1/3)*log(θ) + (1-1/3)*log(1-θ)) \n\n\n\n\n보는것처럼 이 함수 \\(\\mathbb{E}_{\\theta_0}(Y_1)\\)은 \\(\\theta=\\theta_0=\\frac{1}{3}\\) 에서 최대값을 가진다.\n(3) \\(\\frac{\\partial}{\\partial \\theta}Y_1\\) 역시 \\(X_1\\)와 \\(\\theta\\)의 함수이다.\n\n따라서 \\(\\frac{\\partial}{\\partial \\theta}Y_1\\) 역시 확률변수이고 \\(\\frac{\\partial}{\\partial \\theta}Y_1\\)에 대하여 평균등을 취할 수 있으며 LLN을 쓸 수 있다.\n\n(베르누이 예제)\n\\(\\frac{\\partial}{\\partial\\theta}Y_1 = X_1\\frac{1}{\\theta} + (1-X_1)\\frac{-1}{1-\\theta}\\)\n(4) \\(\\mathbb{E}_{\\theta}[\\frac{\\partial}{\\partial \\theta}Y_1]=0\\) 이다.\n(베르누이 예제)\n\\(\\mathbb{E}_{\\theta}[\\frac{\\partial}{\\partial\\theta}Y_1] = \\theta\\frac{1}{\\theta} + (1-\\theta)\\frac{-1}{1-\\theta}=0\\)\n(5) \\(\\mathbb{V}_{\\theta}[\\frac{\\partial}{\\partial\\theta}Y_1]=\\mathbb{E}_{\\theta}[-\\frac{\\partial^2}{\\partial \\theta^2}Y_1]=I(\\theta)\\)\n(베르누이 예제)\n\\(\\mathbb{V}_{\\theta}\\big[\\frac{\\partial}{\\partial\\theta}Y_1\\big]=\\mathbb{E}_{\\theta}\\big[(\\frac{\\partial}{\\partial\\theta}Y_1)^2\\big]=\\mathbb{E}_{\\theta}\\big[-\\frac{\\partial^2}{\\partial\\theta^2}Y_1\\big]=\\frac{1}{\\theta(1-\\theta)}\\)\n\n두번째 등호는 \\(\\mathbb{E}_{\\theta}[\\frac{\\partial}{\\partial\\theta}Y_1]=0\\)을 이용하여 증명가능하다.\n언뜻 보면 \\(\\mathbb{V}_{\\theta}\\big[\\frac{\\partial}{\\partial\\theta}Y_1\\big]\\)를 계산하는 것이 \\(\\mathbb{E}_{\\theta}\\big[-\\frac{\\partial^2}{\\partial\\theta^2}Y_1\\big]\\)를 계산하는것보다 훨씬 쉬워보인다. 그런데 \\(X_1\\)와 \\(1-X_1\\)이 독립이 아니라서 \\(\\mathbb{V}(X+Y)=\\mathbb{V}(X)+\\mathbb{V}(V)+2\\text{Cov}(X,Y)\\)와 같이 공분산 term을 계산해야 하므로 계산이 까다롭다.\n\n\n베르누이에 대한 피셔정보량은 https://en.wikipedia.org/wiki/Fisher_information 에서 확인할 수 있음"
  },
  {
    "objectID": "posts/1_Essays/2023-05-13-적분의 Notations.html",
    "href": "posts/1_Essays/2023-05-13-적분의 Notations.html",
    "title": "[Essays] 적분의 Notations",
    "section": "",
    "text": "참고문헌\nref: https://ncatlab.org/nlab/show/measure+space\n\n\n적분\n- 적분에 대한 원래의 기호는 아래와 같다.\n\\[\\int_a^b f(x)dx\\]\n- 현대의 측도론\n\\[\\int_{x \\in [a,b]} f(x)m(dx)\\]\n여기에서 \\(m\\)은 르벡메져이다. 더미변수 \\(x\\)를 제외한다면 아래와 같이 표현가능하다.\n\\[\\int_{[a,b]} f m\\]\n그런데 보통 아래와 같이 표현하기도 한다.\n\\[\\int_{[a,b]} f dm\\]\n여기에서 \\(d\\)는 with respect to 로 읽으면된다. 그런데 그 뜻은 다르다.\n\\[\\int_{x\\in [a,b]} f(x) dm(x)\\]\n여기에서 \\(dm\\)을 그자체의 메져로 해석할 수도 있음. \\(dm(A)=m(A)\\) 를 만족."
  },
  {
    "objectID": "posts/1_Essays/2022-01-12-토폴로지(1).html",
    "href": "posts/1_Essays/2022-01-12-토폴로지(1).html",
    "title": "[Essays] 토폴로지(1)",
    "section": "",
    "text": "About this doc\n- 수학공부\n- 학부수준\n- 이 문서는 논문을 읽을때 등장하는 topology 용어들을 좀더 명확하게 이해하고 싶어서 작성하였다. 가볍게 정의만 훑어보는 것이라 깊게 들어가지는 않을 예정이다. 교재는 Schaum’s General Topology 를 참고하였다. - Lipschutz, S. (1965). Schaum’s outline of theory and problems of general topology. Schaum’s Outline Series.\n- 여기에서는 토폴로지의 정의와 메트릭스페이스의 정의 그리고 컴플리션의 정의에 대하여 다룬다.\n\n\n토폴로지\n- \\({\\cal T}\\) 가 \\(X\\) 의 subset 으로 이루어진 collection 이라고 하자. \\({\\cal T}\\) 가 \\(X\\) 를 포함하며 uncountable union 에 닫혀있고 finite intersection 에 닫혀있다면 \\({\\cal T}\\) 를 \\(X\\) 의 topology 라고 한다. 그리고 \\((X,{\\cal T})\\) 를 topological space 라고 한다.\n- \\({\\cal T}\\) 가 \\(X\\)의 토플로지일때 \\({\\cal T}\\) 의 원소를 \\({\\cal T}\\)-open set 이라고 한다. 따라서 원래 오픈셋은 마치 확률변수처럼 단독으로 정의할 수 없고 어떠한 토폴로지 \\({\\cal T}\\)와 같이 정의된다.\n- 아래와 같은 collection 을 생각하자.\n\\[{\\cal O}:=\\{O: O=\\cup_i(a_i,b_i), a_i,b_i \\in \\mathbb{R} \\} \\]\n컬렉션 \\({\\cal O}\\) 는 \\(\\mathbb{R}\\) 의 토폴로지가 된다. (증명은 알아서..) 이러한 토폴로지(=오픈인터벌의 카운터블-유니온으로 표현가능한 집합들의 모임)을 특별히 usual topology 라고 한다. 그리고 이 토폴로지의 원소를 \\({\\cal O}\\)-오픈셋이라고 부른다. 따라서 어떤 집합 \\(O\\) 가 \\({\\cal O}\\)-오픈셋 이라는 말은 그 집합이 오픈인터벌의 카운터블-유니온으로 표현가능한 집합임을 의미한다.\n- 참고로 \\({\\cal O}\\) 가 우리가 일반적으로 생각하는 ‘오픈셋들의 모임’ 이고 \\({\\cal O}\\)-오픈셋이 보통 우리가 일반적으로 유클리드 공간에서 상상하는 오픈셋이다. 그래서 앞으로 특별한 언급없이 그냥 ‘오픈셋’ 이라고 부르면 토폴로지 \\((\\mathbb{R},{\\cal O})\\) 에서 정의가능한 ‘\\({\\cal O}\\)-오픈셋’ 을 의미하는 것이라고 생각하면 된다.\n- 즉 우리가 일반적으로 생각하는 오픈셋1은 오픈인터벌 \\((a,b)\\) 의 countable-many union 으로 표현가능한 집합이라고 이해해도 된다.\n- 오픈셋 \\(O\\)의 원소를 interior point of \\(O\\) 라고 한다. \\({\\cal O}\\)의 정의에 의해서 인테리어포인트는 모두 아래의 성질을 만족한다.\n\\[\\forall o \\in O ~ \\exists a,b \\in \\mathbb{R}~ st.~  o \\in (a,b)\\]\n증명은 귀류법을 쓰면 쉽게 된다.\n- 저 정리가 생각보다 중요하다. 그리고 이 정리를 나이테정리 라고 기억하자. 이 정리는 \\({\\cal O}\\)-오픈셋이 아닌 일반적인 \\({\\cal T}\\)-오픈셋에 대하여서도 성립한다. 즉 \\((X,{\\cal T})\\)가 위상공간이고 \\(T\\)가 \\({\\cal T}\\)의 임의의 집합이라 하자. \\(T\\)의 임의의 원소 \\(p\\)에 대하여 (1) \\(p\\) 를 포함하지만 (2) \\(T\\) 보다 작은 다른 \\({\\cal T}\\)-오픈셋이 항상 존재한다.\n- 그리고 교재에 따라서는 위와 같은 성질을 만족하는 것을 오픈셋이라고 정의하기도 한다. 이와 같은 논리흐름으로는 오픈인터벌 \\((a,b)\\)를 정의하고 그로부터 인테리어포인트 \\(o\\)와 오픈셋 \\(O\\)를 정의하고 그로부터 토폴로지 \\({\\cal O}\\)를 정의할 수 있다. 하지만 이러한 방식의 contruction 으로는 \\((\\mathbb{R},{\\cal O})\\) 만 만들수있다. 일반적으로는 적당한 \\({\\cal T}\\)가 \\(X\\)의 토폴로지임을 밝히고 그로부터 오픈셋을 정의하고 그 다음 인테리어포인트를 정의하는 식으로 각 요소들을 contruction 한다.\n- 오픈셋의 여집합을 클로즈드셋이라고 한다. 여기서 사람들이 “모든 집합은 오픈셋이거나 클로즈드셋 이어야 한다” 라고 착각하기 쉬운데 사실 그런것은 아니다.\n- 어떠한 construction을 사용하든지 아래의 사실들이 성립한다. 따로 설명을 쓰지 않은 것은 아주 약간의 머리를 쓰면 쉽게 증명할 수 있는 것들이다. (하지만 그냥 받아들이거나 외우는 것이 편하다.) 참고로 아래의 모든 사실들은 보통위상공간 즉 \\((\\mathbb{R},{\\cal O})\\) 를 전제하고 서술한 것이다.\n(1) \\((a,b)\\) 는 오픈셋이다.\n(2) \\(\\mathbb{R}\\) 은 오픈셋이다. 동시에 클로즈드셋이다2.\n(3) \\(\\emptyset\\) 은 오픈셋이다. 동시에 클로즈드셋이다3.\n(4) 오픈셋은 uncountable union 에 닫혀있다. 즉 \\(O_t\\)가 각각 오픈셋일때 \\(\\cup_t O_t\\) 역시 오픈셋이다.\n(5) 오픈셋은 finite intersection 에 닫혀있다. 즉 \\(O_i\\)가 각각 오픈셋이면 \\(\\cap_{i=1}^{n} O_i\\) 역시 오픈셋이다\n(6) 한점 \\(p\\)로 이루어진 집합 \\(\\{p\\}\\)는 오픈셋이 아니다. 이것이 오픈셋이 되려면 \\(\\{p\\}\\)의 모든원소(라고 해봤자 \\(p\\) 밖에 없음)가 내점이어야 하고 \\(p\\)가 \\(\\{p\\}\\)의 내점이려면 \\(p\\)를 포함하는 오픈인터벌 \\((a,b)\\)가 \\(\\{p\\}\\)의 부분집합으로 존재해야하는데 이것이 불가능하기 때문이다. 4\n(7) 오픈셋의 countable-many intersection 은 오픈셋이 아니다. 왜냐하면 \\(\\cap_{n=1}^{\\infty}(-1/n,1/n)=\\{0\\}\\) 인데 \\(\\{0\\}\\)은 오픈셋이 아니기 때문이다.\n\n\n기저\n- 오픈인터벌 \\((a,b)\\)를 적당히 countable-many union 하면 \\(\\mathbb{R}\\) 에 존재하는 어떠한 오픈셋 \\(O\\)도 표현할 수 있다. 이럴때 \\((a,b)\\) 모아놓은 collection \\({\\cal B}:=\\{(a,b): a<b \\in \\mathbb{R}\\}\\) 를 토폴로지 \\({\\cal O}\\)의 base 라고 한다. 이처럼 어떠한 위상공간 \\((X,{\\cal T})\\) 가 있을때 토폴로지 \\({\\cal T}\\) 의 임의의 집합을 \\({\\cal B}\\)의 원소들의 uncountable union 으로 표현가능때 \\({\\cal B}\\)를 \\({\\cal T}\\)의 base 라고 한다. 그리고 추가적으로 base의 모든 원소는 \\({\\cal T}\\)-오픈셋이어야 한다는 조건도 포함된다.\n- 토폴로지 \\({\\cal T}\\)의 base는 유일하지 않다.\n- 아래와 같은 collection을 상상하여 보자.\n\\[\\tilde{\\cal B}:=\\{all~ ray~ in~\\mathbb{R} \\} := \\{(-\\infty,b): b\\in \\mathbb{R} \\} \\cup \\{(a,\\infty): a \\in \\mathbb{R}\\}\\]\n보는 것처럼 \\(\\tilde{\\cal B}\\)는 위상의 정의를 만족한다. 그리고 \\(\\tilde{\\cal B}\\)는 \\({\\cal O}\\)의 base가 아니다. 하지만 \\(\\pi(\\tilde{\\cal B})\\) 는 \\((a,b)\\)를 포함하고 있기에 \\({\\cal O}\\) 의 base가 된다. 여기에서 \\(\\pi(\\tilde{\\cal B})\\) 는 \\(\\tilde{\\cal B}\\) 에 의해서 생성된 가장 작은 \\(\\pi\\)-system 이다.\n- 참고로 \\(\\pi\\)-시스템은 모든 원소가 finite intersection 에 닫혀있는 collection 을 의미한다. 전체집합은 empty intersection 으로 해석할 수 있으므로 모든 파이시스템은 전체집합을 포함한다. 따라서 파이시스템을 정의하면 전체집합을 같이 정의하는것과 마찬가지이다. 따라서 파이시스템 역시 시그마필드와 토폴로지처럼 전체집합과 동시에 정의된다. 그리고 정의에 따라서 임의의 집합에 대한 토폴로지와 시그마필드 모두 파이시스템이 된다.\n- 위에서 예를 든 \\(\\tilde{\\cal B}\\) 와 같이 그것 자체가 어떤 위상 \\({\\cal T}\\) 의 base는 아니지만 \\(\\pi(\\tilde{\\cal B})\\) 는 \\({\\cal T}\\) 의 base가 될때 \\(\\tilde{\\cal B}\\)를 \\({\\cal T}\\)의 subbase 라고 한다.\n- \\(\\tilde{\\cal B}\\) 가 토폴로지 \\({\\cal T}\\)의 subbase이면 \\(\\tilde{\\cal B}\\)로 \\({\\cal T}\\)를 generate 할 수 있다.\n\n\nmetric space\n- \\(d:X \\times X \\to \\mathbb{R}\\) 가 (1) 음이 아니고 (2) 대칭이며 (3) 삼각부등식을 만족하면 집합 \\(X\\) 에서의 metric 이라고 한다. 이때 음이 아닐 조건은\n\\[\\begin{cases}\nd(a,b) > 0 & a \\neq b \\\\\nd(a,b) = 0 & a=b\n\\end{cases}\\]\n이다. 만약에 메트릭의 모든 조건을 만족하는데 \\(d(a,b)=0\\) 인 서로 다른 \\(a,b \\in X\\) 가 존재하는 경우 \\(d\\) 를 pseudometric 이라고 한다.\n- \\(d\\) 을 집합 \\(X\\) 에서의 메트릭이라고 하자. 메트릭이 존재한다는 것은 집합 \\(X\\)의 어떠한 두 원소라도 그 사이의 거리를 잴 수 있다는 말이고 그것은 집합 \\(X\\)의 임의의 점 \\(p\\)에서 아래와 같은 ball 을 정의할 수 있는 말이다.\n\\[S(p,\\delta) := \\{x:d(p,x)<\\delta,x \\in X \\}\\]\n참고로 위와 같은 ball 들을 모은 collection 을 \\({\\cal B}\\)라고 하자. 그리고 \\({\\cal B}\\)의 임의의 원소를 언카운터블-유니온하여 얻을 수 있는 집합들의 모임을 \\({\\cal T}\\)라고 하자. 그러면 (1) \\({\\cal T}\\) 가 \\(X\\) 의 토폴로지임을 보이고 (2) \\({\\cal B}\\)의 모든 원소가 \\({\\cal T}\\)-오픈셋임을 보인다면 \\({\\cal B}\\)는 \\({\\cal T}\\)의 base가 된다고 주장할 수 있다(Thm 8.4). 그런데 (2)는 (1)이 성립하면 자동으로 성립하므로 (1)만 보이면 된다. 그러기 위해서는 아래의 (i)-(iii)을 보이면 된다.\n(i) 우선 \\({\\cal T}\\)가 언카운터블-유니온에 닫혀있음은 associative laws 에 의해서 쉽게 증명된다.\n(ii) 이제 \\({\\cal T}\\)가 파이나이트-인터섹션에 닫혀있음을 보이자. \\({\\cal T}\\)의 임의의 두 원소는 각각 \\({\\cal B}\\)의 언카운터블-유니온으로 표현가능하다. 가령 예를들어 임의의 \\(T,S \\in {\\cal T}\\) 가 아래와 같이 표현되었다고 치자.\n\\[T=\\bigcup_{t\\in [0,1]}B_{t}, \\quad S=\\bigcup_{s\\in [2,3]}B_{s}\\]\n따라서 \\(T\\cap S\\) 는 distributive laws 에 의해서 아래와 같이 표현가능하다.\n\\[T \\cap S = \\bigcup_{(t,s) \\in [0,1]\\times[2,3]} B_t \\cap B_s \\]\n(i)에 의해서 \\(B_t \\cap B_s\\)가 \\({\\cal T}\\)의 원소이기만 하면 \\(T \\cap S\\) 역시 \\({\\cal T}\\)의 원소가 되는 구조라 (ii)가 증명된다. 따라서 이제 우리가 할일은 \\(B_t\\cap B_s\\)가 \\({\\cal T}\\)의 원소임을 보이는 것이고 이것은 \\(B_t \\cap B_s\\)가 \\({\\cal B}\\)의 언카운터블-유니온으로 표현가능하다는 조건과 동치이다. 우선 \\(B_t \\cap B_s\\)에 속하는 임의의 원소를 $b^* $ 라고 하자. 이 점에 대하여 나이테정리를 만족시키는 ball이 존재한다. 즉\n\\[\\exists S(b^* ,\\delta)~ st. ~ S(b^* ,\\delta) \\subset B_t \\cap B_s\\]\n이다(Lemma 8.3). 그런데 \\(B_t \\cap B_s\\)의 모든점에서 이런식으로 나이테정리를 만족하는 ball을 잡을 수 있다. 이러한 ball들의 합집합을\n\\[\\bigcup_{b^* \\in (B_t \\cap B_s)} S(b^* , \\delta)\\]\n이라고 하자. 자명하게 이 집합은 \\(B_t\\cap B_s\\) 보다 작다(부분집합들의 합이므로). 하지만 \\(B_t\\cap B_s\\)의 모든 원소는 이 집합에 포함되므로 이 집합은 \\(B_t\\cap B_s\\)보다 크다. 따라서\n\\[\\bigcup_{b^* \\in (B_t \\cap B_s)} S(b^* , \\delta)=B_t \\cap B_s\\]\n이 성립한다.\n(iii) \\({\\cal T}\\)가 \\(X\\)를 포함한다는 것을 보이는것은 볼의 반지름을 크게 만들면 쉽게 증명할 수 있다.\n- 참고로 위의 (i)-(iii)을 요약하면 (1) \\(X\\)가 \\({\\cal B}\\)의 언카운터블 유니온으로 표현가능하고 (2) \\({\\cal B}\\)의 임의의 두 원소가 \\({\\cal B}\\)의 언카운터블 유니온으로 표현가능하기만 하면 볼들이 집합이 아니라 어떠한 \\({\\cal B}\\)라도 특정 토폴로지의 base라고 주장할 수 있다. 이것이 교재의 Thm 6.1 이다.\n- 아무튼 위의 과정을 거치면 \\(X\\)위에서 거리를 정의할 수 있을때 그 거리에 의해서 ball을 정의할 수 있고 ball들의 콜렉션을 base \\({\\cal B}\\)로 정의하고 \\({\\cal B}\\) 원소들의 언카운터블-유니온으로 표현가능한 집합모임을 토폴로지 \\({\\cal T}\\)로 정의해도 논리적모순점이 없다. 즉 \\(X\\)에서 메트릭이 정의되기만 하면 그것에 의해서 순차적으로 토폴로지 \\({\\cal T}\\)를 자연스럽게 유도할 수 있는데 이러한 토폴로지를 특별히 \\(X\\)와 \\(d\\)에 의해서 유도된 metric topology 라고 한다. 그리고 \\((X,d)\\)를 metric-space 라고 한다.\n- \\(\\mathbb{R}\\)에서 \\({\\cal O}\\)를 유도하는 메트릭은 우리가 보통 생각하는 유클리드거리이다. 이러한 메트릭을 usual metric 이라고 한다.\n- \\(\\mathbb{R}\\)에서 아래와 같은 거리를 정의할 수 있다.\n\\[d(a,b)=\\begin{cases}\n0 & a=b \\\\\n1 & a\\neq b\n\\end{cases}\\]\n이러한 거리를 trivial metric 이라고 한다. 그리고 이 거리가 유도하는 토폴로지는 \\(2^{\\mathbb{R}}\\) 이다. (아 몰라.. 따지기 싫어.. 그냥 외워..)\n- 만약에 집합 \\(X\\)에서 정의된 2개의 메트릭 \\(d_1\\), \\(d_2\\)가 같은 토폴로지를 유도한다면 두 메트릭 \\(d_1\\)과 \\(d_2\\)는 equivalent 하다고 말한다.\n- 토폴로지컬-스페이스 \\((X,{\\cal T})\\) 가 있다고 하자. 그런데 \\(X\\) 에서 어떠한 메트릭 \\(d\\)가 존재해 그것이 \\({\\cal T}\\)를 유도하였다고 하자. 그럼 \\({\\cal T}\\)는 메트릭-토폴로지가 된다. 이와 같이 (1) \\(X\\)에서 정의되고 (2) 메트릭-토폴로지 \\({\\cal T}\\)를 유도하는 적당한 메트릭 \\(d\\)가 명시된것은 아니지만 그런 메트릭의 존재를 하나 이상 우리가 알고 있을때 위상공간 \\((X,{\\cal T})\\)를 metrizable 하다고 한다.\n- 두 메트릭스페이스 \\((X,d_1)\\) 와 \\((Y,d_2)\\) 가 isometric 하다는 것은 아래가 만족하는 one-one, onto 인 \\(f:X \\to Y\\) 가 존재한다는 것이다.\n\\[d_1(p,q) = d_2(f(p),f(q))\\]\n- 이때 isometric 이라는 relation 은 보는것 처럼 모든 메트릭공간들의 집합 \\({\\cal M}\\)에서 equivalence relation 이다. 즉 아래가 성립한다.\n(i) \\((X,d_1) \\overset{ism}{\\sim} (X,d_1)\\),\n(ii) \\((X,d_1) \\overset{ism}{\\sim} (Y,d_2)\\) implies \\((Y,d_2) \\overset{ism}{\\sim} (X,d_1)\\),\n(iii) \\((X,d_1) \\overset{ism}{\\sim} (Y,d_2)\\) and \\((Y,d_2) \\overset{ism}{\\sim} (Z,d_3)\\) imply \\((X,d_1) \\overset{ism}{\\sim} (Z,d_3)\\).\n\n\ncomplete metric space\n- convergent sequence 은 단독으로 정의될 수 없으며 위상공간 \\((X,{\\cal T})\\) 와 묶어서 정의된다. 그리고 Cauchy sequence 역시 단독으로 정의될 수 없으며 메트릭스페이스 \\((X,d)\\) 와 묶어서 정의된다.\n- convergent sequence 와 Cauchy sequence 는 비슷해보이지만 미묘하게 다른점이 있다.\n(1) 컨버전트-시컨트는 위상공간 \\((X,{\\cal T})\\) 만 있으면 정의할 수 있지만 코시수열은 그 위상공간이 메트릭스페이스 이어야 한다는 제약이 있다. 왜냐하면 컨버전트-시컨스의 정의에는 오픈셋만 필요하지만 코시수열은 볼이 필요하고 볼은 메트릭에 의해서만 정의되기 때문이다.\n(2) 컨버전트-시컨스와 코시수열 모두 열의 각 항이 \\(X\\)의 원소이어야 한다는 조건이 있다. 하지만 컨버전트-시컨스는 그 limit 까지 \\(X\\)의 원소이어야 하는데 코시수열은 그렇지 않다는 차이점이 있다.\n- \\(X=(0,1)\\) 위의 usual metric 에 의해서 유도되는 메트릭스페이스 \\((X,d)\\) 를 생각하자. 수열\n\\[\\big\\{\\frac{1}{2},\\frac{1}{3},\\frac{1}{4},\\dots,\\big\\}\\]\n\\(X\\)에서 정의된 코시수열이지만 \\(X\\)에서 정의되는 컨버전트-시컨스는 아니다.\n- 내가 이해한 바는 아래와 같다.\n(1) 토폴로지 \\((X,{\\cal T})\\) 는 항상 컨버전트-시컨스를 준비가 되어있는 공간이다.\n(2) 위에서 정의가능한 컨버전트-시컨스는 코시수열과 아무런 관련이 없다. 그리고 우리가 통상적으로 고등학교때부터 다루어왔던 수열의 수렴의 개념과도 거리가 멀다.\n(3) 토폴로지 \\((X,{\\cal T})\\) 가 메트릭스페이스라면 컨버전트-시컨스는 코시수열과 어떤관계가 있으며 고등학교때부터 내가 다루어 왔던 상식적인 수렴하는 수열의 개념과도 관련이 있다.\n(4) \\((X,{\\cal T})\\) 가 메트릭스페이스 라고 가정하자. 그럼 아래가 만족한다고 생각할 수 있다.\n\n\\(\\{a_n\\}\\) converges on \\(X\\) \\(\\Longleftrightarrow\\) \\(\\{a_b\\}\\) is Cauchy sequence on \\(X\\) and \\(\\lim_{n\\to\\infty} a_n \\in X\\)\n\n즉 러프하게 말해서 \\(X\\)에서의 컨버전트-시컨스는 (i) \\(X\\)에서의 코시수열이면서 (ii) limit 이 \\(X\\)에 포함되는 수열이라고 말할 수 있다. 이런 정의로 치면 우리가 고등학교때부터 생각해왔던 소박한 정의의 수렴하는 수열은 사실 코시수열에 가깝고 컨버전트-시컨스는 고등학교때부터 배운 소박한 수렴을 하며 동시에 수렴값이 \\(X\\)이 잘 정의되는 수열을 의미한다고 볼 수 있다. 앞으로는 소박한 수렴과 컨버전트-시컨스를 엄밀하게 구분하여 말하도록 하자. 즉 \\(\\{a_n\\}\\)이 코시수열이라는 말은 \\(\\{a_n\\}\\)이 소박한 수렴을 한다는 의미이고 \\(\\{a_n\\}\\)이 컨버전트-시컨스라는 의미는 \\(\\{a_n\\}\\)이 소박한수렴을 하며 동시에 그 극한값이 well-define 된다는 의미(=\\(\\{a_n\\}\\)의 수렴값이 \\(X\\)의 원소라는 의미)이다.\n- (proposition 14.1) 메트릭스페이스 한정으로, 컨버전트-시컨스는 모두 코시수열이다. (당연한 소리를.. 이런걸 proposition 이라고..)\n- 당연히 위 정리의 역은 성립하지 않는다. 즉 메트릭스페이스 \\((X,{\\cal T})\\) 에서 정의된 코시수열이 반드시 컨버전트-시컨스라는 보장은 없다. (이것도 당연한 소리.. 왜냐하면 수렴값이 \\(X\\)에 포함된다는 보장이 없기 때문) 하지만 그 메트릭스페이스가 complete 하다면 위 정리의 역도 성립한다.\n- 컴플리트하지 않은 메트릭스페이스 \\((X,d)\\)를 컴플리트한 메트릭스페이스 \\((X^* , d)\\) 로 바꿀 수 없을까? 유주얼메트릭(usual metric) \\(d\\) 와 \\(X=(0,1)\\) 로 만들어지는 메트릭스페이스는 컴플리트하지 않지만 \\(d\\) 와 \\(X^* =[0,1]\\) 로 만들어지는 메트릭스페이스는 컴플리트하다. 이런 경우 $(X^* ,d) $ 는 \\((X,d)\\) 의 completion 이라고 한다.\n- 즉 아래의 조건들을 만족하면 $(X^* ,d) $ 는 \\((X,d)\\) 의 completion 이라고 부른다.\n(1) \\(X\\subset X^*\\)\n(2) \\((X^* ,d)\\) is complete metric space\n(3) \\((X,d) \\overset{ism}{\\sim} (X^* ,d)\\).\n- 메트릭스페이스 \\((X,d)\\)에서 아래의 식을 만족하는 두 코시수열 \\(\\{a_n\\}\\), \\(\\{\\tilde a_n\\}\\) 을 생각하여보자.\n\\[\\lim_{n\\to\\infty} d(a_n,\\tilde a_n)=0 \\]\n이러한 코시수열들을\n\\[\\{a_n\\} \\overset{slim}{\\sim} \\{\\tilde a_n\\}\\]\n이라고 표현하자. 이때 관계 \\(\\overset{slim}{\\sim}\\) 은 \\(X\\)에서 정의가능한 모든 코시수열들의 집합 \\({\\cal C}_ X\\) 에서 equivalence relation 이 된다고 한다. (증명은 알아서) 따라서 이걸 이용하면 거리공간에서 \\(slim\\) 의 관계를 가지는 임의의 두 수열은 같은 극한을 가진다는 결론이 나온다. (이것도 잘 따져보자.)\n- 잠시 (1) 바이너리-릴레이션(binary relation), (2) 이퀴배런스-릴레이션(equivalence relation), (3) 이퀴배런스-클래스(equivalence class) 그리고 (4) 코션트셋(quotient set)에 대하여 설명하고 넘어가겠다.\n(1) 집합 \\({\\cal C}_ X\\) 의 두 원소 \\(\\{a_n\\}\\), \\(\\{b_n\\}\\) 간 바이너리-릴레이션 \\(R\\)이 존재한다는 문장은 집합론적인 언어로 표현가능하다. 구체적으로는 \\(R\\)을 곱집합 \\({\\cal C}_ X \\times {\\cal C}_ X\\) 의 적당한 부분집합으로 설정하고 순서쌍 \\(\\big(\\{a_n\\},\\{b_n\\}\\big)\\) 이 \\(R\\) 의 원소라는 식으로 표현한다. 예를 들면 아래와 같은 식으로 말이다.\n$ {a_n} and {b_n} has arelation with~ R \\ ({a_n},{b_n}) R _ X _ X \\ {a_n} {b_n}$\n(2) 그리고 \\({\\cal C}_ X\\) 위에서의 바이너리-릴레이션 \\(R\\)이 (i) reflexivity (ii) symmetricity (iii) transitivity 를 만족하면 이 릴레이션을 특별히 이퀴배런스-릴레이션 이라고 말한다.\n(3) 그리고 아래와 같이 \\({\\cal C}_ X\\) 에서 \\(\\{a_n\\}\\) 과 이퀴배런스-릴레이션을 가지는 원소들을 모아놓은 집합을 생각할 수 있다. \\[\\big[\\{a_n\\}\\big]_ R:=\\big\\{ \\{x_n\\} : \\{x_n\\} \\overset{R}{\\sim} \\{a_n\\} ~and~ \\{x_n\\} \\in {\\cal C}_ X \\big\\}\\]\n이 집합을 \\(\\{a_n\\}\\)의 equivalence class on \\({\\cal C}_ X\\) by \\(R\\) 이라고 부른다. 보통은 \\(R\\)을 생략하여 \\(\\big[\\{a_n\\}\\big]\\)와 같이만 표현하지만 나는 기호의 명확성을 위해서 관계까지 명시하였다.\n(4) 이퀴배런스-클래스는 본질적으로 파티션과 밀접한 연관이 있다. 여기에서 클래스 \\({\\cal P}_ A\\) 가 집합 \\(A\\)의 파티션이란 의미는 클래스 \\({\\cal P}_ A\\) 에 속한 모든 원소의 합이 \\(A\\) 이며 클래스 \\({\\cal P}_ A\\) 의 각 원소는 서로 배타적이라는 의미이다. 이퀴배런스-클래스가 그럼 왜 파티션과 관련이 있을까? 그것은 어떠한 집합에서 이퀴배런스-릴레이션이 존재하면 그 집합을 배타적인 이퀴배런스-클래스의 합집합으로 표현가능하기 때문이다. 즉 이퀴배런스-릴레이션 혹은 이퀴배런-클래스의 존재는 파티션의 존재를 임플라이 한다. 그리고 이러한 파티션을 이퀴배런스-릴레이션 \\(R\\)에 의해 생성된 quotient set 혹은 quotient space 라고 한다. 관계 \\(R\\)에 의한 \\(A\\)의 코션트 셋은 기호로 \\(A ~\\overset{R}{\\sim}\\) 와 같이 쓴다. 예를들어 \\[\\begin{align}\n{\\cal C}_ X ~ /\\overset{slim}{\\sim}\n\\end{align}\\] 은 집합 \\(X\\) 상에서 존재하는 코시수열들의 집합 \\({\\cal C}_ X\\) 에서 이퀴배런스-릴레이션 \\(slim\\) 에 의해서 생성된 코션트셋을 의미한다.\n\n\n\n\n\nFootnotes\n\n\n정확하게는 \\(\\cal O\\)-오픈셋↩︎\n공집합이 오픈셋이므로↩︎\n\\(\\mathbb{R}\\)이 오픈셋이므로↩︎\n다만 이것은 위상공간을 \\((\\mathbb{R},{\\cal O})\\)로 생각하였을때 이야기이고 위상공간을 \\((\\mathbb{R},2^{\\mathbb{R}})\\)로 생각한다면 \\(\\{p\\}\\) 도 오픈셋이 된다.↩︎"
  },
  {
    "objectID": "posts/1_Essays/2023-02-09-칸토어집합,칸토어함수,르벡분해.html",
    "href": "posts/1_Essays/2023-02-09-칸토어집합,칸토어함수,르벡분해.html",
    "title": "[Essays] 칸토어 집합, 칸토어 함수, 르벡분해",
    "section": "",
    "text": "아래와 같은 과정으로 얻어지는 집합열 \\(C_0,C_1,\\dots\\) 을 고려하자.\n\n\\(C_0 := [0,1]\\)\n\\(C_n:=\\frac{C_{n-1}}{3} \\cup (\\frac{2}{3} + \\frac{C_{n-1}}{3})\\)\n\n\n이러한 과정은 각 직선의 open middle third를 반복적으로 제거하여 얻어진다. 칸토어 집합 \\({\\cal C}\\)는 위와 같은 집합열의 극한으로 정의한다. 즉\n\\[{\\cal C} = \\lim_{n\\to \\infty} C_n\\]\n칸토어 집합은 아래와 같은 성질이 있다.\n\n[0,1] 사이의 모든 실수를 3진법을 표현한다고 생각하자. \\(C_1\\)은 \\(0.1xxxx\\dots_{(3)}\\)와 같은 숫자가 빠지고, \\(C_2\\)에서는 \\(0.01xxx\\dots_{(3)}\\) 혹은 \\(0.21xxx\\dots_{(3)}\\) 에 대응하는 숫자가 빠지는 과정이 반복적으로 일어난다고 볼 수 있다.\n1의 결과를 잘 생각하면 칸토어 집합에 포함되는 수는 삼진법 소수로 표기했을 때 모든 자리수가 0 또는 2가 된다는 점을 쉽게 눈치챌 수 있다.\n칸토어 집합의 수는 [0,1] 사이의 모든 실수와 일대응대응(전단사)시킬 수 있다.1\n3에 의하여 칸토어 집합은 비가산집합이며, 크기는 \\(2^{\\aleph_0}\\) 이다.\n칸토어 집합을 만드는 과정에서 빠지는 구간의 길이는 \\(1/3, 2/9, 4/27 \\dots\\) 이고 이 길이를 모두 합치면 1이다.\n따라서 칸토어 집합은 르벡측도가 0이다.\n4와6에 의하여 칸토어 집합은 르벡측도가 0인 비가산집합이 된다.\n칸토어집합은 조밀한 곳이 없는 집합이다.\n그 밖에 성질도 있는 듯 하나 이해할 수 없음"
  },
  {
    "objectID": "posts/1_Essays/2023-02-09-칸토어집합,칸토어함수,르벡분해.html#singular",
    "href": "posts/1_Essays/2023-02-09-칸토어집합,칸토어함수,르벡분해.html#singular",
    "title": "[Essays] 칸토어 집합, 칸토어 함수, 르벡분해",
    "section": "Singular",
    "text": "Singular"
  },
  {
    "objectID": "posts/1_Essays/2023-02-09-칸토어집합,칸토어함수,르벡분해.html#state",
    "href": "posts/1_Essays/2023-02-09-칸토어집합,칸토어함수,르벡분해.html#state",
    "title": "[Essays] 칸토어 집합, 칸토어 함수, 르벡분해",
    "section": "State",
    "text": "State\nIn mathematics, more precisely in measure theory, Lebesgue’s decomposition theorem states that for every two \\(\\sigma\\)-finite signed measures \\(\\mu\\) and \\(\\nu\\) on a measurable space \\((\\Omega,\\Sigma)\\) there exist two σ-finite signed measures \\(\\nu_{0}\\) and \\(\\nu_1\\) such that:\n\n\\(\\nu =\\nu _{0}+\\nu _{1}\\),\n\\(\\nu _{0}\\ll \\mu\\) (that is \\(\\nu_{0}\\) is absolutely continuous with respect to \\(\\mu\\))\n\\(\\nu_{1} \\perp \\mu\\) (that is, \\(\\nu_1\\) and \\(\\mu\\) are singular).\n\nThese two measures are uniquely determined by \\(\\mu\\) and \\(\\nu\\)."
  },
  {
    "objectID": "posts/1_Essays/2023-02-09-칸토어집합,칸토어함수,르벡분해.html#refinement",
    "href": "posts/1_Essays/2023-02-09-칸토어집합,칸토어함수,르벡분해.html#refinement",
    "title": "[Essays] 칸토어 집합, 칸토어 함수, 르벡분해",
    "section": "Refinement",
    "text": "Refinement\nLebesgue’s decomposition theorem can be refined in a number of ways.\nFirst, the decomposition of the singular part of a regular Borel measure on the real line can be refined:\n\\[{\\bf \\nu}={\\bf \\nu}_{\\text{cont}}+{\\bf \\nu}_{\\text{sing}}+{\\bf \\nu}_{\\text{pp}}\\]\nwhere\n\n\\({\\bf \\nu}_{\\text{cont}}\\) is the absolutely continuous part\n\\({\\bf \\nu}_{\\text{sing}}\\) is the singular continuous part\n\\({\\bf \\nu}_{\\text{pp}}\\) is the pure point part (a discrete measure)\n\nSecond, absolutely continuous measures are classified by the Radon–Nikodym theorem, and discrete measures are easily understood. Hence (singular continuous measures aside), Lebesgue decomposition gives a very explicit description of measures. The Cantor measure (the probability measure on the real line whose cumulative distribution function is the Cantor function) is an example of a singular continuous measure."
  },
  {
    "objectID": "posts/1_Essays/2023-04-13-마코프체인 인트로.html",
    "href": "posts/1_Essays/2023-04-13-마코프체인 인트로.html",
    "title": "[Essays] 마코프체인 인트로",
    "section": "",
    "text": "import numpy as np\n\n\n확률과정\n- 동전을 무한히 던지는 시행을 생각하자. 동전을 10번 던져서 결과를 관찰했다고 하자. 동전을 30번째 던져서 앞면이 나올지 뒷면이 나올지 알고 싶다면?\n- 현재 삼성전자 주가는 66000이다. 20일뒤의 삼성전자 주가가 얼마일지 알고 싶다면?\n- 원래 미래를 예측하기 위해서 해야하는 과정\n\n\n\n그림1: 1400만개의 미래를 탐색중인 Doctor Strange\n\n\n- 하지만 현실적으로는 이게 너무 힘들지 않을까?\n\n\n날씨예측\n- 아래와 같이 세상의 법칙이 있다고 하자.\n\n어제 맑음 \\(\\to\\) 오늘도 맑음: 40% // 오늘은 비: 60%\n어제 비 \\(\\to\\) 오늘은 맑음: 70% // 오늘도 비 30%\n\n- 모든 \\(t\\)에 대하여 확률변수 \\(X_t\\)를 아래와 같이 정의하자.\n\n\\(X_t=\\begin{cases} 0 & \\text{맑음} \\\\ 1 & \\text{비} \\end{cases}\\)\n\n- 오늘 (2023년4월13일) 비가 왔다고 치자. 10000일 뒤에도 비가 올 확률은 얼마일까?\n\n\n풀이1\n- \\(X_t=0\\) 이면? (어제 비가 안왔으면?)\n\nnp.random.rand() < 0.6\n\nTrue\n\n\n- \\(X_t=1\\) 이면? (어제 비가 왔으면?)\n\nnp.random.rand() < 0.3\n\nFalse\n\n\n- 두 코드를 합치면?\n\ndef rain(before):\n    if before == True: # 비가왔으면 \n        after = (np.random.rand() < 0.3)\n    else: # 비가 안왔으면 \n        after = (np.random.rand() < 0.6) \n    return after \n\n- 테스트\n\nsum([rain(0) for i in range(1000)])\n\n620\n\n\n\nsum([rain(1) for i in range(1000)])\n\n294\n\n\n- 하나의 \\(\\omega\\)에 대응하는 확률과정\n\ndef doctor_strange(today):\n    lst = [today] \n    for i in range(9999): \n        lst.append(rain(lst[i]))\n    return lst \n\n- 4305개의 \\(\\omega\\)에 대응하는 확률과정\n\ntoday = True # 오늘은 비가 왔음 \narr = np.stack([doctor_strange(today) for i in range(4305)])\n\n\narr.shape\n\n(4305, 10000)\n\n\n\narr[:,-1].mean()\n\n0.4429732868757259\n\n\n\narr\n\narray([[ True, False,  True, ..., False, False,  True],\n       [ True, False,  True, ...,  True, False,  True],\n       [ True, False,  True, ..., False, False, False],\n       ...,\n       [ True, False, False, ..., False, False, False],\n       [ True,  True, False, ...,  True, False,  True],\n       [ True,  True, False, ..., False,  True, False]])\n\n\n\n\n풀이2\n- 세상의 법칙\n\n\\(X_{t-1}=0 \\Rightarrow X_{t}\\overset{d}{=} Ber(0.6)\\)\n\\(X_{t-1}=1 \\Rightarrow X_{t}\\overset{d}{=} Ber(0.3)\\)\n\n- 정리하면\n\n\\(P(X_t=0) = P(X_{t-1}=0) \\times 0.4 + P(X_{t-1}=1) \\times 0.7\\)\n\n\\(P(X_t=1) = P(X_{t-1}=0) \\times 0.6 + P(X_{t-1}=1) \\times 0.3\\)\n\n- 매트릭스형태로 바꾸면\n\n\\(\\begin{bmatrix} P(X_t=0)\\\\ P(X_t=1) \\end{bmatrix}= \\begin{bmatrix} 0.4 & 0.7 \\\\ 0.6 & 0.3 \\end{bmatrix} \\begin{bmatrix} P(X_{t-1}=0)\\\\ P(X_{t-1}=1) \\end{bmatrix}\\)\n\\({\\boldsymbol \\mu}_t = {\\bf P} {\\boldsymbol \\mu}_{t-1}\\)\n\n- 이렇게 놓고 보니까 아래를 관찰할 수 있다.\n\n\\({\\boldsymbol \\mu}_2 = {\\bf P}{\\boldsymbol \\mu}_1\\)\n\\({\\boldsymbol \\mu}_3 = {\\bf P}{\\boldsymbol \\mu}_2 = {\\bf P}^2{\\boldsymbol \\mu}_1\\)\n\\(\\dots\\)\n\\({\\boldsymbol \\mu}_n = {\\bf P}^{n-1}{\\boldsymbol \\mu}_1\\)\n\n- \\({\\bf P}^{999}\\)만 계산하면 끝나겠군?\n\nP = np.array([[0.4,0.7],[0.6,0.3]])\nP\n\narray([[0.4, 0.7],\n       [0.6, 0.3]])\n\n\n\nP@P # P의 제곱\n\narray([[0.58, 0.49],\n       [0.42, 0.51]])\n\n\n\nP@P@P@P # P의 4제곱\n\narray([[0.5422, 0.5341],\n       [0.4578, 0.4659]])\n\n\n\nP@P@P@P@P@P@P@P # P의 8제곱\n\narray([[0.53849182, 0.53842621],\n       [0.46150818, 0.46157379]])\n\n\n\nP@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P # P의 16제곱\n\narray([[0.53846154, 0.53846154],\n       [0.46153846, 0.46153846]])\n\n\n근데 \\({\\bf P}\\)가 수렴하는거 같은데?\n\nP@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P # P의 32제곱\n\narray([[0.53846154, 0.53846154],\n       [0.46153846, 0.46153846]])\n\n\n대충 \\({\\bf P}^{9999} \\approx {\\bf P}^{32}\\) 로 두어도 무방할 듯\n\nPlim = P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P\n\n\nμ1 = np.array([[0],[1]])\nμ1\n\narray([[0],\n       [1]])\n\n\n\nPlim @ μ1\n\narray([[0.53846154],\n       [0.46153846]])\n\n\n\n\n풀이3\n- 세상의 법칙\n\n\\(X_{t-1}=0 \\Rightarrow X_{t}\\overset{d}{=} Ber(0.6)\\)\n\\(X_{t-1}=1 \\Rightarrow X_{t}\\overset{d}{=} Ber(0.3)\\)\n\n- 추측: 10000일 뒤에 비가 올 확률이 \\(p\\)라면 9999일 뒤에 비가 올 확률도 \\(p\\)일 것 같다.\n이걸 가정하고 계산해보면\n1 9999일 뒤에 비가 안 올 확률 = \\(1-p\\)\n\n9999일 뒤에 비가 오고 10000일 뒤에 비가 올 확률 = \\(0.6 (1-p)\\)\n9999일 뒤에 비가 오고 10000일 뒤에 비가 안올 올 확률 = \\(0.4 (1-p)\\)\n\n2 9999일 뒤에 비가 올 확률 = \\(p\\)\n\n9999일 뒤에 비가 오고 10000일 뒤에 비가 올 확률 = \\(0.3 p\\)\n9999일 뒤에 비가 오고 10000일 뒤에 비가 안올 올 확률 = \\(0.7 p\\)\n\n따라서 \\(0.6(1-p) + 0.3p = p\\) 이므로,\n\n\\(0.6-0.3p = p\\)\n\\(p=6/13\\)\n\n\n6/13\n\n0.46153846153846156\n\n\n\n\n풀이4\n\nnp.mean(doctor_strange(True))\n\n0.4629"
  },
  {
    "objectID": "posts/1_Essays/2020-03-12-확률,확률변수,시계열,정상성.html",
    "href": "posts/1_Essays/2020-03-12-확률,확률변수,시계열,정상성.html",
    "title": "[Essays] 확률, 확률변수, 시계열, 정상성",
    "section": "",
    "text": "About this doc\n\n확률의 개념을 정의하고 정상성의 의미를 이해한다.\n2020년 1학기 숭실대학교 시계열분석 강의노트\n\n\n\n확률과 르벡측도\n- 이번 강의에서는 확률을 정의하는 방법이 왜 어려운지 설명하겠다.\n(예제1) 동전을 던지면 앞면과 뒷면 중 하나가 나오게 될것이다. 앞면이 나오는 경우를 \\(H\\)라고 하고 뒷면이 나오는 경우를 \\(T\\)라고 하자. 그리고 모든 경우를 모은 집합을 \\(\\Omega\\)와 같이 정의하고, 이것을 sample space라고 부르자. 즉 sample space \\(\\Omega\\)는 아래와 같이 정의한다.\n\\[\\Omega=\\{H,T\\}\\]\n공평한 동전이라면 동전이 앞면이 나올 확률, 뒷면이 나올 확률을 아래와 같이 정의할 수 있다.\n\\[P(\\{H\\})=P(\\{T\\})=\\frac{1}{2}\\]\n(예제2) sample space의 원소수가 유한이 아니라 무한개인 경우도 생각할 수 있다. 예를들어 시계바늘을 돌려서 시계바늘이 가르키는 시간을 sample space로 정의할 수 있다. 다만 시계바늘이 가리키는 시간은 시계바늘이 12시와 이루는 각도와 1:1 관계가 있으므로 \\(\\Omega\\)를 아래와 같이 편리하게 정의할 수 있다.\n\\[\\Omega=[0,2\\pi)\\]\n여기에서 \\(0\\)은 바늘이 12시를 가리키는 사건 \\(\\pi\\)는 6시를 가리키는 사건을 의미한다. 이 경우 sample space의 각 부분집합에 \\(\\Omega^{* }\\) 대한 확률은 아래와 같이 기하학적 확률 (즉 길이의 비율) 로 정의할 수 있다.\n\\[P(\\Omega^* )=\\frac{m(\\Omega^* )}{m(\\Omega)}\\]\n여기에서 \\(m\\)은 구간의 길이를 반환하는 함수이다. (사실 이 함수는 measure이다. 하지만 측도론(혹은 실변수함수론이라고도 불림)을 배우지 않았다면 단순히 길이를 반환하는 함수라고만 생각하자.) 예를들어\n\n\\(m([0,2\\pi))=2\\pi\\)\n\\(m([0,\\pi))=\\pi\\)\n\n와 같이 계산할 수 있다. 그럼 연습삼아 \\(\\Omega^* = [0,\\pi)\\)와 경우의 확률을 계산하여 보자. 사건 \\(\\Omega^* = [0,\\pi)\\)는 ‘’시계바늘이 12시와 6시 사이를 가리키는 사건들의 집합’’으로 해석할 수 있는데 이 확률은 아래와 같이 계산할 수 있다.\n\\[P(\\Omega^* )=\\frac{m(\\Omega^* )}{m(\\Omega)}=\\frac{m([0,\\pi))}{m([0,2\\pi))}=\\frac{1}{2}\\]\n이러한 확률은 잘 정의되는것 처럼 보인다.\n- 하지만 확률을 잘 정의하는 것은 생각보다 쉽지가 않다. 왜냐하면 확률을 잘 정의하기 위해서는\n\nSample space \\(\\Omega\\)의 모든(=임의의) 부분집합 \\(\\Omega^*\\)에 대하여 \\(P(\\Omega^*)\\)를 명확하고 모순없이 정의해야\n\n하는데 이것은 생각보다 쉬운일이 아니다. 또한 정의한 확률은 확률의 공리를 적용하였을때 모순이 없어야 한다. 확률의 공리는 간단하게 말하면\n\n모든 확률은 0보다 크고 1보다 작으며\n전체사건이 일어날 확률은 1이고\n서로소인 사건에 대하여 \\(\\sigma\\)-additive1가 성립해야 한다.\n\n확률의 공리에 대한 좀더 정확한 state는 김우철 수리통계교재 혹은 위키피디아를 참고하여 스스로 확인해 보길 바란다.\n- 확률의 공리는 너무 당연해서 확률을 정의하면 저절로 성립할것 같다. 하지만 예제2의 경우 그렇게 당연하지 않다. 이에 대하여 좀 더 자세히 살펴보자. 예제2에서는 \\(\\Omega=[0,2\\pi)\\)라고 생각하고 확률은 길이의 비율로 정의하였다. 예를들어서 \\(\\Omega^* \\in [0,\\pi)\\)일 확률은\n\\[\\frac{\\pi}{2\\pi}=\\frac{1}{2}\\]\n와 같은 식으로 정의한바 있다. 이런식의 정의는 여러가지 도전적인 질문에 직면한다.\n(질문1) 첫번째 도전적인 질문은 아래와 같다.\n\n\\(\\Omega^* =\\{0\\}\\)일 확률이 얼마인가?\n\n즉 바늘침이 정확하게 12시를 가르킬 확률이 얼마냐는 것이다. 한 점으로 이루어진 집합 \\(\\{0\\}\\)은 분명히 \\(\\Omega=[0,2\\pi)\\)의 부분집합 이므로 앞서 논의한대로라면 이러한 집합에 대한 확률을 명확하게, 모순없이 정의할 수 있어야 한다. 많은 사람들이 이 질문에 대한 답은 \\(0\\) 이라고 알고 있고 그 이유를 ‘’점의 길이는 0 이니까’’ 라고 이해하고 있다. 그럼 이제 아래의 질문을 생각하여 보자.\n(질문2) 두번째 질문은 아래와 같다.\n\n그렇다면 사건 \\(\\{0,\\pi\\}\\)가 일어날 확률은 얼마인가?\n\n질문을 다시 풀어쓰면 바늘침이 정확하게 12시를 가르키거나 혹은 정확하게 6시를 가르킬 확률이 얼마냐는 것이다. 이 질문에 대한 대답은 \\(0+0=0\\)이므로 \\(0\\)이라고 주장할 수 있다. 그렇다면 이제 아래의 질문을 생각해보자.\n(질문3) 세번째 질문은 아래와 같다.\n\n구간 \\([0,2\\pi)\\)는 무수히 많은 점들이 모여서 만들어지는 집합이다. 그런데 점 하나의 길이는 0이다. 0을 무수히 더해도 0이다. 그러므로 구간 \\([0,2\\pi)\\)의 길이도 0이 되어야 한다. 이것은 모순아닌가?\n\n이 질문에 대한 답변은 쉽지 않다. 왜냐하면 \\(m([0,2\\pi))=0\\) 임을 인정하면 지적한대로 전체확률은 1이어야 한다는 기본상식에 어긋나 모순이 생긴다. 확률의 공리2가 깨져버리는 것이다. 하지만 이 질문에 대한 논리는 그럴듯해 보인다. 따라서 이 질문에 대한 대답을 하려면 약간의 직관적인 가정을 덧붙여야 할 것 같다. 예를들면 “점들을 유한번 합치면 그냥 많은 점들이지만 무한히 합치면 이것은 선분이 된다. 따라서 길이가 생긴다.” 라는 식으로 설명할 수 있다. 우리는 이러한 현상을 “무한번 더해서 일어나는 기적”이라고 칭하자.\n(질문4) 그렇다면 아래의 질문은 어떻게 대답할 수 있을까?\n\n\\([0,\\pi)\\) 에서 유리수만 뽑아낸 집합이 있다고 생각하자. 편의상 이 집합을 \\(\\mathbb{Q}\\) 라고 하자. 이 집합은 분명히 무한개의 점을 포함하고 있다. 그렇다면 이 집합도 길이가 있는가? 있다면 얼마인가?\n\n- 이미 점들의 길이를 무한번 더하면 길이가 생긴다고 주장한 상태이므로 길이가 0이라고 주장할 수 없다. 따라서 길이가 있다고 주장해야 한다.\n- 단순히 길이가 \\(\\pi\\)라고 주장한다면 바로 모순에 빠짐을 알 수 있다. (길이가 \\(\\pi\\)라고 주장한다면 \\([0,\\pi)\\) 에서 무리수만 뽑아낸 집합의 길이가 뭐냐고 따질수가 있음.)\n- 길이는 일단 0보다 커야하고 \\(\\pi\\)보다 작아야함은 자명하므로 그 사이에 있는 어떤 값이 길이라고 주장하자. (구체적으로 어떤값인지는 모른다고 하자.) 따라서 (질문4)에 대한 답은 ‘’구체적으로 얼마인지는 모르겠지만 길이가 분명 존재하고 그 길이는 0 보다 크고 \\(\\pi\\) 보다는 작은 어떠한 값 \\(a\\)이다.’’ 정도로 정리할 수 있다.\n(질문5) 질문4로부터 만들어지는 논리는 아래의 질문을 적절하게 대답하지 못한다. (질문이 좀 길어서 나누어서 설명합니다)\n(빌드업1)\n\\(\\mathbb{Q}\\)의 모든점에 \\(\\sqrt{2}\\)를 더한다. 이 점들로 집합을 만들어 \\(\\mathbb{Q}_{\\sqrt{2}}\\)를 만든다. 여기에서 \\(\\mathbb{Q}_{\\sqrt{2}}\\)는 \\(\\Omega\\)의 부분집합이다.2 따라서 \\(\\mathbb{Q}_{\\sqrt{2}}\\)는 길이를 명확하고 모순없이 정의할 수 있어야 한다. 사실 이건 별로 어려운 일이 아니다. 평행이동은 길이를 변화시키지 않는다는 점을 상기하면 별로 어렵지 않게\n\\[m(\\mathbb{Q}_{\\sqrt{2}})=\\alpha\\]\n라고 정의할 수 있다.3\n(빌드업2)\n이제 좀 더 일반적으로 구간 \\([0,\\pi)\\)에 있는 모든 무리수의 집합 \\(\\mathbb{Q}^c:=[0,\\pi) -\\mathbb{Q}\\) 를 생각하자. 이 집합의 서로 다른 임의의 원소 \\(x,y,z\\)에 대하여 \\(\\mathbb{Q}_{x},\\mathbb{Q}_{y},\\mathbb{Q}_{z}\\)를 생각하자. 아래의 성질을 관찰할 수 있다.\n\n\\(\\mathbb{Q}_{x},\\mathbb{Q}_{y},\\mathbb{Q}_{z}\\)는 모두 \\(\\Omega\\)의 부분집합이다. 따라서 길이를 명확하고 모순없이 정의할 수 있어야 한다.\n\\(\\mathbb{Q}_{x},\\mathbb{Q}_{y},\\mathbb{Q}_{z}\\)의 길이는 각각 \\(\\alpha\\)로 정의할 수 있다.\n\\(\\mathbb{Q}_{x},\\mathbb{Q}_{y},\\mathbb{Q}_{z}\\)는 모두 서로소인 집합이다.\n따라서 \\(P(\\mathbb{Q}_{x} \\cup \\mathbb{Q}_{y} \\cup \\mathbb{Q}_{z})=P(\\mathbb{Q}_{x}) + P(\\mathbb{Q}_{y})+ P(\\mathbb{Q}_{z})\\) 이다. (확률의 공리3)\n\n굳이 \\(P(\\mathbb{Q}_{x}) + P(\\mathbb{Q}_{y})+ P(\\mathbb{Q}_{z})\\)를 계산하면 아래와 같이 계산할 수 있겠다.\n\\[P(\\mathbb{Q}_{x}) + P(\\mathbb{Q}_{y})+ P(\\mathbb{Q}_{z})=\\frac{\\alpha}{2\\pi}+\\frac{\\alpha}{2\\pi}+\\frac{\\alpha}{2\\pi}=3 \\times \\frac{\\alpha}{2\\pi}\\]\n(빌드업3)\n눈 여겨볼 점은 아래 식이 성립해야 한다는 것이다.\n\\[P(\\mathbb{Q}_{x}) + P(\\mathbb{Q}_{y})+ P(\\mathbb{Q}_{z}) = 3 \\times \\frac{\\alpha}{2\\pi} \\leq 1\\]\n따라서 \\(\\alpha\\)를 \\((0,\\pi)\\) 사이의 아무값이나 가지도록 하면 안되고 적당히 작은 값을 설정해야 한다. 그런데 임의의 경우에 대하여 이 식은 성립하도록 \\(\\alpha\\)를 작게 설정해야 하는데 그건 불가능할 것 같다. 왜냐하면 좌변의 값은 편의에 따라서 값을 임의로 키울 수 있기 때문이다. 지금은 \\(\\mathbb{Q}^c\\)에서 서로 다른 3개의 무리수를 뽑는다고 가정하였는데 예를 들어 서로 다른 100개의 무리수를 뽑았다면 아래 식이 성립하도록 \\(\\alpha\\)를 설정해야 한다.\n\\[ 100 \\times \\frac{\\alpha}{2\\pi} \\leq 1\\]\n무리수의 개수는 무한개만큼 많으니까 100이라는 숫자는 얼마든지 1000, 10000 과 같이 키울 수 있다. 좀 더 일반적으로 쓰면 아래과 같다.\n\\[ N \\times \\frac{\\alpha}{2\\pi} \\leq 1\\]\n그런데 \\(\\alpha\\)를 아무리 작게 잡아도 위의 부등식을 만족하는 아주 큰 \\(N\\)이 항상 존재하므로 결국 위의 부등식을 만족하려면 \\(\\alpha=0\\) 일 수 밖에 없다. 그런데 \\(\\alpha=0\\)이 된다면 “무한번 더해서 일어나는 기적”은 허구가 되므로 질문3 의 대답에 모순이 된다.\n- 따라서 이 질문은 지금까지 제시한 논리로 방어가 불가능하다. 이처럼 논리적인 모순없는 체계를 만드는 것은 매우 어려운 일이다.\n결론 결론적으로 말하면 길이를 재는 함수 \\(m\\)을 아래와 가정하면 위의 모든 질문에 대한 대답을 논리적 모순없이 설계할 수 있다.\n\n한 점에 대한 길이는 \\(0\\) 이다.\n\\([0,2\\pi)\\) 사이의 모든 유리수를 더한 집합은 그 길이가 \\(0\\)이다.\n\\([0,2\\pi)\\) 사이의 모든 무리수를 더한 집합은 그 길이가 \\(2\\pi\\)이다.\n\n참고로 르벡측도(Lebesgue measure)를 사용하면 위의 성질을 만족한다. (물론 르벡측도의 정의가 위와 같진 않다) 따라서 르벡측도를 활용하여 확률을 정의하는 것이 모순을 최대한 피할 수 있다.\n\n\n비탈리집합\n- 그렇다면 아래와 같이 주장할 수 있을까?\n\n위의 3가지 원리 1-3을 사용하면 \\([0,2\\pi)\\)의 어떤 부분집합에 대하여서도 그 집합의 길이를 모순없이 정의할 수 있다.\n\n결론적으로 말하면 이 주장은 틀렸다\n- 이 주장이 틀린이유를 설명하겠다. 이 주장이 틀린 이유는\n\n위의 3가지 원리 (i)-(iii)을 사용하여도 길이를 모순없이 정의불가능한 어떠한 집합이 \\([0,2\\pi)\\)내에 존재하기 때문\n\n이다. 이제 이러한 집합이 무엇인지 살펴보겠다. 먼저 아래와 같은 관계를 정의하자.\n\n두 실수 \\(x,y\\)에 대하여 \\(x-y \\in \\mathbb{Q}\\) 이면 \\(x\\sim y\\) 라고 정의한다.\n\n아래가 성립함을 바로 알 수 있다.\n\n\\(x \\sim x\\). (Reflexivity)\n\\(x \\sim y\\) if and only if \\(y \\sim x\\). (Symmetry)\nif \\(x \\sim y\\) and \\(y ~ z\\) then \\(x \\sim z\\). (Transitivity)\n\n위의 성질을 만족하는 관계를 동치관계라고 한다.\n- 참고로 집합 \\(A\\)의 원소간 동치관계가 존재하면 그 동치관계를 이용하여 \\(A\\)의 파티션을 항상 만들 수 있다. 여기에서 \\(A=[0,2\\pi)\\)로 바꾸면 우리가 관심 있는 주장이 된다.\n(proof)\n임의의 실수 \\(x \\in [0,2\\pi)\\)에 대하여 동치관계가 성립하는 실수들을 모은 집합을 \\([x]\\)라고 정의하자. 즉\n\\[[x]=\\{y: x\\sim y, y \\in \\mathbb{R}\\} \\cap [0,2\\pi)\\]\n이다. 여기에서 \\([x]\\)를 equivalence class라고 한다. 그런데 \\([x]\\)는 최소한 \\(x\\)를 포함하므로 아래가 항상 성립한다.\n\\[[0,2\\pi) \\subset \\bigcup_{x\\in [0,2\\pi)}[x]\\]\n또한 \\([x]=\\{y: x\\sim y, y \\in \\mathbb{R}\\} \\cap [0,2\\pi)\\)임을 이용하면 아래가 성립함을 알 수 있다.\n\\[[0,2\\pi) \\supset \\bigcup_{x\\in [0,2\\pi)}[x]\\]\n따라서 아래가 성립한다.\n\\[[0,2\\pi) = \\bigcup_{x\\in [0,2\\pi)}[x]\\]\n그리고 아래의 관계도 성립한다.\n\\[[x]\\neq[y] \\Longrightarrow [x] \\cap [y] = \\emptyset \\]\n따라서 \\([0,2\\pi)\\)의 파티션이 존재한다.\n\\[[0,2\\pi)=\\bigcup_ {t\\in {\\cal T} }A_t\\]\n여기에서 \\(A_t=\\{s: t-s \\in \\mathbb{Q} \\} \\cap [0,2\\pi)\\) 이고 \\(t\\)는 각 파티션을 대표하는 원소라고 하자. 그리고 \\({\\cal T}\\)는 단순히 대표원소들의 집합이라고 하자.\n- 이제 이 파티션에서 원소를 하나씩만 선택하여 어떤 집합 \\(V\\)를 만들었다고 하자. 그럼 이 집합은 (i)-(iii)의 원리에 의해서도 길이를 잴 수 없다. 이제부터 왜 \\(V\\)가 잴수없는 집합인지 설명하겠다. 우선 \\(V\\)가 잴수있는 집합이라고 하자. 즉 집합 \\(V\\)의 길이를 잴 수 있고 그 길이를 \\(a\\)이라고 하자. 즉 \\(m(V)=a\\)이라고 가정하자. 여기에서 \\(m\\)은 르벡메져이다. 그리고 아래의 집합들을 정의한다.\n1. \\((-2\\pi,2\\pi)\\)에서 유리수만 모은 집합을 \\(Q^{\\star}\\)라고 정의하자. 즉 \\(Q^{\\star}=\\mathbb{Q} \\cap (-2\\pi,2\\pi)\\).\n2. \\(Q^{\\star}\\)에서 적당한 유리수 하나를 뽑아서 \\(V\\)를 평행이동 시킨 집합 \\(V_q\\)를 정의하자.\n이때 위에서 언급합 \\(V_q\\)는 좀 더 형식적으로 쓰면 \\(V_q:=\\{v+q: v\\in V, q\\in Q^{\\star} \\}\\)와 같이 쓸 수 있다. 이 집합 \\(V_q\\)는 매우 오묘한 특징이 있는데 우선 아래들이 성립한다.\n\n\\(V_q\\)의 길이는 \\(V\\)의 길이와 같다.\n서로 다른 \\(q_1,q_2 \\in Q^{\\star}\\)에 대하여 \\(V_{q_1} \\cap V_{q_2} = \\emptyset\\) 이 성립한다.\n\n이제 이러한 집합 \\(V_q\\)를 가지고 아래의 성질이 성립함을 보이자.\nFact 1: \\([0,2\\pi) \\subset \\bigcup_{q \\in Q^{\\star} } V_q\\).\n(proof)\n증명이 그렇게 어렵진 않다. \\(x \\in [0,2\\pi)\\) 라고 하자. 그런데 \\([0,2\\pi)=\\bigcup_{t \\in {\\cal T} }A_t\\) 이므로 \\(x\\in A_{t'}\\)가 성립하는 \\(t'\\)가 적어도 하나는 \\({\\cal T}\\)에 존재한다. 그런데 아래가 성립한다.\nclaim: \\(A_{t'} \\subset \\bigcup_{q \\in Q^{\\star}} V_q\\)\n따라서 \\(x \\in \\bigcup_{q \\in Q^{\\star}} V_q\\) 가 성립한다. 이제 마지막 식이 성립하는 이유를 좀 더 자세히 살펴보자.\n(proof of claim)\n부분집합의 정의에 의해서 모든 \\(z \\in A_{t'}\\)에 대하여 \\(z \\in \\bigcup_{q\\in Q^{\\star}} V_q\\)임을 보이면 증명이 끝난다. 우선 아래가 성립함을 관찰하자.\n\\[\\{y\\} = V \\cap A_{t'}\\]\n즉 \\(y\\)는 집합 \\(A_{t'}\\)에서 부터 대표로 \\(V\\)에 뽑혀 나간 어떠한 원소이다. 따라서 당연히 \\(y\\)는 \\(A_{t'}\\)에서 랜덤하게 뽑은 임의의 원소 (\\(z\\))와 동치관계에 있다. 즉 아래가 성립한다.\n\nfor all \\(z \\in A_{t'}, y \\sim z\\)\n\n이말은 아래와 같다.\n\nfor all \\(z \\in A_{t'}, y-z \\in \\mathbb{Q}\\)\n\n그런데 \\(y,z\\)모두 \\(A_{t'}\\)의 원소이고 \\(A_{t'} \\subset [0,2\\pi)\\)이므로 \\(y-z \\in (-2\\pi,2\\pi)\\)임을 알 수 있다. 따라서\n\nfor all \\(z \\in A_{t'}, y-z \\in \\mathbb{Q} \\cap (-2\\pi,2\\pi)\\)\n\n라고 쓸 수 있다. 이는 적당한 \\(q' \\in \\mathbb{Q} \\cap (-2\\pi,2\\pi)=Q^{\\star}\\) 가 존재하여 아래식을 성립한다는 말과 같다.\n\nfor all \\(z \\in A_{t'}, y-z = q'\\)\n\n이는 다시 아래식이 성립한다는 것과 같다.\n\nfor all \\(z \\in A_{t'}, z = y-q' , q'\\in Q^{\\star}\\)\n\n그런데 \\(y\\in V\\) 이므로, \\(\\bigcup_{q\\in Q^{\\star}} V_q\\) 중에는 \\(z\\)를 포함하는 집합이 하나는 존재한다. 따라서\n\nfor all \\(z \\in A_{t'}, z \\in \\bigcup_{q\\in Q^{\\star}} V_q\\)\n\n가 성립한다.\n- Fact 1과 별개로 아래의 사실이 성립한다.\nFact 2: \\(\\bigcup_{q \\in Q^{\\star} } V_q \\subset (-2\\pi,4\\pi)\\)\n이는 증명없이 바로 이해할 수 있다. Fact 1,2를 종합하면 아래와 같이 쓸 수 있다.\n\\[[0,2\\pi) \\subset \\bigcup_{q \\in Q^{\\star} } V_q \\subset (-2\\pi,4\\pi)\\]\n따라서 아래가 성립한다.\n\\[m([0,2\\pi)) \\leq \\sum_{q \\in Q^{\\star} } m(V_q) \\leq m((-2\\pi,4\\pi))\\]\n따라서 아래가 성립해야 한다.\n\\[2\\pi \\leq \\infty  \\leq 6\\pi\\]\n이는 모순이다.\n- 결국 아래와 같이 주장할 수 없다.\n\n위의 3가지 원리 (i)-(iii)을 사용하면 \\([0,2\\pi)\\)의 어떤 부분집합에 대하여서도 그 집합의 길이를 모순없이 정의할 수 있다.\n\n따라서 아래와 같이 합의한다.\n\n위의 3가지 원리 (i)-(iii)을 받아들이자. 그럼에도 불구하고 \\([0,2\\pi)\\)의 내에서 그 집합의 길이를 정의할 수 없는 집합이 존재함은 알고 있다. 길이를 정의할 수 없으므로 확률을 정의할 수 없음도 알고 있다. 그러므로 이제부터 이러한 집합을 제외하고 확률을 정의하자.\n\n즉 길이를 정의하기 힘든 집합은 제외하고 확률을 정의하겠다는 의미이다. 이 말은 \\(\\Omega\\)의 모든 부분집합들에 대해서 확률을 정의하지 않고 \\(\\Omega\\)의 특정 부분집합에 대해서만 확률을 정의하겠다는 것과 같은 말인데 이 특정 부분집합들의 모임을 기호로 \\({\\cal F}\\)로 표시하고 \\(\\sigma\\)-field라고 이름 붙인다. 이 강의의 범위에서는 \\({\\cal F}\\)를 sample space의 부분집합 중 확률을 잘 정의할 수 있는 집합들의 모임정도로 이해해도 무방하다. 확률을 잘 정의하는 것은 길이따위를 잘 정의하는 것과 맞닿아 있으므로 사실상 \\({\\cal F}\\)는 sample space의 부분집합 중 잴 수 있는 집합들의 모임정도로 이해할 수 있다. (따라서 당연히 \\({\\cal F}\\)의 원소는 잴 수 있는 집합으로 이해할 수 있다.)\n\n\n시그마필드\n- \\(\\sigma\\)-field에 대한 이해를 돕기 위해서 (예제1)을 다시 생각해보자. \\(\\Omega=\\{H,T\\}\\) 이고, 이것에 대응하는 \\({\\cal F}\\)는 아래와 같이 쓸 수 있다.\n\\[{\\cal F}=\\{\\emptyset, \\{H\\},\\{T\\},\\{H,T\\}\\}\\]\n보는 것처럼 \\({\\cal F}\\)의 원소는 집합이므로 \\({\\cal F}\\)는 집합들의 집합임을 기억하자. 다시 한번 말하지만 \\({\\cal F}\\)의 모든 원소에 확률을 모순없이 정의할 수 있다.\n- \\({\\cal F}\\)는 \\(\\Omega\\)없이 단독으로 정의될 수 없다. 즉 \\(\\Omega\\)와 \\({\\cal F}\\)은 커플같은 것이라고 생각할 수 있다. 그래서 좀 더 명확한 표현을 위해 이 둘을 묶어 \\((\\Omega,{\\cal F})\\)라고 표현하기도 한다. 그리고 이 둘을 묶은 쌍(pair라고 표현함)을 measurable space라고 부른다.\n- \\(\\Omega\\)의 시그마필드 \\({\\cal F}\\)가 반드시 아래와 같을 필요는 없다.\n\\[{\\cal F}= ~all~ subset~ of ~\\Omega\\]\n이것을 이해하기 위해서 아래의 주사위 예제를 생각해보자.\n(예제3) 어떤 사람이 주사위를 던졌다고 하자. 주사위는 1~6의 눈 사이로 나올것이다. sample space는\n\\[\\Omega=\\{1,2,3,4,5,6\\}\\]\n와 같이 설정할 수 있고 각 sample space의 각 이벤트가 발생할 확률은 모두 \\(\\frac{1}{6}\\)로 모순없이 정의할 수 있다. 이 경우 시그마필드 \\({\\cal F}\\)는 아래와 같이 설정할 수 있다.\n\\[{\\cal F}= ~ all ~ subset ~ of ~ \\Omega = \\{\\emptyset,\\{1\\},\\dots,\\{6\\},\\{1,2\\},\\dots,\\{5,6\\},\\dots,\\Omega \\}\\]\n분명히 \\({\\cal F}\\)의 모든 원소에 대하여 확률을 모순없이 정의할 수 있지만 이렇게 모든 \\(\\Omega\\)의 부분집합에 대하여 굳이 확률을 정의할 필요가 없는 경우도 있다. 가령 주사위를 던져서 짝이 나오면 1점을 얻고 홀이 나오면 1점을 잃는 게임을 생각하여 보자. 관심이 있는 것은 짝 혹은 홀이 나올 확률이므로 이 경우는 \\({\\cal F}\\)를 아래와 같이 설정해도 무방하다.\n\\[{\\cal F}= \\{ \\emptyset, \\{1,3,5\\}, \\{2,4,6\\},\\Omega \\}\\]\n- \\(\\sigma\\)-field의 엄밀한 정의는 (i) 공집합과 전체집합을 포함하며 (ii) 여집합에 대하여 닫혀있고 (iii) countable union에 대하여 닫혀있는 집합이다. 이때 (i)의 조건은 생략가능하다. 참고로 앞서 제시한 예시들은 모두 이러한 조건을 만족한다. 하지만 엄밀한 정의를 이해하는 것 보다 왜 시그마필드라는 개념을 생각해야만 하는가?를 이해하는 것이 더 중요하다.\n\n\n현재까지의 요약\n\n확률을 모순없이 정의하는 것은 매우 어려운 작업이다. 왜냐하면 길이를 모순없이 정의하는것이 어렵기 때문이다. 한 예로 구간 \\([0,2\\pi)\\)에서의 임의의 부분집합에 대하여 모순없이 길이를 재는것조차 매우 어렵다.\n르벡메져라는 것을 도입하면 길이를 비교적 모순없이 정의할 수 있다. 하지만 르벡메져로도 잴 수 없는 집합이 존재한다.\n그래서 이러한 집합을 제외하고 길이 혹은 확률을 정의하기로 한다. 즉 확률은 길이를 모순없이 정의할 수 있는 집합들의 모임에서만 정의하기로 한다. 이러한 집합들의 모임을 시그마필드라고 한다.\n\n\n\n확률변수\n- 확률변수는 \\(X\\)는 \\(X:\\Omega \\to \\mathbb{R}\\)인 함수이다. 그런데 조금 특별한 성질을 가진 함수이다. 우선 이 특별한 성질에 대해서는 제쳐두고 단순히 \\(\\Omega\\)의 각 원소에 실수값을 맵핑한 규칙이라고 이해해도 괜찮다.\n(예제1) 동전을 던지는 예제를 다시 생각하자.\n\\[\\Omega=\\{H,T\\}\\]\n공평한 동전이라면 동전이 앞면이 나올 확률, 뒷면이 나올 확률을 아래와 같이 정의할 수 있다.\n\\[P(\\{H\\})=P(\\{T\\})=\\frac{1}{2}\\]\n여기에서 \\(\\Omega\\)의 원소 \\(H\\), \\(T\\)를 각각 \\(0\\)과 \\(1\\)로 정의한다면 이는 확률변수가 된다. 즉 함수 \\(X:\\Omega \\to \\mathbb{R}\\)를 아래와 같이 정의하면\n\n\\(X(H)=0\\)\n\\(X(T)=1\\)\n\n\\(X\\)는 확률변수가 된다. 집합 \\(A\\)의 원소를 \\(a\\)로 표시하는 것처럼 종종 \\(\\Omega\\)의 원소를 \\(\\omega\\)로 표시한다. 예를들면 \\(\\Omega=\\{H,T\\}=\\{\\omega_1,\\omega_2\\}\\)와 같이 쓸 수 있다. 이 경우 확률변수는\n\n\\(X(\\omega_1)=0\\)\n\\(X(\\omega_2)=1\\)\n\n와 같이 정의할 수 있다.\n- 확률변수 \\(X\\)가 \\(X: \\Omega \\to \\mathbb{R}\\)인 함수라면 확률 \\(P\\)는 \\(P:{\\cal F} \\to [0,1]\\)인 함수이다. 확률의 정의역이 \\({\\cal F}\\)라는 의미를 잘 생각해보면 확률은 집합을 실수로 맵핑하는 함수가 된다. 즉 set function이 된다. 반대로 확률변수는 집합의 원소를 실수로 맵핑하는 함수이다. 따라서 아래와 같은 기호를 쓴다.\n\n\\(X(H)=0\\)\n$P({H})= $\n\\(P(\\{\\omega_1\\})=\\frac{1}{2}\\)\n\n즉 아래와 같이 표현하면 옳지 않다.\n\n\\(P(H)=\\frac{1}{2}\\)\n\\(P(\\omega_1)=\\frac{1}{2}\\)\n\n첫 번째 표현은 \\(H\\)자체를 집합으로 착각하여 생기는 혼란이다. 보통 확률을 표현할때 “집합 \\(A\\)에 대하여 집합 \\(A\\)가 발생할 확률을 \\(P(A)\\)라고 하자.”는 식의 표현을 많이 접했을 것이다. \\(P(A)\\)에서 \\(A\\)는 엄연히 집합이지만 \\(H\\)는 집합이 아니다. 두 번째 표현은 첫번째 표현과 같은 이유로 틀린 표현이다.\n- 하지만 아래와 같은 표현은 옳다.\n\\[P(X=1)=\\frac{1}{2}\\]\n언뜻보기에는 이렇게 생각할 수 있다. (1) 원래 \\(P\\)는 set function이므로 입력으로 집합을 받아야 한다. (2) 그런데 \\(X=1\\)는 집합이 아니라 수식이다. (3) 따라서 옳지않다. 이런 따짐은 옳다. 하지만 \\(P(X=1)\\)은 관용적으로 많이 쓰는데 그 이유는 \\(P(X=1)\\)을 아래와 같은 표현의 생략이라고 보기 때문이다.\n\\[P(X=1)=P(\\{\\omega: X(\\omega)=1\\})=P(\\{H\\})=\\frac{1}{2}\\]\n확률을 \\(P(\\{\\omega: X(\\omega)=1\\})\\)와 같은 표현하는 것은 명확하지만 너무 복잡하고 직관적이지 않다. 그래서 간단히 \\(P(X=1)\\)와 같이 쓴다. 이는 매우 관용적인 약속이다.\n- 확률변수는 매우 편리한 도구이므로 앞으로는 확률을 표현할때\n\n\\(P(\\{H\\})=P(\\{T\\})=\\frac{1}{2}\\)\n\\(P(\\{\\omega_1\\})=P(\\{\\omega_2\\})=\\frac{1}{2}\\)\n\n와 같이 표현하는 일은 거의 없을 것이다. 대신에 아래와 같이 표현하는 일이 많이 생길것이다.\n\\[P(X=0)=P(X=1)=\\frac{1}{2}\\]\n- 확률변수가 단지 함수라는 것은 쉽게 납득이 되지 않는다. 왜냐하면 대부분의 사람들이 “확률변수=값이 랜덤하게 바뀌는 변수”의 느낌을 가지기 때문이다. 즉 (1) 확률변수는 변수이고 (2) 확률변수는 결과가 랜덤하게 바뀌어야 한다고 대부분 생각한다.\n- (1)을 좀 더 자세히 설명하여 보자. 보통 우리가 함수라는 표현을 쓸때 \\(y=f(x)\\)라는 기호로 많이 쓴다. 여기에서 \\(f\\)는 함수 즉 function이라고 하고 \\(x\\)를 input 이라고 부르고 \\(y\\) 혹은 \\(f(x)\\)를 output이라 부르기로 약속하자. 이때 input과 output이 엄밀히 정의된 용어는 아니지만 편의상 이렇게 부르기로 하자. 랜덤변수 \\(X\\)가 함수라는 의미는 랜덤변수 \\(X\\)에 대응하는 요소가 \\(f\\)라는 것이다. 따라서 \\(y=f(x)\\)에 대응하는 표현은 \\(x=X(\\omega)\\)와 같이 된다. 여기에서 \\(\\omega\\)를 outcome이라고 부르고 \\(x\\)를 realization이라고 부른다.\n- (2)를 살펴보자. 확률변수의 결과 즉 output이 랜덤으로 바뀐다는 말은 동일한 input에 대한 맵핑의 결과 output이 랜덤으로 바뀐다는 것처럼 오해할 수 있다. 하지만 이는 사실이 아닌데 확률변수는 단지 - \\(X(\\omega_1)=0\\) - \\(X(\\omega_2)=1\\)\n와 같은 맵핑규칙일 뿐이기 때문이다. 보는 것처럼 입력이 \\(\\omega_1\\)이면 항상 \\(0\\)이 출력되고 입력이 \\(\\omega_2\\)면 항상 \\(1\\)이 출력된다. 확률변수가 가지는 “랜덤한”느낌은 입력이 랜덤으로 바뀔 수 있기 때문이지 입력과 출력사이의 맵핑을 정의하는 규칙이 랜덤으로 바뀌는 것은 아니다. 즉 outcome이 랜덤으로 나올수 있기 때문이지 realization이 랜덤으로 나올 수 있는 것은 아니다.\n- 많은 사람들이 아래와 같은 표현 때문에 혼돈을 느낀다. 예제1의 확률변수 \\(X\\)를 아래와 같이 표현할 수 있다.\n\\[X=\\begin{cases}\n0 & w.p.~ \\frac{1}{2} \\\\\n1 & w.p.~ \\frac{1}{2}\n\\end{cases}\\]\n이 표현을 보면 마치 \\(X\\)가 함수가 아닌 변수처럼 느껴지고 그 값이 랜덤으로 바뀌는 것처럼 느껴진다. 놀랍게도 이 표현은 맞는 표현인데 사실 아래와 같은 표현이 간소화 된 표현이기 때문이다.\n\\[X(\\omega)=\\begin{cases}\n0 & \\omega \\in \\{H\\}\\\\\n1 & \\omega \\in \\{T\\}\n\\end{cases}, \\quad where~P(\\{H\\})=P(\\{T\\})=\\frac{1}{2}.\\]\n- 확률변수 \\(X\\)는 확률과 직접적으로는 관련이 없지만 간접적으로는 관련이 있다. 왜냐하면 확률변수 \\(X\\)의 역상(inverse image)이 \\(\\Omega\\)의 부분집합이 되는데, \\(\\Omega\\)의 부분집합에서는 확률을 정의할 수 있기 때문이다. 그렇다면\n\n확률변수의 \\(X\\)의 모든 역상에 대하여 확률을 모순없이 정의할 수 있을까?\n\n와 같은 질문을 할 수 있다.\n- 예제2를 다시 생각하여보자. 이전에는 논의를 편하게 하기 위해서 sample space를 아래와 같이 정의하였다.\n\\[\\Omega=[0,2\\pi)\\]\n사실 동전예제와 맞춰서 생각해보면 sample space는\n\\[\\Omega=\\{\\dots,3:00,\\dots,6:00,\\dots,\\}\\]\n이고 확률변수는\n\n…\n$X({3:00})=/2 $\n…\n\\(X(\\{6:00\\})=\\pi\\)\n…\n\n와 같이 정의해야 한다. 따라서 사실 이전의 예제에서는 확률변수의 realization들의 집합자체를 \\(\\Omega\\)로 정의한 셈이 된다. 따라서 이 경우 확률변수는 항등함수로 정의한 셈이 된다. 즉 \\(X\\)는\n\\[X:[0,2\\pi) \\to [0,2\\pi)\\]\n인 항등함수이다. \\(X\\)는 항등함수이므로 비탈리집합 \\(V\\)에 대한 \\(X\\)의 역상은 비탈리 집합이 된다. 그런데 비탈리집합은 잴 수 없는 집합이므로 확률을 정의할 수 없다. 따라서 \\(X\\)의 모든 역상에 대해서 확률을 모순없이 정의할 수 있는 것은 아니다.\n- 확률변수인데 확률을 정의하지 못하는것은 말이 되지 않으므로 확률변수의 정의를 조금 수정해보자. 수정은 매우 간단한데 확률변수 \\(X\\)의 역상이 잴 수 있는 집합만 나오도록 수정하면 된다. 결국 \\(X\\)가 가측함수(measurable function)이라는 것이 되면 이것이 가능해지는데 가측함수에 대한 자세한 내용은 이 강의의 범위를 넘어서므로 생략한다. 하지만 핵심은 파악할 수 있는데 바로 가능한 \\(X\\)의 역상이 \\({\\cal F}\\)의 원소가 되어야 한다는 것이다. (앞서서 확률변수 \\(X\\)는 조금 특별한 성질이 있는 함수라고 소개하였는데, 이 특별한 성질이 바로 \\(X\\)가 가측함수라는 것이다.) 결국\n\n***확률변수의 \\(X\\)의 모든 역상에 대하여 확률을 모순없이 정의할 수 있다.\n\n는 맞는 주장인데 이는 위의 주장이 성립하도록 우리가 \\(X\\)를 일반적인 함수가 아니라 특별한 성질을 가지는 함수로 재정의 하였기 때문이다.\n\n\n확률밀도함수\n- 예제2를 다시 생각하여보자. 사실 엄밀하게 생각해보면 sample space는\n$$={,3:00,,6:00,,}\n이고 확률변수는\n\n…\n$X({3:00})=/2 $\n…\n\\(X(\\{6:00\\})=\\pi\\)\n…\n\n와 같이 정의해야 하며 확률변수의 realization의 집합을 \\([0,2\\pi)\\)로 설정하는 것이 맞는것 같다. 하지만\n\\[\\Omega=[0,2\\pi)\\]\n와 같이 설정하는 것이 매우 편리해보인다.\n- 예제1의 경우도 사실 아래처럼 정의해도 무방할것 같다.\n\\[\\Omega=\\{0,1\\}\\]\n이것은 sample space대신에 realization을 모은 집합만 고려하고 싶다는 의미인데 이는 결국 \\((\\Omega,{\\cal F})\\)와 같은 것을 생략하고 싶다는 것이다.\n- 지금까지의 논의를 잘 생각해보면 이것이 가능할 것 같다. 결국\n\n\\(X\\)를 확률변수라고 하자!!!\n\n라고 선언하기만 한다면 \\(X\\)의 역상이 모두 가측집합(measurable set)이 되어서 그 역상에 대한 확률을 모순없이 정의할 수 있다. 비탈리집합과 같은 경우는 \\(X\\)의 역상에서 저절로 빠진다. 왜냐하면 그렇게 되도록 \\(X\\)를 정의하였기 때문이다.\n- 결국 확룰변수 \\(X\\)가 가측함수임을 이해하는 것과 그것이 무엇을 의미하는지 이해하는것이 힘들지만 한번 이해하면 단순히 확률변수를 선언하는 것만으로도 많은 것들을 생략하여 간소화 시킬 수 있다.\n- 간소화불가능한 점은 바로 확률 \\(P\\)인데 이것은 sample space \\(\\Omega\\)의 부분집합을 input으로 받는 함수이므로 \\((\\Omega,{\\cal F})\\)가 통째로 생략된다면 확률 \\(P\\)의 정의도 모호해지게 된다. 따라서 확률 \\(P\\)의 개념을 그대로 이어받은 무엇인가를 새롭게 정의해야 하는데 그것이 바로 probability density function(pdf)와 cumulative density function(cdf)이다. 이 둘의 정의는 각자 교재를 참고하길 바란다.\n\n\n시계열\n- 확률변수는 \\(X\\)는 \\(X:\\Omega \\to \\mathbb{R}\\)를 만족하고 추가로 특별한 성질을 가진 함수라고 생각할 수 있다. 이를 확장하면 아래와 같이 확률벡터를 정의할 수 있다.\n- 확률벡터 \\({\\boldsymbol X}\\)는\n\\[{\\boldsymbol X}:\\Omega \\to \\mathbb{R}^m\\]\n를 만족하고 추가로 특별한 성질을 가진 함수이다.\n- 기호는 아래와 같이 쓸 수 있다.\n\n확률변수: \\(X(\\omega)=x\\)\n확률벡터: \\({\\boldsymbol X}(\\omega)=(x_1,x_2,\\dots,x_m)\\)\n\n여기에서 확률벡터 \\({\\boldsymbol X}\\)가 볼드체인 이유는 realization이 스칼라가 아니라 벡터임을 강조하기 위해서이다.\n- 확률벡터는 확률변수들의 모임으로 해석할 수 있다. 즉\n\\[{\\boldsymbol X}=(X_1,X_2,\\dots,X_m)\\]\n와 같이 해석할 수 있다. 앞서서 \\(X(\\omega)=x\\) 와 같은 표현을 소개하였는데 이에 대응하는 확률벡터버전은 아래와 같다.\n\\[{\\boldsymbol X}(\\omega)=(X_1,X_2,\\dots,X_m)(\\omega)=(X_1(\\omega),X_2(\\omega),\\dots,X_m(\\omega))=(x_1,x_2,\\dots,x_m)\\]\n- 이 표현을 이해하는 것은 생각보다 쉽지 않다. 위의 기호중에서 가장 이해하기 쉬운것은 \\((x_1,\\dots,x_m)\\)이다. 시계열수업임을 감안하여 이를 해석해보도록 하자. 예를 들면 아래와 같이 해석할 수 있다.\n\n\\(x_1=\\) 2019-03-20, 삼성전자의 주식값\n\\(x_2=\\) 2019-03-21, 삼성전자의 주식값\n\n따라서\n\\[x_1,\\dots,x_m\\]\n은 삼성전자 주식의 주가를 2019년 3월20일부터 순서대로 \\(m\\)개 나열한 수열이라 볼 수 있다. 또한 \\((x_1,\\dots,x_m)\\)는 위의 수열의 원소를 모두 모아 벡터로 만든것이라 생각할 수 있다.\n- 이제 \\(X_1(\\omega)=x_1, \\dots, X_m(\\omega)=x_m\\) 라고 표현할 수 있음을 주의하자. \\(\\omega\\)만 알면 맵핑규칙에 따라 \\(x_1,\\dots,x_m\\)는 자동으로 결정된다. 그렇다면 여기에서 \\(\\omega\\)란 무엇일까?\n- 가능한 설명모형은 아래와 같다.\n\n14,000,605개의 평행세계가 있다고 가정하자.\n우리는 이중에 하나의 평행세계에 \\(\\frac{1}{14,000,605}\\)의 “확률”로 선택되어져 살고 있다고 생각하자.\n\n확률이라는 용어가 나온김에 좀 더 엄밀하게 정의해보자. 각 평행세계를 \\(\\omega_1,\\dots,\\omega_{14,000,605}\\)라고 정의하면\n\\[\\Omega=\\{\\omega_1,\\dots,\\omega_{14,000,605}\\}\\]\n이고\n\\[P(\\{\\omega_1\\})=\\dots=P(\\{\\omega_{14,000,605}\\})=\\frac{1}{14,000,605}\\]\n가 된다. 이제 다시 아래를 가정하자. \n\n하나의 평행세계가 결정되면 그 평행세계에 해당하는 모든 사건들이 이미 결정되어 있다. 가령 우리가 777번째 해당하는 평행세계로 선택되어 살고 있다고 하자. 즉 \\(\\omega=\\omega_{777}\\)이다. 삼성전자의 주식은 맵핑규칙 \\(X\\)에 따라 자동으로\n\n\\[x_1=X_1(\\omega_{777})\\dots,x_m=X_m(\\omega_{777})\\]\n와 같이 결정된다는 의미이다.\n- 이를 받아 들일 수 없는 사람도 있을 텐데 이는 미래가 고정되지 않고 불확실하다고 생각하기 때문이다. 예를들어 \\(m\\)시점의 삼성전자 주가가 \\(x_m=45,400\\)원이라고 가정하자. 그렇다면 다음날 삼성전자 주가 \\(x_{m+1}\\)은 \\(38,590\\sim 52,210\\) 사이의 어떤 값이다. 주가의 최소단위는 1원 단위이므로 삼성전자 주가를 기준으로 보면 내일은 총 \\(52,210-38,590=13,620\\)개의 새로운 미래가 가능하다. 미래는 언제가 열려있기에 하나의 평행세계가 결정된다고 그 다음을 항상 예측할 수 있는 것은 아니라 주장할 수 있다.\n- 이는 관점의 차이인데 어차피 두 관점은 같다. 왜냐하면 위의 주장은 다시 처음부터\n\\[14,000,605 \\times 13,620\\]\n개의 평행우주를 고려했다고 생각하면 해결된다. 즉 \\(m\\)개의 삼성전자 주가를 모두 파악하기 위해 \\(14,000,605\\)의 평행우주를 고려했고 다시 \\(m+1\\)의 삼성전자 주가를 모두 \\(14,000,605\\times 13,620\\)개의 평행우주를 고려했다고 주장하면 된다. 평행우주의 수는 편의에 따라 무한히 늘릴 수 있다.\n- 다시 본론으로 돌아오자. 아래과 같이 표현할 수도 있다.\n\\[X_m(\\omega)=X(\\omega,m)\\]\n예를들어 777번째 평행우주에서 시점 \\(m=5\\)에 해당하는 삼성전자 주가는\n\\[X_5(\\omega_{777})=X(\\omega_{777},5)\\]\n와 같이 정의할 수 있다.\n- 확률변수는 \\(\\Omega\\)의 원소 \\(\\omega\\)에 하나의 실수값이 대응한다. 하지만 확률벡터는 원소 \\(\\omega\\)에 두 개 이상의 실수값이 대응한다. 상상력을 발휘하면 하나의 원소 \\(\\omega\\)에 무한개의 실수값을 대응시키는 어떠한 존재를 생각할 수 있다. 즉 하나의 원소 \\(\\omega\\)에 대응하는 realization이 함수인 경우를 상상할 수 있다. 이를 확률과정이라고 한다. 확률과정은 아래와 같이 표현할 수 있다.\n\\[X(\\omega,t)=x(t)\\]\n즉 \\(x(t)\\)는 고정된 \\(\\omega\\)에 대한 realization이다. 이를 특별히 sample path 혹은 sample function이라고 부른다. \\(X(\\omega,t)\\)는 상당히 오묘한데 \\(t\\)를 fix하면 확률변수가 되고 \\(\\omega\\)를 fix하면 sample path가 된다. 확률변수를 나타낼때 \\(X(\\omega)\\)를 줄여서 \\(X\\)로 표현하듯이 확률과정을 나타낼때에도 \\(X(\\omega,t)\\)를 줄여 간단히 \\(X(t)\\)라고 쓴다.\n- 교재의 표현을 정리하면 아래와 같다.\n\n확률과정(stochastic process): \\(X(t)\\)\n확률법칙(probability law): 확률. 즉 \\(P:{\\cal F}\\to [0,1]\\).\n확률공간(probability space): \\((\\Omega,{\\cal F},P)\\).\n확률변수(random variable): \\(X\\).\n확률변수들의 모임(random vector,stochastic process):** \\({\\boldsymbol X}\\), \\(X(t)\\)\n집합 \\(T\\)(index set): 확률변수들의 모임 즉 확률벡터 혹은 확률과정에서 확률변수의 index를 표시해주는 집합. 따라서 집합 \\(T\\)의 원소가 하나만 있으면 확률변수를 의미하고, 집합 \\(T\\)의 원소가 유한개이면 확률벡터, 집합 \\(T\\)의 원소가 무한개이면 확률과정이라고 말한다.\n연속형 확률과정: 집합 \\(T\\)가 \\((0,\\infty)\\)와 같이 구간으로 표현된 경우의 확률과정. 즉 집합 \\(T\\)의 원소가 셀 수 없는 무한 (uncountable many)일 경우의 확률과정.\n이산형 확률과정: 집합 \\(T\\)가 \\(\\{1,2,\\dots,\\}\\) 혹은 \\(\\{\\dots,-1,0,1,2,3,\\dots\\}\\) 와 같이 셀 수 있는 무한 (countable many)로 표현된 경우의 확률과정. 이는 무한차원을 가지는 확률벡터로 이해할 수도 있고, 연속형 확률과정의 샘플버전으로 이해할 수도 있다. 우리가 다루는 교재의 시계열은 이산형 확률과정을 의미한다.\n실현값(realization): 확률변수, 확률벡터, 확률과정 따위의 실현값. 즉 \\(\\omega\\)가 고정되었을 경우 맵핑되는 결과. 즉 \\(x\\), \\((x_1,\\dots,x_m)\\) 혹은 \\(x(t)\\).\n표본통로(sample path): 확률과정의 실현값을 특별히 부르는 말. 즉 \\(x(t)\\).\n\n교재의 표현중 “우리가 만일 과거로 돌아갈 수 있어 반복관측을 할 수 있다면 현재 관측된 시계열은 무한히 많이 관측 가능한 확률변수들의 모임 중에서 특별히 실현된 하나에 해당할 것이다.” 의 의미는 “우리가 임의의 평행세계 중 하나로 자유롭게 이동할 수 있어 각 평행세계에서 시계열을 반복관측 할 수 있다고 하자. 그렇다면 현재 우리가 세계에서 관측된 시계열은 무한히 많은 평행세계 중 특별히 실현된 하나에 해당할 뿐이다.” 라는 의미이다. 또한 교재의 표현 중 “지구과학에서 다루는 확률과정에서의 집합 \\(T\\)처럼 지구표현의 위치 또는 어느 지역의 위치 등을 나타내는 위치의 집합인 경우” 는 index set \\(T\\)가\n\\[T=\\{2019-03-20,2019-03-21,\\dots, \\}\\]\n와 같이 시간순서로 나열된것이 아니라\n\\[T=\\{(20,29),(41,30),\\dots, \\}\\]\n아래와 같이 (위도,경도)와 같은 공간인덱스로 나열된 경우를 의미한다. 시계열은 자료가 가까운 시간끼리 상관관계가 있는 것처럼, 지구과학에서 다루는 자료는 가까운 공간끼리 상관관계가 있다. 예를들어 2019-03-20의 삼성전자 주식값과 2019-03-21의 삼성전자 주식값은 서로 연관이 있는것 처럼 (위도 30, 경도 29) 에서의 기온과 (위도 30, 경도 28) 에서의 기온도 서로 연관이 있다.\n\n\n정상성을 왜 가정해야 하는가?\n- \\(X(t)\\), \\(X_t(\\omega)\\), \\(X(\\omega,t)\\), \\(X(\\omega; t)\\), \\(X(t;\\omega)\\), \\(\\{X(\\omega,t): t \\in T\\}\\), \\(\\{X(\\omega,t)\\}\\) 를 확률과정이라고 하자. 만약에 여러 \\(\\omega\\)를 고려하면 여러 뭉치의 sample path가 얻어진다. 그럼 모든 \\(\\omega\\)에 대하여 가능한 sample path를 모두 모은 집합을 생각할 수 있는데 이러한 집합을 앙상블(ensemble)이라고 한다. 즉 앙상블은 아래처럼 각 원소가 함수인 집합이다.\n\n\\(\\Big\\{ \\{X(\\omega_1,t): t \\in T\\},\\{X(\\omega_2,t): t \\in T\\}, \\dots \\Big\\}\\)\n\\(\\Big\\{ X(\\omega_1,t),X(\\omega_2,t), \\dots \\Big\\}\\)\n각 평행세계 \\(\\omega_1,\\omega_2,\\dots\\) 를 자유롭게 선택하여 관측할 수 있는 존재를 상상하자. 편의상 이러한 존재를 “신”이라고 부르자. 신이 \\(\\omega_1,\\dots,\\omega_{776}\\)개의 평행우주에 대하여 삼성전자 주식을 모두 관측하였다고 하자. 하지만 신은 우리가 살고 있는 평행우주 (예를들면 \\(\\omega_{777}\\)) 에 대한 결과는 아직 관측하지 않았다고 하자. 이 존재에게 \\(m\\)시점의 삼성전자 주식이 얼마냐고 묻는다면 신은 뭐라고 대답할까? 아마도 776개의 평행우주에서 관측한 삼성전자 주식의 값을 평균내서 대답할 것이다. 즉 아래와 같이 추론할 것이다.\n예측값 \\(= \\frac{1}{776}\\sum_{i=1}^{776} X(\\omega_i,m)\\)\n\n이 추론은 매우 합리적이다. 그리고 이 추론은 신이 더 많은 평행세계를 관측할수록 정확도가 올라간다. 만약에 신이 가능한 모든 앙상블을 관측하여 \\(m\\)시점의 삼성전자 주식값을 평균냈다고 하자. 이 값을 \\(m\\)시점의 ensemble average라 부른다. 시점 \\(m\\)의 앙상블평균은 아래와 같이 친숙한 기호로 표현할 수 있다.\n\\[E(X_m)=\\int_{\\omega \\in \\Omega}X_m(\\omega)dP=\\int_{-\\infty}^{\\infty}x_mf(x)dx\\]\n여기에서 \\(f(x)\\)는 확률변수 \\(X_m\\)의 pdf이다.\n- 우리의 목표는 결국 신만이 알고 있을 \\(E(X_m)\\)을 추론하는 것이다. 하지만 시계열 자료에서는 \\(E(X_m)\\)을 적절히 추론하는게 매우 어려운데 이는 시계열분석의 경우 분석의 대상이 되는 자료가 반복관측될 수 없기 때문이다. (교재 5장 intro 맨 마지막 부분 참고.) 즉 지금까지 수행하였던 분석 회귀분석등은 여러개의 realization이 존재했다. 하지만 시계열 분석의 경우 오직 하나의 realization만이 존재하기 때문에 어떠한 분석도 수행할 수 없다.\n- (해결책) 만약 관측된 하나의 realization \\(x(t)\\)를 여러개의 realization의 묶음으로 볼 수 있다면 어떨까? 예를들어 동전을 3번 던지는 경우를 생각하자. 가능한 평행세계는 모두 8개이며 각각 아래와 같다.\n\n\\(\\Omega=\\{\\omega_1,\\dots,\\omega_8\\}=\\{HHH,HHT,\\dots,TTT\\}\\)\n\n이제 아래와 같은 맵핑규칙을 고려하자.\n\n\\(\\boldsymbol{X}(HHH)=(X_1,X_2,X_3)(HHH)=(0,0,0)\\)\n\\(\\boldsymbol{X}(TTT)=(X_1,X_2,X_3)(TTT)=(1,1,1)\\)\n\n\\(\\omega\\)를 3차원 벡터로 연결하였으므로 \\({\\boldsymbol X}\\)는 확률벡터가 된다. 동전을 무한번 던졌다고 가정하면 가능한 평행세계는 무한개이다. 따라서 이 경우\n\\[\\{X_t: t=1,2,\\dots,\\}\\]\n는 이산형확률과정이 된다. (이러한 과정을 베르누이 확률과정이라고 부른다.) 우리가 이 중 $t^* $번째 시점에서 동전이 앞면이 나올지 뒷면이 나올지 알고 싶다고 하자. 직관적으로 앞면이 나올 확률과 뒷면이 나올 확률은 같으므로 \\(E(X_{t^* })=\\frac{1}{2}\\times 0 +\\frac{1}{2}\\times 1 =\\frac{1}{2}\\)임을 알 수 있다.\n- 어떤 사람이 정말 \\(E(X_{t^* })=\\frac{1}{2}\\)이냐고 그렇게 생각한 근거가 뭐냐고 따질때 방어할 수 있는 논리가 무엇일까? 만약에 우리가 \\(n\\)개의 평행세계를 각각의 평행세계에서 $t^* $시점에 해당하는 realization을 평균내어 추정했다고 하면 될 것이다. (그리고 관측한 평행세계가 많을 수록 즉 \\(n\\to\\infty\\) 일수록 그 추정치가 \\(\\frac{1}{2}\\)로 수렴함을 보이면 설득될 것이다.)\n- 그런데 우리는 각 평행세계를 이동할 수 없으므로 이는 불가능하다. 즉 항상 \\(n=1\\)이다. 하지만 이 예제의 경우 쉽게 대안을 찾을 수 있는데 대안은 바로 관측된 값들을 평균내는 것이다. 즉 순차적으로 실험을 하여 \\(t^* - 1\\)시점까지의 자료\n\\[x_1,x_2,x_3,\\dots,x_{t^* -1}\\]\n을 확보했다고 하자. 그러면 \\(E(X_{t^* })\\)의 값을 단순히 아래와 같이 추론할 수 있다.\n\\[\\frac{1}{t^* -1} \\sum_{i=1}^{t^* -1 } x_i\\]\n이러한 평균을 time average라고 한다. 직관적으로 이 추론은 매우 합리적으로 느껴지는데 그 이유는 우리가 \\(X_1,X_2,\\dots,\\)이 i.i.d.임을 이해하고 있기 때문이다.\n- 결국 어떠한 이산형확률과정을 구성하는 각 확률변수들이 i.i.d.임을 가정한다면 (이를 백색잡음과정이라고 한다, 교재 5.2.1절 참고) 단순히 time average로 ensemble average를 추론할 수 있다. 이는 매우 당연하지만 놀라울 정도로 쓸모없는 결과인데 사실 대부분의 시계열자료는 i.i.d.를 만족하지 않기 때문이다. (이것이 만족되면 회귀분석을 하면 된다.) 그래서 i.i.d 보다 좀 더 약화된 가정을 구하려는 노력이 필요한데 예를 들면 독립가정을 uncorrelatedness로 바꾸는 것 따위의 노력이다. 정상성 즉 stationary는 이러한 노력의 결정체라고 이해해도 무방하다. 추후에 엄밀한 정의를 다루겠지만 정상성은 i.i.d. 와 uncorrelatedness보다 훨씬 약한 가정이다. 즉 \\(X_t\\)와 \\(X_{t+1}\\)는 서로 독립일 필요도 없으며 서로 무상관일 필요도 없다.\n- 위의 논의를 잘 곱씹어보면 정상성이 가정되지 않으면 하나의 시계열을 여러 확률변수들의 묶음으로 파악하여 추론하는 형태의 접근법을 사용하는 것이 매우 어려움을 의미한다. 따라서 시계열 분석에서는 항상 관심의 대상이 되는 확률과정이 정상성을 가지는지 따져봐야 한다.\n\n\n\n\n\nFootnotes\n\n\n그 우리가 맨날 쓰는거..↩︎\n\\(\\mathbb{Q}_{\\sqrt{2}}\\)는 구간 \\(\\big[\\sqrt{2},~~ \\sqrt{2}+\\pi\\big)\\)에 속하므로↩︎\n당연한거 아냐? \\(m(\\mathbb{Q})=\\alpha\\)이고 \\(\\mathbb{Q}_{\\sqrt{2}}\\)는 단지 \\(\\mathbb{Q}\\)를 \\(\\sqrt{2}\\)만큼 평행이동한 집합일 뿐이니까 길이는 변화없음↩︎"
  },
  {
    "objectID": "posts/1_Essays/2023-03-01-수통문제-Type1 Err, Type2 Err.html",
    "href": "posts/1_Essays/2023-03-01-수통문제-Type1 Err, Type2 Err.html",
    "title": "[Essays] 수통문제: type1 err, type2 err",
    "section": "",
    "text": "using Distributions, Plots\n\n(문제) \\(X_1,X_2\\)가 평균이 \\(\\theta\\)인 지수분포에서 추출한 랜덤표본이라고 하자. 가설 \\(H_0: \\theta=2\\) vs \\(H_1:\\theta=1\\) 에 대하여, \\(H_0\\)에 대한 기각영역을\n\\[\\frac{f(x_1;\\theta=2)f(x_2;\\theta=2)}{f(x_1;\\theta=1)f(x_2;\\theta=1)}<\\frac{1}{2}\\]\n와 같이 설정하자. 이와 같은 검정법에 대한 \\(\\alpha\\)와 \\(\\beta\\)를 구하라.\n(풀이)\n문제요약\n\n\\(f(x) = \\frac{1}{\\theta} \\exp(-\\frac{x}{\\theta})\\) -> 평균이 \\(\\theta\\) 인 지수분포\n검정통계량: \\(T=\\frac{f(x_1;2)f(x_2;2)}{f(x_1;1)f(x_2;1)}\\)\n\\(\\alpha = P(\\text{Reject $H_0$|$H_0$ is true}) = P(T<\\frac{1}{2} | \\text{$H_0$ is true})\\)\n\\(\\beta = P(\\text{Accept $H_0$|$H_1$ is true}) = P(T>\\frac{1}{2} | \\text{$H_1$ is true})\\)\n\n풀이시작\n\nT= x -> 0.5*exp(-0.5*x[1]) * 0.5*exp(-0.5*x[2])  / (exp(-x[1])*exp(-x[2]))\n\n#1 (generic function with 1 method)\n\n\n\\(\\alpha\\)를 구해보자. (시뮬)\n\nθ=2 \nx = rand(Exponential(θ),2)\n\n2-element Vector{Float64}:\n 1.4932782791687658\n 3.904496314340747\n\n\n\nT(x)\n\n3.715796051759978\n\n\n\nTs = [rand(Exponential(θ),2) |> T for i in 1:1400000]\nmean(Ts .< 1/2)\n\n0.1535007142857143\n\n\n\\(\\beta\\)를 구해보자. (시뮬)\n\nθ=1\nx = rand(Exponential(θ),2)\n\n2-element Vector{Float64}:\n 1.0915718974295616\n 3.322182470278192\n\n\n\nTs = [rand(Exponential(θ),2) |> T for i in 1:1400000]\nmean(Ts .> 1/2)\n\n0.5967985714285714\n\n\n\\(\\alpha\\)를 구해보자. (이론)\n\\(T(X_1,X_2) = \\frac{0.25\\exp(-0.5X_1 -0.5X_2)}{\\exp(-X_1-X_2)}=0.25\\exp(0.5X_1+0.5X_2)\\)\n$T(X_1,X_2)< (0.5X_1+0.5X_2) < 2 X_1+X_2< 2 $\n그런데 \\(X_1+X_2 \\sim \\chi^2(4)\\) under \\(H_0\\)\n\\(P(X_1+X_2 < 2\\ln2) = \\int_0^{2\\ln2} \\frac{1}{4\\Gamma(2)}x e^{-x/2}dx=\\int_0^{\\ln2} t e^{-t}dt=\\big[t(-e^{-t})-e^{-t}\\big]_0^{\\ln2}\\)\n\nt = log(2) \nu = t*(-exp(-t)) - exp(-t)\nt = 0\nl = t*(-exp(-t)) - exp(-t)\n\n-1.0\n\n\n\nu-l\n\n0.1534264097200273\n\n\n\\(\\beta\\)를 구해보자. (이론)\n$T(X_1,X_2)> (0.5X_1+0.5X_2) > 2 (X_1+X_2)> 4 $\n그런데 \\(2(X_1+X_2) \\sim \\chi^2(4)\\) under \\(H_1\\)\n\\(P(2(X_1+X_2) > 4\\ln2) = \\int_{4\\ln2}^{\\infty}\\frac{1}{4\\Gamma(2)}x e^{-x/2}dx=\\int_{2\\ln2}^{\\infty} t e^{-t}dt=\\big[t(-e^{-t})-e^{-t}\\big]_{2\\ln2}^{\\infty}\\)\n\nu = 0\nt = 2*log(2)\nl = t*(-exp(-t)) - exp(-t)\nu-l\n\n0.5965735902799727"
  },
  {
    "objectID": "3_hst.html",
    "href": "3_hst.html",
    "title": "HST",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJan 24, 2023\n\n\n[HST] CommunityDetection\n\n\n신록예찬\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "2_python.html",
    "href": "2_python.html",
    "title": "Python",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "2_reviews.html",
    "href": "2_reviews.html",
    "title": "Reviews",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "1_essays.html",
    "href": "1_essays.html",
    "title": "Essays",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nApr 18, 2023\n\n\n[Essays] 적분의 Notations\n\n\n신록예찬\n\n\n\n\nApr 13, 2023\n\n\n[Essays] 마코프체인 인트로\n\n\n신록예찬\n\n\n\n\nMar 1, 2023\n\n\n[Essays] 수통문제: type1 err, type2 err\n\n\n신록예찬\n\n\n\n\nFeb 9, 2023\n\n\n[Essays] 칸토어 집합, 칸토어 함수, 르벡분해\n\n\n신록예찬\n\n\n\n\nJan 20, 2023\n\n\n[Essays] 시계열의 주파수영역 분석\n\n\n신록예찬\n\n\n\n\nJan 20, 2023\n\n\n[Essays] 추정\n\n\n신록예찬\n\n\n\n\nJan 12, 2023\n\n\n[Essays] 토폴로지(1)\n\n\n신록예찬\n\n\n\n\nJan 11, 2023\n\n\n[Essays] 여러가지 부등식\n\n\n신록예찬\n\n\n\n\nJan 7, 2023\n\n\n[Essays] 해석학(1)\n\n\n신록예찬\n\n\n\n\nMar 12, 2020\n\n\n[Essays] 확률, 확률변수, 시계열, 정상성\n\n\n신록예찬\n\n\n\n\nApr 26, 2019\n\n\n[Essays] 퓨리에 변환\n\n\n신록예찬\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "4_notes.html",
    "href": "4_notes.html",
    "title": "Notes",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJan 8, 2000\n\n\n[Note] 깃(Git)\n\n\n신록예찬\n\n\n\n\nJan 7, 2000\n\n\n[Note] 줄리아 설치 및 실행\n\n\n신록예찬\n\n\n\n\nJan 6, 2000\n\n\n[Note] 주피터랩: 설정 및 몇가지 팁\n\n\n신록예찬\n\n\n\n\nJan 4, 2000\n\n\n[Note] 우분투 익히기\n\n\n신록예찬\n\n\n\n\nJan 1, 2000\n\n\n[Note] 우분투 포맷 및 개발용 서버 셋팅\n\n\n신록예찬\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "2_cgsp.html",
    "href": "2_cgsp.html",
    "title": "CGSP",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJan 15, 2023\n\n\n[CGSP] Chap 12.4: Node Subsampling for PSD Estimation\n\n\n신록예찬\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "신록예찬's Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJan 1, 2099\n\n\n연습장1\n\n\n최규빈\n\n\n\n\nJan 1, 2099\n\n\n연습장2\n\n\n신록예찬\n\n\n\n\nMay 19, 2023\n\n\n[BORAM] 신용카드 거래 사기탐지 Try2\n\n\n신록예찬\n\n\n\n\nMay 12, 2023\n\n\n[BORAM] 신용카드 거래 사기탐지 Try1\n\n\n신록예찬\n\n\n\n\nApr 18, 2023\n\n\n[Essays] 적분의 Notations\n\n\n신록예찬\n\n\n\n\nApr 13, 2023\n\n\n[Essays] 마코프체인 인트로\n\n\n신록예찬\n\n\n\n\nApr 3, 2023\n\n\n[SOLAR] 일사량자료정리\n\n\n임지윤, 신록예찬\n\n\n\n\nMar 18, 2023\n\n\n[IT-STGCN] SimualtionPlanner-Tutorial\n\n\nSEOYEON CHOI\n\n\n\n\nMar 1, 2023\n\n\n[Essays] 수통문제: type1 err, type2 err\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap2: 그래프 머신러닝 - Node2Vec, Edge2Vec, Graph2Vec\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap3: 비지도 그래프 학습 - AutoEncoder\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap3: 비지도 그래프 학습 - Graph Neural Network\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap3: 비지도 그래프 학습 - Shallow_Embeddings\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap3: 비지도 그래프 학습 - Structural Deep Network Embedding\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap4: 지도 그래프 학습 - Graph CNN\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap4: 지도 그래프 학습 - 그래프 정규화 방법\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap4: 지도 그래프 학습 - 얕은 임베딩 방법\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap4: 지도 그래프 학습 - 특징 기반 방법\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap5: 응용문제 - 누락된 링크예측\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap5: 응용문제 - 커뮤니티 감지\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap6: 소셜네트워크 그래프\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap7: Graph Neural Network Topic Classifier\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap7: Shallow-Learning Topic Modelling\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap8: 신용카드 거래에 대한 그래프 분석\n\n\n신록예찬\n\n\n\n\nFeb 10, 2023\n\n\n[GML] Chap9: Graph Database Connection\n\n\n신록예찬\n\n\n\n\nFeb 9, 2023\n\n\n[Essays] 칸토어 집합, 칸토어 함수, 르벡분해\n\n\n신록예찬\n\n\n\n\nJan 24, 2023\n\n\n[HST] CommunityDetection\n\n\n신록예찬\n\n\n\n\nJan 20, 2023\n\n\n[Essays] 시계열의 주파수영역 분석\n\n\n신록예찬\n\n\n\n\nJan 20, 2023\n\n\n[Essays] 추정\n\n\n신록예찬\n\n\n\n\nJan 15, 2023\n\n\n[CGSP] Chap 12.4: Node Subsampling for PSD Estimation\n\n\n신록예찬\n\n\n\n\nJan 12, 2023\n\n\n[Essays] 토폴로지(1)\n\n\n신록예찬\n\n\n\n\nJan 11, 2023\n\n\n[Essays] 여러가지 부등식\n\n\n신록예찬\n\n\n\n\nJan 7, 2023\n\n\n[Essays] 해석학(1)\n\n\n신록예찬\n\n\n\n\nDec 30, 2022\n\n\n[IT-STGCN] STGCN: Toy Example\n\n\n신록예찬\n\n\n\n\n\nDec 29, 2022\n\n\n[IT-STGCN] Tables\n\n\n신록예찬\n\n\n\n\nSep 21, 2022\n\n\n[PL] Lesson1: 단순선형회귀\n\n\n신록예찬\n\n\n\n\nMar 12, 2020\n\n\n[Essays] 확률, 확률변수, 시계열, 정상성\n\n\n신록예찬\n\n\n\n\nApr 26, 2019\n\n\n[Essays] 퓨리에 변환\n\n\n신록예찬\n\n\n\n\nJan 8, 2000\n\n\n[Note] 깃(Git)\n\n\n신록예찬\n\n\n\n\nJan 7, 2000\n\n\n[Note] 줄리아 설치 및 실행\n\n\n신록예찬\n\n\n\n\nJan 6, 2000\n\n\n[Note] 주피터랩: 설정 및 몇가지 팁\n\n\n신록예찬\n\n\n\n\nJan 4, 2000\n\n\n[Note] 우분투 익히기\n\n\n신록예찬\n\n\n\n\nJan 1, 2000\n\n\n[Note] 우분투 포맷 및 개발용 서버 셋팅\n\n\n신록예찬\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "3_itstgcn.html",
    "href": "3_itstgcn.html",
    "title": "IT-STGCN",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nMar 18, 2023\n\n\n[IT-STGCN] SimualtionPlanner-Tutorial\n\n\nSEOYEON CHOI\n\n\n\n\nDec 30, 2022\n\n\n[IT-STGCN] STGCN: Toy Example\n\n\n신록예찬\n\n\n\n\n\nDec 29, 2022\n\n\n[IT-STGCN] Tables\n\n\n신록예찬\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "3_solar.html",
    "href": "3_solar.html",
    "title": "SOLAR",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nApr 3, 2023\n\n\n[SOLAR] 일사량자료정리\n\n\n임지윤, 신록예찬\n\n\n\n\n\n\nNo matching items"
  }
]