[
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html",
    "title": "Numpy",
    "section": "",
    "text": "import numpy as np"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#선언",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#선언",
    "title": "Numpy",
    "section": "선언",
    "text": "선언\n\na=np.array([1,2,3]) # list를 선언하고 np.array화 \nl=[1,2,3]"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#기본연산-브로드캐스팅",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#기본연산-브로드캐스팅",
    "title": "Numpy",
    "section": "기본연산 브로드캐스팅",
    "text": "기본연산 브로드캐스팅\n\na+1\n\narray([2, 3, 4])\n\n\n\nl+1\n\nTypeError: can only concatenate list (not \"int\") to list\n\n\n\na*2\n\n\nl*2\n\n\na/2\n\narray([0.5, 1. , 1.5])\n\n\n\nl/2\n\nTypeError: unsupported operand type(s) for /: 'list' and 'int'\n\n\n\na-2\n\narray([-1,  0,  1])\n\n\n\nl-2\n\nTypeError: unsupported operand type(s) for -: 'list' and 'int'\n\n\n\na**2\n\narray([1, 4, 9])\n\n\n\nl**2\n\nTypeError: unsupported operand type(s) for ** or pow(): 'list' and 'int'\n\n\n\na%2 # %2 = 2로 나눈 나머지를 리턴\n\narray([1, 0, 1])\n\n\n\nl%2\n\nTypeError: unsupported operand type(s) for %: 'list' and 'int'"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#기타수학연산지원",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#기타수학연산지원",
    "title": "Numpy",
    "section": "기타수학연산지원",
    "text": "기타수학연산지원\n\nnp.sqrt(a), np.sqrt(l)\n\n(array([1.        , 1.41421356, 1.73205081]),\n array([1.        , 1.41421356, 1.73205081]))\n\n\n\nnp.log(a), np.log(l)\n\n(array([0.        , 0.69314718, 1.09861229]),\n array([0.        , 0.69314718, 1.09861229]))\n\n\n\nnp.exp(a), np.exp(l)\n\n(array([ 2.71828183,  7.3890561 , 20.08553692]),\n array([ 2.71828183,  7.3890561 , 20.08553692]))\n\n\n\nnp.sin(a), np.sin(l)\n\n(array([0.84147098, 0.90929743, 0.14112001]),\n array([0.84147098, 0.90929743, 0.14112001]))"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#인덱싱-1차원",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#인덱싱-1차원",
    "title": "Numpy",
    "section": "인덱싱 1차원",
    "text": "인덱싱 1차원\n- 선언\n\nl=[11,22,33,44,55,66]\na=np.array(l)\n\n- 인덱스로 접근\n\nl[0],l[1],l[2],l[3],l[4],l[5]\n\n(11, 22, 33, 44, 55, 66)\n\n\n\na[0],a[1],a[2],a[3],a[4],a[5]\n\n(11, 22, 33, 44, 55, 66)\n\n\n- :이용 (슬라이싱)\n\nl[2:4] ## index=2에서 출발해서 index=4에서 멈춘다. (4는 포함하지 않음) \n\n[33, 44]\n\n\n\na[2:4]\n\narray([33, 44])\n\n\n- 정수배열에 의한 인덱싱\n\na\n\narray([11, 22, 33, 44, 55, 66])\n\n\n\na[[0,2,4]]\n\narray([11, 33, 55])\n\n\n- 부울값에 의한 인덱싱\n\na\n\narray([11, 22, 33, 44, 55, 66])\n\n\n\na[[True,False,True,False,True,False]]\n\narray([11, 33, 55])\n\n\n응용하면?\n\na < 33\n\narray([ True,  True, False, False, False, False])\n\n\n\na[a<33]\n\narray([11, 22])\n\n\n리스트는 불가능\n\nl\n\n[11, 22, 33, 44, 55, 66]\n\n\n\nl<33 ## 여기서부터 에러남 \n\nTypeError: '<' not supported between instances of 'list' and 'int'"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#인덱싱-2차원",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#인덱싱-2차원",
    "title": "Numpy",
    "section": "인덱싱 2차원",
    "text": "인덱싱 2차원\n- 중첩리스트와 2차원 np.array 선언\n\nA = [[1,2,3,4],[-1,-2,-3,-4],[5,6,7,8],[-5,-6,-7,-8]]\nA2 = np.array(A)\n\n\nA\n\n[[1, 2, 3, 4], [-1, -2, -3, -4], [5, 6, 7, 8], [-5, -6, -7, -8]]\n\n\n\nA2\n\narray([[ 1,  2,  3,  4],\n       [-1, -2, -3, -4],\n       [ 5,  6,  7,  8],\n       [-5, -6, -7, -8]])\n\n\n- A에서 원소인덱싱\n\nA[0][0] # (1,1)의 원소 \n\n1\n\n\n\nA[1][2] # (2,3)의 원소 \n\n-3\n\n\n\nA[-1][0] # (4,1)의 원소 \n\n-5\n\n\n- A2에서 원소인덱싱\n\nA2[0][0] # (1,1)의 원소 \n\n1\n\n\n\nA2[1][2] # (2,3)의 원소 \n\n-3\n\n\n\nA2[-1][0] # (4,1)의 원소 \n\n-5\n\n\n- 이렇게 해도된다? (넘파이에서 제시하는 신기술, R에서는 기본탑재기능, 이중 list는 불가능)\n\nA2[0,0] # (1,1)의 원소 \n\n1\n\n\n\nA2[1,2] # (2,3)의 원소 \n\n-3\n\n\n\nA2[-1,0] # (4,1)의 원소\n\n-5\n\n\n- 슬라이싱!\n\nA2\n\narray([[ 1,  2,  3,  4],\n       [-1, -2, -3, -4],\n       [ 5,  6,  7,  8],\n       [-5, -6, -7, -8]])\n\n\n\nA2[0,:] ## 1행\n\narray([1, 2, 3, 4])\n\n\n\nA2[0] ## 1행\n\narray([1, 2, 3, 4])\n\n\n\nA2[[0,2],:] # 1,3행 \n\narray([[1, 2, 3, 4],\n       [5, 6, 7, 8]])\n\n\n\nA2[[0,2]] # 1,3 행 \n\narray([[1, 2, 3, 4],\n       [5, 6, 7, 8]])\n\n\n\nA2[:,0] # 1열 \n\narray([ 1, -1,  5, -5])\n\n\n\nA2[:,[0,2]] # 1,3열 \n\narray([[ 1,  3],\n       [-1, -3],\n       [ 5,  7],\n       [-5, -7]])"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#차원-배열의-선언",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#차원-배열의-선언",
    "title": "Numpy",
    "section": "1차원 배열의 선언",
    "text": "1차원 배열의 선언\n- 리스트나 튜플을 선언하고 형변환\n\nnp.array((1,2,3))\n\narray([1, 2, 3])\n\n\n\nnp.array([1,2,3])\n\narray([1, 2, 3])\n\n\n- range()를 이용하여 만들고 형변환\n\nnp.array(range(12))\n\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n\n\n- np.zeros, np.ones\n\nnp.zeros(3)\n\narray([0., 0., 0.])\n\n\n\nnp.ones(3)\n\narray([1., 1., 1.])\n\n\n- np.linspace\n\nnp.linspace(0,1,12)\n\narray([0.        , 0.09090909, 0.18181818, 0.27272727, 0.36363636,\n       0.45454545, 0.54545455, 0.63636364, 0.72727273, 0.81818182,\n       0.90909091, 1.        ])\n\n\n- np.arange\n\nnp.arange(5)\n\narray([0, 1, 2, 3, 4])"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#reshape",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#reshape",
    "title": "Numpy",
    "section": "reshape",
    "text": "reshape\n- reshape: ndarray의 특수한 기능\n\nl=[11,22,33,44,55,66]\na=np.array(l)\n\n\na ## 길이가 6인 벡터\n\narray([11, 22, 33, 44, 55, 66])\n\n\n\na.reshape(2,3)\n\narray([[11, 22, 33],\n       [44, 55, 66]])\n\n\n\na ## reshape은 a자체를 변화시키진 않음\n\narray([11, 22, 33, 44, 55, 66])\n\n\n\nb = a.reshape(3,2)\nb\n\narray([[11, 22],\n       [33, 44],\n       [55, 66]])\n\n\n- 다시 b를 a처럼 바꾸고싶다면?\n\nb\n\narray([[11, 22],\n       [33, 44],\n       [55, 66]])\n\n\n\nb.reshape(6)\n\narray([11, 22, 33, 44, 55, 66])\n\n\n- reshape with -1\n\na=np.array(range(24))\na\n\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23])\n\n\n\na.reshape(2,-1)\n\narray([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],\n       [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]])\n\n\n\na.reshape(3,-1)\n\narray([[ 0,  1,  2,  3,  4,  5,  6,  7],\n       [ 8,  9, 10, 11, 12, 13, 14, 15],\n       [16, 17, 18, 19, 20, 21, 22, 23]])\n\n\n\na.reshape(4,-1)\n\narray([[ 0,  1,  2,  3,  4,  5],\n       [ 6,  7,  8,  9, 10, 11],\n       [12, 13, 14, 15, 16, 17],\n       [18, 19, 20, 21, 22, 23]])\n\n\n\na.reshape(6,-1)\n\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11],\n       [12, 13, 14, 15],\n       [16, 17, 18, 19],\n       [20, 21, 22, 23]])\n\n\n\na.reshape(8,-1)\n\narray([[ 0,  1,  2],\n       [ 3,  4,  5],\n       [ 6,  7,  8],\n       [ 9, 10, 11],\n       [12, 13, 14],\n       [15, 16, 17],\n       [18, 19, 20],\n       [21, 22, 23]])\n\n\n\na.reshape(12,-1)\n\narray([[ 0,  1],\n       [ 2,  3],\n       [ 4,  5],\n       [ 6,  7],\n       [ 8,  9],\n       [10, 11],\n       [12, 13],\n       [14, 15],\n       [16, 17],\n       [18, 19],\n       [20, 21],\n       [22, 23]])\n\n\n\na=a.reshape(12,-1)\na\n\narray([[ 0,  1],\n       [ 2,  3],\n       [ 4,  5],\n       [ 6,  7],\n       [ 8,  9],\n       [10, 11],\n       [12, 13],\n       [14, 15],\n       [16, 17],\n       [18, 19],\n       [20, 21],\n       [22, 23]])\n\n\n\na.reshape(-1)\n\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23])"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#차원-배열의-선언-1",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#차원-배열의-선언-1",
    "title": "Numpy",
    "section": "2차원 배열의 선언",
    "text": "2차원 배열의 선언\n\nnp.zeros((3,3)) # np.zeros([3,3])\n\narray([[0., 0., 0.],\n       [0., 0., 0.],\n       [0., 0., 0.]])\n\n\n\nnp.ones((3,3))\n\narray([[1., 1., 1.],\n       [1., 1., 1.],\n       [1., 1., 1.]])\n\n\n\nnp.eye(3)\n\narray([[1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.]])\n\n\n\nnp.diag([1,2,3]) # np.diag((1,2,3))\n\narray([[1, 0, 0],\n       [0, 2, 0],\n       [0, 0, 3]])"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#랜덤으로-생성",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#랜덤으로-생성",
    "title": "Numpy",
    "section": "랜덤으로 생성",
    "text": "랜덤으로 생성\n\nnp.random.randn(10) # 표준정규분포에서 10개 뽑음\n\narray([ 1.08324716,  0.62817097,  0.12847717, -0.04525161,  0.96142135,\n       -1.21223986, -0.17343561,  0.5136161 , -1.26171776,  0.80209933])\n\n\n\nnp.random.rand(10) # 0~1사이에서 10개 뽑음 \n\narray([2.51475291e-05, 4.73976026e-01, 7.39149130e-01, 7.14419133e-01,\n       6.97771860e-01, 3.97994936e-01, 6.77282056e-01, 7.05790725e-01,\n       2.88589932e-01, 7.57068891e-01])\n\n\n\nnp.random.randn(4).reshape(2,2)\n\narray([[ 0.32819241,  0.93190348],\n       [-0.06517115, -0.83736631]])\n\n\n\nnp.random.randn(6).reshape(3,2)\n\narray([[-1.23749937, -0.58528095],\n       [ 1.14685968, -1.30696566],\n       [ 1.38417905, -0.94795928]])"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#행렬",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#행렬",
    "title": "Numpy",
    "section": "행렬",
    "text": "행렬\n\nA= np.array(range(4)).reshape(2,2)\nA\n\narray([[0, 1],\n       [2, 3]])\n\n\n\nA.T # 전치행렬 \n\narray([[0, 2],\n       [1, 3]])\n\n\n\nnp.linalg.inv(A) # 역행렬 \n\narray([[-1.5,  0.5],\n       [ 1. ,  0. ]])\n\n\n\nA@np.linalg.inv(A) # 행렬곱 \n\narray([[1., 0.],\n       [0., 1.]])"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#차원-배열과-연립1차방정식",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#차원-배열과-연립1차방정식",
    "title": "Numpy",
    "section": "2차원 배열과 연립1차방정식",
    "text": "2차원 배열과 연립1차방정식\n- 아래의 연립방정식 고려\n\\(\\begin{cases} y + z + w= 3 \\\\ x + z + w= 3 \\\\ x + y + w= 3 \\\\ x + y + z= 3 \\\\ \\end{cases}\\)\n- 행렬표현은?\n\\(\\begin{bmatrix} 0 & 1 & 1 & 1 \\\\ 1 & 0 & 1 & 1 \\\\ 1 & 1 & 0 & 1 \\\\ 1 & 1 & 1 & 0 \\\\ \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\\\ z \\\\ w \\end{bmatrix} = \\begin{bmatrix} 3 \\\\ 3 \\\\ 3 \\\\ 3 \\end{bmatrix}\\)\n- 풀이\n\nA = np.array([[0,1,1,1],[1,0,1,1],[1,1,0,1],[1,1,1,0]])\nA\n\narray([[0, 1, 1, 1],\n       [1, 0, 1, 1],\n       [1, 1, 0, 1],\n       [1, 1, 1, 0]])\n\n\n\nb=np.array([3,3,3,3]).reshape(4,1)\nb\n\narray([[3],\n       [3],\n       [3],\n       [3]])\n\n\n\nnp.linalg.inv(A) @ b\n\narray([[1.],\n       [1.],\n       [1.],\n       [1.]])\n\n\n- 다른풀이\nb를 아래와 같이 만들어도 된다.\n\nb=np.array([3,3,3,3])\nb\n\narray([3, 3, 3, 3])\n\n\n\nnp.linalg.inv(A) @ b\n\narray([1., 1., 1., 1.])"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#의-유연성",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#의-유연성",
    "title": "Numpy",
    "section": "@의 유연성",
    "text": "@의 유연성\n- 엄밀하게는 아래의 행렬곱이 가능하다. - (2,2) @ (2,1) => (2,1) - (1,2) @ (2,2) => (1,2)\n\nA = np.array([1,2,3,4]).reshape(2,2) \nb = np.array([1,2]).reshape(2,1) \nA@b\n\narray([[ 5],\n       [11]])\n\n\n\nA.shape, b.shape, (A@b).shape\n\n((2, 2), (2, 1), (2, 1))\n\n\n\nA = np.array([1,2,3,4]).reshape(2,2) \nb = np.array([1,2]).reshape(1,2) \nb@A\n\narray([[ 7, 10]])\n\n\n\nA.shape, b.shape, (b@A).shape\n\n((2, 2), (1, 2), (1, 2))\n\n\n- 당연히 아래는 성립안한다.\n\nA = np.array([1,2,3,4]).reshape(2,2) \nb = np.array([1,2]).reshape(2,1) \nb@A\n\nValueError: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 2 is different from 1)\n\n\n\nA = np.array([1,2,3,4]).reshape(2,2) \nb = np.array([1,2]).reshape(1,2) \nA@b\n\nValueError: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 2)\n\n\n- 아래는 어떨까? 계산가능할까? \\(\\to\\) 모두 계산가능! - (2,) @ (2,2) => (2,) - (2,2) @ (2,) => (2,)\n\nA = np.array([1,2,3,4]).reshape(2,2) \nb = np.array([1,2])\nA@b\n\narray([ 5, 11])\n\n\n\nA.shape, b.shape, (A@b).shape\n\n((2, 2), (2,), (2,))\n\n\n\nb를 마치 (2,1)처럼 본다.\n\n\nA = np.array([1,2,3,4]).reshape(2,2) \nb = np.array([1,2])\nb@A\n\narray([ 7, 10])\n\n\n\nb.shape, A.shape, (b@A).shape\n\n((2,), (2, 2), (2,))\n\n\n\nb를 마치 (1,2)처럼 보는 느낌\n\n- 아래는 어떠할까?\n\nb1=np.array([1,2,3,4])\nb2=np.array([1,2,3,4])\nb1@b2\n\n30\n\n\n\nb1.shape,b2.shape,(b1@b2).shape\n\n((4,), (4,), ())\n\n\n\n(1,4) @ (4,1) 로 생각함\n\n\nb1=np.array([1,2,3,4])\nb2=np.array([1,2,3,4])\nb2@b1\n\n30\n\n\n\nb2.shape,b1.shape,(b2@b1).shape\n\n((4,), (4,), ())\n\n\n\n(1,4) @ (4,1) 로 생각함\n\n- 즉 마치 아래와 같이 해석한다.\n\nb1=np.array([1,2,3,4]).reshape(1,4)\nb2=np.array([1,2,3,4]).reshape(4,1)\nb1@b2\n\narray([[30]])\n\n\n\nb1.shape,b2.shape,(b1@b2).shape\n\n((1, 4), (4, 1), (1, 1))\n\n\n- 때로는 (4,1)@(1,4)와 같은 계산결과를 얻고 싶을 수 있는데 이때는 차원을 명시해야함\n\nb1=np.array([1,2,3,4]).reshape(4,1)\nb2=np.array([1,2,3,4]).reshape(1,4)\nb1@b2\n\narray([[ 1,  2,  3,  4],\n       [ 2,  4,  6,  8],\n       [ 3,  6,  9, 12],\n       [ 4,  8, 12, 16]])\n\n\n\nb1.shape, b2.shape, (b1@b2).shape\n\n((4, 1), (1, 4), (4, 4))\n\n\n- 아래도 가능\n\nb1=np.array([1,2,3,4])\nb2=np.array([1,2,3,4])"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#차원",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#차원",
    "title": "Numpy",
    "section": "차원",
    "text": "차원\n- 아래는 모두 미묘하게 다르다.\n\na= np.array(1) # 스칼라, 0d array\na, a.shape\n\n(array(1), ())\n\n\n\na= np.array([1]) #벡터, 1d array\na, a.shape\n\n(array([1]), (1,))\n\n\n\na= np.array([[1]]) #메트릭스, 2d array\na, a.shape\n\n(array([[1]]), (1, 1))\n\n\n\na= np.array([[[1]]]) #텐서, 3d array\na, a.shape\n\n(array([[[1]]]), (1, 1, 1))"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#np.concatenate",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#np.concatenate",
    "title": "Numpy",
    "section": "np.concatenate",
    "text": "np.concatenate\n- 기본예제\n\na=np.array([1,2])\nb=-a \n\n\nnp.concatenate([a,b])\n\narray([ 1,  2, -1, -2])\n\n\n- 응용\n\na=np.array([1,2])\nb=-a\nc=2*a\n\n\nnp.concatenate([a,b,c])\n\narray([ 1,  2, -1, -2,  2,  4])\n\n\n\n여기까진 딱히 칸캐터네이트의 메리트가 없어보이죠?\n리스트였다면 a+b+c 하면 되는 기능이니까?\n\n- 2array 에 적용해보자\n\na=np.array(range(4)).reshape(2,2) \nb=-a\n\n\nnp.concatenate([a,b])\n\narray([[ 0,  1],\n       [ 2,  3],\n       [ 0, -1],\n       [-2, -3]])\n\n\n- 옆으로 붙일려면?\n\nnp.concatenate([a,b],axis=1)\n\narray([[ 0,  1,  0, -1],\n       [ 2,  3, -2, -3]])\n\n\n- axis=1이 뭐지? axis=0,2 등을 치면 어떻게 될까?\n\nnp.concatenate([a,b],axis=0)\n\narray([[ 0,  1],\n       [ 2,  3],\n       [ 0, -1],\n       [-2, -3]])\n\n\n\n이건 그냥 np.concatenate([a,b])와 같다.\nnp.concatenate([a,b])는 np.concatenate([a,b],axis=0) 의 생략버전이군?\n\n\nnp.concatenate([a,b],axis=2)\n\nAxisError: axis 2 is out of bounds for array of dimension 2\n\n\n\n이런건 없다.\n\n- axis의 의미가 뭔지 좀 궁금함. 좀더 예제를 살펴보자.\n\na=np.array(range(2*3*4)).reshape(2,3,4)\na\n\narray([[[ 0,  1,  2,  3],\n        [ 4,  5,  6,  7],\n        [ 8,  9, 10, 11]],\n\n       [[12, 13, 14, 15],\n        [16, 17, 18, 19],\n        [20, 21, 22, 23]]])\n\n\n\nb=-a\nb\n\narray([[[  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11]],\n\n       [[-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23]]])\n\n\n\nnp.concatenate([a,b],axis=0)\n\narray([[[  0,   1,   2,   3],\n        [  4,   5,   6,   7],\n        [  8,   9,  10,  11]],\n\n       [[ 12,  13,  14,  15],\n        [ 16,  17,  18,  19],\n        [ 20,  21,  22,  23]],\n\n       [[  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11]],\n\n       [[-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23]]])\n\n\n\nnp.concatenate([a,b],axis=1)\n\narray([[[  0,   1,   2,   3],\n        [  4,   5,   6,   7],\n        [  8,   9,  10,  11],\n        [  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11]],\n\n       [[ 12,  13,  14,  15],\n        [ 16,  17,  18,  19],\n        [ 20,  21,  22,  23],\n        [-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23]]])\n\n\n\nnp.concatenate([a,b],axis=2)\n\narray([[[  0,   1,   2,   3,   0,  -1,  -2,  -3],\n        [  4,   5,   6,   7,  -4,  -5,  -6,  -7],\n        [  8,   9,  10,  11,  -8,  -9, -10, -11]],\n\n       [[ 12,  13,  14,  15, -12, -13, -14, -15],\n        [ 16,  17,  18,  19, -16, -17, -18, -19],\n        [ 20,  21,  22,  23, -20, -21, -22, -23]]])\n\n\n\n이번에는 2까지 된다?\n\n\nnp.concatenate([a,b],axis=3)\n\nAxisError: axis 3 is out of bounds for array of dimension 3\n\n\n\n3까지는 안된다?\n\n- 뭔가 나름의 방식으로 합쳐지는데 원리가 뭘까?\n(분석1) np.concatenate([a,b],axis=0)\n\na=np.array(range(2*3*4)).reshape(2,3,4)\nb=-a\n\n\na.shape,b.shape, np.concatenate([a,b],axis=0).shape\n\n((2, 3, 4), (2, 3, 4), (4, 3, 4))\n\n\n\n첫번째차원이 바뀌었다 => 첫번째 축이 바뀌었다 => axis=0 (파이썬은 0부터 시작하니까!)\n\n(분석2) np.concatenate([a,b],axis=1)\n\na=np.array(range(2*3*4)).reshape(2,3,4)\nb=-a\n\n\na.shape,b.shape, np.concatenate([a,b],axis=1).shape\n\n((2, 3, 4), (2, 3, 4), (2, 6, 4))\n\n\n\n두번째차원이 바뀌었다 => 두번째 축이 바뀌었다 => axis=1\n\n(분석3) np.concatenate([a,b],axis=2)\n\na=np.array(range(2*3*4)).reshape(2,3,4)\nb=-a\n\n\na.shape,b.shape, np.concatenate([a,b],axis=2).shape\n\n((2, 3, 4), (2, 3, 4), (2, 3, 8))\n\n\n\n세번째차원이 바뀌었다 => 세번째 축이 바뀌었다 => axis=2\n\n(분석4) np.concatenate([a,b],axis=3)\n\na=np.array(range(2*3*4)).reshape(2,3,4)\nb=-a\n\n\na.shape,b.shape, np.concatenate([a,b],axis=3).shape\n\nAxisError: axis 3 is out of bounds for array of dimension 3\n\n\n\n네번째 차원은 없다 => 네번째 축도 없다 => axis=3으로 하면 에러가 난다.\n\n(보너스) np.concatenate([a,b],axis=-1)\n\na=np.array(range(2*3*4)).reshape(2,3,4)\nb=-a\n\n\nnp.concatenate([a,b],axis=-1)\n\narray([[[  0,   1,   2,   3,   0,  -1,  -2,  -3],\n        [  4,   5,   6,   7,  -4,  -5,  -6,  -7],\n        [  8,   9,  10,  11,  -8,  -9, -10, -11]],\n\n       [[ 12,  13,  14,  15, -12, -13, -14, -15],\n        [ 16,  17,  18,  19, -16, -17, -18, -19],\n        [ 20,  21,  22,  23, -20, -21, -22, -23]]])\n\n\n\na.shape,b.shape,np.concatenate([a,b],axis=-1).shape\n\n((2, 3, 4), (2, 3, 4), (2, 3, 8))\n\n\n\n마지막 차원이 바뀌었다 => 마지막 축이 바뀌었다 => axis= -1\n\n(보너스2) np.concatenate([a,b],axis=-2)\n\na=np.array(range(2*3*4)).reshape(2,3,4)\nb=-a\n\n\nnp.concatenate([a,b],axis=-2)\n\narray([[[  0,   1,   2,   3],\n        [  4,   5,   6,   7],\n        [  8,   9,  10,  11],\n        [  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11]],\n\n       [[ 12,  13,  14,  15],\n        [ 16,  17,  18,  19],\n        [ 20,  21,  22,  23],\n        [-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23]]])\n\n\n\na.shape,b.shape,np.concatenate([a,b],axis=-2).shape\n\n((2, 3, 4), (2, 3, 4), (2, 6, 4))\n\n\n\n마지막에서 두번째 차원이 바뀌었다 => 마지막에서 두번째 축이 바뀌었다 => axis=-2\n\n- 0차원은 축이 없으므로 concatenate를 쓸 수 없다.\n\na=np.array(1)\nb=np.array(-1) \n\n\na.shape,b.shape\n\n((), ())\n\n\n\nnp.concatenate([a,b])\n\nValueError: zero-dimensional arrays cannot be concatenated\n\n\n- 꼭 a,b가 같은 차원일 필요는 없다.\n\na=np.array(range(4)).reshape(2,2)\nb=np.array(range(2)).reshape(2,1) \n\n\nnp.concatenate([a,b],axis=1)\n\narray([[0, 1, 0],\n       [2, 3, 1]])\n\n\n\na.shape,b.shape,np.concatenate([a,b],axis=1).shape\n\n((2, 2), (2, 1), (2, 3))"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#np.stack",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#np.stack",
    "title": "Numpy",
    "section": "np.stack",
    "text": "np.stack\n- 혹시 아래가 가능할까? - (3,) 결합 (3,) => (3,2)\n\na=np.array([1,2,3])\nb=-a\n\n\na,b\n\n(array([1, 2, 3]), array([-1, -2, -3]))\n\n\n\nnp.concatenate([a,b],axis=1)\n\nAxisError: axis 1 is out of bounds for array of dimension 1\n\n\n\n불가능\n\n- 아래와 같이 하면 가능하다.\n\na=np.array([1,2,3])\nb=-a\n\n\nnp.concatenate([a.reshape(3,1), b.reshape(3,1)],axis=1)\n\narray([[ 1, -1],\n       [ 2, -2],\n       [ 3, -3]])\n\n\n\n분석: (3) (3) => (3,1) (3,1) => (3,1) concat (3,1)\n\n- 이걸 줄여서 아래와 같이 할 수 있다.\n\nnp.stack([a, b],axis=1)\n\narray([[ 1, -1],\n       [ 2, -2],\n       [ 3, -3]])\n\n\n- 아래도 가능\n\nnp.stack([a,b],axis=0)\n\narray([[ 1,  2,  3],\n       [-1, -2, -3]])\n\n\n- 분석해보고 외우자\n(분석1)\n\na=np.array([1,2,3])\nb=-a\n\n\na.shape,b.shape,np.stack([a,b],axis=0).shape\n\n((3,), (3,), (2, 3))\n\n\n\n\n\n=> 첫위치에 축을 추가 (axis=0) => (1,3) (1,3) => (2,3)\n\n\n\n(분석2)\n\na=np.array([1,2,3])\nb=-a\n\n\na.shape,b.shape,np.stack([a,b],axis=1).shape\n\n((3,), (3,), (3, 2))\n\n\n\n\n\n=> 두번째 위치에 축을 추가 (axis=1) => (3,1) (3,1) => (3,2)\n\n\n\n- 고차원예제\n\na=np.arange(3*4*5).reshape(3,4,5)\nb=-a\n\n\na.shape,b.shape\n\n((3, 4, 5), (3, 4, 5))\n\n\n\nnp.stack([a,b],axis=0).shape # (3,4,5) => (1,3,4,5) // 첫위치에 축이 추가\n\n(2, 3, 4, 5)\n\n\n\nnp.stack([a,b],axis=1).shape # (3,4,5) => (3,1,4,5) // 두번쨰 위치에 축이 추가\n\n(3, 2, 4, 5)\n\n\n\nnp.stack([a,b],axis=2).shape # (3,4,5) => (3,4,1,5) // axis=2 \n\n(3, 4, 2, 5)\n\n\n\nnp.stack([a,b],axis=3).shape # (3,4,5) => (3,4,5,1) // axis=3\n\n(3, 4, 5, 2)\n\n\n\nnp.stack([a,b],axis=-1).shape # (3,4,5) => (3,4,5,1) // axis=-1 <=> axis=3 \n\n(3, 4, 5, 2)\n\n\nnp.concatenate 는 축의 총 갯수를 유지하면서 결합, np.stack은 축의 갯수를 하나 증가시키며 결합"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#sum",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#sum",
    "title": "Numpy",
    "section": "sum",
    "text": "sum\n- 1차원\n\na=np.array([1,2,3])\na\n\narray([1, 2, 3])\n\n\n\na.sum()\n\n6\n\n\n\na.sum(axis=0)\n\n6\n\n\n- 2차원\n\na=np.array(range(6)).reshape(2,3)\na\n\narray([[0, 1, 2],\n       [3, 4, 5]])\n\n\n\na.sum(axis=0)\n\narray([3, 5, 7])\n\n\n\na.sum(axis=1)\n\narray([ 3, 12])\n\n\n- 2차원 결과 분석\n\na.shape, a.sum(axis=0).shape \n\n((2, 3), (3,))\n\n\n\n첫번째 축이 삭제됨\n\n\na.shape, a.sum(axis=1).shape \n\n((2, 3), (2,))\n\n\n\n두번째 축이 삭제됨\n\n- 연습\n\na=np.array(range(10)).reshape(5,2)\na\n\narray([[0, 1],\n       [2, 3],\n       [4, 5],\n       [6, 7],\n       [8, 9]])\n\n\n(문제1) 1열의 합, 2열의 합을 계산하고 싶다면?\n(풀이) 차원이 (5,2) => (2,) 로 나와야 한다 (그럼 첫번째 축이 삭제되어야하네?)\n\na.sum(axis=0)\n\narray([20, 25])\n\n\n(문제2) 1행의 합, 2행의 합, …, 5행의 합을 계산하고 싶다면?\n(풀이) 차원이 (5,2) => (5,)로 나와야 한다 (그럼 두번째 축이 삭제되어야하네?)\n\na.sum(axis=1)\n\narray([ 1,  5,  9, 13, 17])\n\n\n(문제3) a의 모든원소의 합을 계산하고 싶다면?\n(풀이) 차원이 (5,2) => () 로 나와야 한다 (첫번째축, 두번째축 모두 삭제되어야 하네?)\n\na.sum(axis=(0,1))\n\n45\n\n\n\na.sum() # 즉 a.sum(axis=(0,1))이 디폴트값임 \n\n45"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#mean-max-min-prod",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#mean-max-min-prod",
    "title": "Numpy",
    "section": "mean, max, min, prod",
    "text": "mean, max, min, prod\n- 모두 sum과 유사한논리\n\na=np.array(range(10)).reshape(5,2)\na\n\narray([[0, 1],\n       [2, 3],\n       [4, 5],\n       [6, 7],\n       [8, 9]])\n\n\n\na.mean(axis=0), a.std(axis=0), a.max(axis=0), a.min(axis=0), a.prod(axis=0)\n\n(array([4., 5.]),\n array([2.82842712, 2.82842712]),\n array([8, 9]),\n array([0, 1]),\n array([  0, 945]))\n\n\n\na.mean(axis=1), a.std(axis=1), a.max(axis=1), a.min(axis=1), a.prod(axis=1)\n\n(array([0.5, 2.5, 4.5, 6.5, 8.5]),\n array([0.5, 0.5, 0.5, 0.5, 0.5]),\n array([1, 3, 5, 7, 9]),\n array([0, 2, 4, 6, 8]),\n array([ 0,  6, 20, 42, 72]))\n\n\n- 참고로 std는 분모를 n으로 나눈다.\n\na=np.array([1,2,3,4])\na.std()\n\n1.118033988749895\n\n\n\nnp.sqrt(sum((a-a.mean())**2)/4)\n\n1.118033988749895\n\n\n- 분모를 n-1로 나눌려면?\n\na=np.array([1,2,3,4])\na.std(ddof=1)\n\n1.2909944487358056\n\n\n\nnp.sqrt(sum((a-a.mean())**2)/3)\n\n1.2909944487358056"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#argmax-argmin",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#argmax-argmin",
    "title": "Numpy",
    "section": "argmax, argmin",
    "text": "argmax, argmin\n- 1차원\n\na=np.array([1,-2,3,10,4])\na\n\narray([ 1, -2,  3, 10,  4])\n\n\n\na.argmax()\n\n3\n\n\n\na.argmax(axis=0)\n\n3\n\n\n\na.argmin()\n\n1\n\n\n\na.argmin(axis=0)\n\n1\n\n\n- 2차원\n\nnp.random.seed(1)\na=np.random.randn(4*5).reshape(4,5)\na\n\narray([[ 1.62434536, -0.61175641, -0.52817175, -1.07296862,  0.86540763],\n       [-2.3015387 ,  1.74481176, -0.7612069 ,  0.3190391 , -0.24937038],\n       [ 1.46210794, -2.06014071, -0.3224172 , -0.38405435,  1.13376944],\n       [-1.09989127, -0.17242821, -0.87785842,  0.04221375,  0.58281521]])\n\n\n\na.argmin(axis=0)\n\narray([1, 2, 3, 0, 1])\n\n\n\na.argmax(axis=1)\n\narray([0, 1, 0, 4])"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#cumprod-cumsum",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#cumprod-cumsum",
    "title": "Numpy",
    "section": "cumprod, cumsum",
    "text": "cumprod, cumsum\n- 1차원\n\na=np.array([1,2,3,4])\n\n\na.cumsum(), a.cumprod()\n\n(array([ 1,  3,  6, 10]), array([ 1,  2,  6, 24]))\n\n\n\na.cumsum(axis=0), a.cumprod(axis=0)\n\n(array([ 1,  3,  6, 10]), array([ 1,  2,  6, 24]))\n\n\n- 2차원\n\na=np.array(range(3*4)).reshape(3,4)\na\n\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11]])\n\n\n\na.cumsum(axis=0), a.cumprod(axis=0)\n\n(array([[ 0,  1,  2,  3],\n        [ 4,  6,  8, 10],\n        [12, 15, 18, 21]]),\n array([[  0,   1,   2,   3],\n        [  0,   5,  12,  21],\n        [  0,  45, 120, 231]]))\n\n\n\na.cumsum(axis=1), a.cumprod(axis=1)\n\n(array([[ 0,  1,  3,  6],\n        [ 4,  9, 15, 22],\n        [ 8, 17, 27, 38]]),\n array([[   0,    0,    0,    0],\n        [   4,   20,  120,  840],\n        [   8,   72,  720, 7920]]))"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#diff",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#diff",
    "title": "Numpy",
    "section": "diff",
    "text": "diff\n- 1차차분\n\na=np.array([1,2,4,6,7])\na\n\narray([1, 2, 4, 6, 7])\n\n\n\nnp.diff(a)\n\narray([1, 2, 2, 1])\n\n\n- 2차차분\n\nnp.diff(np.diff(a))\n\narray([ 1,  0, -1])\n\n\n\nnp.diff(a,n=2)\n\narray([ 1,  0, -1])\n\n\n- prepend, append\n\na\n\narray([1, 2, 4, 6, 7])\n\n\n\nnp.diff(a,prepend=100) # [100, a] 와 같은 리스트를 차분 \n\narray([-99,   1,   2,   2,   1])\n\n\n\nnp.diff(a,append=100) # [a, 100] 와 같은 리스트를 차분 \n\narray([ 1,  2,  2,  1, 93])\n\n\n\nnp.diff(a,prepend=a[0]) # [a[0], a] 와 같은 리스트를 차분 \n\narray([0, 1, 2, 2, 1])\n\n\n\nnp.diff(a,append=a[-1]) # [a, a[-1]] 와 같은 리스트를 차분\n\narray([1, 2, 2, 1, 0])\n\n\n- 2차원 array의 차분\n\na=np.arange(24).reshape(4,6)\na\n\narray([[ 0,  1,  2,  3,  4,  5],\n       [ 6,  7,  8,  9, 10, 11],\n       [12, 13, 14, 15, 16, 17],\n       [18, 19, 20, 21, 22, 23]])\n\n\n\nnp.diff(a,axis=0)\n\narray([[6, 6, 6, 6, 6, 6],\n       [6, 6, 6, 6, 6, 6],\n       [6, 6, 6, 6, 6, 6]])\n\n\n\nnp.diff(a,axis=1)\n\narray([[1, 1, 1, 1, 1],\n       [1, 1, 1, 1, 1],\n       [1, 1, 1, 1, 1],\n       [1, 1, 1, 1, 1]])"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#splitver1",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#splitver1",
    "title": "Numpy",
    "section": "split(ver1)",
    "text": "split(ver1)\n- 1차원\n\na=np.array([1,2,3,4,5,6])\na\n\narray([1, 2, 3, 4, 5, 6])\n\n\n\nnp.split(a,2)\n\n[array([1, 2, 3]), array([4, 5, 6])]\n\n\n\nnp.split(a,3)\n\n[array([1, 2]), array([3, 4]), array([5, 6])]\n\n\n\nnp.split(a,6)\n\n[array([1]), array([2]), array([3]), array([4]), array([5]), array([6])]\n\n\n- 2차원\n\nb=np.stack([a,a])\nb\n\narray([[1, 2, 3, 4, 5, 6],\n       [1, 2, 3, 4, 5, 6]])\n\n\n\nb.shape\n\n(2, 6)\n\n\n\nnp.split(b,2,axis=0)\n\n[array([[1, 2, 3, 4, 5, 6]]), array([[1, 2, 3, 4, 5, 6]])]\n\n\n\nnp.split(b,2,axis=1)\n\n[array([[1, 2, 3],\n        [1, 2, 3]]),\n array([[4, 5, 6],\n        [4, 5, 6]])]\n\n\n\nnp.split(b,3,axis=1)\n\n[array([[1, 2],\n        [1, 2]]),\n array([[3, 4],\n        [3, 4]]),\n array([[5, 6],\n        [5, 6]])]"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#splitver2",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#splitver2",
    "title": "Numpy",
    "section": "split(ver2)",
    "text": "split(ver2)\n- 1차원: 리스트입력\n\nnp.random.seed(43052)\na=np.random.rand(12)\na\n\narray([0.81768226, 0.04953212, 0.83868626, 0.61977707, 0.12254052,\n       0.11712779, 0.8795562 , 0.97941543, 0.90986893, 0.96667407,\n       0.59164493, 0.84014933])\n\n\n\nnp.split(a,(2,5)) # 처음2, 그다음3(=합쳐서5), 나머지 \n\n[array([0.81768226, 0.04953212]),\n array([0.83868626, 0.61977707, 0.12254052]),\n array([0.11712779, 0.8795562 , 0.97941543, 0.90986893, 0.96667407,\n        0.59164493, 0.84014933])]\n\n\n\nnp.split(a,(1,3,5)) # :1, 1:3, 3:5, 5: \n\n[array([0.81768226]),\n array([0.04953212, 0.83868626]),\n array([0.61977707, 0.12254052]),\n array([0.11712779, 0.8795562 , 0.97941543, 0.90986893, 0.96667407,\n        0.59164493, 0.84014933])]\n\n\n- 2차원: 리스트입력\n\na= np.arange(30).reshape(6,5)\na\n\narray([[ 0,  1,  2,  3,  4],\n       [ 5,  6,  7,  8,  9],\n       [10, 11, 12, 13, 14],\n       [15, 16, 17, 18, 19],\n       [20, 21, 22, 23, 24],\n       [25, 26, 27, 28, 29]])\n\n\n\nnp.split(a,[3,4],axis=0) # :3, 3:4, 4: \n\n[array([[ 0,  1,  2,  3,  4],\n        [ 5,  6,  7,  8,  9],\n        [10, 11, 12, 13, 14]]),\n array([[15, 16, 17, 18, 19]]),\n array([[20, 21, 22, 23, 24],\n        [25, 26, 27, 28, 29]])]\n\n\n\nnp.split(a,[1,3,4],axis=1) # :1, 1:3, 3:4, 4: \n\n[array([[ 0],\n        [ 5],\n        [10],\n        [15],\n        [20],\n        [25]]),\n array([[ 1,  2],\n        [ 6,  7],\n        [11, 12],\n        [16, 17],\n        [21, 22],\n        [26, 27]]),\n array([[ 3],\n        [ 8],\n        [13],\n        [18],\n        [23],\n        [28]]),\n array([[ 4],\n        [ 9],\n        [14],\n        [19],\n        [24],\n        [29]])]"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#np.apply_along_axis",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#np.apply_along_axis",
    "title": "Numpy",
    "section": "np.apply_along_axis",
    "text": "np.apply_along_axis\n\na=np.array(range(12)).reshape(3,4)\na\n\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11]])\n\n\n\ndef mysum(arr): \n    return sum(arr)+1 \n\n\nnp.apply_along_axis(mysum,0,a) # np.apply_along_axis(mysum,axis=0,a) 은 에러발생 순서외어야함 \n\narray([13, 16, 19, 22])\n\n\n\nnp.apply_along_axis(mysum,1,a)\n\narray([ 7, 23, 39])"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#np.apply_over_axes",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#np.apply_over_axes",
    "title": "Numpy",
    "section": "np.apply_over_axes",
    "text": "np.apply_over_axes\n- 뭔가 쓰기 어렵다..\n\na=np.array(range(12)).reshape(3,4)\na\n\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11]])\n\n\n\ndef mysum(arr): \n    return np.sum(arr)+1 \n\n\nnp.apply_over_axes(mysum,a,[0,1])\n\nTypeError: mysum() takes 1 positional argument but 2 were given\n\n\n\nnp.apply_over_axes?\n\n\nSignature: np.apply_over_axes(func, a, axes)\nDocstring:\nApply a function repeatedly over multiple axes.\n`func` is called as `res = func(a, axis)`, where `axis` is the first\nelement of `axes`.  The result `res` of the function call must have\neither the same dimensions as `a` or one less dimension.  If `res`\nhas one less dimension than `a`, a dimension is inserted before\n`axis`.  The call to `func` is then repeated for each axis in `axes`,\nwith `res` as the first argument.\nParameters\n----------\nfunc : function\n    This function must take two arguments, `func(a, axis)`.\na : array_like\n    Input array.\naxes : array_like\n    Axes over which `func` is applied; the elements must be integers.\nReturns\n-------\napply_over_axis : ndarray\n    The output array.  The number of dimensions is the same as `a`,\n    but the shape can be different.  This depends on whether `func`\n    changes the shape of its output with respect to its input.\nSee Also\n--------\napply_along_axis :\n    Apply a function to 1-D slices of an array along the given axis.\nNotes\n-----\nThis function is equivalent to tuple axis arguments to reorderable ufuncs\nwith keepdims=True. Tuple axis arguments to ufuncs have been available since\nversion 1.7.0.\nExamples\n--------\n>>> a = np.arange(24).reshape(2,3,4)\n>>> a\narray([[[ 0,  1,  2,  3],\n        [ 4,  5,  6,  7],\n        [ 8,  9, 10, 11]],\n       [[12, 13, 14, 15],\n        [16, 17, 18, 19],\n        [20, 21, 22, 23]]])\nSum over axes 0 and 2. The result has same number of dimensions\nas the original array:\n>>> np.apply_over_axes(np.sum, a, [0,2])\narray([[[ 60],\n        [ 92],\n        [124]]])\nTuple axis arguments to ufuncs are equivalent:\n>>> np.sum(a, axis=(0,2), keepdims=True)\narray([[[ 60],\n        [ 92],\n        [124]]])\nFile:      ~/anaconda3/envs/py310/lib/python3.10/site-packages/numpy/lib/shape_base.py\nType:      function"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#np.where-np.argwhere",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#np.where-np.argwhere",
    "title": "Numpy",
    "section": "np.where, np.argwhere",
    "text": "np.where, np.argwhere\n- 1차원\n\na=np.array([0,0,0,1,0])\na\n\narray([0, 0, 0, 1, 0])\n\n\n\nnp.where(a==1) # 조건을 만족하는 인덱스가 (3,) 이라는 의미\n\n(array([3]),)\n\n\n\nnp.argwhere(a==1) \n\narray([[3]])\n\n\n- 2차원\n\nnp.random.seed(43052)\na=np.random.randn(12).reshape(3,4)\na\n\narray([[ 0.38342049,  1.0841745 ,  1.14277825,  0.30789368],\n       [ 0.23778744,  0.35595116, -1.66307542, -1.38277318],\n       [-1.92684484, -1.4862163 ,  0.00692519, -0.03488725]])\n\n\n\nnp.where(a<0) # 조건을 만족하는 인덱스가 (1,2), (1,3), (2,0), (2,1), (2,3) 이라는 의미 \n\n(array([1, 1, 2, 2, 2]), array([2, 3, 0, 1, 3]))\n\n\n\nnp.argwhere(a<=0) # 조건을 만족하는 인덱스가 (1,2), (1,3), (2,0), (2,1), (2,3) 이라는 의미 \n\narray([[1, 2],\n       [1, 3],\n       [2, 0],\n       [2, 1],\n       [2, 3]])\n\n\n\na[np.where(a<=0)] # 조건을 만족하는 원소를 모두 출력 => 1차원 array로 나온다. \n\narray([-1.66307542, -1.38277318, -1.92684484, -1.4862163 , -0.03488725])\n\n\n\na[np.argwhere(a<=0)] # 출력불가 \n\nIndexError: index 3 is out of bounds for axis 0 with size 3\n\n\n\na[np.argwhere(a<=0)[0]] # 출력불가 \n\narray([[ 0.23778744,  0.35595116, -1.66307542, -1.38277318],\n       [-1.92684484, -1.4862163 ,  0.00692519, -0.03488725]])\n\n\n\na[np.argwhere(a<=0)[0][0],np.argwhere(a<=0)[0][1]] # 어거지로 출력가능하긴함 \n\n-1.6630754187023522\n\n\n- np.where의 특수기능\n\nnp.random.seed(43052)\na=np.random.randn(12).reshape(3,4)\na\n\narray([[ 0.38342049,  1.0841745 ,  1.14277825,  0.30789368],\n       [ 0.23778744,  0.35595116, -1.66307542, -1.38277318],\n       [-1.92684484, -1.4862163 ,  0.00692519, -0.03488725]])\n\n\n\nnp.where(a<0,0,a) # a<0을 체크 => 조건에 맞으면 0 => 조건에 안맞으면 a \n\narray([[0.38342049, 1.0841745 , 1.14277825, 0.30789368],\n       [0.23778744, 0.35595116, 0.        , 0.        ],\n       [0.        , 0.        , 0.00692519, 0.        ]])\n\n\n\nnp.where(a<0,0,1) # a<0을 체크 => 조건에 맞으면 0 => 조건에 안맞으면 1\n\narray([[1, 1, 1, 1],\n       [1, 1, 0, 0],\n       [0, 0, 1, 0]])\n\n\n- 요약 - np.where: 인덱스의 좌표읽는게 가독성이 썩 좋지는 않음, 그런데 조건에 맞는 원소를 출력하거나 처리하는 (특수기능) 목적으로는 좋은 함수 - np.argwhere: 인덱스의 좌표읽는 가독성은 좋은편임. 그런데 조건에 맞는 원소를 출력하거나 처리하는 기능은 떨어짐"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#인덱싱-고급",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#인덱싱-고급",
    "title": "Numpy",
    "section": "인덱싱 고급",
    "text": "인덱싱 고급\n\na=np.arange(12).reshape(3,4)\na\n\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11]])\n\n\n- 원래배열과 인덱싱결과를 보고 축의개수를 비교해보자.\n\na[0,:] # 인덱싱의 결과 축의 개수가 바뀐다! 2d array -> 1d array \n\narray([0, 1, 2, 3])\n\n\n\na[[0,1],:] # 이것은 축의 개수가 유지된다. 2d array -> 2d array \n\narray([[0, 1, 2, 3],\n       [4, 5, 6, 7]])\n\n\n- 하나의 행, 혹은 열을 뽑을때 축의 개수를 유지하려면 아래와 같이 하면 된다.\n\na[[0],:]\n\narray([[0, 1, 2, 3]])\n\n\n\na[:,[0]]\n\narray([[0],\n       [4],\n       [8]])\n\n\n- 이것은 아래와 미묘하게 다르다는 점을 다시한번 기억하자.\n\na[0,:]\n\narray([0, 1, 2, 3])\n\n\n\na[:,0]\n\narray([0, 4, 8])"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#np.ix_",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#np.ix_",
    "title": "Numpy",
    "section": "np.ix_",
    "text": "np.ix_\n- 아래의 인덱싱을 비교하자.\n\na=np.arange(12).reshape(3,4)\na\n\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11]])\n\n\n\na[0:2,0:2]\n\narray([[0, 1],\n       [4, 5]])\n\n\n\na[[0,1],0:2]\n\narray([[0, 1],\n       [4, 5]])\n\n\n\na[0:2,[0,1]]\n\narray([[0, 1],\n       [4, 5]])\n\n\n- 언뜻생각하면 위의 결과와 아래의 결과가 동일하게 나올것 같다.\n\na[[0,1],[0,1]]\n\narray([0, 5])\n\n\n\n실제로는 [a[0,0], a[1,1]] 이 array로 나옴\n\n- 사실 np.where에서 이미 관찰하였다.\n\nnp.where(a % 5==0)\n\n(array([0, 1, 2]), array([0, 1, 2]))\n\n\n\na[np.where(a % 5==0)]\n\narray([ 0,  5, 10])\n\n\n\na[0:3,0:3] 이 출력되는것이 아니라 a[0,0], a[1,1], a[2,2] 가 출력된다.\n\n- a[[0,1],[0,1]]이 a[0:2,0:2]를 의미하게 하려면 아래와 같이 하면 된다.\n\na[np.ix_([0,1],[0,1])] # 유용해보이지만 생각보다 잘 쓰진 않더라.. \n\narray([[0, 1],\n       [4, 5]])"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#np.random.rand",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#np.random.rand",
    "title": "Numpy",
    "section": "np.random.rand()",
    "text": "np.random.rand()\n- 0~1사이의 난수 10개 생성\n\nnp.random.rand(10)\n\narray([0.8852783 , 0.31328711, 0.6141936 , 0.36838019, 0.08044368,\n       0.47142422, 0.43324944, 0.22441988, 0.01174913, 0.91587271])\n\n\n- 0~2사이의 난수 10개 생성\n\nnp.random.rand(10)*2 \n\narray([1.76650136, 0.65414205, 0.91517695, 1.10990737, 1.11690026,\n       1.50037557, 0.59895898, 1.71776826, 1.20931097, 0.01302267])\n\n\n- 1~2사이의 난수 10개 생성\n\nnp.random.rand(10)+1\n\narray([1.80605888, 1.06988897, 1.76763953, 1.72438164, 1.06247252,\n       1.97571034, 1.76681327, 1.12138996, 1.14946193, 1.08540348])\n\n\n- 1~3사이의 난수 10개 생성\n\nnp.random.rand(10)*2+1\n\narray([1.83316001, 2.82392447, 2.12983406, 2.70590512, 1.91501147,\n       1.52545303, 2.94666317, 2.67759399, 1.61667643, 2.80011097])\n\n\n\n(0,1) -> (0,2) -> (1,3) 사이의 난수생성"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#np.random.randn",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#np.random.randn",
    "title": "Numpy",
    "section": "np.random.randn()",
    "text": "np.random.randn()\n- N(0,1)에서 10개 추출\n\nnp.random.randn(10)  \n\narray([-0.25065063, -1.15695441, -1.29293855, -0.63070219, -0.69898838,\n        1.26693336,  0.84153043, -1.46458729, -0.16847185,  1.29054265])\n\n\n- N(1,1)에서 10개 추출\n\nnp.random.randn(10)+1 # N(1,1)에서 추출 \n\narray([ 1.36478515,  0.90052556,  0.17122775,  0.34652966,  1.07046089,\n       -1.46535548,  2.3927757 ,  0.94466987,  0.15876552,  0.62279321])\n\n\n- N(0,4)에서 10개 추출\n\nnp.random.randn(10)*2 # N(0,4)에서 추출 \n\narray([ 2.66361951,  0.34052965, -1.0283997 , -2.54081612,  3.4852053 ,\n       -0.7170628 , -0.36915341,  1.24489513,  0.90095895, -0.79682218])\n\n\n- N(3,4)에서 10개 추출\n\nnp.random.randn(10)*2+3 # N(3,4)에서 추출 \n\narray([ 0.86608514,  2.63310847,  0.15161244,  1.62661581,  4.47154709,\n        7.37582762,  0.70315947,  2.44134572,  1.99277107, -0.32804188])"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#np.random.randint",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#np.random.randint",
    "title": "Numpy",
    "section": "np.random.randint()",
    "text": "np.random.randint()\n- [0,10)의 범위에서 하나의 정수생성\n\nnp.random.randint(10) # [0,10) 의 범위에서 하나의 정수 생성 \n\n8\n\n\n- [0,10)의 범위에서 20개의 난수 생성\n\nnp.random.randint(10, size=(20,)) \n\narray([5, 8, 7, 1, 4, 8, 1, 0, 4, 7, 1, 5, 3, 4, 2, 5, 8, 9, 8, 9])\n\n\n- [0,10)의 범위에서 (2,2) shape의 정수생성\n\nnp.random.randint(10, size=(2,2)) \n\narray([[1, 9],\n       [3, 3]])\n\n\n- 위와 같은코드. 즉 [0,10)의 범위에서 (2,2) shape의 정수생성\n\nnp.random.randint(low=10,size=(2,2)) # 왜 low지?\n\narray([[8, 4],\n       [0, 4]])\n\n\n- [10,20)의 범위에서 (2,2) shape의 정수생성\n\nnp.random.randint(low=10,high=20,size=(5,5)) \n\narray([[14, 11, 11, 13, 18],\n       [14, 12, 14, 14, 13],\n       [19, 10, 11, 13, 11],\n       [13, 17, 16, 10, 14],\n       [11, 12, 17, 13, 19]])\n\n\n- 의문: np.random.randint(low=10,size=(2,2))는 np.random.randint(high=10,size=(2,2))이어야 맞는거 아닌가?\n저도 그런것 같아요, 그런데 구현을 이상하게 한듯합니다\n\nnp.random.randint?\n\n\nDocstring:\nrandint(low, high=None, size=None, dtype=int)\nReturn random integers from `low` (inclusive) to `high` (exclusive).\nReturn random integers from the \"discrete uniform\" distribution of\nthe specified dtype in the \"half-open\" interval [`low`, `high`). If\n`high` is None (the default), then results are from [0, `low`).\n.. note::\n    New code should use the ``integers`` method of a ``default_rng()``\n    instance instead; please see the :ref:`random-quick-start`.\nParameters\n----------\nlow : int or array-like of ints\n    Lowest (signed) integers to be drawn from the distribution (unless\n    ``high=None``, in which case this parameter is one above the\n    *highest* such integer).\nhigh : int or array-like of ints, optional\n    If provided, one above the largest (signed) integer to be drawn\n    from the distribution (see above for behavior if ``high=None``).\n    If array-like, must contain integer values\nsize : int or tuple of ints, optional\n    Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n    ``m * n * k`` samples are drawn.  Default is None, in which case a\n    single value is returned.\ndtype : dtype, optional\n    Desired dtype of the result. Byteorder must be native.\n    The default value is int.\n    .. versionadded:: 1.11.0\nReturns\n-------\nout : int or ndarray of ints\n    `size`-shaped array of random integers from the appropriate\n    distribution, or a single such random int if `size` not provided.\nSee Also\n--------\nrandom_integers : similar to `randint`, only for the closed\n    interval [`low`, `high`], and 1 is the lowest value if `high` is\n    omitted.\nGenerator.integers: which should be used for new code.\nExamples\n--------\n>>> np.random.randint(2, size=10)\narray([1, 0, 0, 0, 1, 1, 0, 0, 1, 0]) # random\n>>> np.random.randint(1, size=10)\narray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\nGenerate a 2 x 4 array of ints between 0 and 4, inclusive:\n>>> np.random.randint(5, size=(2, 4))\narray([[4, 0, 2, 1], # random\n       [3, 2, 2, 0]])\nGenerate a 1 x 3 array with 3 different upper bounds\n>>> np.random.randint(1, [3, 5, 10])\narray([2, 2, 9]) # random\nGenerate a 1 by 3 array with 3 different lower bounds\n>>> np.random.randint([1, 5, 7], 10)\narray([9, 8, 7]) # random\nGenerate a 2 by 4 array using broadcasting with dtype of uint8\n>>> np.random.randint([1, 3, 5, 7], [[10], [20]], dtype=np.uint8)\narray([[ 8,  6,  9,  7], # random\n       [ 1, 16,  9, 12]], dtype=uint8)\nType:      builtin_function_or_method\n\n\n\n\n\nnote: Return random integers from the “discrete uniform” distribution of the specified dtype in the “half-open” interval [low, high). If high is None (the default), then results are from [0, low)."
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#np.random.choice",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#np.random.choice",
    "title": "Numpy",
    "section": "np.random.choice()",
    "text": "np.random.choice()\n- ver1\n\nnp.random.choice(5,20) # [0,5)에서 20개 뽑음, 중복허용 \n\narray([0, 0, 4, 2, 0, 0, 4, 0, 1, 4, 4, 2, 0, 1, 0, 1, 2, 2, 2, 2])\n\n\n\nnp.random.randint(5,size=(20,)) 와 동일\n\n\nnp.random.choice(5,5,replace=False) # [0,5)에서 5개 뽑음, 중복허용X => 제비뽑기 \n\narray([4, 1, 2, 0, 3])\n\n\n- ver2\n\nnp.random.choice([0,1,2,3],20) # [0,1,2,3]에서 20개 뽑음, 중복허용 \n\narray([3, 3, 0, 3, 1, 1, 2, 0, 0, 1, 0, 0, 3, 2, 2, 0, 1, 2, 1, 2])\n\n\n\nnp.random.choice([\"apple\",\"banana\",\"orange\"],20) # [\"apple\",\"banana\",\"orange\"]에서 20개 뽑음, 중복허용 \n\narray(['banana', 'orange', 'apple', 'banana', 'apple', 'orange', 'banana',\n       'apple', 'banana', 'apple', 'orange', 'banana', 'banana', 'orange',\n       'apple', 'apple', 'banana', 'banana', 'orange', 'banana'],\n      dtype='<U6')"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#통계분포",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#통계분포",
    "title": "Numpy",
    "section": "통계분포",
    "text": "통계분포\n\nnp.random.binomial(n=10,p=0.2,size=(5,)) # X1,...,X5 ~ B(10,0.2) \n\narray([4, 1, 1, 1, 0])\n\n\n\nnp.random.normal(loc=0,scale=2,size=(5,)) # X1,...,X5 ~ N(0,4) \n\narray([ 3.08322663,  1.7758872 ,  0.39141069,  2.36938406, -1.78970012])\n\n\n\nnp.random.uniform(low=2,high=4,size=(5,)) # X1,...,X5 ~ U(2,4)\n\narray([2.25126784, 2.78749105, 3.86552351, 3.12696917, 3.65084364])\n\n\n\nnp.random.poisson(lam=5,size=(5,)) # X1,...,X5 ~ Poi(5) \n\narray([6, 5, 4, 3, 3])\n\n\n\nnp.random.exponential(scale=2, size=(5,)) # X1,...,X5 ~ 평균이 2인 지수분포 \n\narray([3.93952652, 4.07955895, 1.7005346 , 0.40383429, 1.05525183])"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#note-1-메소드-도움말-확인하기",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#note-1-메소드-도움말-확인하기",
    "title": "Numpy",
    "section": "note 1: 메소드 도움말 확인하기",
    "text": "note 1: 메소드 도움말 확인하기\n- 파이썬에서 함수적용하는 2가지 방식 - sum(a) - a.sum()\n\na = np.array([1,2,3,4,5])\na\n\narray([1, 2, 3, 4, 5])\n\n\n\na.sum()\n\n15\n\n\n\nnp.sum(a)\n\n15\n\n\n- a.sum()과 같이 함수를 쓰는 방식을 메소드라고 한다. np.sum()은 그냥 np폴더에 어딘가에 정의된 sum()함수\n- 넘파이: 대부분은 np.sum()등과 같은 함수를 만들고 a.sum()이라는 메소드가 np.sum(a)과 동일한 역할을 하도록 추가 설계하는 식임. \\(\\to\\) 도움말은 np.sum()에 자세히 나와있음\n\na.sum?\n\n\nDocstring:\na.sum(axis=None, dtype=None, out=None, keepdims=False, initial=0, where=True)\nReturn the sum of the array elements over the given axis.\nRefer to `numpy.sum` for full documentation.\nSee Also\n--------\nnumpy.sum : equivalent function\nType:      builtin_function_or_method\n\n\n\n\n\nnp.sum?\n\n\nSignature:\nnp.sum(\n    a,\n    axis=None,\n    dtype=None,\n    out=None,\n    keepdims=<no value>,\n    initial=<no value>,\n    where=<no value>,\n)\nDocstring:\nSum of array elements over a given axis.\nParameters\n----------\na : array_like\n    Elements to sum.\naxis : None or int or tuple of ints, optional\n    Axis or axes along which a sum is performed.  The default,\n    axis=None, will sum all of the elements of the input array.  If\n    axis is negative it counts from the last to the first axis.\n    .. versionadded:: 1.7.0\n    If axis is a tuple of ints, a sum is performed on all of the axes\n    specified in the tuple instead of a single axis or all the axes as\n    before.\ndtype : dtype, optional\n    The type of the returned array and of the accumulator in which the\n    elements are summed.  The dtype of `a` is used by default unless `a`\n    has an integer dtype of less precision than the default platform\n    integer.  In that case, if `a` is signed then the platform integer\n    is used while if `a` is unsigned then an unsigned integer of the\n    same precision as the platform integer is used.\nout : ndarray, optional\n    Alternative output array in which to place the result. It must have\n    the same shape as the expected output, but the type of the output\n    values will be cast if necessary.\nkeepdims : bool, optional\n    If this is set to True, the axes which are reduced are left\n    in the result as dimensions with size one. With this option,\n    the result will broadcast correctly against the input array.\n    If the default value is passed, then `keepdims` will not be\n    passed through to the `sum` method of sub-classes of\n    `ndarray`, however any non-default value will be.  If the\n    sub-class' method does not implement `keepdims` any\n    exceptions will be raised.\ninitial : scalar, optional\n    Starting value for the sum. See `~numpy.ufunc.reduce` for details.\n    .. versionadded:: 1.15.0\nwhere : array_like of bool, optional\n    Elements to include in the sum. See `~numpy.ufunc.reduce` for details.\n    .. versionadded:: 1.17.0\nReturns\n-------\nsum_along_axis : ndarray\n    An array with the same shape as `a`, with the specified\n    axis removed.   If `a` is a 0-d array, or if `axis` is None, a scalar\n    is returned.  If an output array is specified, a reference to\n    `out` is returned.\nSee Also\n--------\nndarray.sum : Equivalent method.\nadd.reduce : Equivalent functionality of `add`.\ncumsum : Cumulative sum of array elements.\ntrapz : Integration of array values using the composite trapezoidal rule.\nmean, average\nNotes\n-----\nArithmetic is modular when using integer types, and no error is\nraised on overflow.\nThe sum of an empty array is the neutral element 0:\n>>> np.sum([])\n0.0\nFor floating point numbers the numerical precision of sum (and\n``np.add.reduce``) is in general limited by directly adding each number\nindividually to the result causing rounding errors in every step.\nHowever, often numpy will use a  numerically better approach (partial\npairwise summation) leading to improved precision in many use-cases.\nThis improved precision is always provided when no ``axis`` is given.\nWhen ``axis`` is given, it will depend on which axis is summed.\nTechnically, to provide the best speed possible, the improved precision\nis only used when the summation is along the fast axis in memory.\nNote that the exact precision may vary depending on other parameters.\nIn contrast to NumPy, Python's ``math.fsum`` function uses a slower but\nmore precise approach to summation.\nEspecially when summing a large number of lower precision floating point\nnumbers, such as ``float32``, numerical errors can become significant.\nIn such cases it can be advisable to use `dtype=\"float64\"` to use a higher\nprecision for the output.\nExamples\n--------\n>>> np.sum([0.5, 1.5])\n2.0\n>>> np.sum([0.5, 0.7, 0.2, 1.5], dtype=np.int32)\n1\n>>> np.sum([[0, 1], [0, 5]])\n6\n>>> np.sum([[0, 1], [0, 5]], axis=0)\narray([0, 6])\n>>> np.sum([[0, 1], [0, 5]], axis=1)\narray([1, 5])\n>>> np.sum([[0, 1], [np.nan, 5]], where=[False, True], axis=1)\narray([1., 5.])\nIf the accumulator is too small, overflow occurs:\n>>> np.ones(128, dtype=np.int8).sum(dtype=np.int8)\n-128\nYou can also start the sum with a value other than zero:\n>>> np.sum([10], initial=5)\n15\nFile:      ~/anaconda3/envs/py310/lib/python3.10/site-packages/numpy/core/fromnumeric.py\nType:      function"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#note-2-hstack-vstack",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#note-2-hstack-vstack",
    "title": "Numpy",
    "section": "note 2: hstack, vstack",
    "text": "note 2: hstack, vstack\n- hstack, vstack 를 쓰는 사람도 있다.\n\na=np.arange(6) \nb=-a\n\n\nnp.vstack([a,b])\n\narray([[ 0,  1,  2,  3,  4,  5],\n       [ 0, -1, -2, -3, -4, -5]])\n\n\n\nnp.stack([a,b],axis=0)\n\narray([[ 0,  1,  2,  3,  4,  5],\n       [ 0, -1, -2, -3, -4, -5]])\n\n\n\nnp.hstack([a,b])\n\narray([ 0,  1,  2,  3,  4,  5,  0, -1, -2, -3, -4, -5])\n\n\n\nnp.concatenate([a,b],axis=0)\n\narray([ 0,  1,  2,  3,  4,  5,  0, -1, -2, -3, -4, -5])"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#note-3-append",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#note-3-append",
    "title": "Numpy",
    "section": "note 3: append",
    "text": "note 3: append\n- 기능1: reshape(-1) + concat\n\na=np.arange(30).reshape(5,6)\nb= -np.arange(8).reshape(2,2,2)\n\n\na.shape, b.shape\n\n((5, 6), (2, 2, 2))\n\n\n\nnp.append(a,b)\n\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,  0, -1, -2, -3,\n       -4, -5, -6, -7])\n\n\n\nnp.concatenate([a.reshape(-1),b.reshape(-1)])\n\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,  0, -1, -2, -3,\n       -4, -5, -6, -7])\n\n\n- 기능2: concat\n\na=np.arange(2*3*4).reshape(2,3,4)\nb=-a\n\n\na.shape,b.shape, np.append(a,b,axis=0).shape\n\n((2, 3, 4), (2, 3, 4), (4, 3, 4))\n\n\n\na.shape,b.shape, np.append(a,b,axis=1).shape\n\n((2, 3, 4), (2, 3, 4), (2, 6, 4))\n\n\n\na.shape,b.shape, np.append(a,b,axis=2).shape\n\n((2, 3, 4), (2, 3, 4), (2, 3, 8))\n\n\n- concat과의 차이?\n\na=np.arange(2*3*4).reshape(2,3,4)\nb=-a\nc=2*a\n\n\nnp.append(a,b,c,axis=0)\n\nTypeError: _append_dispatcher() got multiple values for argument 'axis'\n\n\n\nnp.concatenate([a,b,c],axis=0)\n\narray([[[  0,   1,   2,   3],\n        [  4,   5,   6,   7],\n        [  8,   9,  10,  11]],\n\n       [[ 12,  13,  14,  15],\n        [ 16,  17,  18,  19],\n        [ 20,  21,  22,  23]],\n\n       [[  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11]],\n\n       [[-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23]],\n\n       [[  0,   2,   4,   6],\n        [  8,  10,  12,  14],\n        [ 16,  18,  20,  22]],\n\n       [[ 24,  26,  28,  30],\n        [ 32,  34,  36,  38],\n        [ 40,  42,  44,  46]]])"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#note-4-ravel-flatten",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#note-4-ravel-flatten",
    "title": "Numpy",
    "section": "note 4: ravel, flatten",
    "text": "note 4: ravel, flatten\n\na=np.arange(2*3*4).reshape(2,3,4)\na\n\narray([[[ 0,  1,  2,  3],\n        [ 4,  5,  6,  7],\n        [ 8,  9, 10, 11]],\n\n       [[12, 13, 14, 15],\n        [16, 17, 18, 19],\n        [20, 21, 22, 23]]])\n\n\n\na.reshape(-1)\n\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23])\n\n\n\na.ravel()\n\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23])\n\n\n\na.flatten()\n\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23])"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#note-5-기타-통계함수들",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#note-5-기타-통계함수들",
    "title": "Numpy",
    "section": "note 5: 기타 통계함수들",
    "text": "note 5: 기타 통계함수들\n- 평균, 중앙값, 표준편차, 분산,\n\na=np.random.normal(loc=0,scale=2,size=(100,))\na\n\narray([ 1.10482395, -0.86877641, -2.87354381, -1.07857919,  0.03703613,\n       -1.14739291,  1.87565381,  2.15846406,  0.49726646, -0.00810987,\n        2.53348503,  0.23407604, -0.70033057,  0.82176462, -1.52795024,\n        1.53364238,  2.06437879,  0.80876024, -0.26983189, -1.53527448,\n       -1.28588465, -0.49564791, -2.91531584, -0.18212024,  0.64680382,\n       -1.5480415 ,  1.31911602, -1.58918923, -5.21076055,  0.56745112,\n       -3.6658885 ,  0.5856616 ,  0.5748427 ,  0.56718898, -1.4937509 ,\n       -1.83666952,  0.80465047,  0.97184222,  0.24572426, -1.40343521,\n        1.48031211, -1.79697954,  2.0767591 , -0.88344071,  0.63964122,\n        1.41092588, -0.05452613, -0.29799167,  0.46962945, -2.8253509 ,\n       -1.41275472,  1.27618038, -1.41329545,  0.42832797,  3.36681894,\n       -1.84457945,  1.22956994,  0.81007832,  0.06983388,  0.80544143,\n       -0.13307524,  2.030119  , -4.06015169,  0.2349643 , -0.48281504,\n       -0.35643278, -1.18831743, -2.3565089 ,  0.66814577,  0.21763942,\n       -2.07618811,  1.80628638,  0.78098654,  1.58641403, -1.71025858,\n       -0.29232917,  0.21923226, -1.62321184, -0.44817688,  0.63777853,\n       -1.6351924 ,  2.60108463,  1.15300474, -0.50451115, -2.1568106 ,\n       -1.13993511, -3.32948725, -0.5059582 ,  0.66831111, -1.51265995,\n       -0.7356817 , -0.5188582 ,  0.73946266, -0.55988812,  0.19881875,\n       -1.8650296 , -0.62325849,  1.65669507, -0.45051465, -0.02321452])\n\n\n\nnp.mean(a)\n\n-0.23238783083421655\n\n\n\nnp.median(a)\n\n-0.09380068380510138\n\n\n\nnp.std(a)\n\n1.5287396635800397\n\n\n\nnp.var(a)\n\n2.337044959002813\n\n\n- corr matrix, cov matrix\n\nnp.random.seed(43052)\nx=np.random.randn(10000)\ny=np.random.randn(10000)*2\nz=np.random.randn(10000)*0.5\n\n\nnp.corrcoef([x,y,z]).round(2)\n\narray([[ 1.  , -0.01,  0.01],\n       [-0.01,  1.  ,  0.  ],\n       [ 0.01,  0.  ,  1.  ]])\n\n\n\nnp.cov([x,y,z]).round(2)\n\narray([[ 0.99, -0.02,  0.  ],\n       [-0.02,  4.06,  0.  ],\n       [ 0.  ,  0.  ,  0.25]])"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#note-6-dtype",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#note-6-dtype",
    "title": "Numpy",
    "section": "note 6: dtype",
    "text": "note 6: dtype\n- np.array는 항상 dtype이 있다.\n\na= np.array([1,2,3])\na\n\narray([1, 2, 3])\n\n\n\na.dtype\n\ndtype('int64')\n\n\n\na= np.array([1.0,2.0,3.0])\na\n\narray([1., 2., 3.])\n\n\n\na.dtype\n\ndtype('float64')\n\n\n- 같은 int라도 int16, int32, int64로 나누어진다.\n\na = np.array([1,2,3],dtype=np.int32) # 자료형을 특정하여 선언\na\n\narray([1, 2, 3], dtype=int32)\n\n\n\na.dtype\n\ndtype('int32')\n\n\n- float도 float16, float32, float64가 있다.\n\na = np.array([1,2,3],dtype=np.float32)\n\n\na\n\narray([1., 2., 3.], dtype=float32)\n\n\n- 데이터타입은 아래와 같은 방법으로 변환시킬 수 있다.\n\na = np.array([1,2,3],dtype=np.int32)\na\n\narray([1, 2, 3], dtype=int32)\n\n\n\na=a.astype(dtype=np.int64)\n\n\na.dtype\n\ndtype('int64')\n\n\n- 문자열의 경우\n\na = np.array(['a','b','c'])\na.dtype\n\ndtype('<U1')\n\n\n\na = np.array(['ab','b','c'])\na.dtype\n\ndtype('<U2')\n\n\n\na = np.array(['abc','b','c'])\na.dtype\n\ndtype('<U3')\n\n\n- 문자열 + 숫자혼합 => 문자열로 통일\n\na = np.array(['a',1])\na\n\narray(['a', '1'], dtype='<U21')\n\n\n\na = np.array(['a',1.0])\na\n\narray(['a', '1.0'], dtype='<U32')\n\n\n- 숫자를 문자열로 전환: 필요가 있을까..\n\na=np.array([1,2,3])\na\n\narray([1, 2, 3])\n\n\n\na.astype(np.str_)\n\narray(['1', '2', '3'], dtype='<U21')"
  },
  {
    "objectID": "posts/1. Codes/Python/2000-04-05-Numpy.html#note-7-브로드캐스팅과-시간측정",
    "href": "posts/1. Codes/Python/2000-04-05-Numpy.html#note-7-브로드캐스팅과-시간측정",
    "title": "Numpy",
    "section": "note 7: 브로드캐스팅과 시간측정",
    "text": "note 7: 브로드캐스팅과 시간측정\n\nimport time \n\n\nt1=time.time()\n\n\nt2=time.time()\nt2-t1\n\n0.17961955070495605\n\n\n\nx=np.arange(10**4)\ny=np.arange(10**4)\n\n\narr1=x.reshape(10**4,1)\narr2=y.reshape(1,10**4)\n\n\ndist = (arr1-arr2)**2\n\n\ndist = np.zeros([10**4,10**4])\n\n\nfor i in range(10**4):\n    for j in range(10**4):\n        dist[i,j] = (i-j)**2"
  },
  {
    "objectID": "posts/1. Codes/PyTorchLightning/2022-11-29-Lesson1.html",
    "href": "posts/1. Codes/PyTorchLightning/2022-11-29-Lesson1.html",
    "title": "Lesson1: 단순선형회귀",
    "section": "",
    "text": "import torch\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport pytorch_lightning as pl \n\n\nref\nref: https://guebin.github.io/DL2022/posts/II.%20DNN/2022-09-20-3wk-2.html\n\n\nRegression 1: CPU\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2022/main/posts/II.%20DNN/2022-09-22-regression.csv\")\n\n\nx= torch.tensor(df.x).reshape(-1,1).float()\ny= torch.tensor(df.y).reshape(-1,1).float()\n\n\nds = torch.utils.data.TensorDataset(x,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=100)\n\n\nclass NetLO(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.linr = torch.nn.Linear(1,1)\n        self.loss_fn = torch.nn.MSELoss()\n    def forward(self,x):\n        yhat = self.linr(x)\n        return yhat\n    def configure_optimizers(self):\n        optimizr = torch.optim.SGD(self.parameters(), lr=0.1)\n        return optimizr \n    def training_step(self,batch,batch_idx):\n        x,y = batch\n        yhat = self(x)\n        loss = self.loss_fn(yhat,y) \n        return loss \n\n\nnet = NetLO()\n\n\ntrnr = pl.Trainer(max_epochs=1)\n\nGPU available: True (cuda), used: False\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1767: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n  category=PossibleUserWarning,\n\n\n\nnet.linr.bias.data = torch.tensor([-5.0])\nnet.linr.weight.data = torch.tensor([[10.0]])\n\n\ntrnr.fit(net, train_dataloaders=dl) \n\n\n  | Name    | Type    | Params\n------------------------------------\n0 | linr    | Linear  | 2     \n1 | loss_fn | MSELoss | 0     \n------------------------------------\n2         Trainable params\n0         Non-trainable params\n2         Total params\n0.000     Total estimated model params size (MB)\n\n\n\n\n\n`Trainer.fit` stopped: `max_epochs=1` reached.\n\n\n\nnet.linr.weight, net.linr.bias\n\n(Parameter containing:\n tensor([[8.8111]], requires_grad=True),\n Parameter containing:\n tensor([-3.6577], requires_grad=True))\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\nRegression 2: GPU\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2022/main/posts/II.%20DNN/2022-09-22-regression.csv\")\n\n\nx= torch.tensor(df.x).reshape(-1,1).float()\ny= torch.tensor(df.y).reshape(-1,1).float()\n\n\nds = torch.utils.data.TensorDataset(x,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=100)\n\n\nclass NetLO(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.linr = torch.nn.Linear(1,1)\n        self.loss_fn = torch.nn.MSELoss()\n    def forward(self,x):\n        yhat = self.linr(x)\n        return yhat\n    def configure_optimizers(self):\n        optimizr = torch.optim.SGD(self.parameters(), lr=0.1)\n        return optimizr \n    def training_step(self,batch,batch_idx):\n        x,y = batch\n        yhat = self(x)\n        loss = self.loss_fn(yhat,y) \n        return loss \n\n\nnet = NetLO()\n\n\ntrnr = pl.Trainer(max_epochs=1, accelerator='gpu', devices=1)\n\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\n\n\n\nnet.linr.bias.data = torch.tensor([-5.0])\nnet.linr.weight.data = torch.tensor([[10.0]])\n\n\ntrnr.fit(net, train_dataloaders=dl) \n\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n  | Name    | Type    | Params\n------------------------------------\n0 | linr    | Linear  | 2     \n1 | loss_fn | MSELoss | 0     \n------------------------------------\n2         Trainable params\n0         Non-trainable params\n2         Total params\n0.000     Total estimated model params size (MB)\n\n\n\n\n\n`Trainer.fit` stopped: `max_epochs=1` reached.\n\n\n\nnet.linr.weight, net.linr.bias\n\n(Parameter containing:\n tensor([[8.8111]], requires_grad=True),\n Parameter containing:\n tensor([-3.6577], requires_grad=True))\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')"
  },
  {
    "objectID": "posts/5. Notes/2000-01-06-JupyterLab(2).html",
    "href": "posts/5. Notes/2000-01-06-JupyterLab(2).html",
    "title": "주피터랩: 설정 및 몇가지 팁",
    "section": "",
    "text": "주피터에 R커널을 연결할 경우 그림크기 조정\noptions(repr.plot.width=10, repr.plot.height=3,repr.plot.res=300)\n\n\n깃허브에서 *.py파일 불러오기\nimport requests\nexec(requests.get('http://miruetoto.github.io/my_code/datahandling.py').text)\n\n\nrpy2 magic\nimport rpy2\n%load_ext rpy2.ipython\n\n\n깃허브에서 *.R파일 불러오기\nimport rpy2\n%load_ext rpy2.ipython\n%R library(devtools)\n%R source_url(\"http://miruetoto.github.io/my_code/datahandling.r\")\n\n\nmatplotlib 그림크기조정\nimport matplotlib as mpl \nimport matplotlib.pyplot as plt \nIpython_default=plt.rcParams.copy() # save initial value \nfrom matplotlib import cycler\nplt.rc('figure',dpi=150) # default value 4 figure.dpi is 72.0 \n# plt.rcParams.update(Ipython_default) # load initial value \n\n\nGPU 사용여부 체크\nfrom keras import backend as K\nprint('GPU check 4 Keras: '+ str(K.tensorflow_backend._get_available_gpus()))\nimport torch\nprint('GPU check 4 Pytorch: '+ str(torch.cuda.get_device_name(0)))\n\n\n깃랩관련 (회사아니면 필요없음)\n- load *.py from gitlab\nimport gitlab\ngl = gitlab.Gitlab('http://10.178.145.54:9000', private_token='RkZz465zdyyEChamLKy8')\ngl.auth()\nproject = gl.projects.get(2)\n\n# (1) load RF.py, RF_withGIT.py, RF_withR.py\nRF_py = project.files.get(file_path='modeling/RF.py', ref='fridge').decode()\nRF_GIT_py = project.files.get(file_path='utils/RF_withGIT.py', ref='fridge').decode()\nRF_R_py = project.files.get(file_path='utils/RF_withR.py', ref='fridge').decode()\nexec(str(RF_py, 'utf-8'))\nexec(str(RF_GIT_py, 'utf-8'))\nexec(str(RF_R_py, 'utf-8'))\n- load *.R in gitlab\nimport gitlab\ngl = gitlab.Gitlab('http://10.178.145.54:9000', private_token='RkZz465zdyyEChamLKy8')\ngl.auth()\nproject = gl.projects.get(2)\nRF_R_rcode = project.files.get(file_path='utils/RF_Rfunctions.r', ref='fridge').decode()\n# tricks for source('Rfunctions.r')\nfile1 = open(\"RF_Rfunctions.r\",\"w\") \nfile1.write(str(RF_R_rcode, 'utf-8'))\nfile1.close() \nro.r(\"source('RF_Rfunctions.r')\")\nimport os\nos.remove('RF_Rfunctions.r')"
  },
  {
    "objectID": "posts/5. Notes/2000-01-07-JuliaInstall.html",
    "href": "posts/5. Notes/2000-01-07-JuliaInstall.html",
    "title": "줄리아 설치 및 실행",
    "section": "",
    "text": "설치\n- 여기에 접속한다. 스크롤링하여 ’Generic Linux Binaries for x86 / 64-bit(GPG)’를 찾는다. 그리고 ’64-bit’를 클릭해서 다운받는다. (참고로 왼쪽에 ’help’를 누르면 설치페이지 설명서가 나온다.) 그러면 아래와 같은 파일이 나온다.\njulia-1.3.1-linux-x86_64.tar.gz\n이 파일을 더블클릭해서 압축을 풀어준다. 압축을 풀면 julia-1.3.1라는 폴더가 생긴다. 이 폴더를 원하는 위치로 (줄리아가 설치되기를 원하는 위치) 이동시킨다. 나는 home에 이동시켰다.\n- 아래를 실행하면 줄리아가 실행된다. (둘중 아무거나)\n/home/cgb/julia-1.3.1/bin/julia\n~/julia-1.3.1/bin/julia\n\n\n주피터와 연결\n- 아래중 하나를 실행하여 줄리아를 킨다.\n/home/cgb/julia-1.3.1/bin/julia\n~/julia-1.3.1/bin/julia\n- 줄리아를 실행한뒤에 아래를 입력하면 주피터노트북에 연결된다.\nusing Pkg\nPkg.add(\"IJulia\")\n- 한 가지 의문점이 있다. 나같은 경우는 ’(base)’에서 줄리아를 실행하고 연결하였다. 그런데 혹시 몰라서 (py38r40)에서도 줄리아를 실행해봤는데 잘 실행되었다. 줄리아를 실행시키고 위의 명령 Pkg.add(\"IJulia\")를 다시쳤는데, 이미 연결되어서 더이상 변화시킨게 없다는 메시지가 떴다. 이러면 (base)에 설치된 줄리아가 (py38r40)에서도 실행된 줄리아와 동일하다는 의미일까? \\(\\Longrightarrow\\) 그렇다. 왜냐하면 줄리아는 anaconda내의 폴더에 설치한 것이 아니기 때문에. home에 보통 설치하니깐.\n\n\n환경변수 조정\n- 참고로 어디서든 줄리아를 실행시키고 싶다면 환경변수를 조작하면 된다. 아래를 실행해서 나노에디터를 킨다.\nsudo nano /etc/environment\n맨끝에 다음과 같이 되어있을 것이다.\n~~ usr/local/games\"\n마지막에 /home/cgb/julia-1.3.1/bin/julia를 추가한다. 즉 아래와 같이 만든다.\n~~ usr/local/games:/home/cgb/julia-1.3.1/bin/julia\"\n세이브하고 나온다. (그런데 이 과정을 안거쳐도 되는것 같음.) 이제 커맨드에서 아래를 실행한다.\nexport PATH=$PATH:/home/cgb/julia-1.3.1/bin\n이렇게하면 이제 단순히 julia라고만 쳐도 julia가 실행된다.\n\n\n플루토에서 강의영상 넣는 방법\n- 아래를 삽입\nhtml\"\"\"\n<div style=\"display: flex; justify-content: center;\">\n<div  notthestyle=\"position: relative; right: 0; top: 0; z-index: 300;\">\n<iframe src=\n\"\nhttps://www.youtube.com/embed/\n\"\nwidth=600 height=375  frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\"\"\"\n\n\n플루토를 이용한 홈페이지 만드는 방법\n- 단계1: https://github.com/JuliaPluto/static-export-template 에 가서 Clone\n- 단계2: Setting -> GitHub Pages -> Source -> gh-pages / root\n\n\n플루토 키는 방법\nimport Pluto\nPluto.run(host=\"0.0.0.0\",port=1234,launch_browser=false,require_secret_for_open_links=false,require_secret_for_access=false,threads=\"8\")"
  },
  {
    "objectID": "posts/5. Notes/2000-01-05-JupyterLab(1).html",
    "href": "posts/5. Notes/2000-01-05-JupyterLab(1).html",
    "title": "주피터랩(터미널)",
    "section": "",
    "text": "& 옵션으로 주피터 실행\n- 서버에 접속한다.\nssh lgcgb@10.178.144.65\n아래와 같이 끝에 &을 붙이면 된다.\nconda activate py20190129\njupyter lab &\n실행하고 난뒤에는 엔터를 쳐서 빠져나온다. 이렇게 하면 서버자체에 모니터를 연결하고 커널창을 띄운것과 같은 효과를 준다. 즉 서버에 접속한 컴퓨터를 끄는것과 상관없이 서버에서는 항상 주피터가 열려 있게 된다.\n\n\n& 옵션으로 실행한 주피터프로세스 죽이기\n- 서버에 접속한다.\nssh lgcgb@10.178.144.65\n실행된 프로세스를 찾기위해 아래를 실행한다.\nps aux | grep jupyter-lab\n결과는 아래와 같이 나온다.\nlgcgb    26888  0.2  0.1 326760 86724 ?        Sl   10:14   0:12 /home/lgcgb/anaconda3/envs/py20190129/bin/python3.7 /home/lgcgb/anaconda3/envs/py20190129/bin/jupyter-lab\nlgcgb    27146  0.0  0.0  15720  1008 pts/3    S+   11:56   0:00 grep --color=auto jupyter-lab\n26888에 해당하는 것이 주피터를 띄운 커널이다. 이 번호를 기억했다가 프로세스를 아래와 같은 명령으로 죽인다.\nkill 26888\n\n\n패스워드 없이 주피터 실행\n- 아래와 같이 하면 외부에서 접속할때 패스워드를 입력하지 않음.\njupyter lab --LabApp.token='' --LabApp.password=''\njupyter notebook --NotebookApp.token='' --NotebookApp.password=''"
  },
  {
    "objectID": "posts/5. Notes/2000-01-01-UbuntuSetting.html",
    "href": "posts/5. Notes/2000-01-01-UbuntuSetting.html",
    "title": "우분투 포맷 및 개발용 서버 셋팅",
    "section": "",
    "text": "About this doc\n- 우분투에서 여러가지 개발환경을 설정하는 방법을 포스팅 하겠다.\n- 이 포스트는 우분투를 메인OS(사무용+연구용)로 사용하고 싶은 사람, 우분투를 활용하여 개발용 서버를 구축하고 싶은 사람에게 모두 유용한다.\n- 이 포스트는 2080 이상의 GPU를 활용한 학습을 원하는 사람에게 유용하다.\n- 이 포스트는 R과 파이썬을 동시에 쓰는 사람에게 유용하다.\n- 이 포스트는 Rstudio, Jupyter Lab을 동시에 쓰는 사람에게 유용하다.\n- 매년 조금씩 셋팅방법이 다른것 같다.\n- 가장 최근에는 2022년 2월5일에 이 블로그 내용으로 셋팅해보았음.\n\n\n우분투설치\n- 22.04부터는 파티션 나누지 않고 그냥 설치해도 잘 되는것 같다.\n\n\n한글설정 (개발용 서버일 경우 생략 가능)\n- 아래와 같이 커맨드에 친다.\nibus-setup\n이걸 치면 IBus Preferences 라는 창이 나오는데 여기에서 (1) Input Method 탭 클릭 (2) Add 버튼 클릭 (3) Korean 선택 (4) Hangul 선택을 한다.\n- 위의 단계에서 Korean이 안보이면 Language Support로 가서 한국어팩을 설치하고 리부팅 하면 된다. (보통 실행하자마자 알아서 설치되더라.. 설치가 안되면 Install / Remove Languages... 이라는 탭을 클릭해서 설치하자) 리부팅을 꼭 해야한다는 것에 주의하자.\n- 이제 Region & Language로 가서 설정하면 된다.\n\n\n그래픽카드 드라이버설치\n- 전체적인 내용은 여기를 참고하자.\n- 준비작업\nsudo apt install gcc\nsudo apt install build-essential\n\nNote: gcc, build-essential이 설치되지 않을경우 우분투 업그레이드가 필요할수있음. 그럴때는 sudo apt update 를 실행하면 된다.\n\n- 우선 gedit를 열고 아래를 복사해서 붙여넣는다.\nblacklist nouveau\noptions nouveau modeset=0\n파일이름을 blacklist-nouveau.conf로 home에 저장\n- 루트권한획득\nsudo -i\n아이디와 비밀번호를 입력하고 루트권한을 얻는다.\n- 아래를 입력한다.\nsudo cp /home/cgb2/blacklist-nouveau.conf /etc/modprobe.d\nsudo update-initramfs -u\nsudo reboot \n- 그래픽카드 다운로드: 드라이버 설치파일을 다운받는다. 앤비디아공식홈페이지에서 다운받자. OS를 리눅스 64-bit으로 선택하고 검색을 누르면 다운받아진다.\n- 그래픽키다 설치: 다운받은뒤에는 파일이 있는 폴더로 이동하여\nchmod +x NVIDIA-Linux-x86_64-410.78.run\n를 실행하자. 보통 NVI까지치고 적당히 탭을 누르면 알아서 뒷부분이 완성된다. 이 과정은 추후에 드라이버를 실행할수 있도록 권한을 풀어두는 것이다. 그리고 아래를 실행한다.\nsudo ./NVIDIA-Linux-x86_64-410.78.run\n그 다음 드라이버가 잘 설치되었는지 확인한다.\nnvidia-smi\n\n\n아나콘다\n- (아나콘다 설치) 아나콘다를 다운받은 폴더로 가서 아래와 같이 실행한다.\nbash Anaconda3-2019.03-Linux-x86_64.sh\n대충 bash Ana 정도까지만 치고 tab을 누르면 알아서 완성된다.\n- (환경만들기) 커맨드를 키고 아래를 실행한다.\n(base) conda create -n py38r40 python=3.8\n(base) conda create --name py38r40 python=3.8\n둘 중 아무거나 실행해도 된다. 파이썬 환경이 너무 높으면 나중에 conda tensorflow-gpu가 먹히지 않으니 환경을 만들때 파이썬버전을 3.8.x로 하자. (현시점 2021년 2월25일기준 3.9.x이면 conda tensorflow-gpu 가 동작하지 않음.)\n\n\nssh연결\n- 처음에 ssh를 연결하기위해서는 연결당하는 컴퓨터에 가서 아래를 실행해야 한다.\nsudo apt install openssh-server\n\n22번포트 우회하기\n- step1: /etc/ssh/sshd_config 파일을 연다.\nsudo vi /etc/ssh/sshd_config \n- step2: Port 22 라고 된 부분의 주석을 풀고 원하는 포트번호 설정\n...\n\n#Port 22\n#AddressFamily any\n#ListenAddress 0.0.0.0\n#ListenAddress ::\n\n...\n- step3: 수정내용을 적용\nsudo systemctl restart ssh.service\n- step4: 수정한 포트로 ssh접속\n\n\n\n주피터랩 원격제어\n- 1단계: 주피터랩설치\n(py38r40) conda install -c conda-forge jupyterlab\n\nNote: 사실 위에서 주피터랩을 따로 설치안해도 주피터랩이 잘만 실행된다. 하지만 이렇게하니까 나중에 R커널을 만들기위해 IRkernel::installspec()을 실행할때 에러가 난다.\n\n- 2단계: 패스워드 설정\n(py38r40) jupyter lab --generate-config\n(py38r40) jupyter lab password\n- 3단계: jupyter lab 환경설정\nnano /home/cgb/.jupyter/jupyter_lab_config.py \n아래를 변경\nc.ServerApp.ip = '192.168.0.4'\nc.ServerApp.port = 1306\nc.ServerApp.open_browser = False\n여기에서 192.168.0.4 는 내부아이피다. 고정아피이가 있다면 고정아이피 주소를 쓰면 된다.\n\n\n주피터노트북 원격제어\n- 1단계: 주피터노트북 설치 (보통 lab을 설치하면 이미 설치되어있음)\n(py48r40) conda install -c conda-forge notebook \n- 2단계: 패스워드 설정\nfrom notebook.auth import passwd\npasswd()\nEnter password: \nVerify password: \n생성된값 (argon 어쩌고..)을 복사\n- 3단계: 환경설정\njupyter notebook --generate-config\nnano /home/cgb/.jupyter/jupyter_notebook_config.py\n아이피주소와 패스워드를 바꾼다. (port는 선택, browser도 선택 )\nc.NotebookApp.open_browser = False\nc.NotebookApp.ip = '192.168.0.4'\nc.NotebookApp.port = 1307\nc.NotebookApp.password = ''\n여기에서 192.168.0.4 는 내부아이피다. 고정아피이가 있다면 고정아이피 주소를 쓰면 된다.\n\nTip: 주피터노트북과 랩을 양쪽으로 셋팅후 주피터 노트북으로 실행하면 2개를 모두 쓸 수 있음\n\n\n\nR설치ver1: (base)에 설치\n- 설치전: 기존의 R 삭제\nconda remove r-base -y \nsudo apt-get remove r-base-core \nsudo apt purge r-base* r-recommended r-cran-*\nsudo apt autoremove\n- R설치전 준비작업: 나노에디터를 키고 /etc/apt/sources.list를 연다.\nsudo nano /etc/apt/sources.list\n화살표로 이동하여 맨아래로 간뒤에 아래중 하나를 추가한다. (나는 focal-cran40으로 추가함)\ndeb https://cloud.r-project.org/bin/linux/ubuntu impish-cran40/\ndeb https://cloud.r-project.org/bin/linux/ubuntu hirsute-cran40/\ndeb https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/\ndeb https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/\ndeb https://cloud.r-project.org/bin/linux/ubuntu xenial-cran40/\n저장후 나노에디터 종료. 그리고 아래를 실행.\nsudo apt-get update\n경우에 따라서 아래와 같은 에러메시지가 뜰 수 있다.\n...\nW: GPG error: https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9 \n...\n공개키가 없어서 생기는 에러이므로 아래와 같이 가져온다.\nwget -qO- https://cloud.r-project.org/bin/linux/ubuntu/marutter_pubkey.asc | sudo tee -a /etc/apt/trusted.gpg.d/cran_ubuntu_key.asc\nsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9\n#sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 51716619E084DAB9\n그리고 다시 아래를 실행\nsudo apt-get update\n에러가 없이 뭔가 마무리 되어야한다.\n(base) cgb3@cgb3:~$ sudo apt-get update\nIgn:1 http://linux.dropbox.com/ubuntu disco InRelease\nHit:2 http://security.ubuntu.com/ubuntu focal-security InRelease  \nHit:3 http://kr.archive.ubuntu.com/ubuntu focal InRelease                                 \nHit:4 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease                \nHit:5 http://linux.dropbox.com/ubuntu disco Release                 \nGet:6 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\nHit:8 http://kr.archive.ubuntu.com/ubuntu focal-updates InRelease\nGet:9 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ Packages [46.4 kB]\nHit:10 http://kr.archive.ubuntu.com/ubuntu focal-backports InRelease\nFetched 50.0 kB in 1s (36.5 kB/s)                   \nReading package lists... Done\n- R설치\nwget http://security.ubuntu.com/ubuntu/pool/main/i/icu/libicu66_66.1-2ubuntu2_amd64.deb\nsudo dpkg -i libicu66_66.1-2ubuntu2_amd64.deb\nsudo apt-get install r-base\n- tidyverse 설치전 준비작업 (필요없어진듯)\nsudo apt-get install -y libxml2-dev libcurl4-openssl-dev libssl-dev\n- Rstudio 설치: https://www.rstudio.com/products/rstudio/download-server/debian-ubuntu/\nsudo apt remove rstudio-server\nsudo apt-get install gdebi-core\nwget https://download2.rstudio.org/server/bionic/amd64/rstudio-server-2021.09.2-382-amd64.deb\nsudo gdebi rstudio-server-2021.09.2-382-amd64.deb\n- Rstudio를 설치하면 ~/R/x86_64-conda-linux-gnu-library/4.1이 새로 생성된다. - Rstudio에서 설치한 패키지는 이 폴더에 저장된다.\n- 주피터와 R커널 연결\nR # sudo R \ninstall.packages(\"IRkernel\")\nIRkernel::installspec()\n\n\nR설치ver2: (py38r40)에 설치\n- R설치\n(py38r40) conda install -c conda-forge r-essentials=4.0\n이러면 콘다환경에는 R이 깔리고 base에는 R이 깔리지 않는다.\n- 커널연결\n콘다환경에서 R을 실행한다. Rstudio가 아니라 커맨드에서 R을 실행해야한다. 그리고 아래를 실행하면 주피터랩과 R환경이 연결된다.\nIRkernel::installspec()\n이제 주피터랩에서 R kernel을 사용할 수 있다.\n\n\n가상환경에서 Rstudio server 설치 (어려움)\n- 이제 Rstudio server를 설치하는 방법을 다룬다.\n- 먼저 Rstudio를 설치한다. 참고로 Rstudio server 설치하는법은 여기를 참고하라. 요약하면 터미널에서 아래3줄을 입력하기만 하면된다.\n(py38r40) sudo apt-get install gdebi-core\n(py38r40) wget https://download2.rstudio.org/server/bionic/amd64/rstudio-server-1.2.5033-amd64.deb\n(py38r40) sudo gdebi rstudio-server-1.2.5033-amd64.deb\n\nWarning: Rstudio 1.3x 이상을 설치하지말고 1.2x를 설치해야 한다. 이상하게 1.3x이상은 후에 서술할 Gregor Strurm가 그의 깃허브에서 제안하는 방식이 잘 동작하지 않았다. 이는 알려진 문제였고 이를 해결하는 해결책을 서술한 스레드가 있어보이긴 했지만 나는 그냥 Rstudio 1.2x를 설치하고 쓰는 것을 선택했다.\n\n\nNote: 이미 rstudio server 가 다른버전으로 깔려있다면 sudo apt remove rstudio-server 를 통하여 삭제하고 설치하자.\n\n- 이제 Rstudio 설치가 끝났다. 설치된 Rstudio를 아나콘다 가상환경에 설치된 R과 연결해보자. 우선 아래를 실행한다.\n(py38r40) sudo apt install uuid\n(py38r40) sudo apt install git\n(py38r40) git clone https://github.com/grst/rstudio-server-conda.git\n위에 두줄은 Gregor Sturm이 만든 어떤 프로그램을 쓰기 위한 사전준비작업이다. 마지막줄을 실행하면 Gregor Sturm이 만든 프로그램이 다운받아진다. 이게 프로그램 설치가 완료된것이다. 이제 컴퓨터 껐다 킬때마다 아래를 실행한다.\n(py38r40) ./rstudio-server-conda/local/start_rstudio_server.sh 8787 # use any free port number here. \n이제 192.168.0.4:8787 따위의 주소로 접속하면 Rstudio를 쓸 수 있다. 참고로 system-wide Rstudio server를 죽여야 할 때가 있다. 그럴땐 아래 명령을 치면 된다.\n(py38r40) sudo systemctl disable rstudio-server.service\n(py38r40) sudo systemctl stop rstudio-server.service\n\n\n자주 설치하는 패키지 리스트\n- 아래를 미리 깔아두자..\n# conda install -c conda-forge jupyterlab \nconda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch\npip install fastai\npip install plotly \npip install ipywidgets\npip install jupyter-dash\npip install dash \npip install plotnine\npip install seaborn\npip install opencv-python\npip install folium\npip install pandas_datareader\nconda install -c conda-forge r-essentials=4 \npip install rpy2\nconda install -c conda-forge python-graphviz\n- tensorflow-gpu 는 현재(2022-03-06) python=3.10 에서 동작함\nconda create -n py310 python=3.10 \nconda activate py310 \nconda install -c conda-forge tensorflow-gpu \n- 아래를 설치하면 좋음\nsudo apt install mc \n\n\n터미널 예쁘게 만들기\n- zsh 설치 + oh my zsh 설치\nsudo install zsh \nsh -c \"$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\"\n- 테마변경\n\n.zshrc 파일 열기\n\nnano ~/.zshrc \n\n아래의 내용 수정\n\n...\nZSH_THEME=\"agnoster\"\n...\n- 색상변경\n\n아래의 파일 열기\n\ncd ~/.oh-my-zsh/themes/\nnano agnoster.zsh-theme  \n\n내용수정\n\n...\nprompt_dir() {\n  prompt_segment 39d $CURRENT_FG '%~'\n}\n...\n\n\nsublime text and TeX (개발용 서버일 경우 생략 가능)\n- ‘Ubuntu Software’에 가서 ’sublime Text’를 치면 다운받을 수 있다. 다운받은뒤에 ’file’ -> ’open folder’를 활용하여 깃허브의 로칼저장소를 열어두면 편리하다.\n- 아래를 실행하여 TeX을 깐다.\nsudo apt install texlive-full\n- 이제 sublime과 latex을 연결하여보자. 여기를 참고하자. (1) sublime을 키고 ‘컨트롤+쉬프트+p’를 눌러 ’Install Package Control’ 선택 (2) 다시 ‘컨트롤+쉬프트+p’ 를 눌러 ‘Package Control: Install Package’를 실행 (3) 그러면 바로 검색창이 나오는데 거기서 ’LaTeXTools’를 입력해서 실행 (4) 다시 ’컨트롤+쉬프트+p’를 누르고 ’LaTeXTools: Check system’ 선택. 모두 ’available’이 나오면 잘 설치된 것이다.\n- *.tex파일을 열고 ’컨트롤+b’를 누르자. 처음이면 어떤 메뉴들이 보일텐데 그냥 ’Latex’을 선택하자. 그러면 코딩결과가 pdf로 나온다.\n- (수식미리보기) ‘Perferences’ > ‘Packages Setting’ > ‘LaTeXTools’ > ‘Settings-User’를 선택한다. ’93번째라인’에 ’preview_math_mode’를 “all”로 바꾼다. 그러면 수식들이 미리 출력된다. 그외에도 자유롭게 셋팅을 조정할 수 있다. 원래셋팅은 ’Perferences’ > ‘Packages Setting’ > ‘LaTeXTools’ > ‘Settings-Defaults’ 에 있다."
  },
  {
    "objectID": "posts/5. Notes/2000-01-08-Git.html",
    "href": "posts/5. Notes/2000-01-08-Git.html",
    "title": "깃(Git)",
    "section": "",
    "text": "clone\ngithub repository \\(\\to\\) code \\(\\to\\) clone tab, ssh를 복사 (git@github.com:miruetoto/yechan.git처럼 생김)\n터미널에서 아래를 입력\ngit clone git@github.com:miruetoto/yechan.git 01_yechan\n\n\npull\n- 깃이 설치된 가장 상위폴더(Documents/Github/miruetoto.github.io)에 가서 아래를 입력한다.\ngit pull\n\n\nbranch\n- 서버에 이미 guebin이라는 브랜치가 있다면 아래와 같이 동기화 시킨다.\ngit chechout guebin\ngit push -u origin guebin\n여기에서 git push -u origin guebin을 안해도 동기화가 잘될때도 있는데 아닐때도 있다.\n\n\nremote\n- 깃이 설치된 가장 상위폴더(Documents/Github/miruetoto.github.io)에 가서 아래를 입력하면 깃허브의 url 주소를 확인할 수 있다.\n(base) lgcgb2@lgcgb2:~/Documents/GitHub/miruetoto.github.io$ git remote -v\norigin https://github.com/miruetoto/miruetoto.github.io.git (fetch)\norigin https://github.com/miruetoto/miruetoto.github.io.git (push)\nupstream https://github.com/daattali/beautiful-jekyll.git (fetch)\nupstream https://github.com/daattali/beautiful-jekyll.git (push)\n\n\nconfig\n- 설정보기\ngit config —list \n- 설정삭제\ngit config --unset user.name\ngit config --unser user.email\n- 전역설정삭제\ngit config --unset --global user.name\ngit config --unset --global user.email\n- 중복값 설정삭제\ngit config --unset-all user.name\ngit config --unset-all user.email\n- 중복값 전역으로 설정삭제\ngit config --unset-all --global user.name\ngit config --unset-all --global user.email\n- 비번안치고 푸쉬하는법?\ngit config credential.helper store\n입력이후에 git push\n\n\nGit token\nhttps://github.com/settings/tokens 에서 확인가능\n\nAppendix\n\n리눅스에서 github desktop 설치\n\n여기로 간다.\n한 챕터의 (2.3.1 Linux RC1 와 같이 되어있음) 아래쪽에 보면 ▶ Assets 라고 되어있는데 이걸 클릭하면 다운받을 수 있는 파일들이 나온다. 확장자가 .deb로 끝나는걸 골라서 다운받은뒤에 실행한다."
  },
  {
    "objectID": "posts/5. Notes/2000-01-04-Ubuntu.html",
    "href": "posts/5. Notes/2000-01-04-Ubuntu.html",
    "title": "우분투",
    "section": "",
    "text": "날짜, 달력\ndate \ncal \n\n\n파일시스템\n- 작업경로, 디렉토리 이동, 파일확인\npwd \ncd cgb2 \ncd ~cgb2 ## 어디서든 실행가능\ncd ## cgb2로 로그인 되어있을 경우 cd ~cgb2와 동일 \ncd ~cgb2/Dropbox\nls \nls -a \nls -l # 자세히\nls -lt # 자세히+파일수정시간에 따른 정렬\nls -lt --reverse # 자세히+파일수정시간의 역순으로 정렬 \n- 엄밀하게는 cd cgb2 는 cd ./cgb2로 써야한다. 하지만 ./는 생략가능하므로 그냥 cd cgb2라고 쓰는것\n- 뭐하는 파일인지 알고싶다면?\nfile picture.jpg\n- 카피, 이동, 새폴더, 삭제, 바로가기\ncp file1 file2 # file1을 복사하여 file2를 새로 만듬. file2가 이미 있다면 file1의 내용을 덮어씀 \ncp file1 file2 -i # 위와 동일한데 덮어쓰기 여부에 대한 확인메시지 생성\ncp file1 file2 --interactive # 위와 동일\ncp -r dir1 dir2 # dir1의 모든파일을 복사하여 dir2로 이동한뒤 붙어넣음. dir2가 없다면 새로 만듬. 기존의 dir2에 있던 파일이 삭제되는건 아님 \ncp --recursive dir1 dir2 # 위와 동일 \nmv # 카피사용방법과 동일 \nmkdir temp\nmkdir temp1, temp2, temp3 \nrm file1 # file1삭제 \nrm -r file1 dir1 # file1삭제 dir1폴더삭제 \nrm -rf file1 dir1 # 위와 동일한데 file1이나 dir1이 존재하지 않더라고 rm이 실행\nln ## 바로 가기 만드는건데 쓸줄모름 배우기 싫어\n- -v(verbose)를 쓰면 친절한 느낌이 든다.\n(base) cgb2@cgb2-desktop:~/Dropbox$ cp *.txt temppp -v\n'colab.txt' -> 'temppp/colab.txt'\n\n\necho\n- echo 기본기능\ncgb2@cgb2-desktop:~/Dropbox/temppp$ echo test\ntest\n- echo + * : *가 현재 디렉토리에 있는 모든 파일이름으로 확장된이후에 echo가 동작함.\n(base) cgb2@cgb2-desktop:~/Dropbox/temppp$ ls\ncolab.txt  sample.txt\n(base) cgb2@cgb2-desktop:~/Dropbox/temppp$ echo *\ncolab.txt sample.txt\n- 응용\n(base) cgb2@cgb2-desktop:~$ echo D*\nDesktop Documents Downloads Dropbox\n- 응용2\n(base) cgb2@cgb2-desktop:~$ echo /usr/*\n/usr/bin /usr/games /usr/include /usr/lib /usr/lib32 /usr/lib64 /usr/libexec /usr/libx32 /usr/local /usr/sbin /usr/share /usr/src\n- 응용3\n(base) cgb2@cgb2-desktop:~$ echo ~\n/home/cgb2\n- 응용4\n(base) cgb2@cgb2-desktop:~/Dropbox$ echo $((2+2))\n4\n\n\n기본디렉토리 설명\n/bin 시스템 부팅과 실행에 필요한 바이너리(프로그램)들을 포함\n/etc 시스템 전반의 환경설정. 이 디렉터리의 모든 파일은 텍스트형식임.\n\n/etc/password 사용자 계정정보\n\n/lib 시스템 프로그램에서 사용하는 공유 라이브러리가 저장. 윈도우즈의 DLL과 비슷한 것.\n/usr 사용자가 사용하는 모든 프로그램과 지원파일들 (Program files + 프로그램들의 설정값)\n\n/usr/bin 리눅스 배포판이 설치한 실행 프로그램들이 있다. (여기에 R이 깔린다!!)\n\nhp-align, hp-check, hp-config_usb-printer …\nX11\nvi\ngcc\nsu, sudo\nsar\nssh, ssh-agent, ssh-keygen, ….\nnvidia-smi\n\n/usr/lib 여기에는 /usr/bin에 있는 프로그램들을 위한 공유라이브러리가 저장된다. (여기에 R folder가 있다)\n\n여기에 R폴더가 있다. 그런데 R패키지가 여기에 깔리진 않음\n\n/usr/local/bin 소스코드로 컴파일된 파일, 보통 비어있음\n/usr/local/lib/R/site-library R패키지가 설치되어있음, 예를들면 tidyverse\n\n\n\nvim\n- 파일여는법/만드는법 (sudo는 읽기전용 파일을 만들수있음)\nsudo vim /etc/apt/sources.list\n- 에디터에서 사용법\ni \nESC \n:w \n:q\n:wq\n/keyword  \ndd # 현재행삭제 \n\n\nwget\nwget https://download2.rstudio.org/server/bionic/amd64/rstudio-server-1.2.5033-amd64.deb\n\n\ngdebi\nsudo gdebi rstudio-server-1.2.5033-amd64.deb\n\n\napt\nsudo apt-get remove r-base-core\nsudo apt purge r-base* r-recommended r-cran-*\nsudo apt autoremove\nsudo apt list \nsudo apt update\nsudo apt install openssh-server \nsudo apt-get install gdebi-core\n- sudo apt-get과 sudo apt 차이? 별 차이 없는듯 - https://askubuntu.com/questions/445384/what-is-the-difference-between-apt-and-apt-get\n\nThey are very similar command line tools available in Trusty (14.04) and later. apt-get and apt-cache’s most commonly used commands are available in apt. apt-get may be considered as lower-level and “back-end”, and support other APT-based tools. apt is designed for end-users (human) and its output may be changed between versions.\n\n\n\nconda\nconda \nconda env -h \nconda install -h \nconda remove -h  \nconda update -h \nconda env list\nconda create -n py38r40 python=3.8\nconda env remove -n py38r40 \nconda install -c conda-forge jupyterlab \nconda remove jupyterlab \nconda remove r-base -y \nconda remove -n py38r40 jupyterlab \nconda update scipy\nconda update -n py38r40 scipy\nconda list \n\n\npip\npip\npip list\npip list > list.txt\npip freeze # 좀 더 자세히 나온다 \npip freeze > list.txt \npip show matplotlib # 설치된패키지 정보가 나옴. 좋음.\npip install rpy2\npip install -r list.txt \npip install dash==1.13.3\npip install jupyterlab \"ipywidgets>=7.5\"\npip install -U numpy\npip install --upgrade pip\npip install --upgrade tensorflow\npip uninstall matplotlib\n\n\n리소스 모니터링\ndf # disk \nfree # memory \nnvidia-smi \nwatch -n 5 nvidia-smi -a --display=utilization\ntop\nsar -1 r \n\n# 나노에디터\n\n`-` 파일열기\n\n```default\nsudo nano /etc/apt/sources.list\n- 읽기전용 파일만들기: 파일을 만드는것도 파일 여는방법과 동일함. 즉 아래와 같이 하면 exam.txt가 현재 폴더에 있다면 열고아니면 (읽기전용으로) 만든다.\nsudo nano /home/cgb/Desktop/exam.txt\n- 읽기전용이 아닌 일반파일 만들기\nnano /home/cgb/Desktop/exam.txt\n- 나노에디터종료: 컨트롤+X\n- 파일저장: 컨트롤+O\n- 찾기: 컨트롤+W\n- 되돌리기: 알트+U\n\n\nssh\n- 처음에 ssh를 연결하기위해서는 연결당하는 컴퓨터에 가서 아래를 실행해야 한다.\nsudo apt install openssh-server\n\n22번포트 우회하기\n- step1: /etc/ssh/sshd_config 파일을 연다.\nsudo vi /etc/ssh/sshd_config \n- step2: Port 22 라고 된 부분의 주석을 풀고 원하는 포트번호 설정\n...\n\n#Port 22\n#AddressFamily any\n#ListenAddress 0.0.0.0\n#ListenAddress ::\n\n...\n- step3: 수정내용을 적용\nsudo systemctl restart ssh.service\n- step4: 수정한 포트로 ssh접속\n\n\n\nsublime\n- 찾아바꾸기: 컨트롤+h\n- 화면분할: 옵션+커맨드+2,3,4 …\n\n\n파일생성, 파일삭제\ncat > sample.txt \nrm -r folderName \nrm -rf .local/share/Trash/files/* # 휴지통삭제"
  },
  {
    "objectID": "posts/4. Reviews/2022-12-23-Ebayesthresh.html",
    "href": "posts/4. Reviews/2022-12-23-Ebayesthresh.html",
    "title": "EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "",
    "text": "ref: https://www.jstatsoft.org/article/view/v012i08"
  },
  {
    "objectID": "posts/4. Reviews/2022-12-23-Ebayesthresh.html#ebayesthresh로-무엇을-할-수-있는가",
    "href": "posts/4. Reviews/2022-12-23-Ebayesthresh.html#ebayesthresh로-무엇을-할-수-있는가",
    "title": "EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "Ebayesthresh로 무엇을 할 수 있는가?",
    "text": "Ebayesthresh로 무엇을 할 수 있는가?\n아래와 같은 상황을 가정하자.\n\\[X_i = \\mu_i +\\epsilon_i.\\]\n여기에서 아래를 가정한다.\n\n\\(\\epsilon_i \\overset{iid}{\\sim} N(0,1)\\)\neach \\(\\mu_i\\) is zero with probability \\((1−w)\\), while, with probability \\(w\\), \\(\\mu_i\\) is drawn from a symmetric heavy-tailed density \\(\\gamma\\).\n\n일반적으로 \\(w\\), 즉 \\(\\mu_i\\)가 0이 아닐 확률은 매우 작은값으로 설정된다. 따라서 위와 같은 구조로 \\(\\epsilon_i\\)와 \\(\\mu_i\\)를 생성하면 아래와 같이 된다.\n\n\\(\\epsilon_i\\): 절대값이 작은 신호들이 dense하게 있음.\n\\(\\mu_i\\): 절대값이 큰 신호들이 sparse하게 있음. (sparse한 이유는 \\(w\\)가 작으므로)\n\n따라서 \\(X_i\\)의 모양은 아래의 그림의 왼쪽과 같다.\n\n이 논문의 목표는 왼쪽의 그림 \\(X_i= \\mu_i +\\epsilon_i\\)로부터 오른쪽의 그림 \\(\\hat{\\mu}_i\\)을 구하는 것이다. 즉 작은 절대값의 노이즈 \\(\\epsilon_i\\)에서 큰 절대값의 신호 \\(\\mu_i\\)를 골라내는 일을 목표로 한다. 저자들은 이러한 작업을 “건초더미에서 바늘찾기”라는 말로 비유하였다. 이러한 “건초더미에서 바늘찾기”는 여러 분야에 응용될 수 있다. 구체적으로는 천문학, 이미지프로세싱, 데이터마이닝, 모형선택등에 사용될 수 있다고 한다. 언급한 분야에 대한 자세한 discussion은 Johnstone and Silverman (2004)에서 찾을 수 있다. 또한 “건초더미에서 바늘찾기”는 위에서 언급한 분야 이외에 퓨리에, 웨이블릿 혹은 다른 dictionaries에 의한 함수추정문제를 해결할 수 있다. 이는 퓨리에나 웨이블릿변환과 같은 multiscale trasnform이 원래 신호를 sparese한 구조로 바꾸기 때문이다. 즉 퓨리에변환 웨이블릿변환으로 underlying function을 추정할 수 있다는 의미이다. 우리는 이러한 접근법에 좀 더 초점을 맞추도록 하겠다."
  },
  {
    "objectID": "posts/4. Reviews/2022-12-23-Ebayesthresh.html#간단한-사용법",
    "href": "posts/4. Reviews/2022-12-23-Ebayesthresh.html#간단한-사용법",
    "title": "EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "간단한 사용법",
    "text": "간단한 사용법\nR을 이용하여 Ebayesthresh를 사용하는 간단한 방법을 살펴보도록 하자. 논문에 표현된 그림1을 재현하여 보자.\n\nlibrary(EbayesThresh)\n\n\nset.seed(1)\nx <- rnorm(1000) + sample(c( runif(25,-7,7), rep(0,975)))\nplot(x,type='l',lwd=0.2)\n\n\n\n\n위와 같은 자료 \\(X_i\\)를 관측하였다고 가정하자. 이 신호에는 “건초(\\(\\epsilon_i\\))”더미에 25개의 “바늘(\\(\\mu_i\\))”이 섞여있다. 여기에서 “바늘”만 골라내는 코드는 아래와 같이 작성할 수 있다.\n\nmuhat <- ebayesthresh(x, sdev=1)\n\n결과를 시각화하면 아래와 같다.\n\nplot(x,type='l',lwd=0.2)\nlines(muhat,col=2,lwd=2)"
  },
  {
    "objectID": "posts/4. Reviews/2022-12-23-Ebayesthresh.html#arguments",
    "href": "posts/4. Reviews/2022-12-23-Ebayesthresh.html#arguments",
    "title": "EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "arguments",
    "text": "arguments\n일반적으로 ebayesthresh 함수를 사용하는 방법은 아래와 같다.\n\nmuhat <- ebayesthresh(\n    x,\n    prior = \"laplace\", \n    a = 0.5, \n    bayesfac = FALSE, \n    sdev = NA, \n    verbose = FALSE, \n    threshrule = \"median\"\n)\n\nprior, a: \\(\\mu_i\\)의 density. 보통 \\(\\frac{1}{2}a \\exp(-a|u|)\\)라고 가정한다. parameter \\(a\\)는 Section 2.1에서 자시해 나옴.\nbayesfac, threshrule: Section 2.2, 2.3에 자세히 나온다.\nsdev: \\(\\epsilon_i\\)의 sd를 의미한다. 이 값을 알고 있다면 설정하면 되지만 보통은 이 값을 모른다고 가정한다. \\(\\epsilon_i\\)의 sd를 모르는 경우는 observed data로 부터 추정하는데 보통 \\({\\tt median}(|X_i|)\\)로 추정한다.\n\\(\\epsilon_i\\)의 sd를 \\({\\tt median}(|X_i|)\\)로 추정하는 motivation을 이해하는 것이 중요하다. 이는 sparse assumption of \\(\\mu_i\\)에서 시작한다. 신호 \\(\\mu_i\\)가 합리적인 수준에서 sparse하다면 median absolute value of \\(X_i\\)는 \\(\\mu_i\\)의 값들과 상관이 없을 것이다. 하지만 당연히 신호가 sparse하지 않다면 이러한 방식으로 sdev를 추정하는 것은 매우 조심스럽게 수행되어야 할 것이다.\n\nn <- 1000\nx <- rnorm(n) + sample(c(runif(25,-7,7), rep(0,n-25)))\nprint(sd(x))\nprint(median(abs(x)))\n\n[1] 1.117016\n[1] 0.6787613\n\n\n\n실제로는 잘 추론하지 못하는 것 같다?"
  },
  {
    "objectID": "posts/4. Reviews/2022-12-23-Ebayesthresh.html#원리",
    "href": "posts/4. Reviews/2022-12-23-Ebayesthresh.html#원리",
    "title": "EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "원리",
    "text": "원리\n어떻게 \\(\\hat{\\mu}_i\\)를 추정할 수 있을까? 가장 간단한 방법은 thresholding이다.\n많은 실제예제에서 \\(\\mu_i\\)는 어떤 의미에서 (in some sense) sparse하다고 여길 수 있다. EbayesThresh 패키지는 이처럼 \\(\\mu_i\\)가 sparse하다는 구조 (혹은 가정)을 이용하여 \\(\\mu_i\\)를 적절하게 추정한다.\nSparsity를 이용하는 자연스러운 방법은 threshoding이다: 여기에서 threshold의 값 \\(t\\)를 너무 크게 잡으면 신호를 잡음으로 잘못 판단할 것이고 \\(t\\)의 값이 너무 작다면 잡음을 신호로 잘못 판단할 수 있다. 따라서 \\(t\\)의 선택은 이 양쪽 기준사이의 tradeoff가 있는데 EbayesThresh는 이러한 tradeoff를 자동으로 조정하는 효과가 있다.\n\n\\(\\mu_i\\)는 \\(w\\)의 확률로 0 이며 \\((1-w)\\)의 확률로 0이 아니다. \\(\\mu_i\\)가 0이 아닐경우에는 symmetric heavy-tailed density \\(\\gamma\\)에서 추출된다고 가정한다. 여기에서 prior에 대한 key parameter인 \\(w\\)는 데이터로부터 자동으로 추정된다. (marginal maximum likelihood 를 이용한다) 그리고 추정된 \\(w\\)는 Bayesian model로 다시 대입된다.\n\\(w\\)가 추정되면 Bayesian model은 thresholding procedure를 수행할 수 있다. 왜냐하면 \\(w\\)를 추정하면 \\(t(w)\\)를 선택한다는 말과 같은말이기 때문이다.\n\nargument"
  },
  {
    "objectID": "posts/4. Reviews/2022-12-23-Ebayesthresh.html#the-bayesian-model",
    "href": "posts/4. Reviews/2022-12-23-Ebayesthresh.html#the-bayesian-model",
    "title": "EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "The Bayesian model",
    "text": "The Bayesian model\n\\[X_i \\sim N(\\mu_i,1)\\]\n\\(f_{\\text{prior}}(\\mu)=(1-w)\\delta_0(\\mu)+w \\gamma_a(\\mu), \\quad \\gamma_a(\\mu)=\\frac{1}{2}a\\exp(-a|\\mu|)\\)\n여기에서 \\(\\gamma_a(\\mu)\\)는 하나의 예시일 뿐이다. Ebayesthresh에 디폴트로 설정된 prior=\"laplace\"를 셋팅하면 \\(\\gamma_a(\\mu)\\)가 사용된다. \\(\\gamma\\)의 선택은 tail이 polynomial rates로 줄어드는 어떠한 분포를 사용해도 무방하다. 저자들은 quasi-Cauchy분포를 제안하였는데 이는 Johnstone and Sliverman이 만든 theoretical assumption을 만족하는 분포중 가장 꼬리가 두꺼운 분포이다."
  },
  {
    "objectID": "posts/4. Reviews/2022-12-23-Ebayesthresh.html#thresholding-rules",
    "href": "posts/4. Reviews/2022-12-23-Ebayesthresh.html#thresholding-rules",
    "title": "EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "Thresholding rules",
    "text": "Thresholding rules\n모수 \\(\\mu\\)는 사전분포(prior distribution)를 가진다고 가정하고 \\(X \\sim N(\\mu,1)\\)이라고 가정하자. 이 경우 \\(X=x\\)가 given되었을 경우 \\(\\mu\\)의 사후분포(posterior distribution)를 구할 수 있다. (자세한 내용은 Section 6을 참고해야함) 사후분포의 중앙값을 \\(\\hat{\\mu}(x;w)\\)라고 하자. (사후분포의 중앙값이 \\(w\\)에 영향받는 이유는 사전분포가 \\(w\\)에 depend하기 때문이다. 여기에서 \\(w\\)는 marginal MLE로 적절히 추론한다고 가정한다)\n\\(X_i\\)는 독립이라고 가정한다. 여기에서 \\(X_i\\)가 독립이 아니라면 약간의 정보손실이 있을 수 있다. 하지만 \\(X_i\\) 사이에 너무 많은 dependency가 존재하는 경우가 아니라면 Ebayesthresh는 어느정도 합리적인 결과를 제공한다.\n만약에 bayesfac=TRUE를 사용하면 \\(\\mu\\)의 사후분포의 중앙값 대신에 Bayes factor threshold 를 쓸 수도 있다."
  },
  {
    "objectID": "posts/4. Reviews/2022-12-23-Ebayesthresh.html#choosing-the-threshold",
    "href": "posts/4. Reviews/2022-12-23-Ebayesthresh.html#choosing-the-threshold",
    "title": "EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "Choosing the threshold",
    "text": "Choosing the threshold\n\\(X_i\\)의 marginal density는\n\\((1-w)\\phi(x) +w(\\gamma \\star \\phi)(x)\\)\n\\(l(w) = \\sum_{i=1}^{n}\\log \\big\\{(1-w)\\phi(X_i)+wg(X_i) \\big\\}\\)\n와 같이 정의가능하다. 단, 여기에서 \\(g:= \\gamma\\star \\phi\\) 이다.\n이제 우리는 아래의 식을 풀면된다.\n\\[\\underset{w}{\\operatorname{argmax}} l(w)\\quad\\quad \\text{subject to}\\quad t(w) \\leq \\sqrt{2\\log n}\\]\n여기에서 \\(\\sqrt{2\\log n}\\)은 흔히 말하는 universal threshold 이다.\n만약에 \\(w\\)이외에 \\(a\\)도 추정해야 한다면 아래와 같이 추정할 수 있다.\n\\[\\underset{w}{\\operatorname{argmax}} l(w)\\quad\\quad \\text{subject to}\\quad t(w) \\leq \\sqrt{2\\log n}\\]"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-11-Inequality.html",
    "href": "posts/2. Let's Study/Essays/2023-01-11-Inequality.html",
    "title": "부등식",
    "section": "",
    "text": "부등식\n\n(베르누이 부등식) \\(\\forall n \\in N, h>-1 \\Rightarrow (1+h)^n \\geq 1+nh\\)"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-07-RealAnalysis.html",
    "href": "posts/2. Let's Study/Essays/2023-01-07-RealAnalysis.html",
    "title": "해석학",
    "section": "",
    "text": "이걸 증명하려면 자연수를 정의하는 페아노공리를 알아야함.\n그리고 그 공리로부터 유도되는 여러가지 자연수 성질중 하나인 자연수 집합은 위로 유계가 아니라는 사실을 알아야함.\n아르키메데스성질: For all \\(x \\in \\mathbb{R}\\) there exists \\(N \\in \\mathbb{N}\\) such that \\(x<N\\).\n\n아무 실수나 잡으면 그 숫자보다 큰 자연수가 존재한다는 의미\n아르키메데스 성질은 완비성공리로부터 증명가능함.\n\n아르키메데스 성질을 이용하면 임의의 \\(\\epsilon\\)보다 작은 \\(\\frac{1}{N}\\)을 항상 잡을수 있다. 즉 모든 \\(\\epsilon>0\\) 에 대하여 \\(0\\leq \\frac{1}{N} < \\epsilon\\) 을 만족하는 \\(N\\)이 항상 존재함을 알 수 있다.\n(예제) 아래를 증명하라.\n\\[\\lim_{n\\to \\infty}\\frac{4n}{2n+1}=2\\]\n(풀이) 모든 \\(\\epsilon>0\\)에 대하여 아래가 항상 성립함을 보이면 된다.\n\\[\\exists N \\in \\mathbb{N} \\quad \\text{such that} \\quad n \\geq N \\Rightarrow 0\\leq \\left |\\frac{4n}{2n+1}-2 \\right|<\\epsilon\\]\n그런데 \\(|\\frac{4n}{2n+1}-2|\\leq \\frac{1}{n}\\) 이므로 우리는 모든 \\(\\epsilon >0\\)에 대하여 아래가 성립함을 보이면 된다.\n\\[\\exists N \\in \\mathbb{N} \\quad \\text{such that} \\quad n \\geq N \\Rightarrow 0\\leq \\frac{1}{n} <\\epsilon\\]\n그런데 \\(n\\geq N\\)이라는 조건하에서는 \\(\\frac{1}{n} \\leq \\frac{1}{N}\\) 이므로 우리는 다시 모든 \\(\\epsilon>0\\)에 대하여 아래가 성립함을 보이면 된다.\n\\[\\exists N \\in \\mathbb{N} \\quad \\text{such that} \\quad 0 \\leq \\frac{1}{N} <\\epsilon\\]\n이러한 \\(N\\)은 아르키메데스의 성질에 의하여 항상 존재한다."
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-07-RealAnalysis.html#체-공리",
    "href": "posts/2. Let's Study/Essays/2023-01-07-RealAnalysis.html#체-공리",
    "title": "해석학",
    "section": "체 공리",
    "text": "체 공리\n- 실수는 더하기와 곱셈이라는 연산이 합리적으로 정리되는 집합이라는 의미"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-07-RealAnalysis.html#순서-공리",
    "href": "posts/2. Let's Study/Essays/2023-01-07-RealAnalysis.html#순서-공리",
    "title": "해석학",
    "section": "순서 공리",
    "text": "순서 공리\n- 순서공리에 의하여 부등식이 정의됨\n- 3분성질"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-07-RealAnalysis.html#디리클레함수",
    "href": "posts/2. Let's Study/Essays/2023-01-07-RealAnalysis.html#디리클레함수",
    "title": "해석학",
    "section": "디리클레함수",
    "text": "디리클레함수\n모든 점에서 불연속인 함수임"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-07-RealAnalysis.html#thomae-함수",
    "href": "posts/2. Let's Study/Essays/2023-01-07-RealAnalysis.html#thomae-함수",
    "title": "해석학",
    "section": "Thomae 함수",
    "text": "Thomae 함수\n유리수에서는 불연속, 무리수에서는 연속"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-07-RealAnalysis.html#합성함수의-연속",
    "href": "posts/2. Let's Study/Essays/2023-01-07-RealAnalysis.html#합성함수의-연속",
    "title": "해석학",
    "section": "합성함수의 연속",
    "text": "합성함수의 연속\n함수 \\(f(x)\\)와 \\(g(x)\\)가 모두 \\(x=c\\)에서 연속이면 함수 \\((f\\circ g)(x)\\) 혹은 \\((g \\circ f)(x)\\)도 \\(x=c\\)에서 연속이다."
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-07-RealAnalysis.html#중간값정리-leftrightarrow-완비성공리",
    "href": "posts/2. Let's Study/Essays/2023-01-07-RealAnalysis.html#중간값정리-leftrightarrow-완비성공리",
    "title": "해석학",
    "section": "중간값정리 \\(\\Leftrightarrow\\) 완비성공리",
    "text": "중간값정리 \\(\\Leftrightarrow\\) 완비성공리"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-07-RealAnalysis.html#균등연속임을-판단하는-방법",
    "href": "posts/2. Let's Study/Essays/2023-01-07-RealAnalysis.html#균등연속임을-판단하는-방법",
    "title": "해석학",
    "section": "균등연속임을 판단하는 방법",
    "text": "균등연속임을 판단하는 방법\n\n립쉬츠조건: 어떠한 함수 \\(f\\)가 \\(|f(x)-f(u)|\\leq K|x-u|\\)를 만족하면 이러한 함수는 균등연속이다. \\(\\delta=\\frac{\\epsilon}{K}\\) 로만 선택하면 되므로\n\\(f(x)\\)가 연속이라고하자. \\(f(x)\\)의 정의역이 유계폐구간이면 함수 \\(f\\)는 균등연속이라 주장할 수 있다. 만약에 \\(f(x)\\)의 정의역이 개구간이면 구간의 양 끝점에서의 극한이 존재할때 \\(f\\)를 균등연속이라고 주장할 수 있다.\n\\(f(x)\\)가 개구간에서 정의된 경우"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-07-RealAnalysis.html#균등연속이-아님을-판단하는-방법",
    "href": "posts/2. Let's Study/Essays/2023-01-07-RealAnalysis.html#균등연속이-아님을-판단하는-방법",
    "title": "해석학",
    "section": "균등연속이 아님을 판단하는 방법",
    "text": "균등연속이 아님을 판단하는 방법\n\n어떠한 \\(\\epsilon_0>0\\)가 존재하여, 내가 \\(\\delta\\)를 어떻게 잡든 \\(|x-u|<\\delta\\) and \\(|f(x)-f(u)|\\geq\\epsilon_0\\) 를 만족하는 \\(x\\)와 \\(u\\)가 존재하면 균등연속이 아니다.\n\\(\\lim_{n\\to\\infty}(x_n-u_n)=0\\) 이지만 \\(|f(x_n)-f(u_n)| \\geq \\epsilon_0\\) 임을 확인하면 균등연속이 아니다. 즉 \\(x\\)축에서는 수렴하는 두개의 수열이 함수를 태우면 수렴하지 않는 경우"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-07-RealAnalysis.html#균등연속의-특징",
    "href": "posts/2. Let's Study/Essays/2023-01-07-RealAnalysis.html#균등연속의-특징",
    "title": "해석학",
    "section": "균등연속의 특징",
    "text": "균등연속의 특징\n코시수열을 보존한다. 즉 \\(x_n\\)이 코시수열이고 함수 \\(f\\)가 균등연속이면 \\(f(x_n)\\)역시 코시수열이다.\n연속확장정리: 개구간에서의 균등연속을 사용하고 싶음. \\(f(x)\\)가 개구간 \\((a,b)\\)에서 연속이고 양 끝점, 즉 \\(a\\), \\(b\\)에서의 극한이 존재하면 \\(f(x)\\)는 균등연속이다.\n균등연속의 아이디어: x축에서 수렴하던 어떤애가 y축에서도 수렴했으면 좋겠음. (이게 원래 안되는 건데요, 균등연속일때는 가능합니다)"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-07-RealAnalysis.html#모티브",
    "href": "posts/2. Let's Study/Essays/2023-01-07-RealAnalysis.html#모티브",
    "title": "해석학",
    "section": "모티브",
    "text": "모티브\n아래와 같은 합성함수의 미분을 생각하여 보자.4\n\\[(f\\circ g)'(c) = \\lim_{x\\to c}\\frac{f(g(x))-f(g(c))}{x-c}\\]\n(풀이1)\n고등학교 수준에서는 이것을 아래와 같이 쓸 수 있다.\n\\[\\lim_{x\\to c}\\frac{f(g(x))-f(g(c))}{x-c}=\\lim_{x\\to c}\\left(\\frac{f(g(x))-f(g(c))}{g(x)-g(c)}\\frac{g(x)-g(c)}{x-c}\\right)=f'\\big(g(c)\\big)\\cdot g'(c)\\]\n(아쉬움)\n이 증명의 단점은 \\(g(x)-g(c)\\neq 0\\)이라는 조건이 필요하다는 것이다. 이 조건을 제외할 수는 없을까? 그리스 수학자인 카라테오도리(Caratheodory)는 아래와 같은 명제를 발견하였다.\n(명제) \\(f(x)\\) 가 \\(x=c\\) 에서 미분가능하다 \\(\\Longleftrightarrow\\) 적당한 연속함수 \\(\\varphi(x)\\) 가 존재하여 (i) \\(\\varphi(x)\\) 는 \\(x=c\\) 에서 미분가능하고 (ii) \\(f(x)-f(c)=\\varphi(c)(x-c)\\) 이다.\n이것을 이용하면 합성함수의 미분을 다시 풀어보자.\n(풀이2)\n먼저 \\(g(x)\\) 는 \\(x=c\\) 에서 미분가능하다라는 조건은 아래와 같이 표현할 수 있다.\n\n\\(g(x)\\) 가 \\(x=c\\) 에서 미분가능하다 \\(\\Leftrightarrow\\) \\(g(x)-g(c)=\\varphi(c)(x-c)\\)\n\n또한 \\((f\\circ g)(x)=f(g(x))\\) 는 \\(x=g(c)\\) 에서 미분가능하다라는 조건은 아래와 같이 표현할 수 있다.\n\n\\((f\\circ g)(x)\\) 가 \\(x=g(c)\\) 에서 미분가능하다 \\(\\Leftrightarrow\\) \\(f(g(x))-f(g(c))=\\psi(g(c))(g(x)-g(c))\\)\n\n\n#"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2022-01-12-Topology.html",
    "href": "posts/2. Let's Study/Essays/2022-01-12-Topology.html",
    "title": "토폴로지",
    "section": "",
    "text": "About this doc\n- 수학공부\n- 학부수준\n- 이 문서는 논문을 읽을때 등장하는 topology 용어들을 좀더 명확하게 이해하고 싶어서 작성하였다. 가볍게 정의만 훑어보는 것이라 깊게 들어가지는 않을 예정이다. 교재는 Schaum’s General Topology 를 참고하였다. - Lipschutz, S. (1965). Schaum’s outline of theory and problems of general topology. Schaum’s Outline Series.\n- 여기에서는 토폴로지의 정의와 메트릭스페이스의 정의 그리고 컴플리션의 정의에 대하여 다룬다.\n\n\n토폴로지\n- \\({\\cal T}\\) 가 \\(X\\) 의 subset 으로 이루어진 collection 이라고 하자. \\({\\cal T}\\) 가 \\(X\\) 를 포함하며 uncountable union 에 닫혀있고 finite intersection 에 닫혀있다면 \\({\\cal T}\\) 를 \\(X\\) 의 topology 라고 한다. 그리고 \\((X,{\\cal T})\\) 를 topological space 라고 한다.\n- \\({\\cal T}\\) 가 \\(X\\)의 토플로지일때 \\({\\cal T}\\) 의 원소를 \\({\\cal T}\\)-open set 이라고 한다. 따라서 원래 오픈셋은 마치 확률변수처럼 단독으로 정의할 수 없고 어떠한 토폴로지 \\({\\cal T}\\)와 같이 정의된다.\n- 아래와 같은 collection 을 생각하자.\n\\[{\\cal O}:=\\{O: O=\\cup_i(a_i,b_i), a_i,b_i \\in \\mathbb{R} \\} \\]\n컬렉션 \\({\\cal O}\\) 는 \\(\\mathbb{R}\\) 의 토폴로지가 된다. (증명은 알아서..) 이러한 토폴로지(=오픈인터벌의 카운터블-유니온으로 표현가능한 집합들의 모임)을 특별히 usual topology 라고 한다. 그리고 이 토폴로지의 원소를 \\({\\cal O}\\)-오픈셋이라고 부른다. 따라서 어떤 집합 \\(O\\) 가 \\({\\cal O}\\)-오픈셋 이라는 말은 그 집합이 오픈인터벌의 카운터블-유니온으로 표현가능한 집합임을 의미한다.\n- 참고로 \\({\\cal O}\\) 가 우리가 일반적으로 생각하는 ‘오픈셋들의 모임’ 이고 \\({\\cal O}\\)-오픈셋이 보통 우리가 일반적으로 유클리드 공간에서 상상하는 오픈셋이다. 그래서 앞으로 특별한 언급없이 그냥 ‘오픈셋’ 이라고 부르면 토폴로지 \\((\\mathbb{R},{\\cal O})\\) 에서 정의가능한 ‘\\({\\cal O}\\)-오픈셋’ 을 의미하는 것이라고 생각하면 된다.\n- 즉 우리가 일반적으로 생각하는 오픈셋1은 오픈인터벌 \\((a,b)\\) 의 countable-many union 으로 표현가능한 집합이라고 이해해도 된다.\n- 오픈셋 \\(O\\)의 원소를 interior point of \\(O\\) 라고 한다. \\({\\cal O}\\)의 정의에 의해서 인테리어포인트는 모두 아래의 성질을 만족한다.\n\\[\\forall o \\in O ~ \\exists a,b \\in \\mathbb{R}~ st.~  o \\in (a,b)\\]\n증명은 귀류법을 쓰면 쉽게 된다.\n- 저 정리가 생각보다 중요하다. 그리고 이 정리를 나이테정리 라고 기억하자. 이 정리는 \\({\\cal O}\\)-오픈셋이 아닌 일반적인 \\({\\cal T}\\)-오픈셋에 대하여서도 성립한다. 즉 \\((X,{\\cal T})\\)가 위상공간이고 \\(T\\)가 \\({\\cal T}\\)의 임의의 집합이라 하자. \\(T\\)의 임의의 원소 \\(p\\)에 대하여 (1) \\(p\\) 를 포함하지만 (2) \\(T\\) 보다 작은 다른 \\({\\cal T}\\)-오픈셋이 항상 존재한다.\n- 그리고 교재에 따라서는 위와 같은 성질을 만족하는 것을 오픈셋이라고 정의하기도 한다. 이와 같은 논리흐름으로는 오픈인터벌 \\((a,b)\\)를 정의하고 그로부터 인테리어포인트 \\(o\\)와 오픈셋 \\(O\\)를 정의하고 그로부터 토폴로지 \\({\\cal O}\\)를 정의할 수 있다. 하지만 이러한 방식의 contruction 으로는 \\((\\mathbb{R},{\\cal O})\\) 만 만들수있다. 일반적으로는 적당한 \\({\\cal T}\\)가 \\(X\\)의 토폴로지임을 밝히고 그로부터 오픈셋을 정의하고 그 다음 인테리어포인트를 정의하는 식으로 각 요소들을 contruction 한다.\n- 오픈셋의 여집합을 클로즈드셋이라고 한다. 여기서 사람들이 “모든 집합은 오픈셋이거나 클로즈드셋 이어야 한다” 라고 착각하기 쉬운데 사실 그런것은 아니다.\n- 어떠한 construction을 사용하든지 아래의 사실들이 성립한다. 따로 설명을 쓰지 않은 것은 아주 약간의 머리를 쓰면 쉽게 증명할 수 있는 것들이다. (하지만 그냥 받아들이거나 외우는 것이 편하다.) 참고로 아래의 모든 사실들은 보통위상공간 즉 \\((\\mathbb{R},{\\cal O})\\) 를 전제하고 서술한 것이다.\n(1) \\((a,b)\\) 는 오픈셋이다.\n(2) \\(\\mathbb{R}\\) 은 오픈셋이다. 동시에 클로즈드셋이다2.\n(3) \\(\\emptyset\\) 은 오픈셋이다. 동시에 클로즈드셋이다3.\n(4) 오픈셋은 uncountable union 에 닫혀있다. 즉 \\(O_t\\)가 각각 오픈셋일때 \\(\\cup_t O_t\\) 역시 오픈셋이다.\n(5) 오픈셋은 finite intersection 에 닫혀있다. 즉 \\(O_i\\)가 각각 오픈셋이면 \\(\\cap_{i=1}^{n} O_i\\) 역시 오픈셋이다\n(6) 한점 \\(p\\)로 이루어진 집합 \\(\\{p\\}\\)는 오픈셋이 아니다. 이것이 오픈셋이 되려면 \\(\\{p\\}\\)의 모든원소(라고 해봤자 \\(p\\) 밖에 없음)가 내점이어야 하고 \\(p\\)가 \\(\\{p\\}\\)의 내점이려면 \\(p\\)를 포함하는 오픈인터벌 \\((a,b)\\)가 \\(\\{p\\}\\)의 부분집합으로 존재해야하는데 이것이 불가능하기 때문이다. 4\n(7) 오픈셋의 countable-many intersection 은 오픈셋이 아니다. 왜냐하면 \\(\\cap_{n=1}^{\\infty}(-1/n,1/n)=\\{0\\}\\) 인데 \\(\\{0\\}\\)은 오픈셋이 아니기 때문이다.\n\n\n기저\n- 오픈인터벌 \\((a,b)\\)를 적당히 countable-many union 하면 \\(\\mathbb{R}\\) 에 존재하는 어떠한 오픈셋 \\(O\\)도 표현할 수 있다. 이럴때 \\((a,b)\\) 모아놓은 collection \\({\\cal B}:=\\{(a,b): a<b \\in \\mathbb{R}\\}\\) 를 토폴로지 \\({\\cal O}\\)의 base 라고 한다. 이처럼 어떠한 위상공간 \\((X,{\\cal T})\\) 가 있을때 토폴로지 \\({\\cal T}\\) 의 임의의 집합을 \\({\\cal B}\\)의 원소들의 uncountable union 으로 표현가능때 \\({\\cal B}\\)를 \\({\\cal T}\\)의 base 라고 한다. 그리고 추가적으로 base의 모든 원소는 \\({\\cal T}\\)-오픈셋이어야 한다는 조건도 포함된다.\n- 토폴로지 \\({\\cal T}\\)의 base는 유일하지 않다.\n- 아래와 같은 collection을 상상하여 보자.\n\\[\\tilde{\\cal B}:=\\{all~ ray~ in~\\mathbb{R} \\} := \\{(-\\infty,b): b\\in \\mathbb{R} \\} \\cup \\{(a,\\infty): a \\in \\mathbb{R}\\}\\]\n보는 것처럼 \\(\\tilde{\\cal B}\\)는 위상의 정의를 만족한다. 그리고 \\(\\tilde{\\cal B}\\)는 \\({\\cal O}\\)의 base가 아니다. 하지만 \\(\\pi(\\tilde{\\cal B})\\) 는 \\((a,b)\\)를 포함하고 있기에 \\({\\cal O}\\) 의 base가 된다. 여기에서 \\(\\pi(\\tilde{\\cal B})\\) 는 \\(\\tilde{\\cal B}\\) 에 의해서 생성된 가장 작은 \\(\\pi\\)-system 이다.\n- 참고로 \\(\\pi\\)-시스템은 모든 원소가 finite intersection 에 닫혀있는 collection 을 의미한다. 전체집합은 empty intersection 으로 해석할 수 있으므로 모든 파이시스템은 전체집합을 포함한다. 따라서 파이시스템을 정의하면 전체집합을 같이 정의하는것과 마찬가지이다. 따라서 파이시스템 역시 시그마필드와 토폴로지처럼 전체집합과 동시에 정의된다. 그리고 정의에 따라서 임의의 집합에 대한 토폴로지와 시그마필드 모두 파이시스템이 된다.\n- 위에서 예를 든 \\(\\tilde{\\cal B}\\) 와 같이 그것 자체가 어떤 위상 \\({\\cal T}\\) 의 base는 아니지만 \\(\\pi(\\tilde{\\cal B})\\) 는 \\({\\cal T}\\) 의 base가 될때 \\(\\tilde{\\cal B}\\)를 \\({\\cal T}\\)의 subbase 라고 한다.\n- \\(\\tilde{\\cal B}\\) 가 토폴로지 \\({\\cal T}\\)의 subbase이면 \\(\\tilde{\\cal B}\\)로 \\({\\cal T}\\)를 generate 할 수 있다.\n\n\nmetric space\n- \\(d:X \\times X \\to \\mathbb{R}\\) 가 (1) 음이 아니고 (2) 대칭이며 (3) 삼각부등식을 만족하면 집합 \\(X\\) 에서의 metric 이라고 한다. 이때 음이 아닐 조건은\n\\[\\begin{cases}\nd(a,b) > 0 & a \\neq b \\\\\nd(a,b) = 0 & a=b\n\\end{cases}\\]\n이다. 만약에 메트릭의 모든 조건을 만족하는데 \\(d(a,b)=0\\) 인 서로 다른 \\(a,b \\in X\\) 가 존재하는 경우 \\(d\\) 를 pseudometric 이라고 한다.\n- \\(d\\) 을 집합 \\(X\\) 에서의 메트릭이라고 하자. 메트릭이 존재한다는 것은 집합 \\(X\\)의 어떠한 두 원소라도 그 사이의 거리를 잴 수 있다는 말이고 그것은 집합 \\(X\\)의 임의의 점 \\(p\\)에서 아래와 같은 ball 을 정의할 수 있는 말이다.\n\\[S(p,\\delta) := \\{x:d(p,x)<\\delta,x \\in X \\}\\]\n참고로 위와 같은 ball 들을 모은 collection 을 \\({\\cal B}\\)라고 하자. 그리고 \\({\\cal B}\\)의 임의의 원소를 언카운터블-유니온하여 얻을 수 있는 집합들의 모임을 \\({\\cal T}\\)라고 하자. 그러면 (1) \\({\\cal T}\\) 가 \\(X\\) 의 토폴로지임을 보이고 (2) \\({\\cal B}\\)의 모든 원소가 \\({\\cal T}\\)-오픈셋임을 보인다면 \\({\\cal B}\\)는 \\({\\cal T}\\)의 base가 된다고 주장할 수 있다(Thm 8.4). 그런데 (2)는 (1)이 성립하면 자동으로 성립하므로 (1)만 보이면 된다. 그러기 위해서는 아래의 (i)-(iii)을 보이면 된다.\n(i) 우선 \\({\\cal T}\\)가 언카운터블-유니온에 닫혀있음은 associative laws 에 의해서 쉽게 증명된다.\n(ii) 이제 \\({\\cal T}\\)가 파이나이트-인터섹션에 닫혀있음을 보이자. \\({\\cal T}\\)의 임의의 두 원소는 각각 \\({\\cal B}\\)의 언카운터블-유니온으로 표현가능하다. 가령 예를들어 임의의 \\(T,S \\in {\\cal T}\\) 가 아래와 같이 표현되었다고 치자.\n\\[T=\\bigcup_{t\\in [0,1]}B_{t}, \\quad S=\\bigcup_{s\\in [2,3]}B_{s}\\]\n따라서 \\(T\\cap S\\) 는 distributive laws 에 의해서 아래와 같이 표현가능하다.\n\\[T \\cap S = \\bigcup_{(t,s) \\in [0,1]\\times[2,3]} B_t \\cap B_s \\]\n(i)에 의해서 \\(B_t \\cap B_s\\)가 \\({\\cal T}\\)의 원소이기만 하면 \\(T \\cap S\\) 역시 \\({\\cal T}\\)의 원소가 되는 구조라 (ii)가 증명된다. 따라서 이제 우리가 할일은 \\(B_t\\cap B_s\\)가 \\({\\cal T}\\)의 원소임을 보이는 것이고 이것은 \\(B_t \\cap B_s\\)가 \\({\\cal B}\\)의 언카운터블-유니온으로 표현가능하다는 조건과 동치이다. 우선 \\(B_t \\cap B_s\\)에 속하는 임의의 원소를 $b^* $ 라고 하자. 이 점에 대하여 나이테정리를 만족시키는 ball이 존재한다. 즉\n\\[\\exists S(b^* ,\\delta)~ st. ~ S(b^* ,\\delta) \\subset B_t \\cap B_s\\]\n이다(Lemma 8.3). 그런데 \\(B_t \\cap B_s\\)의 모든점에서 이런식으로 나이테정리를 만족하는 ball을 잡을 수 있다. 이러한 ball들의 합집합을\n\\[\\bigcup_{b^* \\in (B_t \\cap B_s)} S(b^* , \\delta)\\]\n이라고 하자. 자명하게 이 집합은 \\(B_t\\cap B_s\\) 보다 작다(부분집합들의 합이므로). 하지만 \\(B_t\\cap B_s\\)의 모든 원소는 이 집합에 포함되므로 이 집합은 \\(B_t\\cap B_s\\)보다 크다. 따라서\n\\[\\bigcup_{b^* \\in (B_t \\cap B_s)} S(b^* , \\delta)=B_t \\cap B_s\\]\n이 성립한다.\n(iii) \\({\\cal T}\\)가 \\(X\\)를 포함한다는 것을 보이는것은 볼의 반지름을 크게 만들면 쉽게 증명할 수 있다.\n- 참고로 위의 (i)-(iii)을 요약하면 (1) \\(X\\)가 \\({\\cal B}\\)의 언카운터블 유니온으로 표현가능하고 (2) \\({\\cal B}\\)의 임의의 두 원소가 \\({\\cal B}\\)의 언카운터블 유니온으로 표현가능하기만 하면 볼들이 집합이 아니라 어떠한 \\({\\cal B}\\)라도 특정 토폴로지의 base라고 주장할 수 있다. 이것이 교재의 Thm 6.1 이다.\n- 아무튼 위의 과정을 거치면 \\(X\\)위에서 거리를 정의할 수 있을때 그 거리에 의해서 ball을 정의할 수 있고 ball들의 콜렉션을 base \\({\\cal B}\\)로 정의하고 \\({\\cal B}\\) 원소들의 언카운터블-유니온으로 표현가능한 집합모임을 토폴로지 \\({\\cal T}\\)로 정의해도 논리적모순점이 없다. 즉 \\(X\\)에서 메트릭이 정의되기만 하면 그것에 의해서 순차적으로 토폴로지 \\({\\cal T}\\)를 자연스럽게 유도할 수 있는데 이러한 토폴로지를 특별히 \\(X\\)와 \\(d\\)에 의해서 유도된 metric topology 라고 한다. 그리고 \\((X,d)\\)를 metric-space 라고 한다.\n- \\(\\mathbb{R}\\)에서 \\({\\cal O}\\)를 유도하는 메트릭은 우리가 보통 생각하는 유클리드거리이다. 이러한 메트릭을 usual metric 이라고 한다.\n- \\(\\mathbb{R}\\)에서 아래와 같은 거리를 정의할 수 있다.\n\\[d(a,b)=\\begin{cases}\n0 & a=b \\\\\n1 & a\\neq b\n\\end{cases}\\]\n이러한 거리를 trivial metric 이라고 한다. 그리고 이 거리가 유도하는 토폴로지는 \\(2^{\\mathbb{R}}\\) 이다. (아 몰라.. 따지기 싫어.. 그냥 외워..)\n- 만약에 집합 \\(X\\)에서 정의된 2개의 메트릭 \\(d_1\\), \\(d_2\\)가 같은 토폴로지를 유도한다면 두 메트릭 \\(d_1\\)과 \\(d_2\\)는 equivalent 하다고 말한다.\n- 토폴로지컬-스페이스 \\((X,{\\cal T})\\) 가 있다고 하자. 그런데 \\(X\\) 에서 어떠한 메트릭 \\(d\\)가 존재해 그것이 \\({\\cal T}\\)를 유도하였다고 하자. 그럼 \\({\\cal T}\\)는 메트릭-토폴로지가 된다. 이와 같이 (1) \\(X\\)에서 정의되고 (2) 메트릭-토폴로지 \\({\\cal T}\\)를 유도하는 적당한 메트릭 \\(d\\)가 명시된것은 아니지만 그런 메트릭의 존재를 하나 이상 우리가 알고 있을때 위상공간 \\((X,{\\cal T})\\)를 metrizable 하다고 한다.\n- 두 메트릭스페이스 \\((X,d_1)\\) 와 \\((Y,d_2)\\) 가 isometric 하다는 것은 아래가 만족하는 one-one, onto 인 \\(f:X \\to Y\\) 가 존재한다는 것이다.\n\\[d_1(p,q) = d_2(f(p),f(q))\\]\n- 이때 isometric 이라는 relation 은 보는것 처럼 모든 메트릭공간들의 집합 \\({\\cal M}\\)에서 equivalence relation 이다. 즉 아래가 성립한다.\n(i) \\((X,d_1) \\overset{ism}{\\sim} (X,d_1)\\),\n(ii) \\((X,d_1) \\overset{ism}{\\sim} (Y,d_2)\\) implies \\((Y,d_2) \\overset{ism}{\\sim} (X,d_1)\\),\n(iii) \\((X,d_1) \\overset{ism}{\\sim} (Y,d_2)\\) and \\((Y,d_2) \\overset{ism}{\\sim} (Z,d_3)\\) imply \\((X,d_1) \\overset{ism}{\\sim} (Z,d_3)\\).\n\n\ncomplete metric space\n- convergent sequence 은 단독으로 정의될 수 없으며 위상공간 \\((X,{\\cal T})\\) 와 묶어서 정의된다. 그리고 Cauchy sequence 역시 단독으로 정의될 수 없으며 메트릭스페이스 \\((X,d)\\) 와 묶어서 정의된다.\n- convergent sequence 와 Cauchy sequence 는 비슷해보이지만 미묘하게 다른점이 있다.\n(1) 컨버전트-시컨트는 위상공간 \\((X,{\\cal T})\\) 만 있으면 정의할 수 있지만 코시수열은 그 위상공간이 메트릭스페이스 이어야 한다는 제약이 있다. 왜냐하면 컨버전트-시컨스의 정의에는 오픈셋만 필요하지만 코시수열은 볼이 필요하고 볼은 메트릭에 의해서만 정의되기 때문이다.\n(2) 컨버전트-시컨스와 코시수열 모두 열의 각 항이 \\(X\\)의 원소이어야 한다는 조건이 있다. 하지만 컨버전트-시컨스는 그 limit 까지 \\(X\\)의 원소이어야 하는데 코시수열은 그렇지 않다는 차이점이 있다.\n- \\(X=(0,1)\\) 위의 usual metric 에 의해서 유도되는 메트릭스페이스 \\((X,d)\\) 를 생각하자. 수열\n\\[\\big\\{\\frac{1}{2},\\frac{1}{3},\\frac{1}{4},\\dots,\\big\\}\\]\n\\(X\\)에서 정의된 코시수열이지만 \\(X\\)에서 정의되는 컨버전트-시컨스는 아니다.\n- 내가 이해한 바는 아래와 같다.\n(1) 토폴로지 \\((X,{\\cal T})\\) 는 항상 컨버전트-시컨스를 준비가 되어있는 공간이다.\n(2) 위에서 정의가능한 컨버전트-시컨스는 코시수열과 아무런 관련이 없다. 그리고 우리가 통상적으로 고등학교때부터 다루어왔던 수열의 수렴의 개념과도 거리가 멀다.\n(3) 토폴로지 \\((X,{\\cal T})\\) 가 메트릭스페이스라면 컨버전트-시컨스는 코시수열과 어떤관계가 있으며 고등학교때부터 내가 다루어 왔던 상식적인 수렴하는 수열의 개념과도 관련이 있다.\n(4) \\((X,{\\cal T})\\) 가 메트릭스페이스 라고 가정하자. 그럼 아래가 만족한다고 생각할 수 있다.\n\n\\(\\{a_n\\}\\) converges on \\(X\\) \\(\\Longleftrightarrow\\) \\(\\{a_b\\}\\) is Cauchy sequence on \\(X\\) and \\(\\lim_{n\\to\\infty} a_n \\in X\\)\n\n즉 러프하게 말해서 \\(X\\)에서의 컨버전트-시컨스는 (i) \\(X\\)에서의 코시수열이면서 (ii) limit 이 \\(X\\)에 포함되는 수열이라고 말할 수 있다. 이런 정의로 치면 우리가 고등학교때부터 생각해왔던 소박한 정의의 수렴하는 수열은 사실 코시수열에 가깝고 컨버전트-시컨스는 고등학교때부터 배운 소박한 수렴을 하며 동시에 수렴값이 \\(X\\)이 잘 정의되는 수열을 의미한다고 볼 수 있다. 앞으로는 소박한 수렴과 컨버전트-시컨스를 엄밀하게 구분하여 말하도록 하자. 즉 \\(\\{a_n\\}\\)이 코시수열이라는 말은 \\(\\{a_n\\}\\)이 소박한 수렴을 한다는 의미이고 \\(\\{a_n\\}\\)이 컨버전트-시컨스라는 의미는 \\(\\{a_n\\}\\)이 소박한수렴을 하며 동시에 그 극한값이 well-define 된다는 의미(=\\(\\{a_n\\}\\)의 수렴값이 \\(X\\)의 원소라는 의미)이다.\n- (proposition 14.1) 메트릭스페이스 한정으로, 컨버전트-시컨스는 모두 코시수열이다. (당연한 소리를.. 이런걸 proposition 이라고..)\n- 당연히 위 정리의 역은 성립하지 않는다. 즉 메트릭스페이스 \\((X,{\\cal T})\\) 에서 정의된 코시수열이 반드시 컨버전트-시컨스라는 보장은 없다. (이것도 당연한 소리.. 왜냐하면 수렴값이 \\(X\\)에 포함된다는 보장이 없기 때문) 하지만 그 메트릭스페이스가 complete 하다면 위 정리의 역도 성립한다.\n- 컴플리트하지 않은 메트릭스페이스 \\((X,d)\\)를 컴플리트한 메트릭스페이스 \\((X^* , d)\\) 로 바꿀 수 없을까? 유주얼메트릭(usual metric) \\(d\\) 와 \\(X=(0,1)\\) 로 만들어지는 메트릭스페이스는 컴플리트하지 않지만 \\(d\\) 와 \\(X^* =[0,1]\\) 로 만들어지는 메트릭스페이스는 컴플리트하다. 이런 경우 $(X^* ,d) $ 는 \\((X,d)\\) 의 completion 이라고 한다.\n- 즉 아래의 조건들을 만족하면 $(X^* ,d) $ 는 \\((X,d)\\) 의 completion 이라고 부른다.\n(1) \\(X\\subset X^*\\)\n(2) \\((X^* ,d)\\) is complete metric space\n(3) \\((X,d) \\overset{ism}{\\sim} (X^* ,d)\\).\n- 메트릭스페이스 \\((X,d)\\)에서 아래의 식을 만족하는 두 코시수열 \\(\\{a_n\\}\\), \\(\\{\\tilde a_n\\}\\) 을 생각하여보자.\n\\[\\lim_{n\\to\\infty} d(a_n,\\tilde a_n)=0 \\]\n이러한 코시수열들을\n\\[\\{a_n\\} \\overset{slim}{\\sim} \\{\\tilde a_n\\}\\]\n이라고 표현하자. 이때 관계 \\(\\overset{slim}{\\sim}\\) 은 \\(X\\)에서 정의가능한 모든 코시수열들의 집합 \\({\\cal C}_ X\\) 에서 equivalence relation 이 된다고 한다. (증명은 알아서) 따라서 이걸 이용하면 거리공간에서 \\(slim\\) 의 관계를 가지는 임의의 두 수열은 같은 극한을 가진다는 결론이 나온다. (이것도 잘 따져보자.)\n- 잠시 (1) 바이너리-릴레이션(binary relation), (2) 이퀴배런스-릴레이션(equivalence relation), (3) 이퀴배런스-클래스(equivalence class) 그리고 (4) 코션트셋(quotient set)에 대하여 설명하고 넘어가겠다.\n(1) 집합 \\({\\cal C}_ X\\) 의 두 원소 \\(\\{a_n\\}\\), \\(\\{b_n\\}\\) 간 바이너리-릴레이션 \\(R\\)이 존재한다는 문장은 집합론적인 언어로 표현가능하다. 구체적으로는 \\(R\\)을 곱집합 \\({\\cal C}_ X \\times {\\cal C}_ X\\) 의 적당한 부분집합으로 설정하고 순서쌍 \\(\\big(\\{a_n\\},\\{b_n\\}\\big)\\) 이 \\(R\\) 의 원소라는 식으로 표현한다. 예를 들면 아래와 같은 식으로 말이다.\n$ {a_n} and {b_n} has arelation with~ R \\ ({a_n},{b_n}) R _ X _ X \\ {a_n} {b_n}$\n(2) 그리고 \\({\\cal C}_ X\\) 위에서의 바이너리-릴레이션 \\(R\\)이 (i) reflexivity (ii) symmetricity (iii) transitivity 를 만족하면 이 릴레이션을 특별히 이퀴배런스-릴레이션 이라고 말한다.\n(3) 그리고 아래와 같이 \\({\\cal C}_ X\\) 에서 \\(\\{a_n\\}\\) 과 이퀴배런스-릴레이션을 가지는 원소들을 모아놓은 집합을 생각할 수 있다. \\[\\big[\\{a_n\\}\\big]_ R:=\\big\\{ \\{x_n\\} : \\{x_n\\} \\overset{R}{\\sim} \\{a_n\\} ~and~ \\{x_n\\} \\in {\\cal C}_ X \\big\\}\\]\n이 집합을 \\(\\{a_n\\}\\)의 equivalence class on \\({\\cal C}_ X\\) by \\(R\\) 이라고 부른다. 보통은 \\(R\\)을 생략하여 \\(\\big[\\{a_n\\}\\big]\\)와 같이만 표현하지만 나는 기호의 명확성을 위해서 관계까지 명시하였다.\n(4) 이퀴배런스-클래스는 본질적으로 파티션과 밀접한 연관이 있다. 여기에서 클래스 \\({\\cal P}_ A\\) 가 집합 \\(A\\)의 파티션이란 의미는 클래스 \\({\\cal P}_ A\\) 에 속한 모든 원소의 합이 \\(A\\) 이며 클래스 \\({\\cal P}_ A\\) 의 각 원소는 서로 배타적이라는 의미이다. 이퀴배런스-클래스가 그럼 왜 파티션과 관련이 있을까? 그것은 어떠한 집합에서 이퀴배런스-릴레이션이 존재하면 그 집합을 배타적인 이퀴배런스-클래스의 합집합으로 표현가능하기 때문이다. 즉 이퀴배런스-릴레이션 혹은 이퀴배런-클래스의 존재는 파티션의 존재를 임플라이 한다. 그리고 이러한 파티션을 이퀴배런스-릴레이션 \\(R\\)에 의해 생성된 quotient set 혹은 quotient space 라고 한다. 관계 \\(R\\)에 의한 \\(A\\)의 코션트 셋은 기호로 \\(A ~\\overset{R}{\\sim}\\) 와 같이 쓴다. 예를들어 \\[\\begin{align}\n{\\cal C}_ X ~ /\\overset{slim}{\\sim}\n\\end{align}\\] 은 집합 \\(X\\) 상에서 존재하는 코시수열들의 집합 \\({\\cal C}_ X\\) 에서 이퀴배런스-릴레이션 \\(slim\\) 에 의해서 생성된 코션트셋을 의미한다.\n\n\n\n\n\nFootnotes\n\n\n정확하게는 \\(\\cal O\\)-오픈셋↩︎\n공집합이 오픈셋이므로↩︎\n\\(\\mathbb{R}\\)이 오픈셋이므로↩︎\n다만 이것은 위상공간을 \\((\\mathbb{R},{\\cal O})\\)로 생각하였을때 이야기이고 위상공간을 \\((\\mathbb{R},2^{\\mathbb{R}})\\)로 생각한다면 \\(\\{p\\}\\) 도 오픈셋이 된다.↩︎"
  },
  {
    "objectID": "posts/2. Let's Study/CGSP/2022-12-26-Chap-12.2.html",
    "href": "posts/2. Let's Study/CGSP/2022-12-26-Chap-12.2.html",
    "title": "Chap 12.2: Weakly Stationary Graph Processes",
    "section": "",
    "text": "using LinearAlgebra, DSP"
  },
  {
    "objectID": "posts/2. Let's Study/CGSP/2022-12-26-Chap-12.2.html#simultaneously-diagonalizable",
    "href": "posts/2. Let's Study/CGSP/2022-12-26-Chap-12.2.html#simultaneously-diagonalizable",
    "title": "Chap 12.2: Weakly Stationary Graph Processes",
    "section": "Simultaneously Diagonalizable",
    "text": "Simultaneously Diagonalizable\n매트릭스 \\({\\bf A}\\)와 \\({\\bf B}\\)가 대각화 가능하다는 것은 아래의 표현을 만족하는 적당한 invertible matrix \\({\\bf \\Psi}_A\\), \\({\\bf \\Psi}_B\\)와 대각행렬 \\({\\bf \\Lambda}_A\\), \\({\\bf \\Lambda}_B\\)가 존재한다는 의미가 된다.\n\\[{\\bf A} = {\\bf V}_{A} {\\bf \\Lambda}_A {\\bf V}_{A}^{-1}\\]\n\\[{\\bf B} = {\\bf V}_{B} {\\bf \\Lambda}_B {\\bf V}_{B}^{-1}\\]\n그리고 만약에 \\({\\bf V}_{A}={\\bf V}_{B}\\)이라면 즉\n\\[{\\bf A} = {\\bf V} {\\bf \\Lambda}_A {\\bf V}^{-1}\\]\n\\[{\\bf B} = {\\bf V} {\\bf \\Lambda}_B {\\bf V}^{-1}\\]\n이라면 \\(\\{{\\bf A},{\\bf B}\\}\\)가 simultaneously diagonalzable 하다고 표현한다."
  },
  {
    "objectID": "posts/2. Let's Study/CGSP/2022-12-26-Chap-12.2.html#commute",
    "href": "posts/2. Let's Study/CGSP/2022-12-26-Chap-12.2.html#commute",
    "title": "Chap 12.2: Weakly Stationary Graph Processes",
    "section": "Commute",
    "text": "Commute\n두 matrix \\({\\bf A}\\)와 \\({\\bf B}\\)에 대하여\n\\[{\\bf A}{\\bf B}= {\\bf B}{\\bf A}\\]\n인 관계가 성립하면 두 매트릭스가 commute 한다고 표현한다. 그런데 \\({\\bf A}{\\bf B}={\\bf A}{\\bf B}\\)의 조건은 \\({\\bf A}, {\\bf B}\\)가 동시대각화가능할 (simultaneously diagonalzable) 조건과 같다. 1 따라서 simultaneously diagonalzable 는 commute와 같은 말이라 생각해도 무방하다.\n\n참고: 위키피디아.."
  },
  {
    "objectID": "posts/2. Let's Study/CGSP/2022-12-26-Chap-12.2.html#shift-invariant-filter",
    "href": "posts/2. Let's Study/CGSP/2022-12-26-Chap-12.2.html#shift-invariant-filter",
    "title": "Chap 12.2: Weakly Stationary Graph Processes",
    "section": "Shift Invariant Filter",
    "text": "Shift Invariant Filter\n\nref: Djuric and Richard (2018) Chap 8.3 의 내용 중 일부\n\nDefine the matrix \\({\\bf B}\\) as periodic shift matrix such that\n\\[\n{\\bf B} = \\begin{bmatrix}\n0 & 0 & 0 & \\dots  & 0 & 1 \\\\\n1 & 0 & 0 & \\dots & 0 & 0 \\\\\n0 & 1 & 0 & \\dots & 0 & 0 \\\\\n\\dots & \\dots & \\dots & \\dots & \\dots & \\dots\\\\\n0 & 0 & \\dots & 1 & 0 & 0 \\\\\n0 & 0 & \\dots & 0 & 1 & 0 \\\\\n\\end{bmatrix}.\\]\nA generic filter \\({\\boldsymbol h}\\) is given by its \\(z\\)-transform\n\\[h(z)=h_0z^0+h_1z^{-1}+\\cdots +h_{N-1}z^{-(N-1)}\\]\nwhere \\(s_{n-1}=z^{-1}s_n\\). In vector notation, and with respect to the standard basis \\({\\bf I}\\), the filter is represented by the matrix \\({\\bf H}\\), a polynomial in the cyclic shift\n\\[{\\bf H}=h({\\bf B})=h_0{\\bf B}^0+h_1{\\bf B}^1+\\cdots+h_{N-1}{\\bf B}^{N-1}.\\]\nFilters are shift invariant iff\n\\[z\\cdot h(z) = h(z)\\cdot z\\]\nor from the matrix representation\n\\[{\\bf B}h({\\bf B})=h({\\bf B}){\\bf B}.\\]\nExample\nLet \\({\\bf B}\\) as\n\nB= [0 1 0 0 0 0 0\n    0 0 1 0 0 0 0 \n    0 0 0 1 0 0 0 \n    0 0 0 0 1 0 0 \n    0 0 0 0 0 1 0 \n    0 0 0 0 0 0 1 \n    1 0 0 0 0 0 0]\n\n7×7 Matrix{Int64}:\n 0  1  0  0  0  0  0\n 0  0  1  0  0  0  0\n 0  0  0  1  0  0  0\n 0  0  0  0  1  0  0\n 0  0  0  0  0  1  0\n 0  0  0  0  0  0  1\n 1  0  0  0  0  0  0\n\n\nDefine \\({\\boldsymbol h}\\) as\n\nh = [1/3,1/3,1/3]\n\n3-element Vector{Float64}:\n 0.3333333333333333\n 0.3333333333333333\n 0.3333333333333333\n\n\nFurthermore define \\({\\bf H}=h({\\bf B})=h_0{\\bf B}^0+h_1{\\bf B}^1+h_2{\\bf B}^2\\)\n\nH = (1/3)*B^0 + (1/3)*B^1 + (1/3)*B^2 \n\n7×7 Matrix{Float64}:\n 0.333333  0.333333  0.333333  0.0       0.0       0.0       0.0\n 0.0       0.333333  0.333333  0.333333  0.0       0.0       0.0\n 0.0       0.0       0.333333  0.333333  0.333333  0.0       0.0\n 0.0       0.0       0.0       0.333333  0.333333  0.333333  0.0\n 0.0       0.0       0.0       0.0       0.333333  0.333333  0.333333\n 0.333333  0.0       0.0       0.0       0.0       0.333333  0.333333\n 0.333333  0.333333  0.0       0.0       0.0       0.0       0.333333\n\n\nObserve following:\n\nB*H == H*B \n\ntrue\n\n\nThus, filter \\({\\boldsymbol h}\\) is shift invariant filter and matrix \\({\\bf H}\\) is shift invariant operator.\nnote: \\({\\boldsymbol h}\\) is moving average filter.\nnote: for any \\({\\bf x}\\), \\({\\bf H}{\\bf x}\\) is definded by\n\\[\\left[\\frac{x_{n-1}+x_n+x_1}{3},\\frac{x_n+x_1+x_2}{3},\\dots,\\frac{x_{n-3}+x_{n-2}+x_n}{3}\\right].\\]\n\nx = [1,1,1,1,2,2,2]\nH*x\n\n7-element Vector{Float64}:\n 1.0\n 1.0\n 1.3333333333333333\n 1.6666666666666665\n 2.0\n 1.6666666666666665\n 1.3333333333333333\n\n\nnote: In some sense, the matrix \\({\\bf H}{\\bf x}\\) can be thought as generalized version of \\({\\boldsymbol h}\\star {\\bf x}\\) where \\(\\star\\) is convolution up to shift\n\nconv(h,x)\n\n9-element Vector{Float64}:\n 0.3333333333333334\n 0.6666666666666667\n 1.0\n 1.0\n 1.3333333333333333\n 1.6666666666666667\n 2.0\n 1.3333333333333333\n 0.6666666666666667\n\n\nFinally, we observe that, from the Cayley-Hamilton Theorem, \\({\\bf B}\\) satisfies its characteristic polynomial \\(\\Delta({\\bf B})\\), where \\(\\Delta(\\lambda)\\) is the determinant of \\(\\lambda{\\bf I}-{\\bf B}\\). The characteristic polynomial \\(\\Delta({\\bf B})\\) has degree \\(N\\), so, in DSP, as described so far, linear filters are (matrix) polynomial with degree at most \\(N-1\\).\n\n이 부분은 책에 써있길래 가져오긴 했는데, 무슨 의미인지 모르겠음"
  },
  {
    "objectID": "posts/2. Let's Study/CGSP/2022-12-26-Chap-12.2.html#coexisting-approaches",
    "href": "posts/2. Let's Study/CGSP/2022-12-26-Chap-12.2.html#coexisting-approaches",
    "title": "Chap 12.2: Weakly Stationary Graph Processes",
    "section": "Coexisting Approaches",
    "text": "Coexisting Approaches\nStationary graph processes were first defined and analyzed in (Girault 2015). The fundamental problem identified there is that GSOs do not preserve energy in general and therefore cannot be isometric (Gavili and Zhang 2017). This problem is addressed in (Girault, Gonçalves, and Fleury 2015) with the definition of an isometric graph shift that preserves the eigenvector space of the Laplacian GSO but modifies its eigenvalues.\nA stationary graph process is then defined as one whose probability distributions are invariant with respect to multiplications with the isometric shift. One drawback of this approach is that the isometric shift is a complex-valued operator and has a sparsity structure (if any) different from \\({\\bf S}\\). By contrast, the vertex-based definition in\n\\[\\mathbb{E} \\bigg[ \\big({\\bf S}^a{\\bf x}\\big)\\Big(\\big({\\bf S}^H)^b {\\bf x}\\Big)^H  \\bigg]=\\mathbb{E}\\bigg[\\big({\\bf S}^{a+c}{\\bf x}\\big)\\Big(\\big({\\bf S}^H\\big)^{b-c}{\\bf x} \\Big)^H \\bigg]\\]\nis based on the original GSO \\({\\bf S}\\), which is local and real-valued. As a result, above Eq. provides intuition on the relations between stationarity and locality, which can be leveraged to develop stationarity tests or estimation schemes that work with local information. Graph stationarity was also studied in (Perraudin and Vandergheynst 2017) where the requirement of having a covariance matrix diagonalizable by the eigenvectors of the Laplacian GSO is adopted as a definition. This condition is shown to be equivalent to statistical invariance with respect to the translation operator introduced in (Shuman, Ricaud, and Vandergheynst 2016). When the shift \\({\\bf S}\\) coincides with the Laplacian of the graph and the eigenvalues of \\({\\bf S}\\) are all distinct, Definitions 12.1 and 12.2 are equivalent to those in Perraudin and Vandergheynst (2017). Hence, the definitions presented here differ from (Perraudin and Vandergheynst 2017) in that we consider general normal shifts instead of Laplacians and that we see Definition 12.1 as a definition, not a property. These are mathematically minor differences that are important in practice though; see Segarra et al. (2017) for more details."
  },
  {
    "objectID": "posts/2. Let's Study/CGSP/2022-12-24-Chap 8.3.html",
    "href": "posts/2. Let's Study/CGSP/2022-12-24-Chap 8.3.html",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "",
    "text": "using LinearAlgebra, FFTW"
  },
  {
    "objectID": "posts/2. Let's Study/CGSP/2022-12-24-Chap 8.3.html#cyclic-shfit-operator-bf-b",
    "href": "posts/2. Let's Study/CGSP/2022-12-24-Chap 8.3.html#cyclic-shfit-operator-bf-b",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "Cyclic shfit operator \\({\\bf B}\\)",
    "text": "Cyclic shfit operator \\({\\bf B}\\)\nThe matrix \\({\\bf B}\\) representing the periodic shift is\n\nB= [0 0 0 0 1\n    1 0 0 0 0 \n    0 1 0 0 0\n    0 0 1 0 0\n    0 0 0 1 0]\n\n5×5 Matrix{Int64}:\n 0  0  0  0  1\n 1  0  0  0  0\n 0  1  0  0  0\n 0  0  1  0  0\n 0  0  0  1  0\n\n\nThis matrix is the cyclic shift.\nnote: \\({\\bf B}\\) is orthogonal matrix.\n\nB'B\n\n5×5 Matrix{Int64}:\n 1  0  0  0  0\n 0  1  0  0  0\n 0  0  1  0  0\n 0  0  0  1  0\n 0  0  0  0  1\n\n\n(ex1) Define \\({\\bf s}\\) as\n\ns = [1,2,3,4,5]\ns\n\n5-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n\n\nObserve that\n\nB*s\n\n5-element Vector{Int64}:\n 5\n 1\n 2\n 3\n 4\n\n\n\nB^2*s\n\n5-element Vector{Int64}:\n 4\n 5\n 1\n 2\n 3\n\n\n\nB^3*s\n\n5-element Vector{Int64}:\n 3\n 4\n 5\n 1\n 2\n\n\nThus we can interprete the matrix \\({\\bf B}\\) as cyclic shift operator such that\n\\[\n{\\bf B}s_n =s_{n-1}\n\\]\nfor \\(n=1,\\dots, N-1\\) and \\({\\bf B}s_0 =s_N\\).\nnote: \\({\\bf B}\\)는 시계열에서 다루는 backshift operator 와 비슷함."
  },
  {
    "objectID": "posts/2. Let's Study/CGSP/2022-12-24-Chap 8.3.html#dft",
    "href": "posts/2. Let's Study/CGSP/2022-12-24-Chap 8.3.html#dft",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "DFT",
    "text": "DFT\nThe matrix \\({\\bf B}\\) can be expressed as\n\\({\\bf B}={\\bf DFT}^\\ast \\cdot {\\bf \\Lambda} \\cdot {\\bf DFT}\\)\nwhere \\({\\bf DFT}\\) is unitary and symmetric matrix and \\(\\bf \\Lambda\\) is diagonal matrix.\n\nλ, Ψ = eigen(B)\n\nEigen{ComplexF64, ComplexF64, Matrix{ComplexF64}, Vector{ComplexF64}}\nvalues:\n5-element Vector{ComplexF64}:\n -0.8090169943749472 - 0.5877852522924725im\n -0.8090169943749472 + 0.5877852522924725im\n 0.30901699437494734 - 0.9510565162951536im\n 0.30901699437494734 + 0.9510565162951536im\n  0.9999999999999998 + 0.0im\nvectors:\n5×5 Matrix{ComplexF64}:\n  0.138197+0.425325im   0.138197-0.425325im  …  0.447214+0.0im\n -0.361803-0.262866im  -0.361803+0.262866im     0.447214+0.0im\n  0.447214-0.0im        0.447214+0.0im          0.447214+0.0im\n -0.361803+0.262866im  -0.361803-0.262866im     0.447214+0.0im\n  0.138197-0.425325im   0.138197+0.425325im     0.447214+0.0im\n\n\n\nB ≈ Ψ * Diagonal(λ) * Ψ'\n\ntrue\n\n\nDefine \\({\\boldsymbol \\Psi}^\\ast={\\bf DFT}\\).\n\nDFT = Ψ'\n\n5×5 adjoint(::Matrix{ComplexF64}) with eltype ComplexF64:\n  0.138197-0.425325im  -0.361803+0.262866im  …  0.138197+0.425325im\n  0.138197+0.425325im  -0.361803-0.262866im     0.138197-0.425325im\n -0.361803-0.262866im  -0.361803+0.262866im     0.138197-0.425325im\n -0.361803+0.262866im  -0.361803-0.262866im     0.138197+0.425325im\n  0.447214-0.0im        0.447214-0.0im          0.447214-0.0im\n\n\nNote that the eigenvalues are not ordered in julia.\n\nλ[5], exp(-im* 2π/5 * 0)\n\n(0.9999999999999998 + 0.0im, 1.0 - 0.0im)\n\n\n\nλ[3], exp(-im* 2π/5 * 1)\n\n(0.30901699437494734 - 0.9510565162951536im, 0.30901699437494745 - 0.9510565162951535im)\n\n\n\nλ[1], exp(-im* 2π/5 * 2)\n\n(-0.8090169943749472 - 0.5877852522924725im, -0.8090169943749473 - 0.5877852522924732im)\n\n\n\nλ[2], exp(-im* 2π/5 * 3)\n\n(-0.8090169943749472 + 0.5877852522924725im, -0.8090169943749475 + 0.587785252292473im)"
  },
  {
    "objectID": "posts/2. Let's Study/CGSP/2022-12-24-Chap 8.3.html#spectral-components-and-frequencies",
    "href": "posts/2. Let's Study/CGSP/2022-12-24-Chap 8.3.html#spectral-components-and-frequencies",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "Spectral components and Frequencies",
    "text": "Spectral components and Frequencies\nWe remark:\n(1) Spectral components: For \\(k = 0,1,2,\\dots, N-1\\), the \\(k\\)-th column of \\({\\bf DFT}^\\ast\\) is defined by\n\\[\\Psi_k:=\\frac{1}{\\sqrt{N}}\\begin{bmatrix} 1 \\\\ e^{j\\frac{2\\pi}{N}k} \\\\ e^{j\\frac{2\\pi}{N}2k} \\\\ e^{j\\frac{2\\pi}{N}3k} \\\\  \\dots \\\\ e^{j\\frac{2\\pi}{N}(N-1)k} \\end{bmatrix}.\\]\nNote that \\(\\Psi_k\\) can be also interpreted as \\(\\ell\\)-th eigenvector of \\({\\bf A}\\) correspoding \\(\\lambda_\\ell = e^{-j\\frac{2\\pi}{N}k}\\). Those eigenvectors\n\\[\\big\\{{\\bf 1},\\Psi_1,\\Psi_2, \\dots, \\Psi_{N-1}\\big\\}\\]\nform a complete orthonomal basis of \\(\\mathbb{C}^N\\). These vectors are called spectral components.\n(2) Frequencies: The diagonal entries of \\({\\bf \\Lambda}\\) are the eigenvalues of the time shift \\({\\bf B}\\). In Physics and in operator theory, these eigenvalues are the frequencies of the signal. In DSP it is more common to call frequencies\n\\[\\Omega_k=\\frac{-1}{2\\pi j}\\ln\\lambda_k=\\frac{-1}{2\\pi j}\\ln e^{-j \\frac{2\\pi}{N}k}=\\frac{k}{N}, \\quad k=0,1,2,\\dots,N-1.\\]\n\nThe \\(N\\) (time) frequencies \\(\\Omega_k\\) are all distinct, positive, equally spaced, and increasing from \\(0\\) to \\(\\frac{N-1}{N}\\). The spectral components are the complex exponential sinusiodal functions. For example, corresponding to the zero frequency is the DC spectral component (a vector whose entries are constant and all equal to \\(\\frac{1}{\\sqrt{N}}\\))."
  },
  {
    "objectID": "posts/2. Let's Study/CGSP/2022-12-24-Chap 8.3.html#dft-1",
    "href": "posts/2. Let's Study/CGSP/2022-12-24-Chap 8.3.html#dft-1",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "DFT",
    "text": "DFT\n일반적으로 우리가 알고있는 DFT1는 아래와 같다. (이 그림은 위키피디아에서 캡쳐한 것이다)\n\n\n\n그림1: 위키에서 긁어온 DFT의 정의\n\n\n즉 DFT는 임의의 신호 \\(\\{{\\bf x}_n\\}:=x_0,x_1,\\dots,x_{N-1}\\)를 적당한 규칙2에 따라서 \\(\\{{\\bf X}_k\\}:=X_0,X_1,\\dots,X_{N-1}\\)로 바꾸는 변환을 이라고 이해할 수 있다. 이때 사용되는 적당한 규칙은 구체적으로 아래의 수식을 의미한다.\n\\[X_k = \\sum_{n=0}^{N-1}x_n\\cdot e^{-i\\frac{2\\pi}{N}kn}\\]\n그런데 매트릭스를 활용하면 위의 수식을 아래와 같이 표현할 수 있다.\n\\[\\begin{bmatrix} X_1 \\\\ X_2 \\\\ X_3 \\\\ \\dots \\\\ X_{N-1} \\end{bmatrix}\n=\\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 1} & e^{-i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 2} & e^{-i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n\\end{bmatrix}\n\\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ \\dots \\\\ x_{N-1} \\end{bmatrix}\\]\n편의상 \\({\\bf X}\\)와 \\({\\bf x}\\)를 \\(N \\times 1\\) col-vec이라고 생각하고 DFT를 아래와 같은 matrix로 정의하자.\n\\[{\\bf DFT} = \\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 1} & e^{-i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 2} & e^{-i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n    \\end{bmatrix}\\]\n그러면\n\\[{\\bf X} = {\\bf DFT} \\cdot {\\bf x}\\]\n와 같이 표현할 수 있고 \\({\\bf x}\\)에서 \\({\\bf X}\\)로 바꾸는 과정을 단순히 \\({\\bf DFT}\\)행렬을 \\({\\bf x}\\)의 왼쪽에 곱하는 과정으로 이해할 수 있다.\n(참고) 사실 아래와 같이 \\({\\bf DFT}\\)를 정의하는 버전도 있다. (둘이 혼용해서 쓰인다)\n\\[{\\bf DFT} = \\frac{1}{\\sqrt{N}}\\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 1} & e^{-i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 2} & e^{-i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n    \\end{bmatrix}\\]\n\n예제1 아래는 위키에서 긁어온 예제이다. 이 예제를 따라가보자.\n\n\n\n그림2: 위키에서 긁어온 예제이미지\n\n\n예제를 풀기위해서 우선 아래와 같은 벡터를 선언하다.\n\nx = [1, 2-im, -im, -1+2im]\n\n4-element Vector{Complex{Int64}}:\n  1 + 0im\n  2 - 1im\n  0 - 1im\n -1 + 2im\n\n\n(풀이1)\n\\(4\\times 4\\)의 크기를 가지는 DFT행렬을 선언한다.\n(step1) 아래의 매트릭스 생성\n\n_DFT = reshape([i*j for i in 0:3 for j in 0:3], (4,4))\n_DFT\n\n4×4 Matrix{Int64}:\n 0  0  0  0\n 0  1  2  3\n 0  2  4  6\n 0  3  6  9\n\n\n(step2) _DFT의 각 원소에 함수 \\(f: x \\to \\exp(-i\\frac{2\\pi}{4}x)\\)를 취함\n\nf = x -> exp(-im * (2π/4) * x)\nDFT = _DFT .|> f\n\n4×4 Matrix{ComplexF64}:\n 1.0-0.0im           1.0-0.0im          …           1.0-0.0im\n 1.0-0.0im   6.12323e-17-1.0im             -1.83697e-16+1.0im\n 1.0-0.0im          -1.0-1.22465e-16im             -1.0-3.67394e-16im\n 1.0-0.0im  -1.83697e-16+1.0im              5.51091e-16-1.0im\n\n\n이제 \\({\\bf X}\\)를 구하면 아래와 같다.\n\nDFT * x\n\n4-element Vector{ComplexF64}:\n                   2.0 + 0.0im\n   -1.9999999999999998 - 2.0000000000000004im\n 8.881784197001252e-16 - 1.9999999999999998im\n    3.9999999999999987 + 4.000000000000001im\n\n\n위키의 답이 잘 나옴\n(풀이2)\n참고로 아래와 같이 패키지를 이용하여 구할 수도 있다.\n\nfft(x)\n\n4-element Vector{ComplexF64}:\n  2.0 + 0.0im\n -2.0 - 2.0im\n  0.0 - 2.0im\n  4.0 + 4.0im"
  },
  {
    "objectID": "posts/2. Let's Study/CGSP/2022-12-24-Chap 8.3.html#inverse-dft",
    "href": "posts/2. Let's Study/CGSP/2022-12-24-Chap 8.3.html#inverse-dft",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "Inverse DFT",
    "text": "Inverse DFT\n앞으로는 \\({\\bf DFT}\\)를 아래와 같이 정의하자.\n\\[{\\bf DFT} = \\frac{1}{\\sqrt{N}}\\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 1} & e^{-i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 2} & e^{-i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n    \\end{bmatrix}\\]\n\\({\\bf DFT}\\)행렬에는 몇 가지 특징이 있다.\n특징1: 유니터리행렬이다. 즉 \\({\\bf DFT}^\\ast \\cdot {\\bf DFT} = {\\bf DFT}^\\ast \\cdot{\\bf DFT} = {\\bf I}\\) 이다.\n\n_DFT = reshape([i*j for i in 0:3 for j in 0:3], (4,4))\nf = x -> exp(-im * (2π/4) * x)\nDFT = _DFT .|> f\nDFT # 아까의 예제의 DFT!\n\n4×4 Matrix{ComplexF64}:\n 1.0-0.0im           1.0-0.0im          …           1.0-0.0im\n 1.0-0.0im   6.12323e-17-1.0im             -1.83697e-16+1.0im\n 1.0-0.0im          -1.0-1.22465e-16im             -1.0-3.67394e-16im\n 1.0-0.0im  -1.83697e-16+1.0im              5.51091e-16-1.0im\n\n\n\nDFT = (1/√4)*DFT # 새로운 DFT의 정의 \nDFT'DFT .|> round # 유니터리행렬임을 확인!\n\n4×4 Matrix{ComplexF64}:\n  1.0+0.0im  -0.0-0.0im   0.0-0.0im   0.0-0.0im\n -0.0+0.0im   1.0+0.0im  -0.0-0.0im   0.0-0.0im\n  0.0+0.0im  -0.0+0.0im   1.0+0.0im  -0.0-0.0im\n  0.0+0.0im   0.0+0.0im  -0.0+0.0im   1.0+0.0im\n\n\n특징2: \\({\\bf DFT}\\)는 대칭행렬이다. 따라서 이 행렬의 켤레전치는 DFT의 각 원소에서 단순히 \\(i=\\sqrt{-1}\\) 대신에 \\(-i\\) 를 넣은 것과 같다.\n특징1-2를 조합하면 아래와 같이 \\({\\bf DFT}\\)에서 \\(i\\) 대신에 \\(-i\\)를 넣은 행렬이 변환 DFT를 취소시킬 수 있음을 이해할 수 있다. 3\n\\[\\frac{1}{\\sqrt{N}}\\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{i \\frac{2\\pi}{N}\\cdot 1} & e^{i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{i \\frac{2\\pi}{N}\\cdot 2} & e^{i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n    \\end{bmatrix}\\]\n행렬 \\({\\bf DFT}\\)를 discrete Fourier transform으로 생각했듯이 위의 행렬을 inverse discrete Fourier transform으로 해석할 수 있다."
  },
  {
    "objectID": "posts/2. Let's Study/CGSP/2022-12-24-Chap 8.3.html#dft의-또-다른-정의",
    "href": "posts/2. Let's Study/CGSP/2022-12-24-Chap 8.3.html#dft의-또-다른-정의",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "DFT의 또 다른 정의",
    "text": "DFT의 또 다른 정의\n이번에는 \\({\\bf DFT}\\)에 대한 다른 정의를 생각해보자. 우선 아래와 같은 행렬 \\({\\bf B}\\)를 고려하자.\n\nB= [0 0 0 1 \n    1 0 0 0 \n    0 1 0 0\n    0 0 1 0]\n\n4×4 Matrix{Int64}:\n 0  0  0  1\n 1  0  0  0\n 0  1  0  0\n 0  0  1  0\n\n\n이것은 길이가 4인 임의의 column vector를 아래로 한칸씩 이동시키는 매트릭스이다.\n\nx = [1, 2-im, -im, -1+2im]\n\n4-element Vector{Complex{Int64}}:\n  1 + 0im\n  2 - 1im\n  0 - 1im\n -1 + 2im\n\n\n\nB*x # 아래로 한칸이동 \n\n4-element Vector{Complex{Int64}}:\n -1 + 2im\n  1 + 0im\n  2 - 1im\n  0 - 1im\n\n\n\nB^2*x # 아래로 두칸이동, B^2*x = B*(Bx) 이므로 \n\n4-element Vector{Complex{Int64}}:\n  0 - 1im\n -1 + 2im\n  1 + 0im\n  2 - 1im\n\n\n한편 이 매트릭스 \\({\\bf B}\\)는 아래와 같이 고유분해가 가능하다.\n\\[ {\\bf B} = {\\bf \\Psi} {\\bf \\Lambda} {\\bf \\Psi}^\\ast\\]\n\n\\({\\bf \\Psi}\\): make \\(\\frac{1}{\\sqrt{N}}[e^{\\sqrt{-1} \\frac{2\\pi}{N} ij}~\\text{ for }~ i=0,1,2,\\dots,N-1~\\text{ for }~j=0,1,2,\\dots,N-1]\\) and apply reshape function with \\((N,N)\\).\n\\({\\bf \\Lambda}\\): make \\([e^{-\\sqrt{-1}\\frac{2\\pi}{N}i}~\\text{ for }~ i=0,1,2\\dots,N-1]\\) and apply Diagonal function.\n\n\nN = 4 \nλ = [exp(-im * (2π/N) *i) for i in 0:(N-1)]\nΛ = Diagonal(λ)\n_Ψ = 1/√N *[exp(im * (2π/N) * i*j) for i in 0:(N-1) for j in 0:(N-1)]\nΨ = reshape(_Ψ, (N,N))\nB ≈ Ψ * Λ * Ψ'\n\ntrue\n\n\n그런데 위에서 정의된 \\({\\bf \\Psi}^\\ast\\)는 우리가 그전에 정의하였던 \\({\\bf DFT}\\)의 행렬과 같다.\n\n_DFT = reshape([i*j for i in 0:3 for j in 0:3], (4,4))\nDFT = _DFT .|> (x -> exp(-im * (2π/4) * x)) \nDFT = DFT * 1/√N\n\n4×4 Matrix{ComplexF64}:\n 0.5-0.0im           0.5-0.0im          …           0.5-0.0im\n 0.5-0.0im   3.06162e-17-0.5im             -9.18485e-17+0.5im\n 0.5-0.0im          -0.5-6.12323e-17im             -0.5-1.83697e-16im\n 0.5-0.0im  -9.18485e-17+0.5im              2.75546e-16-0.5im\n\n\n\nΨ' == DFT \n\ntrue\n\n\n결국 요약하면 길이가 \\(N\\)인 신호의 \\({\\bf DFT}\\)행렬은 아래의 과정으로 구할 수 있음을 알 수 있다.\n\nForward operator \\({\\bf A}\\)를 정의한다.\n\\({\\bf A}\\)의 고유벡터행렬 \\({\\bf \\Psi}\\)을 구한다. 4\n\\({\\bf \\Psi}\\)의 conjugate transpose matrix \\({\\bf \\Psi}^\\ast\\) 를 구한다. 이것이 \\({\\bf DFT}\\) matrix 이다. 5"
  },
  {
    "objectID": "posts/2. Let's Study/CGSP/2022-12-24-Chap 8.3.html#spectral-component-and-frequencies",
    "href": "posts/2. Let's Study/CGSP/2022-12-24-Chap 8.3.html#spectral-component-and-frequencies",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "Spectral component and Frequencies",
    "text": "Spectral component and Frequencies\n\\({\\bf A}\\)의 고유벡터 \\({\\bf \\Psi}\\)의 각 column을 spectral component라고 부른다.\n\nψ₁ = Ψ[:,1] # ψ₁ is first spectral component \nψ₂ = Ψ[:,2] # ψ₂ is seconde spectral component \nψ₃ = Ψ[:,3] # ψ₃ is third spectral component \nψ₄ = Ψ[:,4] # ψ₄ is last spectral component\n\n그리고 아래와 같은 수열을 \\(\\Omega_{k}=\\frac{k}{N}\\)을 frequency 라고 부른다.\n\nN=4 \nΩ = [k/N for k in 0:(N-1)]\nΩ\n\n4-element Vector{Float64}:\n 0.0\n 0.25\n 0.5\n 0.75"
  },
  {
    "objectID": "posts/2. Let's Study/CGSP/2023-01-15-Chap-12.4.html",
    "href": "posts/2. Let's Study/CGSP/2023-01-15-Chap-12.4.html",
    "title": "Chap 12.4: Node Subsampling for PSD Estimation",
    "section": "",
    "text": "using LinearAlgebra, Plots, FFTW, Statistics\n\n\ncolumnwise_kron = \n(C,D) -> hcat([kron(C[:,i],D[:,i]) for i in 1:size(C)[2]]...)\n\n#49 (generic function with 1 method)\n\n\n\n12.4.1 The Sampling Problem\n아래와 같이 길이가 \\(N=10\\) 인 신호 \\({\\bf x}\\)를 고려하자.\n\nx = rand(10)\n\n10-element Vector{Float64}:\n 0.03235208758206609\n 0.5069925854414447\n 0.5795228508497553\n 0.682832351742401\n 0.64422613488741\n 0.24116013388795854\n 0.8439116925218157\n 0.6362602319916778\n 0.386069828675059\n 0.5313655894235898\n\n\n여기에서 1,3,4,5 번째 원소만 추출하여길이가 \\(K=4\\) 인 신호 \\({\\bf y}\\)를 만들고 싶다.\n\ny = x[[1,3,4,5]]\n\n4-element Vector{Float64}:\n 0.03235208758206609\n 0.5795228508497553\n 0.682832351742401\n 0.64422613488741\n\n\n이 과정은 아래와 같이 수행할 수도 있다.\n\nΦ= [1 0 0 0 0 0 0 0 0 0\n    0 0 1 0 0 0 0 0 0 0\n    0 0 0 1 0 0 0 0 0 0\n    0 0 0 0 1 0 0 0 0 0]\n\n4×10 Matrix{Int64}:\n 1  0  0  0  0  0  0  0  0  0\n 0  0  1  0  0  0  0  0  0  0\n 0  0  0  1  0  0  0  0  0  0\n 0  0  0  0  1  0  0  0  0  0\n\n\n\nΦ*x\n\n4-element Vector{Float64}:\n 0.03235208758206609\n 0.5795228508497553\n 0.682832351742401\n 0.64422613488741\n\n\n즉 적당한 \\(K\\times N\\) selection matrix를 선언하여 subsampling을 수행할 수 있다. 이때 매트릭스 \\({\\bf \\Phi}\\)를 subsampling matrix 혹은 sparse sampling matrix 라고 부른다.\n\n\n12.4.2 Compressed LS Estimator\n\nN = 10\nV = [i*j for i in 0:(N-1) for j in 0:(N-1)] |> \n    x -> reshape(x,(N,N)) .|> \n    x -> exp(im * (2π/N) * x) \n\n10×10 Matrix{ComplexF64}:\n 1.0+0.0im        1.0+0.0im          …        1.0+0.0im\n 1.0+0.0im   0.809017+0.587785im         0.809017-0.587785im\n 1.0+0.0im   0.309017+0.951057im         0.309017-0.951057im\n 1.0+0.0im  -0.309017+0.951057im        -0.309017-0.951057im\n 1.0+0.0im  -0.809017+0.587785im        -0.809017-0.587785im\n 1.0+0.0im       -1.0+1.22465e-16im  …       -1.0+1.10218e-15im\n 1.0+0.0im  -0.809017-0.587785im        -0.809017+0.587785im\n 1.0+0.0im  -0.309017-0.951057im        -0.309017+0.951057im\n 1.0+0.0im   0.309017-0.951057im         0.309017+0.951057im\n 1.0+0.0im   0.809017-0.587785im         0.809017+0.587785im\n\n\n\nG = columnwise_kron(conj(V),V)\n\n100×10 Matrix{ComplexF64}:\n 1.0+0.0im        1.0+0.0im          …        1.0+0.0im\n 1.0+0.0im   0.809017+0.587785im         0.809017-0.587785im\n 1.0+0.0im   0.309017+0.951057im         0.309017-0.951057im\n 1.0+0.0im  -0.309017+0.951057im        -0.309017-0.951057im\n 1.0+0.0im  -0.809017+0.587785im        -0.809017-0.587785im\n 1.0+0.0im       -1.0+1.22465e-16im  …       -1.0+1.10218e-15im\n 1.0+0.0im  -0.809017-0.587785im        -0.809017+0.587785im\n 1.0+0.0im  -0.309017-0.951057im        -0.309017+0.951057im\n 1.0+0.0im   0.309017-0.951057im         0.309017+0.951057im\n 1.0+0.0im   0.809017-0.587785im         0.809017+0.587785im\n 1.0+0.0im   0.809017-0.587785im     …   0.809017+0.587785im\n 1.0+0.0im        1.0+0.0im                   1.0+0.0im\n 1.0+0.0im   0.809017+0.587785im         0.809017-0.587785im\n    ⋮                                ⋱  \n 1.0+0.0im        1.0+0.0im                   1.0+0.0im\n 1.0+0.0im   0.809017+0.587785im         0.809017-0.587785im\n 1.0+0.0im   0.809017+0.587785im     …   0.809017-0.587785im\n 1.0+0.0im   0.309017+0.951057im         0.309017-0.951057im\n 1.0+0.0im  -0.309017+0.951057im        -0.309017-0.951057im\n 1.0+0.0im  -0.809017+0.587785im        -0.809017-0.587785im\n 1.0+0.0im       -1.0-1.11022e-16im          -1.0+2.27596e-15im\n 1.0+0.0im  -0.809017-0.587785im     …  -0.809017+0.587785im\n 1.0+0.0im  -0.309017-0.951057im        -0.309017+0.951057im\n 1.0+0.0im   0.309017-0.951057im         0.309017+0.951057im\n 1.0+0.0im   0.809017-0.587785im         0.809017+0.587785im\n 1.0+0.0im        1.0+0.0im                   1.0+0.0im\n\n\n- 방법1\n\nĉx = vec(x*x')\np̂ = inv(G' * G) * G' * ĉx\n\n10-element Vector{ComplexF64}:\n    0.25854107856772546 + 2.245922875954761e-20im\n   0.004743491121735806 - 1.3138893409553828e-18im\n   0.006946482731189413 - 9.791191432641327e-19im\n   0.001721693617954179 - 1.9827974128203887e-18im\n   0.011344167525098774 + 2.6827005818057562e-19im\n 0.00012662617844242917 - 3.748573865136995e-20im\n   0.011344167525098762 + 2.7448152053954017e-18im\n  0.0017216936179541913 - 9.35534609073096e-19im\n   0.006946482731189404 + 1.954408900185458e-18im\n   0.004743491121735756 - 2.561030398375897e-18im\n\n\n- 방법2\n\nĉy = vec(y*y')\np̂ = (kron(Φ,Φ)*G)' * ĉy\n\n10-element Vector{ComplexF64}:\n   3.759462826821233 + 0.0im\n   2.765185174577697 - 2.0816681711721685e-17im\n   1.077337414764992 + 2.7755575615628914e-17im\n 0.11594812606807317 + 2.0816681711721685e-17im\n 0.08838298603932843 + 3.903127820947816e-17im\n 0.32863702713833354 + 4.622231866529366e-33im\n 0.08838298603932859 + 9.540979117872439e-18im\n  0.1159481260680729 - 2.0816681711721685e-17im\n  1.0773374147649915 + 0.0im\n  2.7651851745776965 - 2.0816681711721685e-17im"
  },
  {
    "objectID": "posts/2. Let's Study/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html",
    "href": "posts/2. Let's Study/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html",
    "title": "Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "",
    "text": "using LinearAlgebra, Plots, FFTW, Statistics"
  },
  {
    "objectID": "posts/2. Let's Study/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#kronecker-product",
    "href": "posts/2. Let's Study/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#kronecker-product",
    "title": "Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "Kronecker product",
    "text": "Kronecker product\n크로네커곱의 정의는 아래와 같다.\n\\[{\\bf A} \\otimes {\\bf B}\n=\\begin{bmatrix}\na_{11}{\\bf B} & a_{12}{\\bf B} & \\dots & a_{1m}{\\bf B} \\\\\na_{21}{\\bf B} & a_{22}{\\bf B} & \\dots & a_{2m}{\\bf B} \\\\\n\\dots & \\dots & \\dots & \\dots \\\\\na_{n1}{\\bf B} & a_{n2}{\\bf B} & \\dots & a_{nm}{\\bf B} \\\\\n\\end{bmatrix}\\]\n두 행렬 \\({\\bf A}_{m\\times n}\\), \\({\\bf B}_{p\\times q}\\)의 크로네커곱 \\({\\bf A}\\otimes {\\bf B}\\)의 차원은 \\(mp \\times nq\\) 가 된다. 계산예시는 아래와 같다.\n\n\n\n위키에서 긁은 예제, 글씨가 좀 작음\n\n\n크로네커곱에 대한 성질들이 위키에 많이 있으니 참고하면 좋다.\n(예제1)\n\nA= [1 2\n    3 4]\nB= [0 5\n    6 7]\nC = kron(A, B)\n\n4×4 Matrix{Int64}:\n  0   5   0  10\n  6   7  12  14\n  0  15   0  20\n 18  21  24  28\n\n\n(예제2)\n\nA= [1 -4 7; -2 3 3]\nB= [8 -9 -6 -5; 1 -3 -4 7; 2 8 -8 -3; 1 2 -5 -1]\nC = kron(A, B)\n\n8×12 Matrix{Int64}:\n   8   -9  -6   -5  -32   36   24   20  56  -63  -42  -35\n   1   -3  -4    7   -4   12   16  -28   7  -21  -28   49\n   2    8  -8   -3   -8  -32   32   12  14   56  -56  -21\n   1    2  -5   -1   -4   -8   20    4   7   14  -35   -7\n -16   18  12   10   24  -27  -18  -15  24  -27  -18  -15\n  -2    6   8  -14    3   -9  -12   21   3   -9  -12   21\n  -4  -16  16    6    6   24  -24   -9   6   24  -24   -9\n  -2   -4  10    2    3    6  -15   -3   3    6  -15   -3"
  },
  {
    "objectID": "posts/2. Let's Study/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#khatrirao-product",
    "href": "posts/2. Let's Study/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#khatrirao-product",
    "title": "Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "Khatri–Rao product",
    "text": "Khatri–Rao product\n카트리-라오곱은 매트릭스 \\({\\bf A}\\)와 \\({\\bf B}\\)가 같은 차원의 블락매트릭스로 정의될때 각 서브매트릭스의 크로네커 곱으로 정의된다. 정의와 계산예시는 아래와 같다.\n\n\n\n예시1: 위키에서 긁은 그림\n\n\n또 다른 계산예시는 아래와 같다. 이 예제는 중요하니까 구현해보자.\n\n\n\n예시2: 위키에서 긁은 그림\n\n\n(예제1)\n\nC= [1 2 3 \n    4 5 6 \n    7 8 9] \nD= [1 4 7\n    2 5 8\n    3 6 9]\n\n3×3 Matrix{Int64}:\n 1  4  7\n 2  5  8\n 3  6  9\n\n\n\nhcat([kron(C[:,i],D[:,i]) for i in 1:3]...)\n\n9×3 Matrix{Int64}:\n  1   8  21\n  2  10  24\n  3  12  27\n  4  20  42\n  8  25  48\n 12  30  54\n  7  32  63\n 14  40  72\n 21  48  81\n\n\n이건 자주 쓸일이 있을것 같으니까 함수로 저장하자.\n\ncolumnwise_kron = \n(C,D) -> hcat([kron(C[:,i],D[:,i]) for i in 1:size(C)[2]]...)\n\n#181 (generic function with 1 method)\n\n\n\ncolumnwise_kron(C,D)\n\n9×3 Matrix{Int64}:\n  1   8  21\n  2  10  24\n  3  12  27\n  4  20  42\n  8  25  48\n 12  30  54\n  7  32  63\n 14  40  72\n 21  48  81"
  },
  {
    "objectID": "posts/2. Let's Study/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#그래프-표현",
    "href": "posts/2. Let's Study/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#그래프-표현",
    "title": "Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "그래프 표현",
    "text": "그래프 표현\n아래의 그림을 살펴보자.\n\n\n\n그래프의 개념을 이해하는 필요한 그림, 일단 오른쪽의 \\({\\bf S}\\)는 무시할 것\n\n\n오른쪽의 \\({\\bf S}\\)는 무시하고 왼쪽의 그래프만 살펴보자. 이 그림에는 6개의 노드가 있고 각각의 노드는 저 마다의 연결구조를 가진다. 이러한 연결구조는 \\({\\bf G}=({\\bf N},{\\bf E})\\) 으로 표현할 수 있는데 여기에서 \\({\\bf N}\\)은 노드들의 집합이고 \\({\\bf E}\\)는 엣지들의 집합이다.1 보통 \\({\\cal E}\\)는 복잡하므로 연결정보를 매트릭스 \\({\\bf E}\\)로 표현하는데 이러한 \\({\\bf E}\\)를 인접행렬이라고 부른다. 인접행렬의 각 원소는 \\(E_{ij}= \\begin{cases} 1 & (i,j) \\in {\\cal E} \\\\ 0 & o.w \\end{cases}\\) 와 같이 정의한다. 이 그림의 경우 \\({\\cal N}\\) 와 \\({\\cal E}\\), \\({\\bf E}\\) 는 아래와 같다.\n\n\\({\\cal N}=\\{1,2,3,4,5,6\\}\\)\n\\({\\bf E}=\\begin{bmatrix} 0 & 1 & 0 & 0 & 1 & 0 \\\\ 1 & 0 & 1 & 0 & 1 & 0\\\\ 0 & 1 & 0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 0 & 1 & 1 \\\\ 1 & 1 & 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 1 & 0 & 0 \\end{bmatrix}\\)\n\\({\\cal E} = \\{(i,j) : E_{ij}=1 \\}\\)"
  },
  {
    "objectID": "posts/2. Let's Study/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#gso",
    "href": "posts/2. Let's Study/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#gso",
    "title": "Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "GSO",
    "text": "GSO\n후에 자세히 서술하겠지만 전통적인 시계열분석기법을 그래프신호로 확장하기 위해서는 단지 퓨리에변환 대신에 그래프퓨리에 변환을 사용하면 된다. 즉 퓨리에변환을 일반화한 그래프퓨리에변환을 잘 정의하면 된다.\n전통적인 신호처리 영역에서의 퓨리에변환은 시계열자료의 인접성을 의미하는 행렬 \\({\\bf B}\\)2의 고유행렬의 켤레전치로 정의할 수 있다. 이를 이용하면 그래프 퓨리에변환은 그래프자료의 인접성을 의미하는 행렬3의 고유행렬의 켤레전치로 정의할 수 있음을 유추할 수 있다. 즉 비유클리드 자료에서도 \\({\\bf B}\\)에 대응하는 어떠한 매트릭스가 정의되어야 하는데 (그리고 이 매트릭스는 그래프자료의 인접성에 대한 정보가 있어야 한다) 이 매트릭스를 \\({\\bf S}\\)라고 정의하고 grahp shift operator (GSO) 라고 이름 붙인다.\n주어진 그래프 \\({\\cal G}=({\\cal N},{\\cal E})\\) 에 대하여 GSO \\({\\bf S}\\)는 \\({\\bf E}+{\\bf I}\\)의 값이 1인 영역에만 값이 있는 어떠한 행렬이다. 다시 아래의 그림을 생각하여 보자.\n\n\n\nGSO의 개념을 이해하는데 필요한 그림\n\n\n왼쪽그래프의 GSO는 오른쪽과 같은 행렬 \\({\\bf S}\\)가 된다. 이제 \\({\\bf S}\\) 의 고유벡터행렬을 구한 뒤에 그것의 켤레전치를 \\({\\bf GFT}\\) 행렬로 정의하면 될 것 같다. 문제는 “\\({\\bf S}\\)의 고유벡터행렬이 항상 존재하는가?” 인데, 사실 이게 항상 존재한다는 보장이 없다. 즉 \\({\\bf S}\\)의 고유벡터 행렬이 존재 안할 수도 있다. 따라서 GSO \\({\\bf S}\\)가 고유분해가능하다는 조건이 추가적으로 필요한데 이러한 조건을 만족하는 GSO를 normal GSO라고 부른다. 우리는 당연히 normal GSO에 대해서만 관심이 있으므로 앞으로 특별한 언급이 없는한 GSO는 모두 normal GSO라고 가정한다."
  },
  {
    "objectID": "posts/2. Let's Study/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#periodogram-correlogram-and-ls-estimator",
    "href": "posts/2. Let's Study/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#periodogram-correlogram-and-ls-estimator",
    "title": "Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "Periodogram, correlogram, and LS estimator",
    "text": "Periodogram, correlogram, and LS estimator\nFrom \\({\\bf C}_{\\tilde{\\bf x}}:= \\mathbb{E}\\left[\\tilde{\\bf x}\\tilde{\\bf x}^H \\right]=\\mathbb{E}\\left[({\\bf V}^H{\\bf x})({\\bf V}^H{\\bf x})^H \\right]=\\text{diag}({\\bf p})\\) it follows that one may express the PSD as \\({\\bf p}=\\mathbb{E}\\left[|{\\bf V}^H{\\bf x}|^2\\right]\\). That is, the PSD is given by the expected value of the squared frequency components of the random process. This leads to a natural approach for the estimation of \\({\\bf p}\\) from a finite set of \\(R\\) realizations of the process \\({\\bf x}\\). Indeed, we compute the \\({\\bf GFT} \\tilde{\\bf x}_r = {\\bf V}^H{\\bf x}_r\\) of each observed signal \\({\\bf x}_r\\) and estimate \\({\\bf p}\\) as\n\\[\n\\hat{\\bf p}_{pg}:= \\frac{1}{R}\\sum_{r=1}^R|\\tilde{\\bf x}_r|^2=\\frac{1}{R}\\sum_{r=1}^{R}|{\\bf V}^H{\\bf x}_{r}|^2.\n\\]\nThe estimator \\(\\hat{\\bf p}_{pg}\\) is termed periodogram due to its evident similarity with its homonym5 in classical estimation. It is simple to show that \\({\\bf p}_{pg}\\) is an unbiased estimator, that is, \\(\\mathbb{E}[\\hat{\\bf p}_{pg}]= {\\bf p}\\). A more detailed analysis of the performance of \\(\\hat{\\bf p}_{pg}\\), for the case where the observations are Gaussian, is given in Proposition 12.1.6\nAn alternative nonparametric estimation scheme, denominated correlogram, can be devised by starting from the definition of \\({\\bf p}\\) in\n\\[{\\bf p}:=\\text{diag}\\big({\\bf V}^H {\\bf C}_{\\bf x}{\\bf V} \\big).\\]\nNamely, one may substitute \\({\\bf C}_{\\bf x}\\) in above equation by the sample covariance \\(\\hat{\\bf C}_{\\bf x} = \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_r{\\bf x}_r^H\\) computed based on the available observations to obtain\n\\[\\hat{\\bf p}_{cg}:= \\text{diag}\\left({\\bf V}^H \\hat{\\bf C}_{\\bf x}{\\bf V} \\right):=\\text{diag}\\left[{\\bf V}^H\\big[ \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_r{\\bf x}_r^H\\big]{\\bf V} \\right].\\]\nNotice that the matrix \\({\\bf V}^H\\hat{\\bf C}_{\\bf x}{\\bf V}\\) is in general, not diagonal because the eigenbasis of \\(\\hat{\\bf C}_{\\bf x}\\) differs from \\({\\bf V}\\), the eigenbasis of \\({\\bf C}_{\\bf x}\\). Nonetheless, we keep only the diagonal elements \\({\\bf v}_i^H \\hat{\\bf C}_{\\bf x}{\\bf v}_i\\) for \\(i = 1, \\dots , N\\) as our PSD estimator. It can be shown that the correlogram \\({\\bf p}_{cg}\\) and the periodogram \\({\\bf p}_{pg}\\) lead to identical estimators, as is the case in classical signal processing.\nThe correlogram can also be interpreted as an LS estimator. The decomposition in \\({\\bf C}_{\\bf x}={\\bf V}\\text{diag}({\\bf p}){\\bf V}^H\\) allows a linear parameterization of the covariance matrix \\({\\bf C}_{\\bf x}\\) as\n\\[\n{\\bf C}_{\\bf x}({\\bf p})=\\sum_{i=1}^N p_i{\\bf v}_i{\\bf v}_i^H.\n\\]\nThis linear parametrization will also be useful for the sampling schemes developed in Section 12.4. Vectorizing \\({\\bf C}_{\\bf x}\\) in \\({\\bf C}_{\\bf x}({\\bf p})=\\sum_{i=1}^N p_i{\\bf v}_i{\\bf v}_i^H\\) results in a set of \\(N^2\\) equations in \\({\\bf p}\\)\n\\[\n{\\bf c}_{\\bf x} = \\text{vec}({\\bf C}_{\\bf x})=\\sum_{i=1}^{N}p_i \\text{vec}({\\bf v}_i{\\bf v}_i^H)={\\bf G}_{np}{\\bf p},\n\\]\nwhere \\(\\text{vec}({\\bf v}_i{\\bf v}_i^H)={\\bf v}_i^\\ast \\otimes {\\bf v}_i\\). Relying on the Khatri-Rao product, we then form the \\(N^2 \\times N\\) matrix \\({\\bf G}_{np}\\) as\n\\[\n{\\bf G}_{np}:= \\left[{\\bf v}_1^\\ast \\otimes {\\bf v}_1, \\dots, {\\bf v}_N^\\ast \\otimes {\\bf v}_N \\right] = {\\bf V}^\\ast \\odot {\\bf V}.\n\\]\n\nHere \\(\\otimes\\) denote the Kronecker matrix product and \\(\\odot\\) denote the Khatri-Rao matrix product.\n\nUsing the sample covariance matrix \\(\\hat{\\bf C}_{\\bf x}\\) as an estimate of \\({\\bf C}_{\\bf x}\\), we can match the estimated covariance vector \\(\\hat{\\bf c}_{\\bf x}=\\text{vec}(\\hat{\\bf C}_{\\bf x})\\) to the true covariance vector \\({\\bf c}_{\\bf x}\\) in the LS sense as\n\\[\n\\hat{\\bf p}_{ls} = \\underset{\\bf p}{\\operatorname{argmin}} \\|\\hat{\\bf c}_{\\bf x}-{\\bf G}_{np}{\\bf p}\\|_2^2=({\\bf G}_{np}^H{\\bf G}_{np})^{-1}{\\bf G}_{np}^H\\hat{\\bf c}_{\\bf x}.\n\\]\nIn other words, the LS estimator minimizes the squared error \\(\\text{tr}\\left[\\big(\\hat{\\bf C}_{\\bf x} − \\hat{\\bf C}_{\\bf x}({\\bf p})\\big)^T \\big(\\hat{\\bf C}_{\\bf x} − \\hat{\\bf C}_{\\bf x}({\\bf p})\\big)\\right]\\). From expression \\(\\hat{\\bf p}_{ls} = \\underset{\\bf p}{\\operatorname{argmin}} \\|\\hat{\\bf c}_{\\bf x}-{\\bf G}_{np}{\\bf p}\\|_2^2=({\\bf G}_{np}^H{\\bf G}_{np})^{-1}{\\bf G}_{np}^H\\hat{\\bf c}_{\\bf x}\\) it can be shown that the \\(i\\)th element of \\(\\hat{\\bf p}_{ls}\\) is \\({\\bf v}_i^H \\hat{\\bf C}_{\\bf x} {\\bf v}_i\\). Combining this with Eq.\n\\[\\hat{\\bf p}_{cg}:= \\text{diag}\\left({\\bf V}^H \\hat{\\bf C}_{\\bf x}{\\bf V} \\right):=\\text{diag}\\left[{\\bf V}^H\\big[ \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_r{\\bf x}_r^H\\big]{\\bf V} \\right]\\]\nwe get that the LS estimator \\(\\hat{\\bf p}_{ls}\\) and the correlogram \\(\\hat{\\bf p}_{cg}\\) —and hence the periodogram as well— are all identical estimators. The estimators derived in this subsection do not assume any data distribution and are well suited for cases where the data probability density function is not available. In what follows, we provide performance bounds for these estimators under the condition that the observed signals are Gaussian."
  },
  {
    "objectID": "posts/2. Let's Study/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#정상시계열을-분석하는-두-가지-흐름-acf와-psd",
    "href": "posts/2. Let's Study/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#정상시계열을-분석하는-두-가지-흐름-acf와-psd",
    "title": "Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "정상시계열을 분석하는 두 가지 흐름, ACF와 PSD",
    "text": "정상시계열을 분석하는 두 가지 흐름, ACF와 PSD\n\n전통적인 분석방법\n클래식한 정상시계열은 유한차수의 ARMA로 근사할 수 있음이 알려져 있다7. 유한차수의 ARMA의 계수 \\(p\\),\\(q\\)를 적절하게 추정하기 위해서는 시계열 \\({\\bf x}\\)를 SACF plot 혹은 SPACF plot 을 이용하면 된다. 이때 SACF 혹은 SPACF 의 그림을 살펴보고 적절한 모형을 선택하기 위해서는 유한차수 ARMA의 이론적 ACF의 모양을 알면 되는데,8 이를 바꾸어서 말하면 결국 정상시계열 \\({\\bf x}\\)의 모든 정보는 ACF에 들어있다는 의미가 된다. 즉 정상시계열은 ACF만 잘 추정하면 모든 것이 해결된다.\n그런데 ACF의 모든 정보는 다시 아래의 행렬에 들어있다.\n\\[{\\bf C}_{\\bf x}=\\mathbb{E}[{\\bf x}{\\bf x}^T]\\]\n여기에서 \\({\\bf x}\\)는 realization이 아니라 확률벡터를 의미함을 유의하자.9 따라서 정상시계열의 경우 \\({\\bf C}_{\\bf x}\\)를 잘 추정하면 모든것이 해결된다고 생각하면 된다.\n\n참고: 정상시계열의 경우 ACF 만 정확하게 알아도 (반대로 PACF만 정확하게 알아도) 이론상 모든 모형을 특정할 수 있다. 즉 정상시계열의 모형을 특정하기 위해서는 ACF plot, PACF plot 하나만 있어도 충분하다. (Wold’s Thm은 떠올리면 모든 정상시계열은 무한MA로 유니크하게 표현할 수 있는데, 이는 PACF plot을 가지고 모든 정상시계열을 유니크하게 특정할 수 있다는 것을 의미한다) 다만 좀 더 모형을 특정하는 과정을 용이하게 하기 위해서 실전에서는 SACF plot 과 SPACF plot 을 함께 보는 것이 유리하다.\n\n(예제) AR(1) 모형\n왜 ACF의 모든정보를 \\({\\bf C}_{\\bf x}\\)로 부터 알수 있는지 코드를 통하여 실습하여 보자. (바로 이해된다면 사실 이 예제는 스킵해도 무방함) 아래와 같은 모형을 가정하자.\n\\[x_{t} = 0.5 x_{t-1} +\\epsilon_t\\]\n여기에서 \\(\\epsilon_t\\)는 서로 독립인 표준정규분포를 따른다. 이 모형에서 길이가 100인 시계열을 임의로 발생시키자.\n\nx = zeros(100*1000)\nx[1] = randn()\nfor t in 2:100\n    x[t] = 0.5*x[t-1] + randn()\nend\n\n모형에서 생성된 하나의 시계열을 시각화 하면 아래와 같다.\n\nplot(x) # 그냥 그려본것임. 별 의미는 없음\n\n\n\n\nlag=1일 경우 이 시계열의 SACF를 계산하면 아래와 같다.\n\nx[1:99] .* x[2:100]\n\n99-element Vector{Float64}:\n  1.587897526021493\n  1.130306190921068\n  0.5698214432110668\n  0.4648189302568683\n  0.3099446153360606\n  0.36362604534744775\n  0.8191871414624922\n -0.1720390842292145\n -0.06301214708310766\n  0.026414715508855904\n -0.007988283356933327\n -0.04178812545299474\n  0.22453267567940685\n  ⋮\n  3.931333581073927\n  1.315564948810858\n  0.9096080102581454\n  0.5410986320348997\n  0.29627801400693676\n  1.0673283524686212\n -1.0394649044573636\n  2.80195248208142\n  4.152973765526384\n  2.316315764368524\n  0.978758337765867\n -0.5840281943972468\n\n\n\n이 계산결과는 각 \\(t\\)에 대하여 \\(x_{t-1}x_t\\) 를 계산한 것과 같다.\n\n이 수열들의 평균은 아래와 같다.\n\nx[1:99] .* x[2:100] |> mean\n\n0.5835563885014224\n\n\n\n이 계산결과는 \\(\\frac{1}{99}\\sum_{t=2}^{100} x_{t-1}x_t\\)를 계산한 것과 같다.\n\n이론적인 값인 0.5 근처의 값이 잘 나옴을 알 수 있다.\nlag=2일 경우도 마찬가지로 구할 수 있다.\n\nx[1:98] .* x[3:100] |> mean\n\n0.38420263596668275\n\n\n이러한 숫자들은 그런데 \\({\\bf x}{\\bf x}^T\\)를 이용하여서도 구할 수 있다.10\n\nx*x'\n\n100×100 Matrix{Float64}:\n  0.760108    1.5879      0.541064   …  -1.57394    -0.472676    0.939172\n  1.5879      3.31719     1.13031       -3.28802    -0.987441    1.96197\n  0.541064    1.13031     0.385143      -1.12037    -0.336463    0.668527\n  0.800507    1.67229     0.569821      -1.65759    -0.497799    0.989089\n  0.441361    0.922022    0.314172      -0.913915   -0.274462    0.545336\n  0.533784    1.1151      0.379961   …  -1.10529    -0.331936    0.659531\n  0.517803    1.08171     0.368586      -1.0722     -0.321998    0.639786\n  1.20252     2.51212     0.855987      -2.49003    -0.747794    1.48581\n -0.108745   -0.227173   -0.0774074      0.225175    0.0676234  -0.134363\n  0.440444    0.920106    0.313519      -0.912016   -0.273892    0.544203\n  0.0455859   0.0952309   0.0324492  …  -0.0943935  -0.0283478   0.0563249\n -0.133198   -0.278257   -0.0948139      0.27581     0.0828298  -0.164577\n  0.238468    0.498169    0.169748      -0.493789   -0.148292    0.294646\n  ⋮                                  ⋱                          \n  2.04697     4.2762      1.45708       -4.2386     -1.27291     2.52919\n  0.488514    1.02053     0.347736      -1.01155    -0.303784    0.603596\n  1.41531     2.95665     1.00746    …  -2.93065    -0.880119    1.74873\n  0.290602    0.60708     0.206858      -0.601742   -0.180712    0.359062\n  0.774954    1.61891     0.551632      -1.60468    -0.481908    0.957516\n  1.04688     2.18698     0.745197      -2.16775    -0.651007    1.2935\n -0.754723   -1.57665    -0.537231       1.56279     0.469328   -0.932519\n -2.82194    -5.89516    -2.00873    …   5.84333     1.75484    -3.48673\n -1.11863    -2.33686    -0.796269       2.31632     0.695624   -1.38215\n -1.57394    -3.28802    -1.12037        3.25911     0.978758   -1.94472\n -0.472676   -0.987441   -0.336463       0.978758    0.293936   -0.584028\n  0.939172    1.96197     0.668527      -1.94472    -0.584028    1.16042\n\n\n여기에서 각 원소들이 의미하는 바는 아래와 같다.\n\n대각선의 원소: \\(x_t^2,~ t=1,2,\\dots,100\\) 을 의미\n대각선 한칸 위, 혹은 한칸 아래: \\(x_{t-1} x_t~ t=2,3,\\dots,100\\) 을 의미\n대각선 두칸 위, 혹은 두칸 아래: \\(x_{t-2} x_t~ t=3,4,\\dots,100\\) 을 의미\n\n\n\n\nx*x'의 계산결과를 캡쳐한 그림, 이것은 \\(\\hat{\\bf C}_{\\bf x}\\)를 의미함\n\n\n확인해보자.\nlag=1, 스크린샷의 노란색\n\n(x[1:99] .* x[2:100])[1:5]\n\n5-element Vector{Float64}:\n 1.587897526021493\n 1.130306190921068\n 0.5698214432110668\n 0.4648189302568683\n 0.3099446153360606\n\n\n\nlag1에 해당하는 숫자들임. 이는 스크린샷에서 노란색으로 표현된 1.589, 1.13031, 0.569821 … 등과 일치한다.\n\nlag=2, 스크린샷의 빨간색\n\n(x[1:98] .* x[3:100])[1:5]\n\n5-element Vector{Float64}:\n 0.5410642277088621\n 1.6722932576420804\n 0.3141719983177106\n 0.5621541352252872\n 0.30066534927151267\n\n\n\nlag2에 해당하는 숫자들임. 이는 스크린샷에서 빨간색으로 표현된 숫자들인 0.54164, 1.67229, 0.31417 … 등과 일치한다.\n\n\n\n스펙트럼 방법\n지금까지는 정상시계열일 경우 ACF를 이용한 간단한 분석방법을 다시 복습했다. 그리고 \\({\\bf C}_{\\bf x}\\)가 ACF를 구함에 필요한 모든정보를 가지고 있음을 이해했다. 한편 \\({\\bf C}_{\\bf x}\\)은 positive definite matrix 이므로 아래와 같이 분해가능하다.\n\\[{\\bf C}_{\\bf x} = {\\bf V} \\text{diag}({\\bf p}) {\\bf V}^H\\]\n이 수식표현을 잘 해석하면 \\({\\bf C}_{\\bf x}\\)의 모든 정보는 \\({\\bf V}\\)와 \\({\\bf p}\\)에 담겨있다는 사실을 이해할 수 있다. 그런데 정상시계열일 경우 한정하여 \\({\\bf C}_{x}\\)의 고유벡터행렬은 \\({\\bf B}\\)의 고유벡터행렬과 일치한다는 사실을 알고 있다. 따라서 \\({\\bf V}\\)는 \\({\\bf B}\\)로 부터 그냥 알 수 있는 정보이다. 따라서 \\({\\bf C}_{\\bf x}\\)의 모든 정보는 \\({\\bf p}\\)에 담겨있다는 사실을 알 수 있다. 이는 적절한 \\({\\bf p}\\)를 추정하는 일은 적절한 \\({\\bf C}_{\\bf x}\\)를 추정하는 것과 같다는 사실을 알려준다.\n요약하면 아래와 같다.\n\n임의의 정상시계열은 이론적인 ACF (혹은 PACF)를 잘 추정하면 유니크하게 특정할 수 있다. (Wold’s Thm)\nACF를 잘 추정한다는 말은 \\({\\bf C}_{\\bf x}\\)를 잘 추정한다는 의미이다.\n그런데 \\({\\bf p}\\)를 잘 추정하면 \\({\\bf C}_{\\bf x}\\)를 잘 추정하는 일이 된다.\n따라서 임의의 정상시계열은 \\({\\bf p}\\)를 잘 추정하면 유니크하게 특정할 수 있다는 결론을 얻는다.\n\n여기에서 \\({\\bf p}\\)를 power spectral density 라고 부른다. 일반적으로 정상시계열을 분석하기 위해서는 \\({\\bf C}_{\\bf x}\\)를 특정하거나, \\({\\bf p}\\)를 특정하면 되는데 여기에서 \\({\\bf p}\\)를 특정한뒤 \\({\\bf p}\\)로 부터 \\({\\bf C}\\)를 역으로 해석하는 방법론을 spectral analysis라고 부른다. 경우에 따라서 \\({\\bf C}_{\\bf x}\\)를 특정하는 것이 용이할 수도 있지만 \\({\\bf p}\\)를 특정하고 해석하는 것이 용이할 때도 있다.\n그렇다면 주어진 시계열 \\({\\bf x}\\)에 대하여 \\({\\bf p}\\)를 어떻게 구할까? 직관적으로 생각하면 단순히 아래의 알고리즘으로 구하면 된다는 것을 알 수 있다.\n\n\\({\\bf C}_{\\bf x}\\)를 알아낸다.\n\\({\\bf C}_{\\bf x}\\)를 고유분해하여 \\({\\bf p}\\)를 구한다.\n\n또 다른 방법으로는 교재에 소개된 바 있는 아래의 수식을 이용하는 것이다.11\n\\[{\\bf p}=\\mathbb{E}\\left[|{\\bf V}^H{\\bf x}|^2\\right]\\]\n이것을 이용하면 아래와 같은 알고리즘을 떠올릴 수 있다.\n\n\\({\\bf B}\\)의 고유벡터행렬 \\({\\bf V}\\)를 구하고 \\({\\bf V}^H{\\bf x}\\)를 계산한다.\n계산된 결과를 원소별로 제곱하여 \\({\\bf p}\\)를 얻는다.\n\n그런데 \\({\\bf V}^H{\\bf x}= {\\bf DFT} \\cdot {\\bf x}\\) 이므로 1의 과정을 아래와 같이 바꾸어 서술할 수 있다.\n\n\\({\\bf x}\\)를 퓨리에변환하여 \\(\\tilde{\\bf x} = {\\bf DFT} \\cdot {\\bf x}\\) 를 계산한다.\n\\(\\tilde{\\bf x}\\)를 원소별로 제곱하여 \\({\\bf p}\\)를 얻는다.\n\n즉 임의의 시계열을 퓨리에변환한 뒤 제곱하면 \\({\\bf p}\\)를 얻을 수 있다.\n(예제2) – 하나의 realization에서 \\(\\hat{\\bf p}\\)를 구해보자.\n(예제1에 이어서) 아래의 모형에서 생성된 \\({\\bf x}\\)를 다시 고려하자.\n\\[x_{t} = 0.5 x_{t-1} +\\epsilon_t\\]\n\nplot(x)\n\n\n\n\n이 자료의 PSD \\({\\bf p}\\)는 아래와 같이 구할 수 있다.\n단계1: \\({\\bf x}\\)의 DFT를 계산\n\nx̃ = fft(x) \n\n100-element Vector{ComplexF64}:\n  -5.756917285643583 + 0.0im\n   -19.0826720904921 - 1.0178306444775302im\n  14.230506824768984 - 11.867854578089997im\n  3.8980118254428726 + 1.2603018602424614im\n -16.157973053188194 + 27.488246322270918im\n   12.32574209329046 - 1.5134316695905219im\n    3.95421224972561 + 15.369129638224624im\n   9.516938110507798 + 19.371467179753544im\n  -19.38292930624831 + 9.49506288623419im\n  -7.853934851478428 + 4.134711886071571im\n -14.072349901900408 - 5.945064076174294im\n -14.596266922162355 + 3.447776409279256im\n   5.857720447482927 + 5.738895112838594im\n                     ⋮\n   5.857720447482924 - 5.738895112838594im\n -14.596266922162352 - 3.4477764092792564im\n -14.072349901900408 + 5.945064076174294im\n   -7.85393485147843 - 4.134711886071569im\n -19.382929306248315 - 9.49506288623419im\n   9.516938110507798 - 19.37146717975354im\n  3.9542122497256105 - 15.36912963822462im\n  12.325742093290458 + 1.5134316695905206im\n -16.157973053188194 - 27.488246322270925im\n  3.8980118254428717 - 1.260301860242461im\n  14.230506824768984 + 11.867854578089993im\n -19.082672090492103 + 1.0178306444775296im\n\n\n\n\\({\\bf B}\\)를 설정하고 고유값분해 하기 귀찮아서 그냥 DFT해주는 패키지 사용함\n\n단계2: \\(\\hat{\\bf p}\\)를 계산\n\np̂ = abs.(x̃).^2\n\n100-element Vector{Float64}:\n   33.14209663374188\n  365.18435333408365\n  343.3532967764883\n   16.782856970223087\n 1016.6837790613963\n  154.21439356883184\n  251.84594035243464\n  465.8258516955045\n  465.85416770456163\n   78.78013503208902\n  233.37481863133453\n  224.93817023139349\n   67.24780595702228\n    ⋮\n   67.24780595702225\n  224.93817023139337\n  233.37481863133453\n   78.78013503208902\n  465.8541677045618\n  465.8258516955044\n  251.84594035243452\n  154.2143935688318\n 1016.6837790613968\n   16.782856970223072\n  343.3532967764882\n  365.1843533340838\n\n\n참고\nfft(x) 대신에 아래의 코드를 이용해도 된다.\n\nN = 100 \nV = [i*j for i in 0:(N-1) for j in 0:(N-1)] |> \n    x -> reshape(x,(N,N)) .|> \n    x -> exp(im * (2π/N) * x)\nV'x\n\n100-element Vector{ComplexF64}:\n  -5.756917285643587 + 0.0im\n -19.082672090492103 - 1.0178306444775291im\n   14.23050682476898 - 11.867854578090007im\n  3.8980118254428824 + 1.2603018602424476im\n  -16.15797305318818 + 27.48824632227092im\n   12.32574209329044 - 1.5134316695905325im\n  3.9542122497256385 + 15.369129638224617im\n    9.51693811050782 + 19.371467179753516im\n  -19.38292930624826 + 9.495062886234233im\n -7.8539348514784155 + 4.134711886071595im\n -14.072349901900417 - 5.945064076174276im\n -14.596266922162371 + 3.447776409279244im\n   5.857720447482956 + 5.7388951128385735im\n                     ⋮\n   5.857720447482839 - 5.738895112838781im\n -14.596266922162307 - 3.4477764092792627im\n  -14.07234990190023 + 5.945064076174198im\n  -7.853934851478599 - 4.134711886071242im\n -19.382929306248577 - 9.49506288623372im\n   9.516938110507212 - 19.371467179753736im\n  3.9542122497250025 - 15.369129638224603im\n  12.325742093290597 + 1.5134316695903638im\n  -16.15797305318867 - 27.488246322270854im\n  3.8980118254424903 - 1.2603018602428118im\n  14.230506824769146 + 11.867854578089572im\n   -19.0826720904922 + 1.0178306444775123im\n\n\n진짜 똑같은지 확인\n\nfft(x)\n\n100-element Vector{ComplexF64}:\n  -5.756917285643583 + 0.0im\n   -19.0826720904921 - 1.0178306444775302im\n  14.230506824768984 - 11.867854578089997im\n  3.8980118254428726 + 1.2603018602424614im\n -16.157973053188194 + 27.488246322270918im\n   12.32574209329046 - 1.5134316695905219im\n    3.95421224972561 + 15.369129638224624im\n   9.516938110507798 + 19.371467179753544im\n  -19.38292930624831 + 9.49506288623419im\n  -7.853934851478428 + 4.134711886071571im\n -14.072349901900408 - 5.945064076174294im\n -14.596266922162355 + 3.447776409279256im\n   5.857720447482927 + 5.738895112838594im\n                     ⋮\n   5.857720447482924 - 5.738895112838594im\n -14.596266922162352 - 3.4477764092792564im\n -14.072349901900408 + 5.945064076174294im\n   -7.85393485147843 - 4.134711886071569im\n -19.382929306248315 - 9.49506288623419im\n   9.516938110507798 - 19.37146717975354im\n  3.9542122497256105 - 15.36912963822462im\n  12.325742093290458 + 1.5134316695905206im\n -16.157973053188194 - 27.488246322270925im\n  3.8980118254428717 - 1.260301860242461im\n  14.230506824768984 + 11.867854578089993im\n -19.082672090492103 + 1.0178306444775296im\n\n\n\n\n전통적인 방법과 스펙트럼 방법의 비교\n시계열자료의 전통적인 분석과 spectral analysis는 대충 아래의 과정으로 비교 설명할 수 있다.\n\n\n\n\n\n\n\n\n단계\n전통적인 방법\n스펙트럴 분석\n\n\n\n\n1\n\\({\\bf x}\\)의 plot을 그려봄\n\\({\\bf x}\\)의 plot을 그려봄\n\n\n2\nSACF plot, SPACF plot 을 그려봄\nPSD plot을 그려봄\n\n\n3\nACF를 추정 (=ARMA(\\(p\\),\\(q\\))에 대응하는 파라메터를 추정)\n\\({\\bf p}\\)를 추정\n\n\n4\n추정된 파라메터를 바탕으로 여러가지 분석 수행\n추정된 파라메터를 바탕으로 여러가지 분석 수행\n\n\n\n눈여겨 볼 점은 PSD plot의 존재이다. 전통적인 시계열에서 SACF plot 과 비슷하게 스펙트럼 방법에서 시계열을 분석하기 위해 필요한 매우 중요한 시각화 이다. 간단하게 비교를 하면 아래와 같다.\nSACF plot\n\nx축: lag=0, lag=1, ….\ny축: lag에 대응하는 상관계수값\n\nPSD plot\n\nx축: \\(\\Omega=\\big\\{\\frac{k}{N}:~ \\text{for}~ k=0,\\dots, N-1\\big\\}\\), 정규화된 freq를 의미함\ny축: 주파수에 대응하는 power값\n\n전통적인 방법에 비하여 스펙트럴 분석이 가지는 장점은 위의 표에서 소개한 일반적인 분석루틴이 시계열이 아닌 그래프신호로 쉽게 확장가능 하다는 점이다12. 따라서 앞으로는 전통적인 시계열 분석방법 대신 스펙트럴 분석만을 다룰 것이다. 스펙트럴 분석의 핵심적인 부분은 \\({\\bf p}\\)를 추정하는 방법과 추정량의 점근적 성질들을 파악하는 것이다. 이 포스트에서는 \\({\\bf p}\\)를 추정하는 방법만을 다룬다."
  },
  {
    "objectID": "posts/2. Let's Study/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#그래프신호에서의-psd의-추정",
    "href": "posts/2. Let's Study/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#그래프신호에서의-psd의-추정",
    "title": "Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "그래프신호에서의 PSD의 추정",
    "text": "그래프신호에서의 PSD의 추정\n이제 그래프 신호에서 \\({\\bf p}\\)를 추정하는 방법에 대하여 살펴보자. 그래프이동변환 (Graph Shift Operator, GSO)13 \\({\\bf S}={\\bf V}{\\bf \\Lambda}{\\bf V}^H\\)에 대하여 정상인 시계열 \\({\\bf x}\\)를 고려한다. 이 신호의 그래프퓨리에 변환14은 아래와 같이 구할 수 있다.\n\\[\\tilde{\\bf x}={\\bf GFT} {\\bf x} = {\\bf V}^H{\\bf x}\\]\n여기에서 \\(\\tilde{\\bf x}\\)를 \\({\\bf x}\\)의 주파수응답(frequency representation)이라고 부른다.15 우리는 아래의 수식에서 \\({\\bf p}\\)의 값에 관심이 있다.\n\\[{\\bf C}_{\\bf x}={\\bf V} \\text{diag}({\\bf p}){\\bf V}^H\\]\n여기에서 \\({\\bf p}\\)를 PSD (power spectrum density) 라고 한다. \\({\\bf p}\\)가 포함된 표현식은 위의 수식 이외에도 2개가 더 있다. 이를 모두 요약하면 아래와 같다16\n\n\\({\\bf C}_{\\bf x}={\\bf V} \\text{diag}({\\bf p}){\\bf V}^H\\)17\n\\({\\bf p}=\\mathbb{E}\\left[|{\\bf V}^H{\\bf x}|^2\\right]\\)\n\\({\\bf c}_{\\bf x} = \\sum_{i=1}^{N}p_i \\text{vec}({\\bf v}_i{\\bf v}_i^H) = {\\bf G}_{np} {\\bf p}\\)\n\n위의 표현중 3.에서 \\({\\bf c}_{\\bf x}\\)은 \\({\\bf C}_x\\)를 벡터화한 것이며 \\({\\bf G}_{np}\\)는 \\({\\bf V}^\\ast\\) 와 \\({\\bf V}\\)를 열별-크로네커곱 (column-wise Kronecker product) 이다. 이때 \\({\\bf G}_{np}\\)의 정의가 조금 생소하니 한번 계산하여 보자.\n(예제) 아래와 같은 GSO \\({\\bf B}\\)를 고려하자.\n\nB= [0 1 0 0 \n    0 0 1 0 \n    0 0 0 1 \n    1 0 0 0]\n\n4×4 Matrix{Int64}:\n 0  1  0  0\n 0  0  1  0\n 0  0  0  1\n 1  0  0  0\n\n\n이러한 GSO에 대하여 \\({\\bf G}_{np}\\)는 아래와 같이 구할 수 있다.\n(1) \\({\\bf V}\\)를 정의\n\nV = [i*j for i in 0:3 for j in 0:3] |> \n    x -> reshape(x,(4,4)) .|> \n    x -> exp(im * (2π/4) * x) \n\n4×4 Matrix{ComplexF64}:\n 1.0+0.0im           1.0+0.0im          …           1.0+0.0im\n 1.0+0.0im   6.12323e-17+1.0im             -1.83697e-16-1.0im\n 1.0+0.0im          -1.0+1.22465e-16im             -1.0+3.67394e-16im\n 1.0+0.0im  -1.83697e-16-1.0im              5.51091e-16+1.0im\n\n\n(2) \\({\\bf G}_{np}={\\bf V}^{\\ast} \\odot {\\bf V}\\), 여기에서 \\(\\odot\\)은 열별-크로네커곱을 의미한다.\n\n# columnwise_kron은 위에서 정의한적 있음~\nGₙₚ = columnwise_kron(conj(V),V)\n\n16×4 Matrix{ComplexF64}:\n 1.0+0.0im           1.0+0.0im          …           1.0+0.0im\n 1.0+0.0im   6.12323e-17+1.0im             -1.83697e-16-1.0im\n 1.0+0.0im          -1.0+1.22465e-16im             -1.0+3.67394e-16im\n 1.0+0.0im  -1.83697e-16-1.0im              5.51091e-16+1.0im\n 1.0+0.0im   6.12323e-17-1.0im             -1.83697e-16+1.0im\n 1.0+0.0im           1.0+0.0im          …           1.0+0.0im\n 1.0+0.0im   6.12323e-17+1.0im             -1.83697e-16-1.0im\n 1.0+0.0im          -1.0+1.22465e-16im             -1.0+3.67394e-16im\n 1.0+0.0im          -1.0-1.22465e-16im             -1.0-3.67394e-16im\n 1.0+0.0im   6.12323e-17-1.0im             -1.83697e-16+1.0im\n 1.0+0.0im           1.0+0.0im          …           1.0+0.0im\n 1.0+0.0im   6.12323e-17+1.0im             -1.83697e-16-1.0im\n 1.0+0.0im  -1.83697e-16+1.0im              5.51091e-16-1.0im\n 1.0+0.0im          -1.0-1.22465e-16im             -1.0-3.67394e-16im\n 1.0+0.0im   6.12323e-17-1.0im             -1.83697e-16+1.0im\n 1.0+0.0im           1.0+0.0im          …           1.0+0.0im\n\n\n위에서 언급한 표현식 1,2,3 을 이용하면 \\({\\bf p}\\)를 추정하는 세 가지 방법을 각각 정의할 수 있다. 하나씩 살펴보자.\n\n1. \\({\\bf C}_{\\bf x}={\\bf V} \\text{diag}({\\bf p}){\\bf V}^H\\)\n확률과정 \\({\\bf x}\\)에서 \\(R\\)개의 realization \\(\\{{\\bf x}_1 \\dots {\\bf x}_R\\}\\) 을 관측하였다고 하자. 수식 \\({\\bf C}_{\\bf x}={\\bf V} \\text{diag}({\\bf p}){\\bf V}^H\\)를 적당히 변형하면 아래를 얻을 수 있다.\n\\[{\\bf p}=\\text{diag}\\big({\\bf V}^H {\\bf C}_{\\bf x}{\\bf V} \\big)\\]\n여기에서\n\\[{\\bf C}_{\\bf x}=\\mathbb{E}[{\\bf x}{\\bf x}^H]\\approx \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_t{\\bf x}_r^H\\]\n이므로 이 수식에 근거하여 \\({\\bf p}\\)을 추정한다면 아래와 같이 할 수 있다.\n\\[\\hat{\\bf p}_{cg}:= \\text{diag}\\left({\\bf V}^H \\hat{\\bf C}_{\\bf x}{\\bf V} \\right):=\\text{diag}\\left[{\\bf V}^H\\big[ \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_r{\\bf x}_r^H\\big]{\\bf V} \\right].\\]\n만약에 확률과정 \\({\\bf x}\\)에서 관측한 시계열이 \\({\\bf x}_r\\) 하나라면18, 즉 \\(R=1\\) 이라면 단순히 아래와 같이 쓸 수 있다.\n\\[\\hat{\\bf p}_{cg}:= \\text{diag}\\left({\\bf V}^H \\hat{\\bf C}_{\\bf x}{\\bf V} \\right):=\\text{diag}\\left[{\\bf V}^H{\\bf x}_r{\\bf x}_r^H{\\bf V} \\right].\\]\n\n주의: 여기에서 \\({\\bf V}^H {\\bf C}_{\\bf x}{\\bf V}\\) 는 항상 대각행렬이지만 \\({\\bf V}^H \\hat{\\bf C}_{\\bf x}{\\bf V}\\) 은 대각행렬이 아닐수도 있음을 유의하자. 즉 이론적인 모수는 대각행렬이지만 sample version은 대각행렬이 아닐 수 있다. 대각선이 아닌 원소는 버리면 된다.)\n\n\n아이디어: 혹시 대각선이 아닌 원소들을 이용하여 오차항 \\(\\epsilon_t\\)의 분산을 추정할 수도 있지 않을까? 이미 연구가 있겠지?\n\n(예제)\n\nN = 100 \nV = [i*j for i in 0:(N-1) for j in 0:(N-1)] |> \n    x -> reshape(x,(N,N)) .|> \n    x -> exp(im * (2π/N) * x)\n\n100×100 Matrix{ComplexF64}:\n 1.0+0.0im       1.0+0.0im        …       1.0+0.0im\n 1.0+0.0im  0.998027+0.0627905im     0.998027-0.0627905im\n 1.0+0.0im  0.992115+0.125333im      0.992115-0.125333im\n 1.0+0.0im  0.982287+0.187381im      0.982287-0.187381im\n 1.0+0.0im  0.968583+0.24869im       0.968583-0.24869im\n 1.0+0.0im  0.951057+0.309017im   …  0.951057-0.309017im\n 1.0+0.0im  0.929776+0.368125im      0.929776-0.368125im\n 1.0+0.0im  0.904827+0.425779im      0.904827-0.425779im\n 1.0+0.0im  0.876307+0.481754im      0.876307-0.481754im\n 1.0+0.0im  0.844328+0.535827im      0.844328-0.535827im\n 1.0+0.0im  0.809017+0.587785im   …  0.809017-0.587785im\n 1.0+0.0im  0.770513+0.637424im      0.770513-0.637424im\n 1.0+0.0im  0.728969+0.684547im      0.728969-0.684547im\n    ⋮                             ⋱  \n 1.0+0.0im  0.728969-0.684547im      0.728969+0.684547im\n 1.0+0.0im  0.770513-0.637424im      0.770513+0.637424im\n 1.0+0.0im  0.809017-0.587785im   …  0.809017+0.587785im\n 1.0+0.0im  0.844328-0.535827im      0.844328+0.535827im\n 1.0+0.0im  0.876307-0.481754im      0.876307+0.481754im\n 1.0+0.0im  0.904827-0.425779im      0.904827+0.425779im\n 1.0+0.0im  0.929776-0.368125im      0.929776+0.368125im\n 1.0+0.0im  0.951057-0.309017im   …  0.951057+0.309017im\n 1.0+0.0im  0.968583-0.24869im       0.968583+0.24869im\n 1.0+0.0im  0.982287-0.187381im      0.982287+0.187381im\n 1.0+0.0im  0.992115-0.125333im      0.992115+0.125333im\n 1.0+0.0im  0.998027-0.0627905im     0.998027+0.0627905im\n\n\n\np̂ = diag(V' * (x*x') * V)\n\n100-element Vector{ComplexF64}:\n 33.142096633741986 + 0.0im\n 365.18435333408354 + 1.5376069362644531e-13im\n  343.3532967764883 + 6.904176529646917e-14im\n 16.782856970223083 - 3.5538396658301444e-14im\n 1016.6837790613963 + 5.475049904926759e-15im\n 154.21439356883144 + 6.4512443306088e-14im\n  251.8459403524346 + 2.1316282072803006e-14im\n 465.82585169550384 + 1.816929057526117e-13im\n 465.85416770456044 + 4.1584439183295984e-14im\n    78.780135032089 + 1.3472456770553478e-14im\n 233.37481863133462 + 6.315728724701355e-14im\n 224.93817023139385 - 3.472109560086835e-14im\n  67.24780595702241 + 7.105427357601002e-14im\n                    ⋮\n   67.2478059570233 + 6.384723798533952e-14im\n 224.93817023139195 + 1.9727655769954595e-14im\n 233.37481863132837 - 2.1872689567834747e-14im\n    78.780135032089 + 1.917599080404094e-14im\n 465.85416770456294 + 4.808950231511622e-14im\n 465.82585169550094 - 4.890486289860305e-14im\n  251.8459403524291 + 2.0146681724568905e-14im\n  154.2143935688347 - 1.0948596967617507e-13im\n 1016.6837790614081 + 1.2114814701286432e-13im\n  16.78285697022108 + 2.376159104534641e-14im\n 343.35329677648286 + 1.1310381241837407e-14im\n 365.18435333408746 + 4.574214786667376e-14im\n\n\n\n\n2. \\({\\bf p}=\\mathbb{E}\\left[|{\\bf V}^H{\\bf x}|^2\\right]\\)\n확률과정 \\({\\bf x}\\)에서 \\(R\\)개의 realization \\(\\{{\\bf x}_1 \\dots {\\bf x}_R\\}\\) 을 관측하였다고 하자. 아래의 수식을 관찰하자.\n\\[{\\bf p}=\\mathbb{E}\\left[|{\\bf V}^H{\\bf x}|^2\\right]\\approx \\frac{1}{R}\\sum_{r=1}^{R} |{\\bf V}^H {\\bf x}_r|^2 \\]\n따라서 \\(\\frac{1}{R}\\sum_{r=1}^{R} |{\\bf V}^H {\\bf x}_r|^2\\) 를 PSD \\({\\bf p}\\)에 대한 추정량이라고 생각할 수 있다. 이러한 추정량을 기호로 \\(\\hat{\\bf p}_{pg}\\)라고 정의하고 periodogram이라고 부른다. 즉\n\\[\\hat{\\bf p}_{pg}=\\frac{1}{R}\\sum_{r=1}^{R} |{\\bf V}^H {\\bf x}_r|^2 \\]\n만약에 확률과정 \\({\\bf x}\\)에서 관측한 시계열이 \\({\\bf x}_r\\) 하나라면, 즉 \\(R=1\\) 이라면 단순히 아래와 같이 쓸 수 있다.\n\\[\\hat{\\bf p}_{pg}=|{\\bf V}^H {\\bf x}_r|^2 \\]\n즉 이 경우 \\(\\hat{\\bf p}_{pg}\\)는 단순히 관측시계열 \\({\\bf x}_r\\)의 그래프 퓨리에 변환 \\(\\tilde{\\bf x}={\\bf V}^H{\\bf x}_r\\) 결과에 절대값을 취하고 제곱한 것과 같다.\n(예제)\n스펙트럼방법챕터 예제2에서 이미 보여준 적 있다. 주어진 시계열 \\({\\bf x}\\)에 대하여 \\(\\hat{\\bf p}_{pg}\\)를 구하는 방법을 요약하면 아래와 같다.\n\nx̃ = fft(x) # 단계1: GFT, 이 신호는 시계열이라서 GFT대신에 DFT를 써도 된다.\np̂ = abs.(x̃).^2 # 단계2: hat p\n\n100-element Vector{Float64}:\n   33.14209663374188\n  365.18435333408365\n  343.3532967764883\n   16.782856970223087\n 1016.6837790613963\n  154.21439356883184\n  251.84594035243464\n  465.8258516955045\n  465.85416770456163\n   78.78013503208902\n  233.37481863133453\n  224.93817023139349\n   67.24780595702228\n    ⋮\n   67.24780595702225\n  224.93817023139337\n  233.37481863133453\n   78.78013503208902\n  465.8541677045618\n  465.8258516955044\n  251.84594035243452\n  154.2143935688318\n 1016.6837790613968\n   16.782856970223072\n  343.3532967764882\n  365.1843533340838\n\n\n\n\n3. \\({\\bf c}_{\\bf x} = {\\bf G}_{np} {\\bf p}\\)\n확률과정 \\({\\bf x}\\)에서 \\(R\\)개의 realization \\(\\{{\\bf x}_1 \\dots {\\bf x}_R\\}\\) 을 관측하였다고 하자. 아래의 수식을 관찰하자.\n\\[{\\bf C}_{\\bf x} = {\\bf V} \\text{diag}({\\bf p}) {\\bf V}^H\\]\n이 수식으로부터 아래를 얻을 수 있다.\n\\[{\\bf c}_{\\bf x} = \\sum_{i=1}^{N}p_i \\text{vec}({\\bf v}_i{\\bf v}_i^H) = {\\bf G}_{np} {\\bf p}\\]\n여기에서 \\({\\bf c}_{\\bf x}\\) 대신에 \\(\\hat{\\bf c}_{\\bf x}\\) 를 대입하면 아래와 같이 생각할 수 있다.\n\\[\\hat{\\bf c}_{\\bf x} \\approx  {\\bf G}_{np} {\\bf p}\\]\n이 문제는 아래와 같은 회귀모형으로 생각할 수 있다.\n\n\n\n\n\n\n\n\n\n회귀모형\n우리의 문제\n\n\n\n\n모형\n\\({\\bf y} \\approx {\\bf X}{\\boldsymbol \\beta}\\)\n\\(\\hat{\\bf c}_{\\bf x} \\approx {\\bf G}_{np}{\\bf p}\\)\n\n\n설명변수\n\\({\\bf X}\\)19\n\\({\\bf G}_{np}\\)20\n\n\n반응변수\n\\({\\bf y}\\)21\n\\(\\hat{\\bf c}_{\\bf x}\\)22\n\n\n추정하고 싶은 파라메터\n\\({\\boldsymbol \\beta}\\)23\n\\(\\hat{\\bf p}\\)24\n\n\n오차항\n대부분 정규분포를 가정\n??? 모르겠는데??\n\n\n\n회귀분석에서 아래의 수식이 익숙하다면\n\\[\n\\hat{\\boldsymbol \\beta}_{ls} = \\underset{\\boldsymbol \\beta}{\\operatorname{argmin}} \\|{\\bf y}-{\\bf X}{\\boldsymbol \\beta}\\|_2^2=({\\bf X}^T{\\bf X})^{-1}{\\bf X}^T{\\bf y}.\n\\]\n\\({\\bf p}\\)를 추정하기 위한 아래의 수식도 쉽게 이해할 수 있다. (의문: 그런데 왜 MSE를 손실함수로 쓰고 있는 거야? 오차항이 설마 정규분포?)\n\\[\n\\hat{\\bf p}_{ls} = \\underset{\\bf p}{\\operatorname{argmin}} \\|\\hat{\\bf c}_{\\bf x}-{\\bf G}_{np}{\\bf p}\\|_2^2=({\\bf G}_{np}^H{\\bf G}_{np})^{-1}{\\bf G}_{np}^H\\hat{\\bf c}_{\\bf x}.\n\\]\n(예제)\n(1) \\({\\bf V}\\)를 정의\n\nN = 100 \nV = [i*j for i in 0:(N-1) for j in 0:(N-1)] |> \n    x -> reshape(x,(N,N)) .|> \n    x -> exp(im * (2π/N) * x)\n\n100×100 Matrix{ComplexF64}:\n 1.0+0.0im       1.0+0.0im        …       1.0+0.0im\n 1.0+0.0im  0.998027+0.0627905im     0.998027-0.0627905im\n 1.0+0.0im  0.992115+0.125333im      0.992115-0.125333im\n 1.0+0.0im  0.982287+0.187381im      0.982287-0.187381im\n 1.0+0.0im  0.968583+0.24869im       0.968583-0.24869im\n 1.0+0.0im  0.951057+0.309017im   …  0.951057-0.309017im\n 1.0+0.0im  0.929776+0.368125im      0.929776-0.368125im\n 1.0+0.0im  0.904827+0.425779im      0.904827-0.425779im\n 1.0+0.0im  0.876307+0.481754im      0.876307-0.481754im\n 1.0+0.0im  0.844328+0.535827im      0.844328-0.535827im\n 1.0+0.0im  0.809017+0.587785im   …  0.809017-0.587785im\n 1.0+0.0im  0.770513+0.637424im      0.770513-0.637424im\n 1.0+0.0im  0.728969+0.684547im      0.728969-0.684547im\n    ⋮                             ⋱  \n 1.0+0.0im  0.728969-0.684547im      0.728969+0.684547im\n 1.0+0.0im  0.770513-0.637424im      0.770513+0.637424im\n 1.0+0.0im  0.809017-0.587785im   …  0.809017+0.587785im\n 1.0+0.0im  0.844328-0.535827im      0.844328+0.535827im\n 1.0+0.0im  0.876307-0.481754im      0.876307+0.481754im\n 1.0+0.0im  0.904827-0.425779im      0.904827+0.425779im\n 1.0+0.0im  0.929776-0.368125im      0.929776+0.368125im\n 1.0+0.0im  0.951057-0.309017im   …  0.951057+0.309017im\n 1.0+0.0im  0.968583-0.24869im       0.968583+0.24869im\n 1.0+0.0im  0.982287-0.187381im      0.982287+0.187381im\n 1.0+0.0im  0.992115-0.125333im      0.992115+0.125333im\n 1.0+0.0im  0.998027-0.0627905im     0.998027+0.0627905im\n\n\n(2) \\({\\bf G}_{np}={\\bf V}^{\\ast} \\odot {\\bf V}\\), 여기에서 \\(\\odot\\)은 열별-크로네커곱을 의미한다.\n\n# columnwise_kron은 위에서 정의한적 있음~\nGₙₚ = columnwise_kron(conj(V),V)\n\n10000×100 Matrix{ComplexF64}:\n 1.0+0.0im       1.0+0.0im        …       1.0+0.0im\n 1.0+0.0im  0.998027+0.0627905im     0.998027-0.0627905im\n 1.0+0.0im  0.992115+0.125333im      0.992115-0.125333im\n 1.0+0.0im  0.982287+0.187381im      0.982287-0.187381im\n 1.0+0.0im  0.968583+0.24869im       0.968583-0.24869im\n 1.0+0.0im  0.951057+0.309017im   …  0.951057-0.309017im\n 1.0+0.0im  0.929776+0.368125im      0.929776-0.368125im\n 1.0+0.0im  0.904827+0.425779im      0.904827-0.425779im\n 1.0+0.0im  0.876307+0.481754im      0.876307-0.481754im\n 1.0+0.0im  0.844328+0.535827im      0.844328-0.535827im\n 1.0+0.0im  0.809017+0.587785im   …  0.809017-0.587785im\n 1.0+0.0im  0.770513+0.637424im      0.770513-0.637424im\n 1.0+0.0im  0.728969+0.684547im      0.728969-0.684547im\n    ⋮                             ⋱  \n 1.0+0.0im  0.770513-0.637424im      0.770513+0.637424im\n 1.0+0.0im  0.809017-0.587785im      0.809017+0.587785im\n 1.0+0.0im  0.844328-0.535827im   …  0.844328+0.535827im\n 1.0+0.0im  0.876307-0.481754im      0.876307+0.481754im\n 1.0+0.0im  0.904827-0.425779im      0.904827+0.425779im\n 1.0+0.0im  0.929776-0.368125im      0.929776+0.368125im\n 1.0+0.0im  0.951057-0.309017im      0.951057+0.309017im\n 1.0+0.0im  0.968583-0.24869im    …  0.968583+0.24869im\n 1.0+0.0im  0.982287-0.187381im      0.982287+0.187381im\n 1.0+0.0im  0.992115-0.125333im      0.992115+0.125333im\n 1.0+0.0im  0.998027-0.0627905im     0.998027+0.0627905im\n 1.0+0.0im       1.0+0.0im                1.0+0.0im\n\n\n(3) \\(\\hat{\\bf p}_{ls}=({\\bf G}_{np}^H{\\bf G}_{np})^{-1}{\\bf G}_{np}^H\\hat{\\bf c}_{\\bf x}\\)\n\nĉₓ = vec(x*x')\np̂ = inv(Gₙₚ' * Gₙₚ) * Gₙₚ' * ĉₓ \n\n100-element Vector{ComplexF64}:\n  0.003314209663374193 - 2.7356277964988863e-19im\n   0.03651843533340838 - 4.01518191768058e-18im\n   0.03433532967764885 + 2.515448157755484e-17im\n 0.0016782856970223292 - 1.0070028487673847e-17im\n   0.10166837790613971 + 3.1129277935880596e-18im\n  0.015421439356883134 + 9.403422807142065e-18im\n  0.025184594035243472 - 3.993782799800785e-18im\n   0.04658258516955039 - 1.850761436988587e-18im\n   0.04658541677045607 + 1.1559103895961936e-17im\n  0.007878013503208905 + 3.559698092088507e-18im\n  0.023337481863133468 + 2.6204945155857973e-18im\n   0.02249381702313939 + 5.304406111488559e-18im\n  0.006724780595702225 - 1.655564138463681e-17im\n                       ⋮\n  0.006724780595702329 + 1.8121162053534517e-18im\n  0.022493817023139205 - 1.0461976779111972e-17im\n   0.02333748186313285 - 6.792203007975684e-18im\n  0.007878013503208907 - 2.3575339315335667e-18im\n  0.046585416770456294 + 1.5392042695643853e-17im\n  0.046582585169550106 - 1.123245521985718e-17im\n  0.025184594035242928 + 1.1628578774983873e-18im\n  0.015421439356883466 + 5.864828990948797e-18im\n   0.10166837790614085 + 2.2712943512935246e-17im\n 0.0016782856970221013 + 4.829637376114682e-18im\n   0.03433532967764831 + 3.3208196889839756e-19im\n  0.036518435333408754 + 1.3795822112205515e-17im\n\n\n\n?? 뭔가 스케일이 안맞음\n\n\nN^2 * p̂\n\n100-element Vector{ComplexF64}:\n  33.14209663374193 - 2.7356277964988864e-15im\n 365.18435333408377 - 4.0151819176805797e-14im\n  343.3532967764885 + 2.515448157755484e-13im\n 16.782856970223293 - 1.0070028487673847e-13im\n 1016.6837790613971 + 3.1129277935880596e-14im\n 154.21439356883135 + 9.403422807142065e-14im\n 251.84594035243472 - 3.9937827998007846e-14im\n  465.8258516955039 - 1.850761436988587e-14im\n  465.8541677045607 + 1.1559103895961937e-13im\n  78.78013503208905 + 3.559698092088507e-14im\n 233.37481863133468 + 2.6204945155857973e-14im\n 224.93817023139388 + 5.304406111488559e-14im\n  67.24780595702225 - 1.655564138463681e-13im\n                    ⋮\n  67.24780595702329 + 1.8121162053534517e-14im\n 224.93817023139206 - 1.0461976779111972e-13im\n  233.3748186313285 - 6.792203007975684e-14im\n  78.78013503208906 - 2.3575339315335666e-14im\n 465.85416770456294 + 1.5392042695643854e-13im\n 465.82585169550106 - 1.123245521985718e-13im\n 251.84594035242927 + 1.1628578774983874e-14im\n 154.21439356883465 + 5.864828990948797e-14im\n 1016.6837790614085 + 2.2712943512935246e-13im\n  16.78285697022101 + 4.8296373761146824e-14im\n  343.3532967764831 + 3.3208196889839758e-15im\n  365.1843533340875 + 1.3795822112205514e-13im\n\n\n\n\\(N^2\\)를 곱해주니까 아까부터 구하던 값이 그대로 잘 나옴. (\\({\\bf DFT}\\) 혹은 \\({\\bf GFT}\\)를 정의할때 \\(\\frac{1}{\\sqrt N}\\)으로 스케일링 하느냐 마느냐 차이때문에 생기는 현상임)"
  },
  {
    "objectID": "posts/2. Let's Study/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#의문점",
    "href": "posts/2. Let's Study/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#의문점",
    "title": "Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "의문점",
    "text": "의문점\n아래의 그림을 살펴보자.\n\n\n\n그림12.3(교재에서 긁어온 그림): Power spectral density estimation. All estimators are based on the same random process defined on the Karate club network (Zachary 1977). (A) Periodogram estimation with different numbers of observations. (B) Windowed average periodogram from a single realization and a different number of windows. (C) Windowed average periodogram for four windows and a varying number of realizations. (D) Parametric MA estimation for 1 and 10 realizations.\n\n\n이 그림은 다양한 방법으로 true PSD \\({\\bf p}\\)를 추정한 결과를 나타내는 PSD plot 이다25. 우리가 적용한 방법은 (A)에서 \\(R=1\\)일 경우이다. 보는것 처럼 true PSD 를 놀라울 정도로 제대로 추정하지 못한다26. 만약에 우리가 모형에서 하나의 시계열이 아니라 1000개의 정도의 시계열을 관측하였다면 좀 더 합리적으로 추정할 수 있다. 그런데 사실 하나의 모형에서 1000개씩이나 되는 시계열을 관측하는 일은 현실적으로 불가능하다27 따라서 우리는 비교적 적은 \\(R\\)에서 합리적인 PSD의 추정치를 이끌어내야 한다. 그림 (B),(C)는 상대적으로 적은 \\(R\\)에 대해 \\({\\bf p}\\)를 추정하는 windowed periodogram 을 이용하여 PSD를 추정한 결과이다. (C)를 살펴보면 \\(R=1\\) 일경우 \\({\\bf p}\\)를 추정한 값들이 나와있는데 (A)와 비교하면 꽤 합리적으로 보인다.\n문제는 (A)-(C)에서 제안된 방법 모두가 (D)에 제시된 전통적인 방법에 비하여 퍼포먼스가 떨어진다는 것이다. (D)는 parametric 모형을 사용한 결과이다. 파라메트릭 방법이므로 특정 모델을 한정하고 거기에 대응하는 한두개의 모수만 추정하면 되므로 추정이 잘 된다.28 반면 (A)-(C)의 경우 한 두개의 파라메터가 아니라 \\({\\bf p}\\)의 모든 원소를 추정해야하므로 추정할 파라메터가 데이터의 수 \\(N\\)과 같다29. 따라서 추정치의 분산이 크다. 사실 이것은 파라메트릭 방법과 세미파라메트릭 방법이라는 구조적인 차이때문에 어쩔 수 없는 것 같다. 그래도 세미파라메트릭 방법은 머리아프게 모델링을 할 필요가 없고30 내가 적합한 모델이 맞는지 확인할 필요도 없다31는 장점이 있다.\n아래는 나름 PSD를 추정하는 신기술인 것 같다.\n\n\n\n그림12.4(교재에서 긁어온 그림): PSD estimation from a subset of nodes. Estimators are based on a random process defined on the Karate club network (Zachary 1977). (A) Graph sampling for nonparametric PSD estimation. Here, 20 out of 34 nodes are observed. The sampled nodes are highlighted by the circles around the nodes. (B) Nonparametric PSD estimation based on observations from 20 nodes and 100 data snapshots. (C) Graph sampling for parametric MA PSD estimation. Here, 4 out of 34 nodes are observed. (D) Parametric MA PSD estimation based on observations from 4 nodes and 100 data snapshots.\n\n\n그래프신호의 sub-sampling을 이용하는 것 같은데 교재의 뒤쪽에 서술되어있다. \\(R=100\\)임을 고려하여도 퍼포먼스가 좋은 편인듯 하다32."
  },
  {
    "objectID": "posts/3. Researches/STGCN/2022-12-30-STGCN-Toy Example.html",
    "href": "posts/3. Researches/STGCN/2022-12-30-STGCN-Toy Example.html",
    "title": "Toy Example",
    "section": "",
    "text": "import networkx as nx\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport torch"
  },
  {
    "objectID": "posts/3. Researches/STGCN/2022-12-30-STGCN-Toy Example.html#data",
    "href": "posts/3. Researches/STGCN/2022-12-30-STGCN-Toy Example.html#data",
    "title": "Toy Example",
    "section": "data",
    "text": "data\n\nfrom torch_geometric_temporal.dataset import WikiMathsDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = WikiMathsDatasetLoader()\n\ndataset = loader.get_dataset(lags=14)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)"
  },
  {
    "objectID": "posts/3. Researches/STGCN/2022-12-30-STGCN-Toy Example.html#recurrentgcn",
    "href": "posts/3. Researches/STGCN/2022-12-30-STGCN-Toy Example.html#recurrentgcn",
    "title": "Toy Example",
    "section": "RecurrentGCN",
    "text": "RecurrentGCN\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h"
  },
  {
    "objectID": "posts/3. Researches/STGCN/2022-12-30-STGCN-Toy Example.html#learn",
    "href": "posts/3. Researches/STGCN/2022-12-30-STGCN-Toy Example.html#learn",
    "title": "Toy Example",
    "section": "Learn",
    "text": "Learn\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features=14, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [03:48<00:00,  4.57s/it]"
  },
  {
    "objectID": "posts/3. Researches/STGCN/2022-12-30-STGCN-Toy Example.html#예제의-차원-조사",
    "href": "posts/3. Researches/STGCN/2022-12-30-STGCN-Toy Example.html#예제의-차원-조사",
    "title": "Toy Example",
    "section": "예제의 차원 조사",
    "text": "예제의 차원 조사\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([1068, 14])\n\n\n\n1068: number of nodes // 1068개의 노드가 있음\n14: number of features // 하나의 노드에 맵핑된 차원의수\n\n\n_edge_index.shape\n\ntorch.Size([2, 27079])\n\n\n\n_edge_attr.shape\n\ntorch.Size([27079])\n\n\n\n_y.shape\n\ntorch.Size([1068])\n\n\n\n1068: number of nodes\n\n\n_x.shape\n\ntorch.Size([1068, 14])"
  },
  {
    "objectID": "3_researches_hst.html",
    "href": "3_researches_hst.html",
    "title": "HST",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJan 24, 2023\n\n\nCommunityDetection\n\n\n신록예찬\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "4_reviews.html",
    "href": "4_reviews.html",
    "title": "Reviews",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nDec 23, 2022\n\n\nEbayesThresh: R Programs for Empirical Bayes Thresholding\n\n\n신록예찬\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "신록예찬's Blog",
    "section": "",
    "text": "About this blog\nThis blog was created for my personal research, study and lecture preparation. Therefore, the contents of the blog can be thought of as my practice notes. As a result, sometimes the content of a post may be left unstructured or unfinished. The blog is named after my favorite essay ‘신록예찬’, which is also a nickname I use informally. You can check the written article in the sidebar on the left. It is a great honor for me if these posts can help others to learn and research.\n\nSome urls that help me\nfirst bunch\n\nhttps://openai.com/blog/chatgpt/\nhttps://matplotlib.org/stable/gallery/index.html\nhttps://jupyterlab.readthedocs.io/en/stable/index.html\nhttps://pandas.pydata.org/docs/user_guide/index.html#user-guide\nhttps://docs.julialang.org/en/v1/\nhttps://keras.io/examples/\nhttps://docs.juliaplots.org/stable/\nhttp://personal.psu.edu/drh20/asymp/fall2006/lectures/\nhttps://www.pytorchlightning.ai/\nhttps://plotly.com/graphing-libraries/\nhttps://quarto.org/\n\nsecond bunch\n\nhttps://editor.codecogs.com/\nhttps://www.tablesgenerator.com/\nhttps://github.com/PacktPublishing/Deep-Learning-with-PyTorch-Lightning\nhttps://github.com/rusty1s/pytorch_geometric\nhttps://www.rayshader.com/reference/plot_gg.html\nhttps://github.com/southkorea\nhttps://zvon.org/\nhttps://rpy2.github.io/doc/v3.1.x/html/index.html\nhttps://pywavelets.readthedocs.io/en/latest/ref/wavelets.html\nhttps://pygsp.readthedocs.io/en/stable/#\nhttps://tikz.net/neural_networks/\nhttps://plotly.com/python/plotly-express/\nhttps://docs.fast.ai/\nhttps://course.fast.ai/#\nhttps://github.com/fastai/fastai/tree/master/dev_nbs/course\n\nlectures notes\n\nhttp://personal.psu.edu/drh20/asymp/fall2006/lectures/\n\nblogs run by acquaintance\n\nhttps://kimha02.github.io/ham/\nhttps://simjaein.github.io/ji1598/\nhttps://seoyeonc.github.io/md/\nhttps://seoyeonc.github.io/blog/\nhttps://seoyeonc.github.io/ms/ *suspension\nhttps://seoyeonc.github.io/chch/ *suspension"
  },
  {
    "objectID": "1_codes_python.html",
    "href": "1_codes_python.html",
    "title": "Python",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nApr 5, 2000\n\n\nNumpy\n\n\n신록예찬\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "3_researches_stgcn.html",
    "href": "3_researches_stgcn.html",
    "title": "STGCN",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nDec 30, 2022\n\n\nToy Example\n\n\n신록예찬\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "2_study_cgsp.html",
    "href": "2_study_cgsp.html",
    "title": "BOOK: CGSP",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJan 15, 2023\n\n\nChap 12.4: Node Subsampling for PSD Estimation\n\n\n신록예찬\n\n\n\n\nDec 27, 2022\n\n\nChap 12.2 ~ 3: Power Spectral Density and its Estimators\n\n\n신록예찬\n\n\n\n\nDec 26, 2022\n\n\nChap 12.2: Weakly Stationary Graph Processes\n\n\n신록예찬\n\n\n\n\nDec 24, 2022\n\n\nChap 8.3: Discrete Fourier Transform\n\n\n신록예찬\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "2_study_essays.html",
    "href": "2_study_essays.html",
    "title": "Essays",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 20, 2023\n\n\n추정\n\n\n신록예찬\n\n\n\n\nJan 17, 2023\n\n\n1st ST-GCN Example dividing train and test\n\n\nSEOYEON CHOI\n\n\n\n\nJan 12, 2023\n\n\n토폴로지\n\n\n신록예찬\n\n\n\n\nJan 11, 2023\n\n\n부등식\n\n\n신록예찬\n\n\n\n\nJan 7, 2023\n\n\n해석학\n\n\n신록예찬\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "5_notes.html",
    "href": "5_notes.html",
    "title": "Notes",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJan 8, 2000\n\n\n깃(Git)\n\n\n신록예찬\n\n\n\n\nJan 7, 2000\n\n\n줄리아 설치 및 실행\n\n\n신록예찬\n\n\n\n\nJan 6, 2000\n\n\n주피터랩: 설정 및 몇가지 팁\n\n\n신록예찬\n\n\n\n\nJan 5, 2000\n\n\n주피터랩(터미널)\n\n\n신록예찬\n\n\n\n\nJan 4, 2000\n\n\n우분투\n\n\n신록예찬\n\n\n\n\nJan 1, 2000\n\n\n우분투 포맷 및 개발용 서버 셋팅\n\n\n신록예찬\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "1_codes_pl.html",
    "href": "1_codes_pl.html",
    "title": "PyTorch Lightning",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nSep 21, 2022\n\n\nLesson1: 단순선형회귀\n\n\n신록예찬\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html",
    "href": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "",
    "text": "Try to divide train and test(GNAR fivenet)"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#st-gcn",
    "href": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#st-gcn",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "1) ST-GCN",
    "text": "1) ST-GCN\n\nmean_f_fiveVTS_train = torch.tensor(fiveVTS_train_mean).reshape(160,5,1).float()\n\n/home/cgb2/anaconda3/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \"\"\"Entry point for launching an IPython kernel.\n\n\n\nmean_X_fiveVTS = mean_f_fiveVTS_train[:159,:,:]\nmean_y_fiveVTS = mean_f_fiveVTS_train[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(mean_X_fiveVTS,mean_y_fiveVTS)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:24<00:00,  2.02it/s]\n\n\n\nmean_fhat_fiveVTS = torch.stack([model(xt, edge_index, edge_attr) for xt in mean_X_fiveVTS]).detach().numpy()\n\n\nfiveVTS_test.float()\n\ntensor([[-1.3798,  0.1459,  0.9158,  1.4848, -3.5004],\n        [-0.6878, -0.9167,  1.2704,  1.0167, -0.3307],\n        [ 0.7200,  2.8028,  1.6711, -0.6230,  0.5819],\n        [ 0.7209, -0.4410,  1.3555,  0.1693,  1.3739],\n        [ 1.2559,  1.2374, -1.2614,  1.1569,  1.3480],\n        [ 1.7057, -2.0821,  1.1786,  0.0351,  2.3181],\n        [-1.2413, -1.8109,  0.4296, -1.6056,  1.8224],\n        [-1.7336, -1.5126, -0.6606, -0.5410, -0.5155],\n        [ 0.7925,  1.1118, -0.0874, -0.4713, -1.4689],\n        [-1.3085, -0.8209, -1.0603, -0.8488,  0.6158],\n        [-0.1514, -1.7553, -2.1784, -1.1333, -0.7315],\n        [-1.4409, -1.7015,  0.0866, -0.5748, -0.9676],\n        [-0.6027,  0.0888, -1.5058, -1.1654, -0.7148],\n        [ 1.2753, -0.4101,  0.4946, -2.9917, -1.2779],\n        [-1.4045, -0.2712,  0.4429, -0.2222, -0.7184],\n        [-0.6562,  1.2038,  0.9780,  0.1263, -1.9698],\n        [-0.3942, -0.1619,  2.1763,  0.6952,  0.8985],\n        [ 0.9426,  0.6274,  1.4339, -0.3655,  0.6060],\n        [-0.0232,  1.3773, -0.4090,  1.0618, -0.2948],\n        [ 0.3657,  1.2116, -1.9235,  0.2128,  0.9628],\n        [-0.0054, -0.7658, -1.5171,  0.9022, -0.3424],\n        [ 0.0250,  0.0988, -0.2425,  0.2302,  2.5867],\n        [ 0.8274, -0.0193,  1.6451, -0.5173,  1.9787],\n        [ 0.4465, -0.6417,  0.1839,  0.1950,  0.6193],\n        [-0.8528, -0.1507, -1.1756, -0.7493, -0.1694],\n        [ 0.5451, -0.1640, -0.7052, -2.2439, -0.0902],\n        [-1.2375,  0.6400, -0.0717,  0.8026,  0.3689],\n        [-0.4006, -0.4902,  1.2855,  0.5666, -0.7605],\n        [-0.3460, -0.0311,  0.4690, -0.6269, -0.5895],\n        [-0.2426, -0.6435,  0.6376,  0.7295, -2.5957],\n        [ 1.9069,  1.2954, -0.4734,  0.0094, -0.4509],\n        [ 0.2476,  0.3806,  0.5114, -0.3037, -0.3522],\n        [ 0.1092, -1.0953, -1.1172,  0.2607,  0.6302],\n        [-0.4281,  0.9575,  1.1477, -1.8067,  0.2051],\n        [-2.3917,  1.0070,  0.4690, -1.0293, -1.2361],\n        [-2.2108, -1.4035,  0.5568, -0.6005, -2.4205],\n        [-0.7226, -0.4141,  0.9886, -0.6103,  0.5877],\n        [-2.9386, -0.5597,  0.0786,  0.0106, -2.3684],\n        [-0.9860,  0.2154, -0.1190,  0.7797, -2.9880],\n        [ 0.4472,  0.4042,  0.7200, -0.4425, -1.7816]])\n\n\n\nxt_test = fiveVTS_test.float().reshape(40,5,1)[:-1,:,:]\n\n\nmean_fhat_fiveVTS_forecast = torch.stack([model(xt, edge_index, edge_attr) for xt in xt_test]).detach().numpy()\n\n\nvis2(fiveVTS_test[1:],mean_fhat_fiveVTS_forecast);\n\n\n\n\n\nvis2(fiveVTS_train_mean,mean_fhat_fiveVTS);"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#fourier-transform",
    "href": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#fourier-transform",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "2) Fourier transform",
    "text": "2) Fourier transform\n\nw=np.zeros((159*N,159*N))\n\n\nfor i in range(159*N):\n    for j in range(159*N):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\n# #w= edges\n# d = np.array(w.sum(axis=1))\n# L = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\n# lamb, Psi = np.linalg.eigh(L)\n# Lamb = np.diag(lamb)\n\n\n# np.fft(mean_fhat_fiveVTS[:,0,0])\n\n\n# mean_fhat_fiveVTS.shape\n\n\n# fft_result =np.stack([np.fft.fft(mean_fhat_fiveVTS[:,n,0]) for n in range(N)]).T\n\n\n# plt.plot(abs(fft_result[:,0])**2)\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\n\n\nfhatbar = Psi.T @ mean_fhat_fiveVTS.reshape(159*N,1)\npower = fhatbar**2"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#ebayes",
    "href": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#ebayes",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "3) Ebayes",
    "text": "3) Ebayes\n\nplt.plot(fhatbar.reshape(159,5)[:,0]**2)\n\n\n\n\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\n#power_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(159*N)])\nfhatbar_threshed = ebayesthresh(FloatVector(fhatbar))\n\n\nebayesthresh(FloatVector(fhatbar))\n\n\n\n        FloatVector with 795 elements.\n        \n        \n          \n          \n            \n            1.229290\n            \n          \n            \n            0.000000\n            \n          \n            \n            -0.204739\n            \n          \n            \n            ...\n            \n          \n            \n            0.000000\n            \n          \n            \n            0.000000\n            \n          \n            \n            0.000000\n            \n          \n          \n        \n        \n        \n\n\n\nebayesthresh(FloatVector([1,2,3,444,0]))\n\n\n\n        FloatVector with 5 elements.\n        \n        \n          \n          \n            \n            0.000000\n            \n          \n            \n            0.000000\n            \n          \n            \n            0.000000\n            \n          \n            \n            442.517400\n            \n          \n            \n            0.000000\n            \n          \n          \n        \n        \n        \n\n\n\nplt.plot(fhatbar)\nplt.plot(fhatbar_threshed)"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#inverse-fourier-transform",
    "href": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#inverse-fourier-transform",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "4) Inverse Fourier transform",
    "text": "4) Inverse Fourier transform\n\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_mean_spatio_temporal = fhatbarhat.reshape(159,N,1)\n\n# fhatbarhat = Psi @ fhatbar\n# fhatbarhat_mean_spatio_temporal = fhatbarhat.reshape(159,N,1)\n\n\nvis2(mean_fhat_fiveVTS,fhatbarhat_mean_spatio_temporal.reshape(159,5));"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#st-gcn-1",
    "href": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#st-gcn-1",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "5) ST-GCN",
    "text": "5) ST-GCN\n\nmean_spatio_temporal = torch.tensor(fhatbarhat_mean_spatio_temporal).reshape(159,5,1).float()\n\n\nmean_X_spatio_temporal = mean_spatio_temporal[:158,:,:]\nmean_y_spatio_temporal = mean_spatio_temporal[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(mean_X_spatio_temporal,mean_y_spatio_temporal)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n\nmean_X_spatio_temporal_fore = mean_spatio_temporal[119:,:,:]\n\n\nmean_fhat_spatio_temporal = torch.stack([model(xt, edge_index, edge_attr) for xt in mean_X_spatio_temporal_fore]).detach().numpy()\n\n\nBox plot\n\nsum((mean_fhat_spatio_temporal.reshape(40,5) -  fiveVTS_test)**2)\n\n\nplt.figure(figsize=(20, 8))\nplt.boxplot((mean_fhat_spatio_temporal.reshape(40,5) -  fiveVTS_test))\n\n\nplt.figure(figsize=(20, 8))\nplt.boxplot(((mean_fhat_spatio_temporal.reshape(40,5) -  fiveVTS_test)).reshape(200,1))"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#fourier-transform-1",
    "href": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#fourier-transform-1",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "6) Fourier transform",
    "text": "6) Fourier transform\n\nmean_fhat_spatio_temporal = torch.stack([model(xt, edge_index, edge_attr) for xt in mean_spatio_temporal]).detach().numpy()\n\n\nw=np.zeros((159*N,159*N))\n\n\nfor i in range(159*N):\n    for j in range(159*N):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ mean_fhat_spatio_temporal.reshape(159*N,1)\npower = fhatbar**2"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#ebayes-1",
    "href": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#ebayes-1",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "7) Ebayes",
    "text": "7) Ebayes\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(159*N)])\nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#inverse-fourier-transform-1",
    "href": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#inverse-fourier-transform-1",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "8) Inverse Fourier transform",
    "text": "8) Inverse Fourier transform\n\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_mean_spatio_temporal = fhatbarhat.reshape(159,N,1)"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#st-gcn-2",
    "href": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#st-gcn-2",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "9) ST-GCN",
    "text": "9) ST-GCN\n\nmean_spatio_temporal2 = torch.tensor(fhatbarhat_mean_spatio_temporal).reshape(159,5,1).float()\n\n\nmean_X_spatio_temporal2 = mean_spatio_temporal2[:158,:,:]\nmean_y_spatio_temporal2 = mean_spatio_temporal2[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(mean_X_spatio_temporal2,mean_y_spatio_temporal2)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n\nmean_X_spatio_temporal_fore2 = mean_spatio_temporal2[119:,:,:]\n\n\nmean_fhat_spatio_temporal2 = torch.stack([model(xt, edge_index, edge_attr) for xt in mean_X_spatio_temporal_fore2]).detach().numpy()\n\n\nBox plot\n\nsum((mean_fhat_spatio_temporal2.reshape(40,5) -  fiveVTS_test)**2)\n\n\nplt.figure(figsize=(20, 8))\nplt.boxplot((mean_fhat_spatio_temporal2.reshape(40,5) -  fiveVTS_test))\n\n\nplt.figure(figsize=(20, 8))\nplt.boxplot(((mean_fhat_spatio_temporal2.reshape(40,5) -  fiveVTS_test)).reshape(200,1))"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#st-gcn-3",
    "href": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#st-gcn-3",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "1) ST-GCN",
    "text": "1) ST-GCN\n\nlinear_f_fiveVTS_train = torch.tensor(linear_fiveVTS_train).reshape(160,5,1).float()\n\n\nlinear_X_fiveVTS = linear_f_fiveVTS_train[:159,:,:]\nlinear_y_fiveVTS = linear_f_fiveVTS_train[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(linear_X_fiveVTS,linear_y_fiveVTS)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n\nlinear_fhat_fiveVTS = torch.stack([model(xt, edge_index, edge_attr) for xt in linear_X_fiveVTS]).detach().numpy()"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#fourier-transform-2",
    "href": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#fourier-transform-2",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "2) Fourier transform",
    "text": "2) Fourier transform\n\nw=np.zeros((159*N,159*N))\n\n\nfor i in range(159*N):\n    for j in range(159*N):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ linear_fhat_fiveVTS.reshape(159*N,1)\npower = fhatbar**2"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#ebayes-2",
    "href": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#ebayes-2",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "3) Ebayes",
    "text": "3) Ebayes\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(159*N)])\nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#inverse-fourier-transform-2",
    "href": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#inverse-fourier-transform-2",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "4) Inverse Fourier transform",
    "text": "4) Inverse Fourier transform\n\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_linear_spatio_temporal = fhatbarhat.reshape(159,N,1)"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#st-gcn-4",
    "href": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#st-gcn-4",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "5) ST-GCN",
    "text": "5) ST-GCN\n\nlinear_spatio_temporal = torch.tensor(fhatbarhat_linear_spatio_temporal).reshape(159,5,1).float()\n\n\nlinear_X_spatio_temporal = linear_spatio_temporal[:158,:,:]\nlinear_y_spatio_temporal = linear_spatio_temporal[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(linear_X_spatio_temporal,linear_y_spatio_temporal)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n\n\nlinear_X_spatio_temporal_fore = linear_spatio_temporal[119:,:,:]\n\n\nlinear_fhat_spatio_temporal = torch.stack([model(xt, edge_index, edge_attr) for xt in linear_X_spatio_temporal_fore]).detach().numpy()\n\n\nBox plot\n\nplt.figure(figsize=(20, 8))\nplt.boxplot((linear_fhat_spatio_temporal.reshape(40,5) -  fiveVTS_test))\n\n\nplt.figure(figsize=(20, 8))\nplt.boxplot(((linear_fhat_spatio_temporal.reshape(40,5) -  fiveVTS_test)).reshape(200,1))"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#fourier-transform-3",
    "href": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#fourier-transform-3",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "6) Fourier transform",
    "text": "6) Fourier transform\n\nlinear_fhat_spatio_temporal = torch.stack([model(xt, edge_index, edge_attr) for xt in linear_spatio_temporal]).detach().numpy()\n\n\nw=np.zeros((159*N,159*N))\n\n\nfor i in range(159*N):\n    for j in range(159*N):\n        if i==j :\n            w[i,j] = 0\n        elif np.abs(i-j) <= 1 : \n            w[i,j] = 1\n\n\nd = np.array(w.sum(axis=1))\nD = np.diag(d)\nL = np.array(np.diag(1/np.sqrt(d)) @ (D-w) @ np.diag(1/np.sqrt(d)))\nlamb, Psi = np.linalg.eigh(L)\nLamb = np.diag(lamb)\nfhatbar = Psi @ linear_fhat_fiveVTS.reshape(159*N,1)\npower = fhatbar**2"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#ebayes-3",
    "href": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#ebayes-3",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "7) Ebayes",
    "text": "7) Ebayes\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\npower_threshed=np.array([np.array(ebayesthresh(FloatVector(fhatbar[i]**2))) for i in range(159*N)])\nfhatbar_threshed = np.where(power_threshed>0,fhatbar,0)"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#inverse-fourier-transform-3",
    "href": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#inverse-fourier-transform-3",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "8) Inverse Fourier transform",
    "text": "8) Inverse Fourier transform\n\nfhatbarhat = Psi @ fhatbar_threshed\nfhatbarhat_linear_spatio_temporal = fhatbarhat.reshape(159,N,1)"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#st-gcn-5",
    "href": "posts/2. Let's Study/Essays/2023-01-17-Algorithm_traintest.html#st-gcn-5",
    "title": "1st ST-GCN Example dividing train and test",
    "section": "9) ST-GCN",
    "text": "9) ST-GCN\n\nlinear_spatio_temporal2 = torch.tensor(fhatbarhat_linear_spatio_temporal).reshape(159,5,1).float()\n\n\nlinear_X_spatio_temporal2 = linear_spatio_temporal2[:158,:,:]\nlinear_y_spatio_temporal2 = linear_spatio_temporal2[1:,:,:]\n\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(linear_X_spatio_temporal2,linear_y_spatio_temporal2)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n\nlinear_X_spatio_temporal_fore2 = linear_spatio_temporal2[119:,:,:]\n\n\nlinear_fhat_spatio_temporal2 = torch.stack([model(xt, edge_index, edge_attr) for xt in linear_X_spatio_temporal_fore2]).detach().numpy()\n\n\nBox plot\n\nplt.figure(figsize=(20, 8))\nplt.boxplot((linear_fhat_spatio_temporal2.reshape(40,5) -  fiveVTS_test))\n\n\nplt.figure(figsize=(20, 8))\nplt.boxplot(((linear_fhat_spatio_temporal2.reshape(40,5) -  fiveVTS_test)).reshape(200,1))"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/Untitled3.html",
    "href": "posts/2. Let's Study/Essays/Untitled3.html",
    "title": "신록예찬's Blog",
    "section": "",
    "text": "1+1\n\n2\n\n\n- 그나마 여기에서 가장 잘되는 것 같음…"
  },
  {
    "objectID": "posts/2. Let's Study/Essays/Untitled.html",
    "href": "posts/2. Let's Study/Essays/Untitled.html",
    "title": "추정",
    "section": "",
    "text": "using Distributions, Plots\n\n\n추정\n데이터로부터 모수 혹은 모수의 함수를 추측하는 일을 추정이라고 한다.\n(예시)\n아래와 같은 베르누이 분포에서 데이터 \\({\\bf x}=(x_1,\\dots,x_{10})\\)을 얻었다고 하자.\n\nx = rand(Bernoulli(0.37),10)\nx\n\n10-element Vector{Bool}:\n 0\n 0\n 1\n 0\n 1\n 0\n 1\n 0\n 0\n 0\n\n\n이러한 데이터로부터 평균 \\(p\\)와 분산 \\(p(1-p)\\)를 추측할 수 있는데 이를 추정이라고 한다. 여기에서 평균은 모수 \\(p\\)이고 분산은 모수 \\(p\\)의 함수이다."
  },
  {
    "objectID": "posts/3. Researches/HST/Untitled.html",
    "href": "posts/3. Researches/HST/Untitled.html",
    "title": "HST Example",
    "section": "",
    "text": "1+1\n\n2"
  },
  {
    "objectID": "posts/3. Researches/HST/2023-01-23-CommunityDetection.html",
    "href": "posts/3. Researches/HST/2023-01-23-CommunityDetection.html",
    "title": "CommunityDetection",
    "section": "",
    "text": "ref\n- Roddenberry et al. (2020)\n\nhttps://arxiv.org/pdf/2001.10944.pdf\nintro에 그래프는 single correct한 structure를 알 수 없다는 이야기가 있는데 이를 이용해야함.\n\n\n\n\n\n\n\n\n\n방법론\n\nRoddenberry, T Mitchell, Michael T Schaub, Hoi-To Wai, and Santiago Segarra. 2020. “Exact Blind Community Detection from Signals on Multiple Graphs.” IEEE Transactions on Signal Processing 68: 5016–30."
  },
  {
    "objectID": "posts/2. Let's Study/Essays/2023-01-20-Estimation.html",
    "href": "posts/2. Let's Study/Essays/2023-01-20-Estimation.html",
    "title": "추정",
    "section": "",
    "text": "using Distributions, Plots\n\n\n추정\n데이터로부터 모수 혹은 모수의 함수를 추측하는 일을 추정이라고 한다.\n(예시)\n아래와 같은 베르누이 분포에서 데이터 \\({\\bf x}=(x_1,\\dots,x_{10})\\)을 얻었다고 하자.\n\nx = rand(Bernoulli(0.37),10)\nx\n\n10-element Vector{Bool}:\n 0\n 0\n 1\n 0\n 1\n 0\n 1\n 0\n 0\n 0\n\n\n이러한 데이터로부터 평균 \\(p\\)와 분산 \\(p(1-p)\\)를 추측할 수 있는데 이를 추정이라고 한다. 여기에서 평균은 모수 \\(p\\)이고 분산은 모수 \\(p\\)의 함수이다."
  }
]