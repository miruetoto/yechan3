{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **\\[Essays\\]** 강화학습(1) – bandit\n",
        "\n",
        "신록예찬  \n",
        "2023-08-23\n",
        "\n",
        "# 환경셋팅\n",
        "\n",
        "`-` 설치\n",
        "\n",
        "``` python\n",
        "!pip install -q swig\n",
        "!pip install gymnasium\n",
        "!pip install gymnasium[box2d]\n",
        "```\n",
        "\n",
        "# imports"
      ],
      "id": "7ebc963d-36ff-4de5-86aa-82051a78b3ad"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "df6688cb-b243-4e39-80c3-3886d1481186"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Intro\n",
        "\n",
        "`-` 강화학습(대충설명): 어떠한 “(게임)환경”이 있을때 거기서 “뭘 할지”를\n",
        "학습하는 과업\n",
        "\n",
        "`-` 딥마인드: breakout $\\to$ 알파고\n",
        "\n",
        "<https://www.youtube.com/watch?v=TmPfTpjtdgg>\n",
        "\n",
        "`-` 강화학습의 미래? (이거 잘하면 먹고 살 수 있을까?)\n",
        "\n",
        "# Game1: 벤딧문제\n",
        "\n",
        "`-` 문제설명: 두개의 버튼이 있다. 버튼0을 누르면 1의 보상을, 버튼1를\n",
        "누르면 100의 보상을 준다고 가정\n",
        "\n",
        "`-` 어떤 행동을 해야할까? –\\> ?? 아는게없음 –\\> 일단 “아무거나” 눌러보자"
      ],
      "id": "e2589db3-9fa7-4709-ad22-b2db805ca55c"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "action_space = ['button0','button1']\n",
        "action = np.random.choice(action_space)\n",
        "action"
      ],
      "id": "d771a51a-0733-42df-bf20-b06444164b35"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 보상은 아래와 같은 방식으로 받을 것이다."
      ],
      "id": "1898c432-fbb4-4d51-81dd-3cc243e5eea3"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "if action == 'button0': \n",
        "    reward = 1 \n",
        "else:\n",
        "    reward = 100"
      ],
      "id": "97ab8e9f-5d74-4600-bbc9-64ed47fec6d9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 아무거나 10번 버튼을 눌러보면 다음과 같은 결과가 나온다."
      ],
      "id": "02f37683-8b44-4afa-b1ef-465e7103f3e0"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "button1 100\n",
            "button0 1\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button0 1\n",
            "button0 1\n",
            "button1 100\n",
            "button1 100"
          ]
        }
      ],
      "source": [
        "for _ in range(10):\n",
        "    action = np.random.choice(action_space)\n",
        "    if action == 'button0': \n",
        "        reward = 1 \n",
        "    else:\n",
        "        reward = 100\n",
        "    print(action,reward)"
      ],
      "id": "afb693ba-a1f0-4886-88f2-093c8c632cbb"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 깨달았음: `button0`을 누르면 1점을 받고, `button1`을 누르면 100점을\n",
        "받는 “환경”이구나? $\\to$ `button1`을 누르는 “동작”을 해야하는\n",
        "상황이구나?\n",
        "\n",
        "-   여기에서 $\\to$ 의 과정을 체계화 시킨 학문이 강화학습이다."
      ],
      "id": "d33d38d3-d08e-467e-bbcb-a78e61b9573c"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100"
          ]
        }
      ],
      "source": [
        "action_space = ['button0','button1']\n",
        "for _ in range(10):\n",
        "    #action = np.random.choice(action_space) # 무지한자의 행동 (찍어)\n",
        "    action = action_space[1] # 깨달은자의 행동 (button1을 눌러)\n",
        "    if action == 'button0': \n",
        "        reward = 1 \n",
        "    else:\n",
        "        reward = 100\n",
        "    print(action,reward)"
      ],
      "id": "0a189b7f-eaaf-4d7e-b2a9-b9742ab245d4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 강화학습: 환경의 이해 $\\to$ 뭘 해야 하는지 깨달음\n",
        "\n",
        "**위의 과정이 잘 되었다는 의미로 사용하는 문장들**\n",
        "\n",
        "-   강화학습이 성공적으로 잘 되었다.\n",
        "-   환경이 해결되었다.\n",
        "-   에이전트가 환경의 과제를 완료했다.\n",
        "-   에이전트가 환경에서 성공적으로 학습했다.\n",
        "-   에이전트가 올바른 행동을 학습했다.\n",
        "-   게임 클리어 (비공식)\n",
        "\n",
        "`-` 환경이 해결되었는지 나타내는 지표를 정해야겠다 $\\to$ 주어진 상황을\n",
        "게임처럼 이해하고, 게임의 클리어조건을 설정\n",
        "\n",
        "-   첫 생각: `button1`을 누르면 클리어 아니야?\n",
        "-   두번째 생각: 아니지? 우연히 누를수도 있잖아.\n",
        "-   게임클리어조건: 최근 20번의 보상이 1900 이상이면 게임이 클리어\n",
        "    되었다고 보자![1]\n",
        "\n",
        "`-` 무지한자 – 게임을 클리어 할 수 없다.\n",
        "\n",
        "[1] `button1`을 눌러야하는건 맞지만 20번에 실수한번정도는 눈감아 주자"
      ],
      "id": "68650c96-7b21-4b2e-8728-065119dd0599"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_try = 1   action = button1    reward = 100    rwd20 = 100\n",
            "n_try = 2   action = button1    reward = 100    rwd20 = 200\n",
            "n_try = 3   action = button1    reward = 100    rwd20 = 300\n",
            "n_try = 4   action = button0    reward = 1  rwd20 = 301\n",
            "n_try = 5   action = button1    reward = 100    rwd20 = 401\n",
            "n_try = 6   action = button1    reward = 100    rwd20 = 501\n",
            "n_try = 7   action = button0    reward = 1  rwd20 = 502\n",
            "n_try = 8   action = button1    reward = 100    rwd20 = 602\n",
            "n_try = 9   action = button0    reward = 1  rwd20 = 603\n",
            "n_try = 10  action = button1    reward = 100    rwd20 = 703\n",
            "n_try = 11  action = button0    reward = 1  rwd20 = 704\n",
            "n_try = 12  action = button0    reward = 1  rwd20 = 705\n",
            "n_try = 13  action = button0    reward = 1  rwd20 = 706\n",
            "n_try = 14  action = button1    reward = 100    rwd20 = 806\n",
            "n_try = 15  action = button1    reward = 100    rwd20 = 906\n",
            "n_try = 16  action = button0    reward = 1  rwd20 = 907\n",
            "n_try = 17  action = button1    reward = 100    rwd20 = 1007\n",
            "n_try = 18  action = button1    reward = 100    rwd20 = 1107\n",
            "n_try = 19  action = button0    reward = 1  rwd20 = 1108\n",
            "n_try = 20  action = button0    reward = 1  rwd20 = 1109\n",
            "n_try = 21  action = button1    reward = 100    rwd20 = 1109\n",
            "n_try = 22  action = button0    reward = 1  rwd20 = 1010\n",
            "n_try = 23  action = button1    reward = 100    rwd20 = 1010\n",
            "n_try = 24  action = button1    reward = 100    rwd20 = 1109\n",
            "n_try = 25  action = button1    reward = 100    rwd20 = 1109\n",
            "n_try = 26  action = button0    reward = 1  rwd20 = 1010\n",
            "n_try = 27  action = button1    reward = 100    rwd20 = 1109\n",
            "n_try = 28  action = button1    reward = 100    rwd20 = 1109\n",
            "n_try = 29  action = button1    reward = 100    rwd20 = 1208\n",
            "n_try = 30  action = button1    reward = 100    rwd20 = 1208\n",
            "n_try = 31  action = button1    reward = 100    rwd20 = 1307\n",
            "n_try = 32  action = button0    reward = 1  rwd20 = 1307\n",
            "n_try = 33  action = button1    reward = 100    rwd20 = 1406\n",
            "n_try = 34  action = button1    reward = 100    rwd20 = 1406\n",
            "n_try = 35  action = button0    reward = 1  rwd20 = 1307\n",
            "n_try = 36  action = button0    reward = 1  rwd20 = 1307\n",
            "n_try = 37  action = button0    reward = 1  rwd20 = 1208\n",
            "n_try = 38  action = button0    reward = 1  rwd20 = 1109\n",
            "n_try = 39  action = button1    reward = 100    rwd20 = 1208\n",
            "n_try = 40  action = button1    reward = 100    rwd20 = 1307\n",
            "n_try = 41  action = button0    reward = 1  rwd20 = 1208\n",
            "n_try = 42  action = button0    reward = 1  rwd20 = 1208\n",
            "n_try = 43  action = button1    reward = 100    rwd20 = 1208\n",
            "n_try = 44  action = button1    reward = 100    rwd20 = 1208\n",
            "n_try = 45  action = button1    reward = 100    rwd20 = 1208\n",
            "n_try = 46  action = button1    reward = 100    rwd20 = 1307\n",
            "n_try = 47  action = button0    reward = 1  rwd20 = 1208\n",
            "n_try = 48  action = button0    reward = 1  rwd20 = 1109\n",
            "n_try = 49  action = button0    reward = 1  rwd20 = 1010\n",
            "n_try = 50  action = button1    reward = 100    rwd20 = 1010"
          ]
        }
      ],
      "source": [
        "action_space = ['button0','button1']\n",
        "rewards = []\n",
        "for i in range(50): # 1000번해도 못깸\n",
        "    action = np.random.choice(action_space) # 무지한자의 행동 (찍어)\n",
        "    #action = action_space[1] # 깨달은자의 행동 (button1을 눌러)\n",
        "    if action == 'button0': \n",
        "        reward = 1 \n",
        "        rewards.append(reward)\n",
        "    else:\n",
        "        reward = 100\n",
        "        rewards.append(reward)\n",
        "    print(\n",
        "        f\"n_try = {i+1}\\t\"\n",
        "        f\"action = {action}\\t\"\n",
        "        f\"reward = {reward}\\t\"\n",
        "        f\"rwd20 = {sum(rewards[-20:])}\"\n",
        "    )\n",
        "    if np.sum(rewards[-20:])>1900:\n",
        "        break\n",
        "    "
      ],
      "id": "cd7ee8d2-4bef-4901-98a3-766efc21c600"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 깨달은자 – 게임 클리어"
      ],
      "id": "cd9b5175-d1ff-4603-b2e1-c75c9fb24d54"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_try = 1   action = button1    reward = 100    rwd20 = 100\n",
            "n_try = 2   action = button1    reward = 100    rwd20 = 200\n",
            "n_try = 3   action = button1    reward = 100    rwd20 = 300\n",
            "n_try = 4   action = button1    reward = 100    rwd20 = 400\n",
            "n_try = 5   action = button1    reward = 100    rwd20 = 500\n",
            "n_try = 6   action = button1    reward = 100    rwd20 = 600\n",
            "n_try = 7   action = button1    reward = 100    rwd20 = 700\n",
            "n_try = 8   action = button1    reward = 100    rwd20 = 800\n",
            "n_try = 9   action = button1    reward = 100    rwd20 = 900\n",
            "n_try = 10  action = button1    reward = 100    rwd20 = 1000\n",
            "n_try = 11  action = button1    reward = 100    rwd20 = 1100\n",
            "n_try = 12  action = button1    reward = 100    rwd20 = 1200\n",
            "n_try = 13  action = button1    reward = 100    rwd20 = 1300\n",
            "n_try = 14  action = button1    reward = 100    rwd20 = 1400\n",
            "n_try = 15  action = button1    reward = 100    rwd20 = 1500\n",
            "n_try = 16  action = button1    reward = 100    rwd20 = 1600\n",
            "n_try = 17  action = button1    reward = 100    rwd20 = 1700\n",
            "n_try = 18  action = button1    reward = 100    rwd20 = 1800\n",
            "n_try = 19  action = button1    reward = 100    rwd20 = 1900\n",
            "n_try = 20  action = button1    reward = 100    rwd20 = 2000"
          ]
        }
      ],
      "source": [
        "action_space = ['button0','button1']\n",
        "rewards = []\n",
        "for i in range(50): # 1000번해도 못깸\n",
        "    #action = np.random.choice(action_space) # 무지한자의 행동 (찍어)\n",
        "    action = action_space[1] # 깨달은자의 행동 (button1을 눌러)\n",
        "    if action == 'button0': \n",
        "        reward = 1 \n",
        "        rewards.append(reward)\n",
        "    else:\n",
        "        reward = 100\n",
        "        rewards.append(reward)\n",
        "    print(\n",
        "        f\"n_try = {i+1}\\t\"\n",
        "        f\"action = {action}\\t\"\n",
        "        f\"reward = {reward}\\t\"\n",
        "        f\"rwd20 = {sum(rewards[-20:])}\"\n",
        "    )\n",
        "    if np.sum(rewards[-20:])>1900:\n",
        "        break"
      ],
      "id": "a47f0eea-5688-454a-8c9d-9e4c6d5552fe"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 수정1: `action_space`의 수정"
      ],
      "id": "8a1063c6-0eb3-4293-badf-ac14e5675a03"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "action_space =  gym.spaces.Discrete(2)\n",
        "action_space"
      ],
      "id": "4b1d0578-eb81-4dc3-a1ba-1653e7e73aa3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 좋은점1: sample"
      ],
      "id": "d6cec88c-787f-4ac6-a66f-6ffaa727b370"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1"
          ]
        }
      ],
      "source": [
        "for _ in range(10):\n",
        "    print(action_space.sample())"
      ],
      "id": "1c796bc8-d37c-4b05-8ee1-14c5bb6f177d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 좋은점2: in"
      ],
      "id": "7510ad54-b876-4549-8cf2-e5c0f69859b0"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "0 in action_space"
      ],
      "id": "a10de998-fd16-480b-8360-d1c41f3eccd2"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "1 in action_space"
      ],
      "id": "b765df83-0ef1-4533-9ba4-5953f264595d"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "2 in action_space"
      ],
      "id": "522688ea-b1b6-4545-8001-6cfe16b944a6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 코드 1차수정"
      ],
      "id": "43d95a11-4911-44a0-bb6f-1a57d1d672aa"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_try = 1   action = 0  reward = 1  rwd20 = 1\n",
            "n_try = 2   action = 0  reward = 1  rwd20 = 2\n",
            "n_try = 3   action = 0  reward = 1  rwd20 = 3\n",
            "n_try = 4   action = 0  reward = 1  rwd20 = 4\n",
            "n_try = 5   action = 0  reward = 1  rwd20 = 5\n",
            "n_try = 6   action = 1  reward = 100    rwd20 = 105\n",
            "n_try = 7   action = 1  reward = 100    rwd20 = 205\n",
            "n_try = 8   action = 1  reward = 100    rwd20 = 305\n",
            "n_try = 9   action = 1  reward = 100    rwd20 = 405\n",
            "n_try = 10  action = 0  reward = 1  rwd20 = 406\n",
            "n_try = 11  action = 0  reward = 1  rwd20 = 407\n",
            "n_try = 12  action = 1  reward = 100    rwd20 = 507\n",
            "n_try = 13  action = 0  reward = 1  rwd20 = 508\n",
            "n_try = 14  action = 0  reward = 1  rwd20 = 509\n",
            "n_try = 15  action = 0  reward = 1  rwd20 = 510\n",
            "n_try = 16  action = 0  reward = 1  rwd20 = 511\n",
            "n_try = 17  action = 1  reward = 100    rwd20 = 611\n",
            "n_try = 18  action = 0  reward = 1  rwd20 = 612\n",
            "n_try = 19  action = 0  reward = 1  rwd20 = 613\n",
            "n_try = 20  action = 1  reward = 100    rwd20 = 713\n",
            "n_try = 21  action = 0  reward = 1  rwd20 = 713\n",
            "n_try = 22  action = 1  reward = 100    rwd20 = 812\n",
            "n_try = 23  action = 1  reward = 100    rwd20 = 911\n",
            "n_try = 24  action = 0  reward = 1  rwd20 = 911\n",
            "n_try = 25  action = 1  reward = 100    rwd20 = 1010\n",
            "n_try = 26  action = 1  reward = 100    rwd20 = 1010\n",
            "n_try = 27  action = 0  reward = 1  rwd20 = 911\n",
            "n_try = 28  action = 1  reward = 100    rwd20 = 911\n",
            "n_try = 29  action = 1  reward = 100    rwd20 = 911\n",
            "n_try = 30  action = 0  reward = 1  rwd20 = 911\n",
            "n_try = 31  action = 0  reward = 1  rwd20 = 911\n",
            "n_try = 32  action = 1  reward = 100    rwd20 = 911\n",
            "n_try = 33  action = 0  reward = 1  rwd20 = 911\n",
            "n_try = 34  action = 0  reward = 1  rwd20 = 911\n",
            "n_try = 35  action = 1  reward = 100    rwd20 = 1010\n",
            "n_try = 36  action = 0  reward = 1  rwd20 = 1010\n",
            "n_try = 37  action = 0  reward = 1  rwd20 = 911\n",
            "n_try = 38  action = 0  reward = 1  rwd20 = 911\n",
            "n_try = 39  action = 0  reward = 1  rwd20 = 911\n",
            "n_try = 40  action = 0  reward = 1  rwd20 = 812\n",
            "n_try = 41  action = 1  reward = 100    rwd20 = 911\n",
            "n_try = 42  action = 1  reward = 100    rwd20 = 911\n",
            "n_try = 43  action = 0  reward = 1  rwd20 = 812\n",
            "n_try = 44  action = 0  reward = 1  rwd20 = 812\n",
            "n_try = 45  action = 1  reward = 100    rwd20 = 812\n",
            "n_try = 46  action = 1  reward = 100    rwd20 = 812\n",
            "n_try = 47  action = 0  reward = 1  rwd20 = 812\n",
            "n_try = 48  action = 1  reward = 100    rwd20 = 812\n",
            "n_try = 49  action = 1  reward = 100    rwd20 = 812\n",
            "n_try = 50  action = 1  reward = 100    rwd20 = 911"
          ]
        }
      ],
      "source": [
        "action_space = gym.spaces.Discrete(2)\n",
        "rewards = []\n",
        "for i in range(50): # 1000번해도 못깸\n",
        "    action = action_space.sample() # 무지한자의 행동 (찍어)\n",
        "    #action = 1 # 깨달은자의 행동 (button1을 눌러)\n",
        "    if action == 0: \n",
        "        reward = 1 \n",
        "        rewards.append(reward)\n",
        "    else:\n",
        "        reward = 100\n",
        "        rewards.append(reward)\n",
        "    print(\n",
        "        f\"n_try = {i+1}\\t\"\n",
        "        f\"action = {action}\\t\"\n",
        "        f\"reward = {reward}\\t\"\n",
        "        f\"rwd20 = {sum(rewards[-20:])}\"\n",
        "    )\n",
        "    if np.sum(rewards[-20:])>1900:\n",
        "        break"
      ],
      "id": "4d4e9079-5aff-468a-8037-b1a19e8e1bfa"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 수정2: Env 클래스\n",
        "\n",
        "`-` env 생성"
      ],
      "id": "16dfb6c2-98ac-49b8-8a46-619e93dc8d66"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Bandit:\n",
        "    def step(self,action):\n",
        "        if action == 0: \n",
        "            return 1\n",
        "        else:\n",
        "            return 100"
      ],
      "id": "0f8150e2-9959-4020-9414-e82e6b3795c3"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_try = 1   action = 1  reward = 100    rwd20 = 100\n",
            "n_try = 2   action = 1  reward = 100    rwd20 = 200\n",
            "n_try = 3   action = 1  reward = 100    rwd20 = 300\n",
            "n_try = 4   action = 1  reward = 100    rwd20 = 400\n",
            "n_try = 5   action = 1  reward = 100    rwd20 = 500\n",
            "n_try = 6   action = 1  reward = 100    rwd20 = 600\n",
            "n_try = 7   action = 1  reward = 100    rwd20 = 700\n",
            "n_try = 8   action = 1  reward = 100    rwd20 = 800\n",
            "n_try = 9   action = 1  reward = 100    rwd20 = 900\n",
            "n_try = 10  action = 1  reward = 100    rwd20 = 1000\n",
            "n_try = 11  action = 1  reward = 100    rwd20 = 1100\n",
            "n_try = 12  action = 1  reward = 100    rwd20 = 1200\n",
            "n_try = 13  action = 1  reward = 100    rwd20 = 1300\n",
            "n_try = 14  action = 1  reward = 100    rwd20 = 1400\n",
            "n_try = 15  action = 1  reward = 100    rwd20 = 1500\n",
            "n_try = 16  action = 1  reward = 100    rwd20 = 1600\n",
            "n_try = 17  action = 1  reward = 100    rwd20 = 1700\n",
            "n_try = 18  action = 1  reward = 100    rwd20 = 1800\n",
            "n_try = 19  action = 1  reward = 100    rwd20 = 1900\n",
            "n_try = 20  action = 1  reward = 100    rwd20 = 2000"
          ]
        }
      ],
      "source": [
        "env = Bandit()\n",
        "rewards = []\n",
        "for i in range(50): # 1000번해도 못깸\n",
        "    #action = action_space.sample() # 무지한자의 행동 (찍어)\n",
        "    action = 1 # 깨달은자의 행동 (button1을 눌러)\n",
        "    reward = env.step(action)\n",
        "    rewards.append(reward)\n",
        "    print(\n",
        "        f\"n_try = {i+1}\\t\"\n",
        "        f\"action = {action}\\t\"\n",
        "        f\"reward = {reward}\\t\"\n",
        "        f\"rwd20 = {sum(rewards[-20:])}\"\n",
        "    )\n",
        "    if np.sum(rewards[-20:])>1900:\n",
        "        break"
      ],
      "id": "2af252df-c080-412f-b549-084f8721d507"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 수정3: Agent 클래스\n",
        "\n",
        "`-` Agent 클래스를 만들자 (액션을 하고, 환경에서 받은 reward를\n",
        "간직하도록)"
      ],
      "id": "af16180f-a4b1-4cac-97f1-e8998a55a343"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Agent1:\n",
        "    def __init__(self):\n",
        "        self.action_space = gym.spaces.Discrete(2)\n",
        "        self.action = None\n",
        "        self.reward = None\n",
        "        self.actions = []\n",
        "        self.rewards = []\n",
        "    def act(self):\n",
        "        # self.action = self.action_space.sample() # 무지한 자\n",
        "        self.action = 1 # 깨달은 자 \n",
        "    def save_experience(self): \n",
        "        self.actions.append(self.action)\n",
        "        self.rewards.append(self.reward)"
      ],
      "id": "3a8a43e7-3975-487b-a643-8c7266112c9b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "— 대충 아래와 같은 느낌으로 돌아가요 —\n",
        "\n",
        "**시점0**: init"
      ],
      "id": "d8a6e231-e78e-4dc9-bbc9-8174fefcae4f"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = Bandit()\n",
        "agent = Agent1()"
      ],
      "id": "8e3fa8f0-b41f-4d92-9477-1f6725c4e831"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.action, agent.reward"
      ],
      "id": "7b528099-158b-4e65-8181-92d1a6372d40"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**시점1**: agent \\>\\> env"
      ],
      "id": "495690eb-f3d5-42c0-8755-368725fc3baa"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.act()"
      ],
      "id": "545483f3-e2e3-4fd5-9009-f22df31761aa"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.action, agent.reward"
      ],
      "id": "a7b88291-b73b-4deb-9469-0b50e06a0d7f"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "env.agent_action = agent.action "
      ],
      "id": "c1cc49b4-180f-4ac6-8322-82bc0d36dc04"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**시점2**: agent \\<\\< env"
      ],
      "id": "548268a1-c29f-4cd3-9486-0b489f2812ca"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.reward = env.step(env.agent_action) \n",
        "# agent.reward = env.step(agent.action) 도 같은 결과를 주는 코드임!!"
      ],
      "id": "dd742d0b-e19c-4194-b581-5aa0cac4a12a"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.action, agent.reward, env.agent_action"
      ],
      "id": "d3b53960-00d4-4652-9500-dc3860688ea5"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.actions, agent.rewards"
      ],
      "id": "55df6ce8-fc00-42be-a880-ab486a16c469"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.save_experience()"
      ],
      "id": "b4e131cf-05a0-44e7-8421-80f5458d47a3"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.actions, agent.rewards"
      ],
      "id": "9f1024c0-f468-41cc-8f62-52811b1fc8fe"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "— 전체코드 —"
      ],
      "id": "64d758de-bb0a-465f-817f-7029fa4f0e31"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_try = 1   action = 1  reward = 100    rwd20 = 100\n",
            "n_try = 2   action = 1  reward = 100    rwd20 = 200\n",
            "n_try = 3   action = 1  reward = 100    rwd20 = 300\n",
            "n_try = 4   action = 1  reward = 100    rwd20 = 400\n",
            "n_try = 5   action = 1  reward = 100    rwd20 = 500\n",
            "n_try = 6   action = 1  reward = 100    rwd20 = 600\n",
            "n_try = 7   action = 1  reward = 100    rwd20 = 700\n",
            "n_try = 8   action = 1  reward = 100    rwd20 = 800\n",
            "n_try = 9   action = 1  reward = 100    rwd20 = 900\n",
            "n_try = 10  action = 1  reward = 100    rwd20 = 1000\n",
            "n_try = 11  action = 1  reward = 100    rwd20 = 1100\n",
            "n_try = 12  action = 1  reward = 100    rwd20 = 1200\n",
            "n_try = 13  action = 1  reward = 100    rwd20 = 1300\n",
            "n_try = 14  action = 1  reward = 100    rwd20 = 1400\n",
            "n_try = 15  action = 1  reward = 100    rwd20 = 1500\n",
            "n_try = 16  action = 1  reward = 100    rwd20 = 1600\n",
            "n_try = 17  action = 1  reward = 100    rwd20 = 1700\n",
            "n_try = 18  action = 1  reward = 100    rwd20 = 1800\n",
            "n_try = 19  action = 1  reward = 100    rwd20 = 1900\n",
            "n_try = 20  action = 1  reward = 100    rwd20 = 2000"
          ]
        }
      ],
      "source": [
        "env = Bandit()\n",
        "agent = Agent1()\n",
        "for i in range(50):\n",
        "    ## 1. 본질적인 코드\n",
        "    # step1: agent >> env \n",
        "    agent.act()\n",
        "    env.agent_action = agent.action \n",
        "    # step2: agnet << env \n",
        "    agent.reward = env.step(env.agent_action) \n",
        "    agent.save_experience()\n",
        "    \n",
        "    ## 2. 비본질적 코드 \n",
        "    print(\n",
        "        f\"n_try = {i+1}\\t\"\n",
        "        f\"action = {agent.action}\\t\"\n",
        "        f\"reward = {agent.reward}\\t\"\n",
        "        f\"rwd20 = {sum(agent.rewards[-20:])}\"\n",
        "    )\n",
        "    if np.sum(agent.rewards[-20:])>1900:\n",
        "        break"
      ],
      "id": "bd8ebd38-0b87-47f5-bf32-141a42388734"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   위의 코드를 거의 뼈대로 사용합니당!\n",
        "\n",
        "# 학습과정 포함\n",
        "\n",
        "`-` Game1에 대한 생각:\n",
        "\n",
        "-   사실 강화학습은 “환경을 이해 $\\to$ 뭘 해야 하는지 깨달음” 의\n",
        "    과정에서 화살표를 수식화 하는 과정이다.\n",
        "-   지금까지 살펴보면 Game1은 환경(env)을 이해하는 순간 에이전트가\n",
        "    최적의 행동(action)[1]을 직관적으로 결정하였으므로 학습의 과정이\n",
        "    포함되었다고 볼 수 없다.\n",
        "\n",
        "`-` 지금까지의 코드 복습\n",
        "\n",
        "1.  클래스를 선언하는 부분\n",
        "    -   `Env`클래스의 선언\n",
        "    -   `Agent`클래스의 선언\n",
        "2.  환경과 에이전트를 인스턴스화 (초기화)\n",
        "3.  for loop를 반복하며 게임을 진행\n",
        "    -   메인코드: (1) agent \\>\\> env (2) agent \\<\\< env (3) 데이터저장\n",
        "    -   비본질적코드: 학습과정 display, 학습종료조건\n",
        "\n",
        "`-` 앞으로 구성할 코드의 형태: 에이전트가 데이터를 보고 스스로\n",
        "`button1`을 눌러야 한다는 것을 추론하면 좋겠음\n",
        "\n",
        "1.  클래스를 선언하는 부분\n",
        "    -   `Env`클래스의 선언\n",
        "    -   **`Agent`클래스의 선언**: **학습의 과정 포함 $\\to$ act함수\n",
        "        수정**\n",
        "2.  환경과 에이전트를 인스턴스화 (초기화)\n",
        "3.  for loop를 반복하며 게임을 진행\n",
        "    -   메인코드: (1) agent \\>\\> env (2) agent \\<\\< env (3) 데이터저장\n",
        "        **(4) 학습**\n",
        "    -   비본질적코드: 학습과정 display, 학습종료조건\n",
        "\n",
        "`-` 에이전트가 학습을 어떻게 하는가?[2]\n",
        "\n",
        "-   $\\pi(0) = \\frac{Q_t(1)}{Q_t(1)+Q_t(0)}$\n",
        "-   $\\pi(1) = \\frac{Q_t(0)}{Q_t(1)+Q_t(0)}$\n",
        "\n",
        "여기에서 각각의 기호는 아래를 의미한다.\n",
        "\n",
        "-   $\\pi(0)$: 에이전트가 action = 0 을 할 확률, 즉 에이전트가\n",
        "    `button0`을 누를 확률\n",
        "-   $\\pi(1)$: 에이전트가 action = 1 을 할 확률, 즉 에이전트가\n",
        "    `button1`을 누를 확률\n",
        "-   $Q_t(0)$: ($t$시점까지 파악한) action = 0 을 하였을 경우 에이전트가\n",
        "    환경으로 받은 보상의 평균값\n",
        "-   $Q_t(1)$: ($t$시점까지 파악한) action = 1 을 하였을 경우 에이전트가\n",
        "    환경으로 받은 보상의 평균값\n",
        "\n",
        "`-` 걱정: $t=0$이면 어쩌지? $t=1$이면 어쩌지?.. $\\to$ 잡기술1: 일정\n",
        "시간동안은 랜덤액션을 하면서 데이터를 쌓자.\n",
        "\n",
        "`-` 쌓은 데이터를 바탕으로 환경을 이해하고 action을 뽑는 코드\n",
        "\n",
        "[1] `button1`을 누른다\n",
        "\n",
        "[2] 행동을 이런식으로 하도록 “전략(=정책)”을 설정하는 것은 상식적이다.\n",
        "그렇지만 유일한 해결책은 아님!!"
      ],
      "id": "9857118b-fb63-449a-a4ad-16e86857babb"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.actions = [0,0,1,0,0,1,1,1,1,0]\n",
        "agent.actions "
      ],
      "id": "ad0bddcd-a6a6-4ff9-bf74-6e65210cba68"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.rewards = [1,0.9,105,1.2,1,95,100,101,90,1]\n",
        "agent.rewards"
      ],
      "id": "5ad6ae8e-9ff1-4bc9-bcb8-230177d572bf"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "actions = np.array(agent.actions)\n",
        "rewards = np.array(agent.rewards)"
      ],
      "id": "02f5a801-b7f0-4647-999d-eab0f35cfe91"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "q0= rewards[actions==0].mean()\n",
        "q1= rewards[actions==1].mean()"
      ],
      "id": "8ba856ab-f709-4716-ad6f-09a77295220c"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.q = np.array([q0,q1])\n",
        "agent.q"
      ],
      "id": "afeae8aa-afff-4ea7-a9c2-bbe288e95145"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "action = np.random.choice([0,1],p=agent.q/agent.q.sum())\n",
        "action"
      ],
      "id": "988ff6d7-8370-4d44-9afa-3bfe2a25693f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 코드를 구현해보자."
      ],
      "id": "40399f8c-5227-43a9-9ebc-48400f08e642"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 게임을 푸는 전략을 바꾸는 것이지 게임자체를 바꿀게 아니니까 수정할게 없죠?\n",
        "class Bandit():\n",
        "    def step(self,action):\n",
        "        if action == 0: \n",
        "            return 1\n",
        "        else:\n",
        "            return 100"
      ],
      "id": "67665c93-1cd4-4dc5-b577-2de0ebc5cfb3"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "# learn 추가\n",
        "class Agent:\n",
        "    def __init__(self):\n",
        "        self.action_space = gym.spaces.Discrete(2)\n",
        "        self.action = None\n",
        "        self.reward = None\n",
        "        self.actions = []\n",
        "        self.rewards = []\n",
        "        self.n_experiences = 0\n",
        "        self.q = np.array([0,0])\n",
        "    def act(self):\n",
        "        if self.n_experiences < 30:\n",
        "            self.action = self.action_space.sample()\n",
        "        else:\n",
        "            self.action = np.random.choice([0, 1], p=self.q/self.q.sum())\n",
        "    def save_experience(self): \n",
        "        self.actions.append(self.action)\n",
        "        self.rewards.append(self.reward)\n",
        "        self.n_experiences = self.n_experiences + 1 \n",
        "    def learn(self):\n",
        "        if self.n_experiences < 30: \n",
        "            pass \n",
        "        else:\n",
        "            actions = np.array(self.actions)\n",
        "            rewards = np.array(self.rewards)\n",
        "            q0= rewards[actions==0].mean() \n",
        "            q1= rewards[actions==1].mean()        \n",
        "            self.q = np.array([q0,q1])"
      ],
      "id": "b87cd3f2-fc9a-4b0a-a0b3-cf350c19de61"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_try = 1   action = 1  reward = 100    rwd20 = 100 q = [0 0]\n",
            "n_try = 2   action = 1  reward = 100    rwd20 = 200 q = [0 0]\n",
            "n_try = 3   action = 1  reward = 100    rwd20 = 300 q = [0 0]\n",
            "n_try = 4   action = 0  reward = 1  rwd20 = 301 q = [0 0]\n",
            "n_try = 5   action = 0  reward = 1  rwd20 = 302 q = [0 0]\n",
            "n_try = 6   action = 1  reward = 100    rwd20 = 402 q = [0 0]\n",
            "n_try = 7   action = 0  reward = 1  rwd20 = 403 q = [0 0]\n",
            "n_try = 8   action = 1  reward = 100    rwd20 = 503 q = [0 0]\n",
            "n_try = 9   action = 0  reward = 1  rwd20 = 504 q = [0 0]\n",
            "n_try = 10  action = 0  reward = 1  rwd20 = 505 q = [0 0]\n",
            "n_try = 11  action = 1  reward = 100    rwd20 = 605 q = [0 0]\n",
            "n_try = 12  action = 1  reward = 100    rwd20 = 705 q = [0 0]\n",
            "n_try = 13  action = 1  reward = 100    rwd20 = 805 q = [0 0]\n",
            "n_try = 14  action = 1  reward = 100    rwd20 = 905 q = [0 0]\n",
            "n_try = 15  action = 1  reward = 100    rwd20 = 1005    q = [0 0]\n",
            "n_try = 16  action = 0  reward = 1  rwd20 = 1006    q = [0 0]\n",
            "n_try = 17  action = 0  reward = 1  rwd20 = 1007    q = [0 0]\n",
            "n_try = 18  action = 0  reward = 1  rwd20 = 1008    q = [0 0]\n",
            "n_try = 19  action = 1  reward = 100    rwd20 = 1108    q = [0 0]\n",
            "n_try = 20  action = 0  reward = 1  rwd20 = 1109    q = [0 0]\n",
            "n_try = 21  action = 0  reward = 1  rwd20 = 1010    q = [0 0]\n",
            "n_try = 22  action = 1  reward = 100    rwd20 = 1010    q = [0 0]\n",
            "n_try = 23  action = 0  reward = 1  rwd20 = 911 q = [0 0]\n",
            "n_try = 24  action = 0  reward = 1  rwd20 = 911 q = [0 0]\n",
            "n_try = 25  action = 0  reward = 1  rwd20 = 911 q = [0 0]\n",
            "n_try = 26  action = 1  reward = 100    rwd20 = 911 q = [0 0]\n",
            "n_try = 27  action = 1  reward = 100    rwd20 = 1010    q = [0 0]\n",
            "n_try = 28  action = 0  reward = 1  rwd20 = 911 q = [0 0]\n",
            "n_try = 29  action = 0  reward = 1  rwd20 = 911 q = [0 0]\n",
            "n_try = 30  action = 0  reward = 1  rwd20 = 911 q = [  1. 100.]\n",
            "n_try = 31  action = 1  reward = 100    rwd20 = 911 q = [  1. 100.]\n",
            "n_try = 32  action = 1  reward = 100    rwd20 = 911 q = [  1. 100.]\n",
            "n_try = 33  action = 1  reward = 100    rwd20 = 911 q = [  1. 100.]\n",
            "n_try = 34  action = 1  reward = 100    rwd20 = 911 q = [  1. 100.]\n",
            "n_try = 35  action = 1  reward = 100    rwd20 = 911 q = [  1. 100.]\n",
            "n_try = 36  action = 1  reward = 100    rwd20 = 1010    q = [  1. 100.]\n",
            "n_try = 37  action = 1  reward = 100    rwd20 = 1109    q = [  1. 100.]\n",
            "n_try = 38  action = 1  reward = 100    rwd20 = 1208    q = [  1. 100.]\n",
            "n_try = 39  action = 1  reward = 100    rwd20 = 1208    q = [  1. 100.]\n",
            "n_try = 40  action = 1  reward = 100    rwd20 = 1307    q = [  1. 100.]\n",
            "n_try = 41  action = 1  reward = 100    rwd20 = 1406    q = [  1. 100.]\n",
            "n_try = 42  action = 1  reward = 100    rwd20 = 1406    q = [  1. 100.]\n",
            "n_try = 43  action = 1  reward = 100    rwd20 = 1505    q = [  1. 100.]\n",
            "n_try = 44  action = 1  reward = 100    rwd20 = 1604    q = [  1. 100.]\n",
            "n_try = 45  action = 1  reward = 100    rwd20 = 1703    q = [  1. 100.]\n",
            "n_try = 46  action = 1  reward = 100    rwd20 = 1703    q = [  1. 100.]\n",
            "n_try = 47  action = 1  reward = 100    rwd20 = 1703    q = [  1. 100.]\n",
            "n_try = 48  action = 1  reward = 100    rwd20 = 1802    q = [  1. 100.]\n",
            "n_try = 49  action = 1  reward = 100    rwd20 = 1901    q = [  1. 100.]"
          ]
        }
      ],
      "source": [
        "env = Bandit()\n",
        "agent = Agent()\n",
        "for i in range(60):\n",
        "    ## 본질적인 코드\n",
        "    # step1: agent >> env \n",
        "    agent.act()\n",
        "    env.agent_action = agent.action \n",
        "    # step2: agnet << env \n",
        "    agent.reward = env.step(env.agent_action) \n",
        "    agent.save_experience()\n",
        "    # step3: learn\n",
        "    agent.learn()\n",
        "    \n",
        "    ## 비본질적 코드 \n",
        "    print(\n",
        "        f\"n_try = {agent.n_experiences}\\t\"\n",
        "        f\"action = {agent.action}\\t\"\n",
        "        f\"reward = {agent.reward}\\t\"\n",
        "        f\"rwd20 = {np.sum(agent.rewards[-20:])}\\t\"\n",
        "        f\"q = {agent.q}\"\n",
        "    )\n",
        "    if np.sum(agent.rewards[-20:])>1900:\n",
        "        break"
      ],
      "id": "63a98fa1-f6b1-43e1-a037-c5662d904bb1"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  }
}