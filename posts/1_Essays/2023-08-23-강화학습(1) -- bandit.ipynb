{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c1e9fa04-6ae1-4c9a-8951-e6c8a2dbbc32",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"**[Essays]** 강화학습(1) -- bandit\"\n",
    "author: \"신록예찬\"\n",
    "date: \"08/23/2023\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e99970-800a-4db5-836a-c90f91c78883",
   "metadata": {},
   "source": [
    "# 환경셋팅 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999137d6-3490-456b-a0d4-cef641649cea",
   "metadata": {},
   "source": [
    "`-` 설치  \n",
    "\n",
    "```Python\n",
    "!pip install -q swig\n",
    "!pip install gymnasium\n",
    "!pip install gymnasium[box2d]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f811c2f-fda8-472e-818b-16be2dc72e69",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df6688cb-b243-4e39-80c3-3886d1481186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecbb46a-57bb-42ba-8505-27fd76d46f84",
   "metadata": {},
   "source": [
    "# Intro "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44201b4d-cc97-41f8-b546-51b34488edc4",
   "metadata": {},
   "source": [
    "`-` 강화학습(대충설명): 어떠한 \"(게임)환경\"이 있을때 거기서 \"뭘 할지\"를 학습하는 과업"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41290c2-a566-4ddc-95bc-31ad38c7c70c",
   "metadata": {},
   "source": [
    "`-` 딥마인드: breakout $\\to$ 알파고 \n",
    "\n",
    "<https://www.youtube.com/watch?v=TmPfTpjtdgg>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1161a00e-f943-453c-b548-03f69e4a5103",
   "metadata": {},
   "source": [
    "`-` 강화학습의 미래? (이거 잘하면 먹고 살 수 있을까?) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f59b1b-5bef-461b-a47b-0d0a36627085",
   "metadata": {},
   "source": [
    "# Game1: 벤딧문제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363a599e-56d5-4f52-a952-5d1839b01fe7",
   "metadata": {},
   "source": [
    "`-` 문제설명: 두개의 버튼이 있다. 버튼0을 누르면 1의 보상을, 버튼1를 누르면 100의 보상을 준다고 가정 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fe24a3-7249-4e7f-ba05-6532b733824e",
   "metadata": {},
   "source": [
    "`-` 어떤 행동을 해야할까? --> ?? 아는게없음 --> 일단 \"아무거나\" 눌러보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d771a51a-0733-42df-bf20-b06444164b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'button1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_space = ['button0','button1']\n",
    "action = np.random.choice(action_space)\n",
    "action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a8f6c1-bd25-43fb-91e4-d2cb5ae3968d",
   "metadata": {},
   "source": [
    "`-` 보상은 아래와 같은 방식으로 받을 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97ab8e9f-5d74-4600-bbc9-64ed47fec6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if action == 'button0': \n",
    "    reward = 1 \n",
    "else:\n",
    "    reward = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33183f9f-25fc-4d2d-a883-6ced86f080fc",
   "metadata": {},
   "source": [
    "`-` 아무거나 10번 버튼을 눌러보면 다음과 같은 결과가 나온다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afb693ba-a1f0-4886-88f2-093c8c632cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "button1 100\n",
      "button0 1\n",
      "button1 100\n",
      "button1 100\n",
      "button1 100\n",
      "button1 100\n",
      "button0 1\n",
      "button0 1\n",
      "button1 100\n",
      "button1 100\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    action = np.random.choice(action_space)\n",
    "    if action == 'button0': \n",
    "        reward = 1 \n",
    "    else:\n",
    "        reward = 100\n",
    "    print(action,reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c3b95f-1ce7-4e51-af68-4b9e48e9cb61",
   "metadata": {},
   "source": [
    "`-` 깨달았음: `button0`을 누르면 1점을 받고, `button1`을 누르면 100점을 받는 \"환경\"이구나? $\\to$ `button1`을 누르는 \"동작\"을 해야하는 상황이구나? \n",
    "\n",
    "- 여기에서 $\\to$ 의 과정을 체계화 시킨 학문이 강화학습이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a189b7f-eaaf-4d7e-b2a9-b9742ab245d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "button1 100\n",
      "button1 100\n",
      "button1 100\n",
      "button1 100\n",
      "button1 100\n",
      "button1 100\n",
      "button1 100\n",
      "button1 100\n",
      "button1 100\n",
      "button1 100\n"
     ]
    }
   ],
   "source": [
    "action_space = ['button0','button1']\n",
    "for _ in range(10):\n",
    "    #action = np.random.choice(action_space) # 무지한자의 행동 (찍어)\n",
    "    action = action_space[1] # 깨달은자의 행동 (button1을 눌러)\n",
    "    if action == 'button0': \n",
    "        reward = 1 \n",
    "    else:\n",
    "        reward = 100\n",
    "    print(action,reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4889869-c687-4ce1-a419-f2b4b42002df",
   "metadata": {},
   "source": [
    "`-` 강화학습: 환경의 이해 $\\to$ 뭘 해야 하는지 깨달음\n",
    "\n",
    "**위의 과정이 잘 되었다는 의미로 사용하는 문장들**\n",
    "\n",
    "- 강화학습이 성공적으로 잘 되었다.\n",
    "- 환경이 해결되었다.\n",
    "- 에이전트가 환경의 과제를 완료했다.\n",
    "- 에이전트가 환경에서 성공적으로 학습했다.\n",
    "- 에이전트가 올바른 행동을 학습했다.\n",
    "- 게임 클리어 (비공식)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e455131b-c00a-4c38-9158-abbc70165848",
   "metadata": {},
   "source": [
    "`-` 환경이 해결되었는지 나타내는 지표를 정해야겠다 $\\to$ 주어진 상황을 게임처럼 이해하고, 게임의 클리어조건을 설정 \n",
    "\n",
    "- 첫 생각: `button1`을 누르면 클리어 아니야?\n",
    "- 두번째 생각: 아니지? 우연히 누를수도 있잖아.\n",
    "- 게임클리어조건: 최근 20번의 보상이 1900 이상이면 게임이 클리어 되었다고 보자!^[`button1`을 눌러야하는건 맞지만 20번에 실수한번정도는 눈감아 주자]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a17389-0722-4232-b148-f5deccdddcff",
   "metadata": {},
   "source": [
    "`-` 무지한자 -- 게임을 클리어 할 수 없다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd7ee8d2-4bef-4901-98a3-766efc21c600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_try = 1\taction = button1\treward = 100\trwd20 = 100\n",
      "n_try = 2\taction = button1\treward = 100\trwd20 = 200\n",
      "n_try = 3\taction = button1\treward = 100\trwd20 = 300\n",
      "n_try = 4\taction = button0\treward = 1\trwd20 = 301\n",
      "n_try = 5\taction = button1\treward = 100\trwd20 = 401\n",
      "n_try = 6\taction = button1\treward = 100\trwd20 = 501\n",
      "n_try = 7\taction = button0\treward = 1\trwd20 = 502\n",
      "n_try = 8\taction = button1\treward = 100\trwd20 = 602\n",
      "n_try = 9\taction = button0\treward = 1\trwd20 = 603\n",
      "n_try = 10\taction = button1\treward = 100\trwd20 = 703\n",
      "n_try = 11\taction = button0\treward = 1\trwd20 = 704\n",
      "n_try = 12\taction = button0\treward = 1\trwd20 = 705\n",
      "n_try = 13\taction = button0\treward = 1\trwd20 = 706\n",
      "n_try = 14\taction = button1\treward = 100\trwd20 = 806\n",
      "n_try = 15\taction = button1\treward = 100\trwd20 = 906\n",
      "n_try = 16\taction = button0\treward = 1\trwd20 = 907\n",
      "n_try = 17\taction = button1\treward = 100\trwd20 = 1007\n",
      "n_try = 18\taction = button1\treward = 100\trwd20 = 1107\n",
      "n_try = 19\taction = button0\treward = 1\trwd20 = 1108\n",
      "n_try = 20\taction = button0\treward = 1\trwd20 = 1109\n",
      "n_try = 21\taction = button1\treward = 100\trwd20 = 1109\n",
      "n_try = 22\taction = button0\treward = 1\trwd20 = 1010\n",
      "n_try = 23\taction = button1\treward = 100\trwd20 = 1010\n",
      "n_try = 24\taction = button1\treward = 100\trwd20 = 1109\n",
      "n_try = 25\taction = button1\treward = 100\trwd20 = 1109\n",
      "n_try = 26\taction = button0\treward = 1\trwd20 = 1010\n",
      "n_try = 27\taction = button1\treward = 100\trwd20 = 1109\n",
      "n_try = 28\taction = button1\treward = 100\trwd20 = 1109\n",
      "n_try = 29\taction = button1\treward = 100\trwd20 = 1208\n",
      "n_try = 30\taction = button1\treward = 100\trwd20 = 1208\n",
      "n_try = 31\taction = button1\treward = 100\trwd20 = 1307\n",
      "n_try = 32\taction = button0\treward = 1\trwd20 = 1307\n",
      "n_try = 33\taction = button1\treward = 100\trwd20 = 1406\n",
      "n_try = 34\taction = button1\treward = 100\trwd20 = 1406\n",
      "n_try = 35\taction = button0\treward = 1\trwd20 = 1307\n",
      "n_try = 36\taction = button0\treward = 1\trwd20 = 1307\n",
      "n_try = 37\taction = button0\treward = 1\trwd20 = 1208\n",
      "n_try = 38\taction = button0\treward = 1\trwd20 = 1109\n",
      "n_try = 39\taction = button1\treward = 100\trwd20 = 1208\n",
      "n_try = 40\taction = button1\treward = 100\trwd20 = 1307\n",
      "n_try = 41\taction = button0\treward = 1\trwd20 = 1208\n",
      "n_try = 42\taction = button0\treward = 1\trwd20 = 1208\n",
      "n_try = 43\taction = button1\treward = 100\trwd20 = 1208\n",
      "n_try = 44\taction = button1\treward = 100\trwd20 = 1208\n",
      "n_try = 45\taction = button1\treward = 100\trwd20 = 1208\n",
      "n_try = 46\taction = button1\treward = 100\trwd20 = 1307\n",
      "n_try = 47\taction = button0\treward = 1\trwd20 = 1208\n",
      "n_try = 48\taction = button0\treward = 1\trwd20 = 1109\n",
      "n_try = 49\taction = button0\treward = 1\trwd20 = 1010\n",
      "n_try = 50\taction = button1\treward = 100\trwd20 = 1010\n"
     ]
    }
   ],
   "source": [
    "action_space = ['button0','button1']\n",
    "rewards = []\n",
    "for i in range(50): # 1000번해도 못깸\n",
    "    action = np.random.choice(action_space) # 무지한자의 행동 (찍어)\n",
    "    #action = action_space[1] # 깨달은자의 행동 (button1을 눌러)\n",
    "    if action == 'button0': \n",
    "        reward = 1 \n",
    "        rewards.append(reward)\n",
    "    else:\n",
    "        reward = 100\n",
    "        rewards.append(reward)\n",
    "    print(\n",
    "        f\"n_try = {i+1}\\t\"\n",
    "        f\"action = {action}\\t\"\n",
    "        f\"reward = {reward}\\t\"\n",
    "        f\"rwd20 = {sum(rewards[-20:])}\"\n",
    "    )\n",
    "    if np.sum(rewards[-20:])>1900:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dedceb-fe4b-4a2c-8f89-56783ee4c20c",
   "metadata": {},
   "source": [
    "`-` 깨달은자 -- 게임 클리어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a47f0eea-5688-454a-8c9d-9e4c6d5552fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_try = 1\taction = button1\treward = 100\trwd20 = 100\n",
      "n_try = 2\taction = button1\treward = 100\trwd20 = 200\n",
      "n_try = 3\taction = button1\treward = 100\trwd20 = 300\n",
      "n_try = 4\taction = button1\treward = 100\trwd20 = 400\n",
      "n_try = 5\taction = button1\treward = 100\trwd20 = 500\n",
      "n_try = 6\taction = button1\treward = 100\trwd20 = 600\n",
      "n_try = 7\taction = button1\treward = 100\trwd20 = 700\n",
      "n_try = 8\taction = button1\treward = 100\trwd20 = 800\n",
      "n_try = 9\taction = button1\treward = 100\trwd20 = 900\n",
      "n_try = 10\taction = button1\treward = 100\trwd20 = 1000\n",
      "n_try = 11\taction = button1\treward = 100\trwd20 = 1100\n",
      "n_try = 12\taction = button1\treward = 100\trwd20 = 1200\n",
      "n_try = 13\taction = button1\treward = 100\trwd20 = 1300\n",
      "n_try = 14\taction = button1\treward = 100\trwd20 = 1400\n",
      "n_try = 15\taction = button1\treward = 100\trwd20 = 1500\n",
      "n_try = 16\taction = button1\treward = 100\trwd20 = 1600\n",
      "n_try = 17\taction = button1\treward = 100\trwd20 = 1700\n",
      "n_try = 18\taction = button1\treward = 100\trwd20 = 1800\n",
      "n_try = 19\taction = button1\treward = 100\trwd20 = 1900\n",
      "n_try = 20\taction = button1\treward = 100\trwd20 = 2000\n"
     ]
    }
   ],
   "source": [
    "action_space = ['button0','button1']\n",
    "rewards = []\n",
    "for i in range(50): # 1000번해도 못깸\n",
    "    #action = np.random.choice(action_space) # 무지한자의 행동 (찍어)\n",
    "    action = action_space[1] # 깨달은자의 행동 (button1을 눌러)\n",
    "    if action == 'button0': \n",
    "        reward = 1 \n",
    "        rewards.append(reward)\n",
    "    else:\n",
    "        reward = 100\n",
    "        rewards.append(reward)\n",
    "    print(\n",
    "        f\"n_try = {i+1}\\t\"\n",
    "        f\"action = {action}\\t\"\n",
    "        f\"reward = {reward}\\t\"\n",
    "        f\"rwd20 = {sum(rewards[-20:])}\"\n",
    "    )\n",
    "    if np.sum(rewards[-20:])>1900:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde7a39a-e09d-4575-a368-d84c5b2d2c9e",
   "metadata": {},
   "source": [
    "# 수정1: `action_space`의 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b1d0578-eb81-4dc3-a1ba-1653e7e73aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_space =  gym.spaces.Discrete(2)\n",
    "action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55f236a-4393-485a-9f2f-716e789f9ee6",
   "metadata": {},
   "source": [
    "`-` 좋은점1: sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c796bc8-d37c-4b05-8ee1-14c5bb6f177d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(action_space.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5b06d5-8e75-4b53-b80e-3d62faf96e96",
   "metadata": {},
   "source": [
    "`-` 좋은점2: in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a10de998-fd16-480b-8360-d1c41f3eccd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0 in action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b765df83-0ef1-4533-9ba4-5953f264595d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 in action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "522688ea-b1b6-4545-8001-6cfe16b944a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 in action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a981a650-1690-4839-b843-3eeba29c33dc",
   "metadata": {},
   "source": [
    "`-` 코드 1차수정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d4e9079-5aff-468a-8037-b1a19e8e1bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_try = 1\taction = 0\treward = 1\trwd20 = 1\n",
      "n_try = 2\taction = 0\treward = 1\trwd20 = 2\n",
      "n_try = 3\taction = 0\treward = 1\trwd20 = 3\n",
      "n_try = 4\taction = 0\treward = 1\trwd20 = 4\n",
      "n_try = 5\taction = 0\treward = 1\trwd20 = 5\n",
      "n_try = 6\taction = 1\treward = 100\trwd20 = 105\n",
      "n_try = 7\taction = 1\treward = 100\trwd20 = 205\n",
      "n_try = 8\taction = 1\treward = 100\trwd20 = 305\n",
      "n_try = 9\taction = 1\treward = 100\trwd20 = 405\n",
      "n_try = 10\taction = 0\treward = 1\trwd20 = 406\n",
      "n_try = 11\taction = 0\treward = 1\trwd20 = 407\n",
      "n_try = 12\taction = 1\treward = 100\trwd20 = 507\n",
      "n_try = 13\taction = 0\treward = 1\trwd20 = 508\n",
      "n_try = 14\taction = 0\treward = 1\trwd20 = 509\n",
      "n_try = 15\taction = 0\treward = 1\trwd20 = 510\n",
      "n_try = 16\taction = 0\treward = 1\trwd20 = 511\n",
      "n_try = 17\taction = 1\treward = 100\trwd20 = 611\n",
      "n_try = 18\taction = 0\treward = 1\trwd20 = 612\n",
      "n_try = 19\taction = 0\treward = 1\trwd20 = 613\n",
      "n_try = 20\taction = 1\treward = 100\trwd20 = 713\n",
      "n_try = 21\taction = 0\treward = 1\trwd20 = 713\n",
      "n_try = 22\taction = 1\treward = 100\trwd20 = 812\n",
      "n_try = 23\taction = 1\treward = 100\trwd20 = 911\n",
      "n_try = 24\taction = 0\treward = 1\trwd20 = 911\n",
      "n_try = 25\taction = 1\treward = 100\trwd20 = 1010\n",
      "n_try = 26\taction = 1\treward = 100\trwd20 = 1010\n",
      "n_try = 27\taction = 0\treward = 1\trwd20 = 911\n",
      "n_try = 28\taction = 1\treward = 100\trwd20 = 911\n",
      "n_try = 29\taction = 1\treward = 100\trwd20 = 911\n",
      "n_try = 30\taction = 0\treward = 1\trwd20 = 911\n",
      "n_try = 31\taction = 0\treward = 1\trwd20 = 911\n",
      "n_try = 32\taction = 1\treward = 100\trwd20 = 911\n",
      "n_try = 33\taction = 0\treward = 1\trwd20 = 911\n",
      "n_try = 34\taction = 0\treward = 1\trwd20 = 911\n",
      "n_try = 35\taction = 1\treward = 100\trwd20 = 1010\n",
      "n_try = 36\taction = 0\treward = 1\trwd20 = 1010\n",
      "n_try = 37\taction = 0\treward = 1\trwd20 = 911\n",
      "n_try = 38\taction = 0\treward = 1\trwd20 = 911\n",
      "n_try = 39\taction = 0\treward = 1\trwd20 = 911\n",
      "n_try = 40\taction = 0\treward = 1\trwd20 = 812\n",
      "n_try = 41\taction = 1\treward = 100\trwd20 = 911\n",
      "n_try = 42\taction = 1\treward = 100\trwd20 = 911\n",
      "n_try = 43\taction = 0\treward = 1\trwd20 = 812\n",
      "n_try = 44\taction = 0\treward = 1\trwd20 = 812\n",
      "n_try = 45\taction = 1\treward = 100\trwd20 = 812\n",
      "n_try = 46\taction = 1\treward = 100\trwd20 = 812\n",
      "n_try = 47\taction = 0\treward = 1\trwd20 = 812\n",
      "n_try = 48\taction = 1\treward = 100\trwd20 = 812\n",
      "n_try = 49\taction = 1\treward = 100\trwd20 = 812\n",
      "n_try = 50\taction = 1\treward = 100\trwd20 = 911\n"
     ]
    }
   ],
   "source": [
    "action_space = gym.spaces.Discrete(2)\n",
    "rewards = []\n",
    "for i in range(50): # 1000번해도 못깸\n",
    "    action = action_space.sample() # 무지한자의 행동 (찍어)\n",
    "    #action = 1 # 깨달은자의 행동 (button1을 눌러)\n",
    "    if action == 0: \n",
    "        reward = 1 \n",
    "        rewards.append(reward)\n",
    "    else:\n",
    "        reward = 100\n",
    "        rewards.append(reward)\n",
    "    print(\n",
    "        f\"n_try = {i+1}\\t\"\n",
    "        f\"action = {action}\\t\"\n",
    "        f\"reward = {reward}\\t\"\n",
    "        f\"rwd20 = {sum(rewards[-20:])}\"\n",
    "    )\n",
    "    if np.sum(rewards[-20:])>1900:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe7aa65-a4f3-478e-8afd-3cb48908cb18",
   "metadata": {},
   "source": [
    "# 수정2: Env 클래스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d802bfdd-7ede-48f8-8eef-ee4d549ec7e2",
   "metadata": {},
   "source": [
    "`-` env 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f8150e2-9959-4020-9414-e82e6b3795c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bandit:\n",
    "    def step(self,action):\n",
    "        if action == 0: \n",
    "            return 1\n",
    "        else:\n",
    "            return 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2af252df-c080-412f-b549-084f8721d507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_try = 1\taction = 1\treward = 100\trwd20 = 100\n",
      "n_try = 2\taction = 1\treward = 100\trwd20 = 200\n",
      "n_try = 3\taction = 1\treward = 100\trwd20 = 300\n",
      "n_try = 4\taction = 1\treward = 100\trwd20 = 400\n",
      "n_try = 5\taction = 1\treward = 100\trwd20 = 500\n",
      "n_try = 6\taction = 1\treward = 100\trwd20 = 600\n",
      "n_try = 7\taction = 1\treward = 100\trwd20 = 700\n",
      "n_try = 8\taction = 1\treward = 100\trwd20 = 800\n",
      "n_try = 9\taction = 1\treward = 100\trwd20 = 900\n",
      "n_try = 10\taction = 1\treward = 100\trwd20 = 1000\n",
      "n_try = 11\taction = 1\treward = 100\trwd20 = 1100\n",
      "n_try = 12\taction = 1\treward = 100\trwd20 = 1200\n",
      "n_try = 13\taction = 1\treward = 100\trwd20 = 1300\n",
      "n_try = 14\taction = 1\treward = 100\trwd20 = 1400\n",
      "n_try = 15\taction = 1\treward = 100\trwd20 = 1500\n",
      "n_try = 16\taction = 1\treward = 100\trwd20 = 1600\n",
      "n_try = 17\taction = 1\treward = 100\trwd20 = 1700\n",
      "n_try = 18\taction = 1\treward = 100\trwd20 = 1800\n",
      "n_try = 19\taction = 1\treward = 100\trwd20 = 1900\n",
      "n_try = 20\taction = 1\treward = 100\trwd20 = 2000\n"
     ]
    }
   ],
   "source": [
    "env = Bandit()\n",
    "rewards = []\n",
    "for i in range(50): # 1000번해도 못깸\n",
    "    #action = action_space.sample() # 무지한자의 행동 (찍어)\n",
    "    action = 1 # 깨달은자의 행동 (button1을 눌러)\n",
    "    reward = env.step(action)\n",
    "    rewards.append(reward)\n",
    "    print(\n",
    "        f\"n_try = {i+1}\\t\"\n",
    "        f\"action = {action}\\t\"\n",
    "        f\"reward = {reward}\\t\"\n",
    "        f\"rwd20 = {sum(rewards[-20:])}\"\n",
    "    )\n",
    "    if np.sum(rewards[-20:])>1900:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab6b075-778a-4dcc-b813-50cbd8074d5c",
   "metadata": {},
   "source": [
    "# 수정3: Agent 클래스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3166cb6b-2cf0-46e9-b801-38a467904a7c",
   "metadata": {},
   "source": [
    "`-` Agent 클래스를 만들자 (액션을 하고, 환경에서 받은 reward를 간직하도록)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a8a43e7-3975-487b-a643-8c7266112c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent1:\n",
    "    def __init__(self):\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "        self.action = None\n",
    "        self.reward = None\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "    def act(self):\n",
    "        # self.action = self.action_space.sample() # 무지한 자\n",
    "        self.action = 1 # 깨달은 자 \n",
    "    def save_experience(self): \n",
    "        self.actions.append(self.action)\n",
    "        self.rewards.append(self.reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d06a51c-e845-4591-973c-54c330ac9a7f",
   "metadata": {},
   "source": [
    "--- 대충 아래와 같은 느낌으로 돌아가요 ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2b3b33-1cc3-468f-8370-fcffc269b4fe",
   "metadata": {},
   "source": [
    "**시점0**: init "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e3fa8f0-b41f-4d92-9477-1f6725c4e831",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Bandit()\n",
    "agent = Agent1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b528099-158b-4e65-8181-92d1a6372d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action, agent.reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de742dd9-4f82-4fde-b30f-42a5e952e36f",
   "metadata": {},
   "source": [
    "**시점1**: agent >> env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "545483f3-e2e3-4fd5-9009-f22df31761aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.act()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7b88291-b73b-4deb-9469-0b50e06a0d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action, agent.reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1cc49b4-180f-4ac6-8322-82bc0d36dc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.agent_action = agent.action "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b19a4d7-b01d-4cf7-9497-1e42221b4094",
   "metadata": {},
   "source": [
    "**시점2**: agent << env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd742d0b-e19c-4194-b581-5aa0cac4a12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.reward = env.step(env.agent_action) \n",
    "# agent.reward = env.step(agent.action) 도 같은 결과를 주는 코드임!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3b53960-00d4-4652-9500-dc3860688ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action, agent.reward, env.agent_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55df6ce8-fc00-42be-a880-ab486a16c469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.actions, agent.rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4e131cf-05a0-44e7-8421-80f5458d47a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.save_experience()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f1024c0-f468-41cc-8f62-52811b1fc8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1], [100])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.actions, agent.rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81eb0b9-27c4-4281-875e-fe65651465ae",
   "metadata": {},
   "source": [
    "--- 전체코드 --- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd8ebd38-0b87-47f5-bf32-141a42388734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_try = 1\taction = 1\treward = 100\trwd20 = 100\n",
      "n_try = 2\taction = 1\treward = 100\trwd20 = 200\n",
      "n_try = 3\taction = 1\treward = 100\trwd20 = 300\n",
      "n_try = 4\taction = 1\treward = 100\trwd20 = 400\n",
      "n_try = 5\taction = 1\treward = 100\trwd20 = 500\n",
      "n_try = 6\taction = 1\treward = 100\trwd20 = 600\n",
      "n_try = 7\taction = 1\treward = 100\trwd20 = 700\n",
      "n_try = 8\taction = 1\treward = 100\trwd20 = 800\n",
      "n_try = 9\taction = 1\treward = 100\trwd20 = 900\n",
      "n_try = 10\taction = 1\treward = 100\trwd20 = 1000\n",
      "n_try = 11\taction = 1\treward = 100\trwd20 = 1100\n",
      "n_try = 12\taction = 1\treward = 100\trwd20 = 1200\n",
      "n_try = 13\taction = 1\treward = 100\trwd20 = 1300\n",
      "n_try = 14\taction = 1\treward = 100\trwd20 = 1400\n",
      "n_try = 15\taction = 1\treward = 100\trwd20 = 1500\n",
      "n_try = 16\taction = 1\treward = 100\trwd20 = 1600\n",
      "n_try = 17\taction = 1\treward = 100\trwd20 = 1700\n",
      "n_try = 18\taction = 1\treward = 100\trwd20 = 1800\n",
      "n_try = 19\taction = 1\treward = 100\trwd20 = 1900\n",
      "n_try = 20\taction = 1\treward = 100\trwd20 = 2000\n"
     ]
    }
   ],
   "source": [
    "env = Bandit()\n",
    "agent = Agent1()\n",
    "for i in range(50):\n",
    "    ## 1. 본질적인 코드\n",
    "    # step1: agent >> env \n",
    "    agent.act()\n",
    "    env.agent_action = agent.action \n",
    "    # step2: agnet << env \n",
    "    agent.reward = env.step(env.agent_action) \n",
    "    agent.save_experience()\n",
    "    \n",
    "    ## 2. 비본질적 코드 \n",
    "    print(\n",
    "        f\"n_try = {i+1}\\t\"\n",
    "        f\"action = {agent.action}\\t\"\n",
    "        f\"reward = {agent.reward}\\t\"\n",
    "        f\"rwd20 = {sum(agent.rewards[-20:])}\"\n",
    "    )\n",
    "    if np.sum(agent.rewards[-20:])>1900:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ea51d8-a117-4596-9b38-4ae27be93c3b",
   "metadata": {},
   "source": [
    "- 위의 코드를 거의 뼈대로 사용합니당!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cde14e5-49a0-4a07-9833-040517f99fc1",
   "metadata": {},
   "source": [
    "# 학습과정 포함 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8671e2-f2cd-420a-be50-dbf896266ae4",
   "metadata": {},
   "source": [
    "`-` Game1에 대한 생각: \n",
    "\n",
    "- 사실 강화학습은 \"환경을 이해 $\\to$ 뭘 해야 하는지 깨달음\" 의 과정에서 화살표를 수식화 하는 과정이다.\n",
    "- 지금까지 살펴보면 Game1은 환경(env)을 이해하는 순간 에이전트가 최적의 행동(action)^[`button1`을 누른다]을 직관적으로 결정하였으므로 학습의 과정이 포함되었다고 볼 수 없다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26759750-4762-427a-993e-179c2fd859fe",
   "metadata": {},
   "source": [
    "`-` 지금까지의 코드 복습 \n",
    "\n",
    "1. 클래스를 선언하는 부분\n",
    "   - `Env`클래스의 선언\n",
    "   - `Agent`클래스의 선언\n",
    "2. 환경과 에이전트를 인스턴스화 (초기화)\n",
    "3. for loop를 반복하며 게임을 진행\n",
    "   - 메인코드: (1) agent >> env (2) agent << env (3) 데이터저장\n",
    "   - 비본질적코드: 학습과정 display, 학습종료조건"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bff0af3-9ed9-44d4-8cf9-8d53d773b3ae",
   "metadata": {},
   "source": [
    "`-` 앞으로 구성할 코드의 형태: 에이전트가 데이터를 보고 스스로 `button1`을 눌러야 한다는 것을 추론하면 좋겠음\n",
    "\n",
    "1. 클래스를 선언하는 부분\n",
    "   - `Env`클래스의 선언\n",
    "   - **`Agent`클래스의 선언**: **학습의 과정 포함 $\\to$ act함수 수정**\n",
    "2. 환경과 에이전트를 인스턴스화 (초기화)\n",
    "3. for loop를 반복하며 게임을 진행\n",
    "   - 메인코드: (1) agent >> env (2) agent << env (3) 데이터저장 **(4) 학습**\n",
    "   - 비본질적코드: 학습과정 display, 학습종료조건"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af18dd6d-f1f0-47e9-bc44-444c27136976",
   "metadata": {},
   "source": [
    "`-` 에이전트가 학습을 어떻게 하는가?^[행동을 이런식으로 하도록 \"전략(=정책)\"을 설정하는 것은 상식적이다. 그렇지만 유일한 해결책은 아님!!]\n",
    "\n",
    "- $\\pi(0) = \\frac{Q_t(1)}{Q_t(1)+Q_t(0)}$\n",
    "- $\\pi(1) = \\frac{Q_t(0)}{Q_t(1)+Q_t(0)}$\n",
    "\n",
    "여기에서 각각의 기호는 아래를 의미한다. \n",
    "\n",
    "- $\\pi(0)$: 에이전트가 action = 0 을 할 확률, 즉 에이전트가 `button0`을 누를 확률\n",
    "- $\\pi(1)$: 에이전트가 action = 1 을 할 확률, 즉 에이전트가 `button1`을 누를 확률\n",
    "- $Q_t(0)$: ($t$시점까지 파악한) action = 0 을 하였을 경우 에이전트가 환경으로 받은 보상의 평균값 \n",
    "- $Q_t(1)$: ($t$시점까지 파악한) action = 1 을 하였을 경우 에이전트가 환경으로 받은 보상의 평균값 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a199086-d25d-4acb-9dc4-bddac037c9e7",
   "metadata": {},
   "source": [
    "`-` 걱정: $t=0$이면 어쩌지? $t=1$이면 어쩌지?.. $\\to$ 잡기술1: 일정 시간동안은 랜덤액션을 하면서 데이터를 쌓자. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec2c9d1-9916-44b2-8c11-fded7af0e500",
   "metadata": {},
   "source": [
    "`-` 쌓은 데이터를 바탕으로 환경을 이해하고 action을 뽑는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad0bddcd-a6a6-4ff9-bf74-6e65210cba68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 1, 1, 1, 1, 0]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.actions = [0,0,1,0,0,1,1,1,1,0]\n",
    "agent.actions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ad6ae8e-9ff1-4bc9-bcb8-230177d572bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0.9, 105, 1.2, 1, 95, 100, 101, 90, 1]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.rewards = [1,0.9,105,1.2,1,95,100,101,90,1]\n",
    "agent.rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "02f5a801-b7f0-4647-999d-eab0f35cfe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = np.array(agent.actions)\n",
    "rewards = np.array(agent.rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ba856ab-f709-4716-ad6f-09a77295220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "q0= rewards[actions==0].mean()\n",
    "q1= rewards[actions==1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "afeae8aa-afff-4ea7-a9c2-bbe288e95145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.02, 98.2 ])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.q = np.array([q0,q1])\n",
    "agent.q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "988ff6d7-8370-4d44-9afa-3bfe2a25693f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = np.random.choice([0,1],p=agent.q/agent.q.sum())\n",
    "action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd816c5-5039-466f-a960-999c4a3c8be5",
   "metadata": {},
   "source": [
    "`-` 코드를 구현해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67665c93-1cd4-4dc5-b577-2de0ebc5cfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 게임을 푸는 전략을 바꾸는 것이지 게임자체를 바꿀게 아니니까 수정할게 없죠?\n",
    "class Bandit():\n",
    "    def step(self,action):\n",
    "        if action == 0: \n",
    "            return 1\n",
    "        else:\n",
    "            return 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b87cd3f2-fc9a-4b0a-a0b3-cf350c19de61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn 추가\n",
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "        self.action = None\n",
    "        self.reward = None\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.n_experiences = 0\n",
    "        self.q = np.array([0,0])\n",
    "    def act(self):\n",
    "        if self.n_experiences < 30:\n",
    "            self.action = self.action_space.sample()\n",
    "        else:\n",
    "            self.action = np.random.choice([0, 1], p=self.q/self.q.sum())\n",
    "    def save_experience(self): \n",
    "        self.actions.append(self.action)\n",
    "        self.rewards.append(self.reward)\n",
    "        self.n_experiences = self.n_experiences + 1 \n",
    "    def learn(self):\n",
    "        if self.n_experiences < 30: \n",
    "            pass \n",
    "        else:\n",
    "            actions = np.array(self.actions)\n",
    "            rewards = np.array(self.rewards)\n",
    "            q0= rewards[actions==0].mean() \n",
    "            q1= rewards[actions==1].mean()        \n",
    "            self.q = np.array([q0,q1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "63a98fa1-f6b1-43e1-a037-c5662d904bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_try = 1\taction = 1\treward = 100\trwd20 = 100\tq = [0 0]\n",
      "n_try = 2\taction = 1\treward = 100\trwd20 = 200\tq = [0 0]\n",
      "n_try = 3\taction = 1\treward = 100\trwd20 = 300\tq = [0 0]\n",
      "n_try = 4\taction = 0\treward = 1\trwd20 = 301\tq = [0 0]\n",
      "n_try = 5\taction = 0\treward = 1\trwd20 = 302\tq = [0 0]\n",
      "n_try = 6\taction = 1\treward = 100\trwd20 = 402\tq = [0 0]\n",
      "n_try = 7\taction = 0\treward = 1\trwd20 = 403\tq = [0 0]\n",
      "n_try = 8\taction = 1\treward = 100\trwd20 = 503\tq = [0 0]\n",
      "n_try = 9\taction = 0\treward = 1\trwd20 = 504\tq = [0 0]\n",
      "n_try = 10\taction = 0\treward = 1\trwd20 = 505\tq = [0 0]\n",
      "n_try = 11\taction = 1\treward = 100\trwd20 = 605\tq = [0 0]\n",
      "n_try = 12\taction = 1\treward = 100\trwd20 = 705\tq = [0 0]\n",
      "n_try = 13\taction = 1\treward = 100\trwd20 = 805\tq = [0 0]\n",
      "n_try = 14\taction = 1\treward = 100\trwd20 = 905\tq = [0 0]\n",
      "n_try = 15\taction = 1\treward = 100\trwd20 = 1005\tq = [0 0]\n",
      "n_try = 16\taction = 0\treward = 1\trwd20 = 1006\tq = [0 0]\n",
      "n_try = 17\taction = 0\treward = 1\trwd20 = 1007\tq = [0 0]\n",
      "n_try = 18\taction = 0\treward = 1\trwd20 = 1008\tq = [0 0]\n",
      "n_try = 19\taction = 1\treward = 100\trwd20 = 1108\tq = [0 0]\n",
      "n_try = 20\taction = 0\treward = 1\trwd20 = 1109\tq = [0 0]\n",
      "n_try = 21\taction = 0\treward = 1\trwd20 = 1010\tq = [0 0]\n",
      "n_try = 22\taction = 1\treward = 100\trwd20 = 1010\tq = [0 0]\n",
      "n_try = 23\taction = 0\treward = 1\trwd20 = 911\tq = [0 0]\n",
      "n_try = 24\taction = 0\treward = 1\trwd20 = 911\tq = [0 0]\n",
      "n_try = 25\taction = 0\treward = 1\trwd20 = 911\tq = [0 0]\n",
      "n_try = 26\taction = 1\treward = 100\trwd20 = 911\tq = [0 0]\n",
      "n_try = 27\taction = 1\treward = 100\trwd20 = 1010\tq = [0 0]\n",
      "n_try = 28\taction = 0\treward = 1\trwd20 = 911\tq = [0 0]\n",
      "n_try = 29\taction = 0\treward = 1\trwd20 = 911\tq = [0 0]\n",
      "n_try = 30\taction = 0\treward = 1\trwd20 = 911\tq = [  1. 100.]\n",
      "n_try = 31\taction = 1\treward = 100\trwd20 = 911\tq = [  1. 100.]\n",
      "n_try = 32\taction = 1\treward = 100\trwd20 = 911\tq = [  1. 100.]\n",
      "n_try = 33\taction = 1\treward = 100\trwd20 = 911\tq = [  1. 100.]\n",
      "n_try = 34\taction = 1\treward = 100\trwd20 = 911\tq = [  1. 100.]\n",
      "n_try = 35\taction = 1\treward = 100\trwd20 = 911\tq = [  1. 100.]\n",
      "n_try = 36\taction = 1\treward = 100\trwd20 = 1010\tq = [  1. 100.]\n",
      "n_try = 37\taction = 1\treward = 100\trwd20 = 1109\tq = [  1. 100.]\n",
      "n_try = 38\taction = 1\treward = 100\trwd20 = 1208\tq = [  1. 100.]\n",
      "n_try = 39\taction = 1\treward = 100\trwd20 = 1208\tq = [  1. 100.]\n",
      "n_try = 40\taction = 1\treward = 100\trwd20 = 1307\tq = [  1. 100.]\n",
      "n_try = 41\taction = 1\treward = 100\trwd20 = 1406\tq = [  1. 100.]\n",
      "n_try = 42\taction = 1\treward = 100\trwd20 = 1406\tq = [  1. 100.]\n",
      "n_try = 43\taction = 1\treward = 100\trwd20 = 1505\tq = [  1. 100.]\n",
      "n_try = 44\taction = 1\treward = 100\trwd20 = 1604\tq = [  1. 100.]\n",
      "n_try = 45\taction = 1\treward = 100\trwd20 = 1703\tq = [  1. 100.]\n",
      "n_try = 46\taction = 1\treward = 100\trwd20 = 1703\tq = [  1. 100.]\n",
      "n_try = 47\taction = 1\treward = 100\trwd20 = 1703\tq = [  1. 100.]\n",
      "n_try = 48\taction = 1\treward = 100\trwd20 = 1802\tq = [  1. 100.]\n",
      "n_try = 49\taction = 1\treward = 100\trwd20 = 1901\tq = [  1. 100.]\n"
     ]
    }
   ],
   "source": [
    "env = Bandit()\n",
    "agent = Agent()\n",
    "for i in range(60):\n",
    "    ## 본질적인 코드\n",
    "    # step1: agent >> env \n",
    "    agent.act()\n",
    "    env.agent_action = agent.action \n",
    "    # step2: agnet << env \n",
    "    agent.reward = env.step(env.agent_action) \n",
    "    agent.save_experience()\n",
    "    # step3: learn\n",
    "    agent.learn()\n",
    "    \n",
    "    ## 비본질적 코드 \n",
    "    print(\n",
    "        f\"n_try = {agent.n_experiences}\\t\"\n",
    "        f\"action = {agent.action}\\t\"\n",
    "        f\"reward = {agent.reward}\\t\"\n",
    "        f\"rwd20 = {np.sum(agent.rewards[-20:])}\\t\"\n",
    "        f\"q = {agent.q}\"\n",
    "    )\n",
    "    if np.sum(agent.rewards[-20:])>1900:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
